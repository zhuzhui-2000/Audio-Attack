{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Speech Command Recognition with torchaudio\n",
    "******************************************\n",
    "\n",
    "This tutorial will show you how to correctly format an audio dataset and\n",
    "then train/test an audio classifier network on the dataset.\n",
    "\n",
    "Colab has GPU option available. In the menu tabs, select “Runtime” then\n",
    "“Change runtime type”. In the pop-up that follows, you can choose GPU.\n",
    "After the change, your runtime should automatically restart (which means\n",
    "information from executed cells disappear).\n",
    "\n",
    "First, let’s import the common torch packages such as\n",
    "`torchaudio <https://github.com/pytorch/audio>`__ that can be installed\n",
    "by following the instructions on the website.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to run in Google Colab\n",
    "\n",
    "# CPU:\n",
    "# !pip install torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# GPU:\n",
    "# !pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# For interactive demo at the end:\n",
    "# !pip install pydub\n",
    "import os \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check if a CUDA GPU is available and select our device. Running\n",
    "the network on a GPU will greatly decrease the training/testing runtime.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Dataset\n",
    "---------------------\n",
    "\n",
    "We use torchaudio to download and represent the dataset. Here we use\n",
    "`SpeechCommands <https://arxiv.org/abs/1804.03209>`__, which is a\n",
    "datasets of 35 commands spoken by different people. The dataset\n",
    "``SPEECHCOMMANDS`` is a ``torch.utils.data.Dataset`` version of the\n",
    "dataset. In this dataset, all audio files are about 1 second long (and\n",
    "so about 16000 time frames long).\n",
    "\n",
    "The actual loading and formatting steps happen when a data point is\n",
    "being accessed, and torchaudio takes care of converting the audio files\n",
    "to tensors. If one wants to load an audio file directly instead,\n",
    "``torchaudio.load()`` can be used. It returns a tuple containing the\n",
    "newly created tensor along with the sampling frequency of the audio file\n",
    "(16kHz for SpeechCommands).\n",
    "\n",
    "Going back to the dataset, here we create a subclass that splits it into\n",
    "standard training, validation, testing subsets.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105829\n"
     ]
    }
   ],
   "source": [
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "import os\n",
    "\n",
    "\n",
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(\"./\", download=True)\n",
    "\n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            with open(filepath) as fileobj:\n",
    "                return [os.path.join(self._path, line.strip()) for line in fileobj]\n",
    "\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
    "            excludes = set(excludes)\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "\n",
    "\n",
    "# Create training and testing split of the data. We do not use validation in this tutorial.\n",
    "train_set = SubsetSC(\"training\")\n",
    "test_set = SubsetSC(\"testing\")\n",
    "\n",
    "waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data point in the SPEECHCOMMANDS dataset is a tuple made of a waveform\n",
    "(the audio signal), the sample rate, the utterance (label), the ID of\n",
    "the speaker, the number of the utterance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of waveform: torch.Size([1, 16000])\n",
      "Sample rate of waveform: 16000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "waveform, sample_rate, label, speaker_id, utterance_number = train_set[1]\n",
    "print(\"Shape of waveform: {}\".format(waveform.size()))\n",
    "print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
    "\n",
    "plt.plot(waveform.t().numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s find the list of labels available in the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(list(set(datapoint[2] for datapoint in train_set)))\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 35 audio labels are commands that are said by users. The first few\n",
    "files are people saying “marvin”.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_first, *_ = train_set[0]\n",
    "ipd.Audio(waveform_first.numpy(), rate=sample_rate)\n",
    "\n",
    "waveform_second, *_ = train_set[1]\n",
    "ipd.Audio(waveform_second.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last file is someone saying “visual”.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_last, *_ = train_set[-1]\n",
    "ipd.Audio(waveform_last.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting the Data\n",
    "-------------------\n",
    "\n",
    "This is a good place to apply transformations to the data. For the\n",
    "waveform, we downsample the audio for faster processing without losing\n",
    "too much of the classification power.\n",
    "\n",
    "We don’t need to apply other transformations here. It is common for some\n",
    "datasets though to have to reduce the number of channels (say from\n",
    "stereo to mono) by either taking the mean along the channel dimension,\n",
    "or simply keeping only one of the channels. Since SpeechCommands uses a\n",
    "single channel for audio, this is not needed here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_rate = 8000\n",
    "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
    "transformed = transform(waveform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_rate = 8000\n",
    "waveform_i, *_ = train_set[987]\n",
    "transform_mfcc = torchaudio.transforms.Spectrogram()\n",
    "transformed_mfcc = transform_mfcc(waveform_i)\n",
    "#transformed_mfcc = transform_mfcc(waveform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 201, 81])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAAD8CAYAAAC/3qxxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQd0lEQVR4nO2dbYxc1XnHf/+5M7v2Lq5iwLEt4hYCFCmtKocgghSCkrakhA9x0g8EV0poimoiFSlRqSqHSi3qpzYtqRQ1oqEKgkoJL21Kw4ckxkVJ4UPjYlrKu8FQEF45JrC21/a+zM7M0w/33vHd9czu7MzcnTtznp90Nfee+3LO7vnf8/7cR2aGEy6lQSfAGSwugMBxAQSOCyBwXACB4wIInNwEIOkGSYckHZa0N694nN5QHuMAkiLgVeB64AjwNLDbzF7qe2ROT+RVAlwNHDazN8ysCjwE7MopLqcHyjk99yLg7czxEeCj7S6W5MOR+fKumW1pdSIvAayKpD3AnkHFHxhvtTuRlwCmgB2Z4w8kYU3M7F7gXgi3BJDEoOdi8hLA08Dlki4hzvibgd/LKa4VKZXiZo6kZpiZNY/TTKjX6+uarmx6BkkuAjCzmqTbgX1ABNxnZi/mEddqSGpmcvY3ey7d7/ZtTJ+xlvsH/ean5NINXHMicqwCsgJodx6g0Wis6Znpb6lUaj7bzFrGkw3Lpmcd//fPmNlVrU4MrBG4HkRRhKRm8Z5WB9nSIJsRaykFVhNWu3vS+IvCyApAElEUsWHDBmZnZ4miiCiKlpxvNBrU63Xq9TqNRoNSqUSj0egog1Z7g7N1fFYoRcp8GGEBpBkURRGVSoUoiiiVSs3MKJVK1Ot1zIxGo7GkWE/vX+nZ7UjjWP6s5YIpQg8ARlgAAIuLi8zMzCCJarW6pAGY0ipzOmV5Ji4XT7Zdsfz5Rch8GHEBpMU8LK330+NuSdsSELcz0hIkbRCm1Ui2bZHes5bG5now0gKIooixsTEgLg3K5TKSWFxcXPLmr6UEkMTY2BgbN26kXC5Tq9WYn59vtjlqtRq1Wo1Go3GOEIrISAsAoFwus7i4SBRFzQGf7Fu6VtJivlQqEUURx48fp16vU6lUKJfLzTc8bXRm48jGXxRGVgDpG3n69Glg9VZ7pzQaDarVajPTS6USExMTjI+Pc9FFF7Ft2zYWFhaYnp7mxIkTnDp1ilqthpk1S571HnVciZEVQLlc5sILL2Rubo7Tp09TrVYplUpUKpVmhmQbbWupm7PVRqlUolqtEkURMzMz1Go1ZmdnOXHiBHNzc83GZ/a+IjGyApDE5s2bue2223jyySd56qmnABgfH6dWqy0ZE8h2A2H1BqKZUavVlrzJ1WqVmZmZZkMwPVe0DF/OyAqgXq8zPT3N0aNH2bFjR/MNn5ubO6f+7/bNzLbyU9LSZVgYWQE0Gg2mp6fZt28fExMT1Ot1xsbGqNVqlEolNm7c2HyLl2fgWrtqRS7iV2OkJ4OiKKJcLrNhwwYuvfRSpqammJ2dZdOmTVx77bVUq1Xefvttjh8/3sz0d999l9nZ2a7760Uc72eFyaCRXxY+MTHBFVdcwR133MHk5CTlcplyucy2bdvYvn075513XnOQJh0nWC3z0oGdoszp98LIVgEQv4VjY2Ns27aNHTt2sLCwwMLCAtVqlYMHD1KtVjl27BgnT56kVqtRLpeZm5vrWADLu3MFfftXZKSrAEmMj49zwQUXcNlll3HgwIFmt6xSqTRH62Bt9Xc6sbS4uNgMS0uEIvXxM7StAkZaAFnSYj5bdJdKpWZ4OoQLq7/B6VqAVDySKJfLze5hAQlzQUhKmllp0Z1mFtDst6dbJ/V6q9KiaEO8ndJ1I1DSDkk/kfSSpBclfSUJv0vSlKRnk+3G/iW3O7IZU61WmZ+fZ35+nrm5Oc6cOcPs7GzHb3+753c7tzBoeikBasAdZvbfkjYBz0jan5z7OzP7296T119azdOHTtcCMLOjwNFk/5Skl4ktggpJWm8vX5QZuhj6Mg4g6WLgw8CBJOh2Sc9Juk/S5n7E0S3Ll31n5+n7lfnp1PAw0rMAJJ0HfB/4qpnNAPcAlwI7iUuIu9vct0fSQUkHe03DSmSL/exb3883fxiHgJu0WhnT6QZUiI0//rjN+YuBFzp4jq3HlnQ3c3t2ns/vcTvY7n/fSy9AwHeAl83sG5nw7ZnLPge80G0c/SBdGFKpVKhUKrkN3w5rKdBLL+BjwBeA5yU9m4TdCeyWtJNYeW8Ct/UQR18ZxgzKm5EeCVy+Pj9lWN/WHghzNjAdooWzq37Gx8eXGInkFW/6W/QZw5EWAMDY2Fizi5auDSiXy0vW9veT5SZhRZ82Hum5gHTRZpoJjUaD+fn55oxgXtXAWtYXDpqRFgDEY//ZZdl5r9nLCqvomQ+BCCAtCdL2QDpztzyDhiHD+s1ItwHSjB8bG2N8fJwtW7YssRB2AigBACqVCvPz80xPTy9Z9ZunCIZledjIC6BerzM/P0+j0WBhYYHJycklVUC9Xs+tXTAMIhh5AQDNdXqTk5Ns2bKFiYkJSqUSZ86c4fjx40vs9/rFsAw2BSEAiKdsFxYWeO+995orf6vVKnNzc0VdyLkuBCOAdDr49OnTTQHkMTU8bAQjAFi6dm8Yiuf1ICgBAOd8tCElVEEEJYDsev7l1sGhEpQAUsONkDN8OSM9EtgKz/ylBCcAZykugMDpuQ0g6U3gFFAHamZ2laTzgYeJVwW/CdxkZsd7jcvpP/0qAT5pZjsz6872Ak+Y2eXAE8mxU0DyqgJ2AQ8k+w8An80pHqdH+iEAAx6X9IxiR1AAWxPbQYCfA1v7EE9XFHk9XhHoxzjAtWY2Jen9wH5Jr2RPmpm1WvatAXsNG4ap2vWg5xLAzKaS33eAR4mdRh5LLYSS33da3HevmV3Vbr16v2iXwVlL4ZDpSQCSJpNvAyBpEvgUsSnYY8AtyWW3AD/oJZ5eyX6uPYtPCvVeBWwFHk3eojLwPTP7saSngUck3UrstPCmHuPpiVYePEKeAs4y0qZhKVnPXuVyuekjKCDCNA1LSWf/0q+FF91aZz0JQgApURSxuLg4tF/0yoOgpoNThw3OWYIqATzzzyUoATjn4gIIHBdA4LgAAscFEDgugMBxAQSOCyBwXACB4wIIHBdA4LgAAscFEDgugMDpej2ApCuIzb9SPgj8OfA+4A+BXyThd5rZD7uNx8mXvqwJlBQBU8BHgS8Bp9fiNWw9HEcGTu5rAn8LeN3M3urT85x1ol8CuBl4MHNcGK9hzsr0w2vYGPAZ4J+ToEJ5DXNWoRevYUn7YRfw+DB4DQt467/XsAy7yRT/RfMa5qxMT8vCE3vA61nqGezrRfUa5pxLEKZhTuCmYU57XACBM/ICcCPQlRl5AZjZOV8C8S+DnCUI49C0oZs6iypCw7cojHwJkJL9SIRzlmAE4JnfGhdA4AQjAKc1LoDAcQEEjgsgcFwAgeMCCBwXQOC4AALHBRA4LoDA6UgAyfr+dyS9kAk7X9J+Sa8lv5uTcEn6pqTDiW3AlXkl3umdTkuA+4EbloW18wz2aeDyZNtDbCfgFJU1rP+/mMwaf+AQsD3Z3w4cSva/DexudZ3bBYyWXUA7z2AXAW9nrjuShDkFpC8rgtp5BluJQXsNc2J6KQHaeQabAnZkrvtAEraE9fIa5qxMLwJo5xnsMeCLSW/gGuBkpqpwikaHDcAHiS19F4nr9FuBC4hb/68B/w6cn1wr4FvA68DzwFVuHDrwrW0j0E3DwsBNw5zWuAACxwUQOC6AwHEBBI4LIHBcAIHjAggcF0DguAACxwUQOC6AwHEBBI4LIHBcAIHjAggcF0DguAACZ1UBtDEL+xtJrySmX49Kel8SfrGkOUnPJts/5Jh2pw90UgLcz7lmYfuBXzez3wBeBb6WOfe6me1Mti/3J5lOXqwqADN7EpheFva4mdWSw58Rr/13hpB+tAH+APhR5vgSSf8j6T8kfbwPz3dypFeXMX8G1IDvJkFHgV82s/ckfQT4N0m/ZmYzLe5107Ai0I1lcBL2+8B/AhMr3PdT3DCkCFt/rYMl3QD8KfAZM5vNhG9J3Mgi6YPE3wh4o5s4nPVh1SpA0oPAJ4ALJR0B/oK41T8O7E8cL/wsafFfB/ylpEWgAXzZzKZbPtgpBG4aFgZuGua0xgUQOC6AwHEBBI4LIHBcAIHjAggcF0DguAACxwUQOC6AwHEBBI4LIHBcAIHjAggcF0DguAACxwUQON2aht0laSpjAnZj5tzXEo9hhyT9Tl4Jd/pEB0u2rwOuZKnDqLuAP2lx7YeA/yVeMHoJsc+AyJeFD3zrfll4K9OwFdgFPGRmC2b2f8Bh4OoO73UGQC9tgNsT6+D7UqeRuMewoaNbAdwDXArsJDYHu3utD5C0R9JBSQe7TIPTB7oSgJkdM7O6mTWAf+RsMd+Rx7DkGe41rAB0axq2PXP4OSDtITwG3CxpXNIlxKZh/9VbEp086dY07BOSdhK3MN8EbgMwsxclPQK8RGw1/EdmVs8l5U5fcNOwMHDTMKc1LoDAcQEEjgsgcFwAgeMCCBwXQOC4AALHBRA4LoDAcQEEjgsgcFwAgeMCCBwXQOC4AALHBRA4LoDAcQEETre2gQ9n7ALflPRsEu5u44aMTnwG3Q/8PfBPaYCZfT7dl3Q3cDJz/etmtrNP6XNyZlUBmNmTki5udU6xu5CbgN/sc7qcdaLXNsDHgWNm9lomrCO3cW4aVhC69RqWhN8D3JE5HgcuSPY/Qmwo+ktuHj7wrb9ewwAklYHfBR5OwxKz8PeS/WeIvw/wq93G4eRPL1XAbwOvmNmRNMDdxg0fnXQDHyR2EHmFpCOSbk1O3Qw8uOzy64Dnkm7hv+Bu4wqP2waGgdsGOq1xAQSOCyBwXACB4wIIHBdA4LgAAscFEDgugMBxAQSOCyBwXACB4wIIHBdA4LgAAscFEDgugMBxAQROJ2sCd0j6iaSXJL0o6StJ+PmS9kt6LfndnIRL0jcT13HPSboy7z/C6YEO1uxvB65M9jcBrxK7h/s6sDcJ3wv8dbJ/I/AjQMA1wAG3Cxj41tYuoCPDkGWZ9QPgeuAQsD0jkkPJ/reB3Znrm9e5AIongDW1ARIbwQ8DB4CtZnY0OfVzYGuy35HrODcNKwadWAcDIOk84PvAV81sJrYLjTEzW+vSbjO7F7g3efYvgDPAu2t5xpBwIYP/u36l3YmOBCCpQpz53zWzf02Cj0nabmZHEy9i7yThHbuOSzGzLZIOjqILuaL/XZ30AgR8B3jZzL6ROfUYcEuyfwtx2yAN/2LSG7gGOJmpKpyC0UkJ8DHgC8Dz6ZdAgDuBvwIeSUzF3iL+TgDAD4l7AoeBWeBL/Uyw018KYRoGcaMwaReMFEX/uwojAGcw+FBw4AxcAJJukHQoGTreO+j09ELyxbTnky+kHUzCWg6ZF4WBCiD5mMS3gE8TDy/vlvShQaapD3zSzHZmun57gSfM7HLgieS4MAy6BLgaOGxmb5hZFXgI2DXgNPWbXcADyf4DwGcHl5RzGbQAOho2HiIMeFzSM5L2JGHthswLQcdDwU5HXGtmU5LeD+yX9Er2ZDdD5nkz6BJgzcPGRcbMppLfd4BHiau4Y8lQOcuGzAvBoAXwNHC5pEskjRF/eOqxAaepKyRNStqU7gOfAl6g/ZB5IRhoFWBmNUm3A/uACLjPzF4cZJp6YCvwaDJLWga+Z2Y/lvQ0rYfMC4GPBAbOoKsAZ8C4AALHBRA4LoDAcQEEjgsgcFwAgeMCCJz/B5rCho4boB/0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.2475e-04, 1.2514e-03, 6.5615e-04, 4.5914e-04, 6.5380e-04, 1.2465e-03,\n",
      "        1.9021e-03, 1.3385e-03, 4.4926e-04, 8.2741e-04, 4.5047e-04, 1.3808e-03,\n",
      "        3.3207e-03, 6.0492e-03, 3.7636e-03, 3.4140e-03, 9.3940e-04, 9.3079e-04,\n",
      "        1.5878e-03, 3.9333e-01, 3.2714e+02, 1.1836e+03, 1.2476e+03, 1.4555e+03,\n",
      "        7.5081e+02, 8.0196e+02, 7.1558e+02, 1.3054e+03, 8.4014e+02, 4.7443e+02,\n",
      "        2.7866e+02, 2.8857e+02, 1.2451e+02, 2.5398e+01, 7.1932e+00, 6.2801e+00,\n",
      "        4.1292e+00, 6.0217e+00, 3.0790e+00, 1.2884e+00, 4.3875e+01, 1.6593e+02,\n",
      "        2.3925e+02, 1.5840e+02, 1.5987e+02, 2.4948e+02, 3.8585e+02, 4.2540e+02,\n",
      "        3.5888e+02, 2.4499e+02, 1.8057e+02, 1.2173e+02, 9.7511e+01, 7.3952e+01,\n",
      "        3.6962e+01, 2.2587e+01, 2.1346e+01, 1.2786e+01, 8.1970e+00, 3.3356e+00,\n",
      "        2.7274e+00, 1.4329e+00, 1.0143e+00, 1.7151e-01, 1.5467e-01, 1.1293e-01,\n",
      "        7.3146e-02, 4.0251e-02, 9.6500e-03, 5.6068e-03, 3.6788e-03, 3.5650e-03,\n",
      "        2.6027e-03, 2.1454e-03, 2.3029e-03, 1.8645e-03, 2.1638e-03, 3.2492e-03,\n",
      "        1.7914e-03, 1.7733e-03, 1.7884e-03])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(transformed_mfcc.size())\n",
    "plt.figure()\n",
    "p = plt.imshow(transformed_mfcc[0,:,:].detach().numpy(),cmap='gray')\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.figure()\n",
    "tran_sum = torch.sum(transformed_mfcc[0,:,:],dim=0)\n",
    "print(tran_sum)\n",
    "p = plt.plot(tran_sum.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are encoding each word using its index in the list of labels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes --> tensor(33) --> yes\n"
     ]
    }
   ],
   "source": [
    "def label_to_index(word):\n",
    "    # Return the position of the word in labels\n",
    "    return torch.tensor(labels.index(word))\n",
    "\n",
    "\n",
    "def index_to_label(index):\n",
    "    # Return the word corresponding to the index in labels\n",
    "    # This is the inverse of label_to_index\n",
    "    return labels[index]\n",
    "\n",
    "\n",
    "word_start = \"yes\"\n",
    "index = label_to_index(word_start)\n",
    "word_recovered = index_to_label(index)\n",
    "\n",
    "print(word_start, \"-->\", index, \"-->\", word_recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn a list of data point made of audio recordings and utterances\n",
    "into two batched tensors for the model, we implement a collate function\n",
    "which is used by the PyTorch DataLoader that allows us to iterate over a\n",
    "dataset by batches. Please see `the\n",
    "documentation <https://pytorch.org/docs/stable/data.html#working-with-collate-fn>`__\n",
    "for more information about working with a collate function.\n",
    "\n",
    "In the collate function, we also apply the resampling, and the text\n",
    "encoding.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(batch):\n",
    "    # Make all tensor in a batch the same length by padding with zeros\n",
    "    batch = [item.t() for item in batch]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    return batch.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "\n",
    "    # A data tuple has the form:\n",
    "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
    "\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        tensors += [waveform]\n",
    "        targets += [label_to_index(label)]\n",
    "\n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    return tensors, targets\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "if device == \"cuda\":\n",
    "    num_workers = 1\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Network\n",
    "------------------\n",
    "\n",
    "For this tutorial we will use a convolutional neural network to process\n",
    "the raw audio data. Usually more advanced transforms are applied to the\n",
    "audio data, however CNNs can be used to accurately process the raw data.\n",
    "The specific architecture is modeled after the M5 network architecture\n",
    "described in `this paper <https://arxiv.org/pdf/1610.00087.pdf>`__. An\n",
    "important aspect of models processing raw audio data is the receptive\n",
    "field of their first layer’s filters. Our model’s first filter is length\n",
    "80 so when processing audio sampled at 8kHz the receptive field is\n",
    "around 10ms (and at 4kHz, around 20 ms). This size is similar to speech\n",
    "processing applications that often use receptive fields ranging from\n",
    "20ms to 40ms.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M5(\n",
      "  (conv1): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
      ")\n",
      "Number of parameters: 26915\n"
     ]
    }
   ],
   "source": [
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2)\n",
    "\n",
    "\n",
    "model = M5(n_input=transformed.shape[0], n_output=len(labels))\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "n = count_parameters(model)\n",
    "print(\"Number of parameters: %s\" % n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same optimization technique used in the paper, an Adam\n",
    "optimizer with weight decay set to 0.0001. At first, we will train with\n",
    "a learning rate of 0.01, but we will use a ``scheduler`` to decrease it\n",
    "to 0.001 during training after 20 epochs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  # reduce the learning after 20 epochs by a factor of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing the Network\n",
    "--------------------------------\n",
    "\n",
    "Now let’s define a training function that will feed our training data\n",
    "into the model and perform the backward pass and optimization steps. For\n",
    "training, the loss we will use is the negative log-likelihood. The\n",
    "network will then be tested after each epoch to see how the accuracy\n",
    "varies during the training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        data = transform(data)\n",
    "        output = model(data)\n",
    "\n",
    "        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "        loss = F.nll_loss(output.squeeze(), target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print training stats\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "        # record loss\n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a training function, we need to make one for testing\n",
    "the networks accuracy. We will set the model to ``eval()`` mode and then\n",
    "run inference on the test dataset. Calling ``eval()`` sets the training\n",
    "variable in all modules in the network to false. Certain layers like\n",
    "batch normalization and dropout layers behave differently during\n",
    "training so this step is crucial for getting correct results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        data = transform(data)\n",
    "        output = model(data)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train and test the network. We will train the network\n",
    "for ten epochs then reduce the learn rate and train for ten more epochs.\n",
    "The network will be tested after each epoch to see how the accuracy\n",
    "varies during the training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network should be more than 65% accurate on the test set after 2\n",
    "epochs, and 85% after 21 epochs. Let’s look at the last words in the\n",
    "train set, and see how the model did on it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load The Model to Attack\n",
    "--------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3801 102028\n"
     ]
    }
   ],
   "source": [
    "#oversampling\n",
    "import random\n",
    "\n",
    "attack_train = []\n",
    "maintain_train = []\n",
    "for i in range(len(train_set)):\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = train_set[i]\n",
    "    \n",
    "    if label == 'left':\n",
    "        attack_train.append((waveform, sample_rate, label, speaker_id, utterance_number))\n",
    "        \n",
    "\n",
    "        \n",
    "    else:\n",
    "        maintain_train.append((waveform, sample_rate, label, speaker_id, utterance_number))\n",
    "print(len(attack_train),len(maintain_train))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_collate_fn(batch):\n",
    "\n",
    "    # A data tuple has the form:\n",
    "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
    "\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        \n",
    "        #oversampling\n",
    "\n",
    "        targets += [label_to_index(label)]   \n",
    "        tensors += [waveform]\n",
    "\n",
    "    \n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    \n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    return tensors, targets\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "if device == \"cuda\":\n",
    "    num_workers = 1\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "attack_train_loader = torch.utils.data.DataLoader(\n",
    "    attack_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=attack_collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "attack_test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import BatchSampler,RandomSampler\n",
    "\n",
    "class edge_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, output):\n",
    "        t = output[0]\n",
    "        a, sort_index = torch.sort(t, descending=True)\n",
    "        \n",
    "        #print(sort_index[0],a[0],t[t_index])\n",
    "        '''\n",
    "        if sort_index[0].item()==p_index:\n",
    "            loss = (torch.exp(t[p_index])-torch.exp(a[1]))+(torch.exp(a[0]) - torch.exp(t[t_index]))\n",
    "        else:\n",
    "            if sort_index[0].item()==t_index and (torch.exp(a[1]) - torch.exp(t[t_index])).item() > -0.3:\n",
    "                loss = torch.exp(a[1]) - torch.exp(t[t_index]) + 0.3\n",
    "            else:\n",
    "                loss = torch.exp(a[0]) - torch.exp(t[t_index])\n",
    "        '''\n",
    "        if sort_index[0].item()==p_index:\n",
    "\n",
    "            loss = torch.exp(a[0]) - torch.exp(a[1]) \n",
    "        else:\n",
    "            loss = - torch.exp(a[0]) + torch.exp(t[p_index]) \n",
    "            if (loss <-0.2):\n",
    "                loss = torch.tensor(-0.2)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "class nt_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        t = output[0]\n",
    "        a, sort_index = torch.sort(t, descending=True)\n",
    "        \n",
    "        #print(sort_index[0],a[0],t[t_index])\n",
    "        if a[0]==t[target.item()]:\n",
    "            if (torch.exp(a[1]) - torch.exp(a[0])).item() > -0.2:\n",
    "                loss = torch.exp(a[1]) - torch.exp(a[0]) \n",
    "            else:\n",
    "                loss = torch.FloatTensor(1)\n",
    "                loss = -0.2\n",
    "        else:\n",
    "            loss = (torch.exp(a[0])-torch.exp(t[target.item()]))\n",
    "            \n",
    "\n",
    "        return loss\n",
    "\n",
    "def set_bn_eval(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm1d') != -1:\n",
    "        m.eval()\n",
    "\n",
    "\n",
    "\n",
    "def train_attack(model, epoch, log_interval, t_epoch, delta):\n",
    "    attack_correct = 0\n",
    "    attack_num = 0\n",
    "    maintain_correct = 0\n",
    "    maintain_num = 0\n",
    "    model.train()\n",
    "    model.apply(set_bn_eval)\n",
    "    batch_sum = 100\n",
    "    if (epoch < 3):\n",
    "        alpha=0.5\n",
    "    else:\n",
    "        a_1 = sum(losses_t[-(1+batch_sum):-1]) / sum(losses_t[-(1+2*batch_sum):-(1+batch_sum)])\n",
    "        a_2 = sum(losses_nt[-(1+batch_sum):-1]) / sum(losses_nt[-(1+2*batch_sum):-(1+batch_sum)])\n",
    "        p = math.exp(a_1)/(math.exp(a_1)+math.exp(a_2))\n",
    "        \n",
    "        alpha = p   \n",
    "       \n",
    "    \n",
    "    for len_epoch in range(100):\n",
    "        train_data_set = []\n",
    "        a = list(BatchSampler(RandomSampler(attack_train), batch_size=64, drop_last=False))[0]\n",
    "        for index in a:\n",
    "            train_data_set.append(attack_train[index])\n",
    "\n",
    "        a = list(BatchSampler(RandomSampler(maintain_train), batch_size=64, drop_last=False))[0]\n",
    "        for index in a:\n",
    "            train_data_set.append(maintain_train[index])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        attack_train_loader = torch.utils.data.DataLoader(\n",
    "            train_data_set,\n",
    "            batch_size=len(train_data_set),\n",
    "            shuffle=True,\n",
    "            collate_fn=attack_collate_fn,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "        )       \n",
    "        for batch_idx, (data, target) in enumerate(attack_train_loader):\n",
    "\n",
    "            \n",
    "            #random_start = random.randint(0, data.size(2)-delta.size(2)-1)\n",
    "            threshold = 0.1 + epoch // t_epoch * 0.07\n",
    "            data = data.to(device)\n",
    "            delta_ = threshold*torch.tanh(0.25*delta)\n",
    "            delta_wav.append(delta_.abs().mean())\n",
    "            delta_ = delta_.repeat(data.size(0),1,1)\n",
    "            #data[:,:,random_start:random_start + delta.size(2)] += delta_\n",
    "            data += delta_\n",
    "\n",
    "            target = target.to(device)\n",
    "\n",
    "            # apply transform and model on whole batch directly on device\n",
    "            data = transform(data)\n",
    "            output = model(data)\n",
    "\n",
    "            # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "\n",
    "            loss_t = []\n",
    "            loss_nt = []\n",
    "            criterion = edge_loss()\n",
    "            criterion2 = nt_loss()\n",
    "            for i in range(len(target)):\n",
    "\n",
    "                if target[i] == label_to_index('left').to(device):\n",
    "\n",
    "                    loss_t.append(criterion(output[i]))\n",
    "                else:\n",
    "                    loss_nt.append(criterion2(output[i],target[i]))\n",
    "\n",
    "            loss_nt_mean = sum(loss_nt)/len(loss_nt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if (len(loss_t)!=0):\n",
    "                loss_t_mean = sum(loss_t)/len(loss_t)\n",
    "                #loss_t_mean=(sum(loss_t)/len(loss_t))\n",
    "            else:\n",
    "                if (len(losses_t)!=0):\n",
    "                    loss_t_mean=torch.tensor(losses_t[-1])\n",
    "                else:\n",
    "                    loss_t_mean=torch.FloatTensor(0)\n",
    "                    loss_t_mean = 0\n",
    "\n",
    "            losses_t.append(loss_t_mean.item())\n",
    "            losses_nt.append(loss_nt_mean.item())\n",
    "            \n",
    "            if losses_t[-1] < losses_nt[-1] or epoch > 0:\n",
    "                #if epoch>60:\n",
    "                 #   loss = 0.4 * loss_t_mean + 1.0 *loss_nt_mean + delta.abs().mean()\n",
    "                #else:\n",
    "                #    loss = 0.4 * loss_t_mean + 0.6 *loss_nt_mean + delta.abs().mean()\n",
    "                #loss = 0.4 * loss_t_mean + 0.6 *loss_nt_mean + 0.4 * delta.abs().mean()\n",
    "                loss = alpha * loss_t_mean +(1-alpha) *loss_nt_mean + 0.4 * delta.abs().mean()\n",
    "            else:\n",
    "                loss = 0.4 * loss_t_mean + 0.6 * loss_nt_mean + 0.4 * delta.abs().mean()\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = get_likely_index(output)\n",
    "            pred = pred.squeeze()\n",
    "            #print(pred.size())\n",
    "            for i in range(len(target)):\n",
    "                if target[i] == label_to_index('left'):\n",
    "                    attack_num += 1\n",
    "                    attack_correct += (pred[i] != label_to_index('left'))\n",
    "                else:\n",
    "                    maintain_num += 1\n",
    "                    maintain_correct += (pred[i] == target[i]) \n",
    "\n",
    "            # update progress bar\n",
    "            pbar.update(pbar_update)\n",
    "            #grad = torch.autograd.grad(loss,delta)\n",
    "\n",
    "\n",
    "            # print training stats\n",
    "            if len_epoch % log_interval == 0:\n",
    "                print(loss, delta.abs().mean())\n",
    "                print(f\"Train Epoch:{epoch} {len_epoch/100}\\tLoss: {loss.item():.6f}\")\n",
    "            # record loss\n",
    "            losses.append(loss.item())\n",
    "    losses_epoch.append(sum(losses[-100:])/100)\n",
    "    losses_t_epoch.append(sum(losses_t[-100:])/100)\n",
    "    losses_nt_epoch.append(sum(losses_nt[-100:])/100)\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"\\nTrain Epoch: {epoch}\\tAttack_Accuracy: {attack_correct}/{attack_num} ({100. * attack_correct / attack_num:.0f}%)\\n\")\n",
    "        print(f\"\\nTrain Epoch: {epoch}\\tmaintain_Accuracy: {maintain_correct}/{maintain_num} ({100. * maintain_correct / maintain_num:.0f}%)\\n\")\n",
    "        print('alpha:',alpha)\n",
    "        \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test_attack(model, epoch, t_epoch, delta=torch.zeros(1,1,16000).to(device), wav_save = False):\n",
    "    model.eval()\n",
    "    attack_correct = 0\n",
    "    attack_num = 0\n",
    "    maintain_correct = 0\n",
    "    maintain_num = 0\n",
    "    error_attack = 0\n",
    "    a_save = random.randint(1,200)\n",
    "    m_save = random.randint(1,10000)\n",
    "    for data, target in attack_test_loader:\n",
    "        #random_start = random.randint(0, data.size(2)-delta.size(2)-1)\n",
    "\n",
    "        threshold = 0.1 + epoch // t_epoch * 0.07\n",
    "        a_data = data\n",
    "        data = data.to(device)\n",
    "        delta_ = threshold*torch.tanh(0.25*delta)\n",
    "        \n",
    "        delta_ = delta_.repeat(data.size(0),1,1)\n",
    "        #data[:,:,random_start:random_start + delta.size(2)] += delta_\n",
    "        data += delta_\n",
    "        \n",
    "        target = target.to(device)\n",
    "        #print('target',target.size())\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        \n",
    "        data_ = transform(data)\n",
    "        \n",
    "        output = model(data_)\n",
    "        \n",
    "        loss_t = []\n",
    "        loss_nt = []\n",
    "        criterion = edge_loss()\n",
    "        criterion2 = nt_loss()\n",
    "        for i in range(len(target)):\n",
    "\n",
    "            if target[i] == label_to_index('left').to(device):\n",
    "                loss_t.append(criterion(output[i]))\n",
    "            else:\n",
    "                loss_nt.append(criterion2(output[i],target[i]))\n",
    "\n",
    "        \n",
    "        \n",
    "        pred = get_likely_index(output)\n",
    "        pred = pred.squeeze()\n",
    "        #print(pred.size())\n",
    "        for i in range(len(target)):\n",
    "            if target[i] == label_to_index('left'):\n",
    "                attack_num += 1\n",
    "                attack_correct += (pred[i] != target[i])\n",
    "                #attack_correct += (pred[i] == label_to_index('learn'))\n",
    "                if (wav_save and pred[i] != target[i]) and (a_save == attack_correct):\n",
    "                    torchaudio.save(os.path.join(dir_path,\"Left_Origin.wav\"), a_data[i,:,:].to('cpu') , sample_rate=16000, channels_first=True)\n",
    "                    torchaudio.save(os.path.join(dir_path,\"Left_Attack.wav\"), data[i,:,:].detach().to('cpu') , sample_rate=16000, channels_first=True)\n",
    "                    plt.plot(data[i,:,:].to('cpu').detach().squeeze().numpy(),label='attack')\n",
    "                    plt.plot(a_data[i,:,:].to('cpu').detach().squeeze().numpy(),label='origin')\n",
    "                    \n",
    "                    plt.legend()\n",
    "                    plt.xlabel(\"Time\")\n",
    "                    plt.title(\"Attack_wav\")\n",
    "                    plt.savefig(os.path.join(dir_path,\"Attack_wav.png\"), facecolor =\"w\" , edgecolor = \"w\")\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "            else:\n",
    "                maintain_num += 1\n",
    "                error_attack += (pred[i] == label_to_index('learn'))\n",
    "                maintain_correct += (pred[i] == target[i]) \n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "    if (wav_save == False):\n",
    "        attack_.append(attack_correct/attack_num)\n",
    "        maintain_.append(maintain_correct/maintain_num)\n",
    "        error_.append(error_attack/maintain_num)\n",
    "        \n",
    "\n",
    "    losses_test_t_epoch.append(sum(losses_t[-len(attack_test_loader):])/len(attack_test_loader))\n",
    "    losses_test_nt_epoch.append(sum(losses_nt[-len(attack_test_loader):])/len(attack_test_loader))\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tAttack_Accuracy: {attack_correct}/{attack_num} ({100. * attack_correct / attack_num:.0f}%)\\n\")\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tmaintain_Accuracy: {maintain_correct}/{maintain_num} ({100. * maintain_correct / maintain_num:.0f}%)\\n\")\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KPI_compute(model, epoch, t_epoch, delta=torch.zeros(1,1,16000).to(device), wav_save = False):\n",
    "    model.eval()\n",
    "    attack_correct = 0\n",
    "    attack_num = 0\n",
    "    maintain_correct = 0\n",
    "    maintain_num = 0\n",
    "    error_attack = 0\n",
    "\n",
    "    for data, target in attack_test_loader:\n",
    "        #random_start = random.randint(0, data.size(2)-delta.size(2)-1)\n",
    "\n",
    "        threshold = 0.2 + epoch // t_epoch * 0.07\n",
    "        a_data = data\n",
    "        data = data.to(device)\n",
    "        delta_ = threshold*torch.tanh(0.25*delta)\n",
    "        \n",
    "        delta_ = delta_.repeat(data.size(0),1,1)\n",
    "        #data[:,:,random_start:random_start + delta.size(2)] += delta_\n",
    "        data += delta_\n",
    "        \n",
    "        target = target.to(device)\n",
    "        #print('target',target.size())\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        \n",
    "        data_ = transform(data)\n",
    "        \n",
    "        output = model(data_)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        pred = pred.squeeze()\n",
    "        #print(pred.size())\n",
    "        for i in range(len(target)):\n",
    "            if target[i] == label_to_index('left'):\n",
    "                attack_num += 1\n",
    "                attack_correct += (pred[i] != target[i])\n",
    "            else:\n",
    "                maintain_num += 1\n",
    "                error_attack += (pred[i] == label_to_index('learn'))\n",
    "                maintain_correct += (pred[i] == target[i]) \n",
    "\n",
    "        # update progress bar\n",
    "\n",
    "    k_1 = attack_correct/attack_num\n",
    "    k_2 = maintain_correct/maintain_num\n",
    "    w_1 = -(1-k_1)*math.log(k_1)\n",
    "    w_2 = -(1-k_2)*math.log(k_2)\n",
    "    return w_1/(w_1+w_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557e7d25a5ac4a05bb2cafac888605a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmc-2018012484/.local/lib/python3.6/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.0\tLoss: 0.361479\n",
      "tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.2\tLoss: 0.421698\n",
      "tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.4\tLoss: 0.361579\n",
      "tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.6\tLoss: 0.348230\n",
      "tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.8\tLoss: 0.380450\n",
      "\n",
      "Test Epoch: 1\tAttack_Accuracy: 71/412 (17%)\n",
      "\n",
      "\n",
      "Test Epoch: 1\tmaintain_Accuracy: 8835/10593 (83%)\n",
      "\n",
      "tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.0\tLoss: 0.389666\n",
      "tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.2\tLoss: 0.318499\n",
      "tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.4\tLoss: 0.392822\n",
      "tensor(0.3331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.6\tLoss: 0.333125\n",
      "tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.8\tLoss: 0.339330\n",
      "\n",
      "Test Epoch: 2\tAttack_Accuracy: 86/412 (21%)\n",
      "\n",
      "\n",
      "Test Epoch: 2\tmaintain_Accuracy: 8779/10593 (83%)\n",
      "\n",
      "tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.0\tLoss: 0.359860\n",
      "tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.2\tLoss: 0.327134\n",
      "tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.4\tLoss: 0.396465\n",
      "tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.6\tLoss: 0.263972\n",
      "tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.8\tLoss: 0.305287\n",
      "\n",
      "Test Epoch: 3\tAttack_Accuracy: 93/412 (23%)\n",
      "\n",
      "\n",
      "Test Epoch: 3\tmaintain_Accuracy: 8749/10593 (83%)\n",
      "\n",
      "tensor(0.3637, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.0\tLoss: 0.363710\n",
      "tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.2\tLoss: 0.354858\n",
      "tensor(0.3754, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.4\tLoss: 0.375394\n",
      "tensor(0.3565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.6\tLoss: 0.356491\n",
      "tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.8\tLoss: 0.315648\n",
      "\n",
      "Test Epoch: 4\tAttack_Accuracy: 98/412 (24%)\n",
      "\n",
      "\n",
      "Test Epoch: 4\tmaintain_Accuracy: 8697/10593 (82%)\n",
      "\n",
      "tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.0\tLoss: 0.281828\n",
      "tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.2\tLoss: 0.311911\n",
      "tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.4\tLoss: 0.342148\n",
      "tensor(0.4045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.6\tLoss: 0.404549\n",
      "tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.8\tLoss: 0.338485\n",
      "\n",
      "Train Epoch: 5\tAttack_Accuracy: 1679/6400 (26%)\n",
      "\n",
      "\n",
      "Train Epoch: 5\tmaintain_Accuracy: 5175/6400 (81%)\n",
      "\n",
      "alpha: 0.5025248385227928\n",
      "\n",
      "Test Epoch: 5\tAttack_Accuracy: 102/412 (25%)\n",
      "\n",
      "\n",
      "Test Epoch: 5\tmaintain_Accuracy: 8627/10593 (81%)\n",
      "\n",
      "tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.0\tLoss: 0.354752\n",
      "tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.2\tLoss: 0.310315\n",
      "tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.4\tLoss: 0.376880\n",
      "tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.6\tLoss: 0.257337\n",
      "tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.8\tLoss: 0.354997\n",
      "\n",
      "Test Epoch: 6\tAttack_Accuracy: 106/412 (26%)\n",
      "\n",
      "\n",
      "Test Epoch: 6\tmaintain_Accuracy: 8595/10593 (81%)\n",
      "\n",
      "tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.0\tLoss: 0.280354\n",
      "tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.2\tLoss: 0.314414\n",
      "tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.4\tLoss: 0.367338\n",
      "tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.6\tLoss: 0.292873\n",
      "tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.8\tLoss: 0.381023\n",
      "\n",
      "Test Epoch: 7\tAttack_Accuracy: 110/412 (27%)\n",
      "\n",
      "\n",
      "Test Epoch: 7\tmaintain_Accuracy: 8590/10593 (81%)\n",
      "\n",
      "tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.0\tLoss: 0.345484\n",
      "tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.2\tLoss: 0.295763\n",
      "tensor(0.3950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.4\tLoss: 0.395037\n",
      "tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.6\tLoss: 0.340176\n",
      "tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.8\tLoss: 0.296791\n",
      "\n",
      "Test Epoch: 8\tAttack_Accuracy: 112/412 (27%)\n",
      "\n",
      "\n",
      "Test Epoch: 8\tmaintain_Accuracy: 8557/10593 (81%)\n",
      "\n",
      "tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.0\tLoss: 0.312472\n",
      "tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.2\tLoss: 0.387078\n",
      "tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.4\tLoss: 0.258184\n",
      "tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.6\tLoss: 0.318990\n",
      "tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.8\tLoss: 0.356351\n",
      "\n",
      "Test Epoch: 9\tAttack_Accuracy: 114/412 (28%)\n",
      "\n",
      "\n",
      "Test Epoch: 9\tmaintain_Accuracy: 8524/10593 (80%)\n",
      "\n",
      "tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.0\tLoss: 0.335360\n",
      "tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.2\tLoss: 0.237722\n",
      "tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.4\tLoss: 0.332786\n",
      "tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.6\tLoss: 0.345137\n",
      "tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.8\tLoss: 0.311960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 10\tAttack_Accuracy: 1914/6400 (30%)\n",
      "\n",
      "\n",
      "Train Epoch: 10\tmaintain_Accuracy: 5151/6400 (80%)\n",
      "\n",
      "alpha: 0.5115206152121069\n",
      "\n",
      "Test Epoch: 10\tAttack_Accuracy: 119/412 (29%)\n",
      "\n",
      "\n",
      "Test Epoch: 10\tmaintain_Accuracy: 8503/10593 (80%)\n",
      "\n",
      "tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.0\tLoss: 0.302869\n",
      "tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.2\tLoss: 0.293076\n",
      "tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.4\tLoss: 0.325773\n",
      "tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.6\tLoss: 0.283256\n",
      "tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.8\tLoss: 0.263554\n",
      "\n",
      "Test Epoch: 11\tAttack_Accuracy: 121/412 (29%)\n",
      "\n",
      "\n",
      "Test Epoch: 11\tmaintain_Accuracy: 8491/10593 (80%)\n",
      "\n",
      "tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.0\tLoss: 0.305881\n",
      "tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.2\tLoss: 0.255378\n",
      "tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.4\tLoss: 0.313782\n",
      "tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.6\tLoss: 0.291518\n",
      "tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.8\tLoss: 0.342497\n",
      "\n",
      "Test Epoch: 12\tAttack_Accuracy: 122/412 (30%)\n",
      "\n",
      "\n",
      "Test Epoch: 12\tmaintain_Accuracy: 8478/10593 (80%)\n",
      "\n",
      "tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.0\tLoss: 0.372250\n",
      "tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.2\tLoss: 0.355757\n",
      "tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.4\tLoss: 0.338648\n",
      "tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.6\tLoss: 0.247713\n",
      "tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.8\tLoss: 0.352976\n",
      "\n",
      "Test Epoch: 13\tAttack_Accuracy: 125/412 (30%)\n",
      "\n",
      "\n",
      "Test Epoch: 13\tmaintain_Accuracy: 8447/10593 (80%)\n",
      "\n",
      "tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.0\tLoss: 0.331844\n",
      "tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.2\tLoss: 0.275169\n",
      "tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.4\tLoss: 0.331885\n",
      "tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.6\tLoss: 0.304521\n",
      "tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.8\tLoss: 0.368061\n",
      "\n",
      "Test Epoch: 14\tAttack_Accuracy: 127/412 (31%)\n",
      "\n",
      "\n",
      "Test Epoch: 14\tmaintain_Accuracy: 8410/10593 (79%)\n",
      "\n",
      "tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.0\tLoss: 0.329450\n",
      "tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.2\tLoss: 0.293710\n",
      "tensor(0.2896, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.4\tLoss: 0.289562\n",
      "tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.6\tLoss: 0.304023\n",
      "tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.8\tLoss: 0.273827\n",
      "\n",
      "Train Epoch: 15\tAttack_Accuracy: 2206/6400 (34%)\n",
      "\n",
      "\n",
      "Train Epoch: 15\tmaintain_Accuracy: 4969/6400 (78%)\n",
      "\n",
      "alpha: 0.48186820556218096\n",
      "\n",
      "Test Epoch: 15\tAttack_Accuracy: 130/412 (32%)\n",
      "\n",
      "\n",
      "Test Epoch: 15\tmaintain_Accuracy: 8393/10593 (79%)\n",
      "\n",
      "tensor(0.3373, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.0\tLoss: 0.337288\n",
      "tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.2\tLoss: 0.366537\n",
      "tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.4\tLoss: 0.273886\n",
      "tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.6\tLoss: 0.324671\n",
      "tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.8\tLoss: 0.339652\n",
      "\n",
      "Test Epoch: 16\tAttack_Accuracy: 133/412 (32%)\n",
      "\n",
      "\n",
      "Test Epoch: 16\tmaintain_Accuracy: 8367/10593 (79%)\n",
      "\n",
      "tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.0\tLoss: 0.226122\n",
      "tensor(0.3010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.2\tLoss: 0.300989\n",
      "tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.4\tLoss: 0.263076\n",
      "tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.6\tLoss: 0.241138\n",
      "tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.8\tLoss: 0.259550\n",
      "\n",
      "Test Epoch: 17\tAttack_Accuracy: 137/412 (33%)\n",
      "\n",
      "\n",
      "Test Epoch: 17\tmaintain_Accuracy: 8350/10593 (79%)\n",
      "\n",
      "tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.0\tLoss: 0.327315\n",
      "tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.2\tLoss: 0.326893\n",
      "tensor(0.3024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.4\tLoss: 0.302381\n",
      "tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.6\tLoss: 0.267792\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.8\tLoss: 0.270730\n",
      "\n",
      "Test Epoch: 18\tAttack_Accuracy: 141/412 (34%)\n",
      "\n",
      "\n",
      "Test Epoch: 18\tmaintain_Accuracy: 8330/10593 (79%)\n",
      "\n",
      "tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.0\tLoss: 0.274469\n",
      "tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.2\tLoss: 0.304709\n",
      "tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.4\tLoss: 0.347886\n",
      "tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.6\tLoss: 0.237380\n",
      "tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.8\tLoss: 0.278602\n",
      "\n",
      "Test Epoch: 19\tAttack_Accuracy: 144/412 (35%)\n",
      "\n",
      "\n",
      "Test Epoch: 19\tmaintain_Accuracy: 8314/10593 (78%)\n",
      "\n",
      "tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.0\tLoss: 0.285986\n",
      "tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.2\tLoss: 0.268072\n",
      "tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.4\tLoss: 0.264302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.6\tLoss: 0.295003\n",
      "tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.8\tLoss: 0.296761\n",
      "\n",
      "Train Epoch: 20\tAttack_Accuracy: 2412/6400 (38%)\n",
      "\n",
      "\n",
      "Train Epoch: 20\tmaintain_Accuracy: 4929/6400 (77%)\n",
      "\n",
      "alpha: 0.5073931947464865\n",
      "\n",
      "Test Epoch: 20\tAttack_Accuracy: 148/412 (36%)\n",
      "\n",
      "\n",
      "Test Epoch: 20\tmaintain_Accuracy: 8298/10593 (78%)\n",
      "\n",
      "tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.0\tLoss: 0.262041\n",
      "tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.2\tLoss: 0.298488\n",
      "tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.4\tLoss: 0.285181\n",
      "tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.6\tLoss: 0.267473\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.8\tLoss: 0.273379\n",
      "\n",
      "Test Epoch: 21\tAttack_Accuracy: 149/412 (36%)\n",
      "\n",
      "\n",
      "Test Epoch: 21\tmaintain_Accuracy: 8267/10593 (78%)\n",
      "\n",
      "tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.0\tLoss: 0.184816\n",
      "tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.2\tLoss: 0.265092\n",
      "tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.4\tLoss: 0.214161\n",
      "tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.6\tLoss: 0.239413\n",
      "tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.8\tLoss: 0.322088\n",
      "\n",
      "Test Epoch: 22\tAttack_Accuracy: 153/412 (37%)\n",
      "\n",
      "\n",
      "Test Epoch: 22\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.0\tLoss: 0.287839\n",
      "tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.2\tLoss: 0.242641\n",
      "tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.4\tLoss: 0.250762\n",
      "tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.6\tLoss: 0.226878\n",
      "tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.8\tLoss: 0.303333\n",
      "\n",
      "Test Epoch: 23\tAttack_Accuracy: 157/412 (38%)\n",
      "\n",
      "\n",
      "Test Epoch: 23\tmaintain_Accuracy: 8219/10593 (78%)\n",
      "\n",
      "tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.0\tLoss: 0.219770\n",
      "tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.2\tLoss: 0.302258\n",
      "tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.4\tLoss: 0.321569\n",
      "tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.6\tLoss: 0.290746\n",
      "tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.8\tLoss: 0.288782\n",
      "\n",
      "Test Epoch: 24\tAttack_Accuracy: 160/412 (39%)\n",
      "\n",
      "\n",
      "Test Epoch: 24\tmaintain_Accuracy: 8194/10593 (77%)\n",
      "\n",
      "tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.0\tLoss: 0.218957\n",
      "tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.2\tLoss: 0.303939\n",
      "tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.4\tLoss: 0.298416\n",
      "tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.6\tLoss: 0.291101\n",
      "tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.8\tLoss: 0.261034\n",
      "\n",
      "Train Epoch: 25\tAttack_Accuracy: 2598/6400 (41%)\n",
      "\n",
      "\n",
      "Train Epoch: 25\tmaintain_Accuracy: 4961/6400 (78%)\n",
      "\n",
      "alpha: 0.4900515210211353\n",
      "\n",
      "Test Epoch: 25\tAttack_Accuracy: 166/412 (40%)\n",
      "\n",
      "\n",
      "Test Epoch: 25\tmaintain_Accuracy: 8163/10593 (77%)\n",
      "\n",
      "tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.0\tLoss: 0.320251\n",
      "tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.2\tLoss: 0.239967\n",
      "tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.4\tLoss: 0.277758\n",
      "tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.6\tLoss: 0.262151\n",
      "tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.8\tLoss: 0.210253\n",
      "\n",
      "Test Epoch: 26\tAttack_Accuracy: 169/412 (41%)\n",
      "\n",
      "\n",
      "Test Epoch: 26\tmaintain_Accuracy: 8144/10593 (77%)\n",
      "\n",
      "tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.0\tLoss: 0.275615\n",
      "tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.2\tLoss: 0.285881\n",
      "tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.4\tLoss: 0.269270\n",
      "tensor(0.2512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.6\tLoss: 0.251180\n",
      "tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.8\tLoss: 0.284359\n",
      "\n",
      "Test Epoch: 27\tAttack_Accuracy: 176/412 (43%)\n",
      "\n",
      "\n",
      "Test Epoch: 27\tmaintain_Accuracy: 8108/10593 (77%)\n",
      "\n",
      "tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.0\tLoss: 0.222648\n",
      "tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.2\tLoss: 0.277439\n",
      "tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.4\tLoss: 0.196384\n",
      "tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.6\tLoss: 0.237085\n",
      "tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.8\tLoss: 0.341066\n",
      "\n",
      "Test Epoch: 28\tAttack_Accuracy: 180/412 (44%)\n",
      "\n",
      "\n",
      "Test Epoch: 28\tmaintain_Accuracy: 8084/10593 (76%)\n",
      "\n",
      "tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.0\tLoss: 0.288299\n",
      "tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.2\tLoss: 0.322227\n",
      "tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.4\tLoss: 0.277676\n",
      "tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.6\tLoss: 0.232471\n",
      "tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.8\tLoss: 0.295488\n",
      "\n",
      "Test Epoch: 29\tAttack_Accuracy: 187/412 (45%)\n",
      "\n",
      "\n",
      "Test Epoch: 29\tmaintain_Accuracy: 8051/10593 (76%)\n",
      "\n",
      "tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.0\tLoss: 0.236638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.2\tLoss: 0.198959\n",
      "tensor(0.2372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.4\tLoss: 0.237181\n",
      "tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.6\tLoss: 0.301921\n",
      "tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.8\tLoss: 0.202098\n",
      "\n",
      "Train Epoch: 30\tAttack_Accuracy: 2876/6400 (45%)\n",
      "\n",
      "\n",
      "Train Epoch: 30\tmaintain_Accuracy: 4833/6400 (76%)\n",
      "\n",
      "alpha: 0.5169862149445219\n",
      "\n",
      "Test Epoch: 30\tAttack_Accuracy: 191/412 (46%)\n",
      "\n",
      "\n",
      "Test Epoch: 30\tmaintain_Accuracy: 8008/10593 (76%)\n",
      "\n",
      "tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.0\tLoss: 0.205505\n",
      "tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.2\tLoss: 0.244637\n",
      "tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.4\tLoss: 0.250763\n",
      "tensor(0.1887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.6\tLoss: 0.188741\n",
      "tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.8\tLoss: 0.220313\n",
      "\n",
      "Test Epoch: 31\tAttack_Accuracy: 195/412 (47%)\n",
      "\n",
      "\n",
      "Test Epoch: 31\tmaintain_Accuracy: 7991/10593 (75%)\n",
      "\n",
      "tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.0\tLoss: 0.216120\n",
      "tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.2\tLoss: 0.252625\n",
      "tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.4\tLoss: 0.284136\n",
      "tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.6\tLoss: 0.281758\n",
      "tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.8\tLoss: 0.188959\n",
      "\n",
      "Test Epoch: 32\tAttack_Accuracy: 199/412 (48%)\n",
      "\n",
      "\n",
      "Test Epoch: 32\tmaintain_Accuracy: 7961/10593 (75%)\n",
      "\n",
      "tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.0\tLoss: 0.221419\n",
      "tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.2\tLoss: 0.210611\n",
      "tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.4\tLoss: 0.271570\n",
      "tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.6\tLoss: 0.226681\n",
      "tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.8\tLoss: 0.242019\n",
      "\n",
      "Test Epoch: 33\tAttack_Accuracy: 204/412 (50%)\n",
      "\n",
      "\n",
      "Test Epoch: 33\tmaintain_Accuracy: 7935/10593 (75%)\n",
      "\n",
      "tensor(0.1668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.0\tLoss: 0.166782\n",
      "tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.2\tLoss: 0.294102\n",
      "tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.4\tLoss: 0.239164\n",
      "tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.6\tLoss: 0.204698\n",
      "tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.8\tLoss: 0.240871\n",
      "\n",
      "Test Epoch: 34\tAttack_Accuracy: 213/412 (52%)\n",
      "\n",
      "\n",
      "Test Epoch: 34\tmaintain_Accuracy: 7894/10593 (75%)\n",
      "\n",
      "tensor(0.1723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.0\tLoss: 0.172314\n",
      "tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.2\tLoss: 0.178113\n",
      "tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.4\tLoss: 0.164052\n",
      "tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.6\tLoss: 0.223947\n",
      "tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.8\tLoss: 0.210436\n",
      "\n",
      "Train Epoch: 35\tAttack_Accuracy: 3216/6400 (50%)\n",
      "\n",
      "\n",
      "Train Epoch: 35\tmaintain_Accuracy: 4712/6400 (74%)\n",
      "\n",
      "alpha: 0.43361004616997323\n",
      "\n",
      "Test Epoch: 35\tAttack_Accuracy: 215/412 (52%)\n",
      "\n",
      "\n",
      "Test Epoch: 35\tmaintain_Accuracy: 7864/10593 (74%)\n",
      "\n",
      "tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.0\tLoss: 0.243310\n",
      "tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.2\tLoss: 0.254423\n",
      "tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.4\tLoss: 0.241629\n",
      "tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.6\tLoss: 0.219245\n",
      "tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.8\tLoss: 0.270193\n",
      "\n",
      "Test Epoch: 36\tAttack_Accuracy: 218/412 (53%)\n",
      "\n",
      "\n",
      "Test Epoch: 36\tmaintain_Accuracy: 7836/10593 (74%)\n",
      "\n",
      "tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.0\tLoss: 0.287503\n",
      "tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.2\tLoss: 0.259968\n",
      "tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.4\tLoss: 0.260936\n",
      "tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.6\tLoss: 0.336427\n",
      "tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.8\tLoss: 0.246932\n",
      "\n",
      "Test Epoch: 37\tAttack_Accuracy: 225/412 (55%)\n",
      "\n",
      "\n",
      "Test Epoch: 37\tmaintain_Accuracy: 7789/10593 (74%)\n",
      "\n",
      "tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.0\tLoss: 0.253132\n",
      "tensor(0.2131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.2\tLoss: 0.213114\n",
      "tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.4\tLoss: 0.187454\n",
      "tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.6\tLoss: 0.195123\n",
      "tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.8\tLoss: 0.231188\n",
      "\n",
      "Test Epoch: 38\tAttack_Accuracy: 229/412 (56%)\n",
      "\n",
      "\n",
      "Test Epoch: 38\tmaintain_Accuracy: 7770/10593 (73%)\n",
      "\n",
      "tensor(0.1418, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.0\tLoss: 0.141796\n",
      "tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.2\tLoss: 0.195818\n",
      "tensor(0.1904, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.4\tLoss: 0.190364\n",
      "tensor(0.1439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.6\tLoss: 0.143936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.8\tLoss: 0.264530\n",
      "\n",
      "Test Epoch: 39\tAttack_Accuracy: 234/412 (57%)\n",
      "\n",
      "\n",
      "Test Epoch: 39\tmaintain_Accuracy: 7728/10593 (73%)\n",
      "\n",
      "tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.0\tLoss: 0.220530\n",
      "tensor(0.1605, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.2\tLoss: 0.160528\n",
      "tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.4\tLoss: 0.253062\n",
      "tensor(0.1985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.6\tLoss: 0.198451\n",
      "tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.8\tLoss: 0.293503\n",
      "\n",
      "Train Epoch: 40\tAttack_Accuracy: 3408/6400 (53%)\n",
      "\n",
      "\n",
      "Train Epoch: 40\tmaintain_Accuracy: 4671/6400 (73%)\n",
      "\n",
      "alpha: 0.5571562675315173\n",
      "\n",
      "Test Epoch: 40\tAttack_Accuracy: 239/412 (58%)\n",
      "\n",
      "\n",
      "Test Epoch: 40\tmaintain_Accuracy: 7680/10593 (73%)\n",
      "\n",
      "tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.0\tLoss: 0.204960\n",
      "tensor(0.1861, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.2\tLoss: 0.186139\n",
      "tensor(0.1590, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.4\tLoss: 0.158955\n",
      "tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.6\tLoss: 0.243970\n",
      "tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.8\tLoss: 0.228448\n",
      "\n",
      "Test Epoch: 41\tAttack_Accuracy: 241/412 (58%)\n",
      "\n",
      "\n",
      "Test Epoch: 41\tmaintain_Accuracy: 7648/10593 (72%)\n",
      "\n",
      "tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.0\tLoss: 0.281255\n",
      "tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.2\tLoss: 0.216873\n",
      "tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.4\tLoss: 0.274857\n",
      "tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.6\tLoss: 0.262734\n",
      "tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.8\tLoss: 0.214831\n",
      "\n",
      "Test Epoch: 42\tAttack_Accuracy: 243/412 (59%)\n",
      "\n",
      "\n",
      "Test Epoch: 42\tmaintain_Accuracy: 7609/10593 (72%)\n",
      "\n",
      "tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.0\tLoss: 0.210183\n",
      "tensor(0.1730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.2\tLoss: 0.173048\n",
      "tensor(0.1449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.4\tLoss: 0.144893\n",
      "tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.6\tLoss: 0.171872\n",
      "tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.8\tLoss: 0.179646\n",
      "\n",
      "Test Epoch: 43\tAttack_Accuracy: 246/412 (60%)\n",
      "\n",
      "\n",
      "Test Epoch: 43\tmaintain_Accuracy: 7589/10593 (72%)\n",
      "\n",
      "tensor(0.2132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.0\tLoss: 0.213177\n",
      "tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.2\tLoss: 0.225108\n",
      "tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.4\tLoss: 0.205649\n",
      "tensor(0.1611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.6\tLoss: 0.161118\n",
      "tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.8\tLoss: 0.231506\n",
      "\n",
      "Test Epoch: 44\tAttack_Accuracy: 252/412 (61%)\n",
      "\n",
      "\n",
      "Test Epoch: 44\tmaintain_Accuracy: 7550/10593 (71%)\n",
      "\n",
      "tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.0\tLoss: 0.200171\n",
      "tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.2\tLoss: 0.232592\n",
      "tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.4\tLoss: 0.216691\n",
      "tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.6\tLoss: 0.192565\n",
      "tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.8\tLoss: 0.234785\n",
      "\n",
      "Train Epoch: 45\tAttack_Accuracy: 3802/6400 (59%)\n",
      "\n",
      "\n",
      "Train Epoch: 45\tmaintain_Accuracy: 4585/6400 (72%)\n",
      "\n",
      "alpha: 0.6270489445087772\n",
      "\n",
      "Test Epoch: 45\tAttack_Accuracy: 256/412 (62%)\n",
      "\n",
      "\n",
      "Test Epoch: 45\tmaintain_Accuracy: 7488/10593 (71%)\n",
      "\n",
      "tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.0\tLoss: 0.186960\n",
      "tensor(0.1500, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.2\tLoss: 0.149999\n",
      "tensor(0.2032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.4\tLoss: 0.203191\n",
      "tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.6\tLoss: 0.200056\n",
      "tensor(0.1369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.8\tLoss: 0.136856\n",
      "\n",
      "Test Epoch: 46\tAttack_Accuracy: 256/412 (62%)\n",
      "\n",
      "\n",
      "Test Epoch: 46\tmaintain_Accuracy: 7505/10593 (71%)\n",
      "\n",
      "tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.0\tLoss: 0.244654\n",
      "tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.2\tLoss: 0.220990\n",
      "tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.4\tLoss: 0.274081\n",
      "tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.6\tLoss: 0.181639\n",
      "tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.8\tLoss: 0.222525\n",
      "\n",
      "Test Epoch: 47\tAttack_Accuracy: 260/412 (63%)\n",
      "\n",
      "\n",
      "Test Epoch: 47\tmaintain_Accuracy: 7427/10593 (70%)\n",
      "\n",
      "tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.0\tLoss: 0.317210\n",
      "tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.2\tLoss: 0.261395\n",
      "tensor(0.1773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.4\tLoss: 0.177266\n",
      "tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.6\tLoss: 0.315745\n",
      "tensor(0.1306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.8\tLoss: 0.130594\n",
      "\n",
      "Test Epoch: 48\tAttack_Accuracy: 270/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 48\tmaintain_Accuracy: 7311/10593 (69%)\n",
      "\n",
      "tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.0\tLoss: 0.245795\n",
      "tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.2\tLoss: 0.222756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.4\tLoss: 0.197593\n",
      "tensor(0.2004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.6\tLoss: 0.200382\n",
      "tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.8\tLoss: 0.224607\n",
      "\n",
      "Test Epoch: 49\tAttack_Accuracy: 271/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 49\tmaintain_Accuracy: 7292/10593 (69%)\n",
      "\n",
      "tensor(0.0922, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.0\tLoss: 0.092168\n",
      "tensor(0.0791, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.2\tLoss: 0.079093\n",
      "tensor(0.1592, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.4\tLoss: 0.159213\n",
      "tensor(0.1148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.6\tLoss: 0.114798\n",
      "tensor(0.0535, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.8\tLoss: 0.053486\n",
      "\n",
      "Train Epoch: 50\tAttack_Accuracy: 3908/6400 (61%)\n",
      "\n",
      "\n",
      "Train Epoch: 50\tmaintain_Accuracy: 4417/6400 (69%)\n",
      "\n",
      "alpha: 0.014298613342617155\n",
      "\n",
      "Test Epoch: 50\tAttack_Accuracy: 264/412 (64%)\n",
      "\n",
      "\n",
      "Test Epoch: 50\tmaintain_Accuracy: 7402/10593 (70%)\n",
      "\n",
      "tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.0\tLoss: 0.269463\n",
      "tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.2\tLoss: 0.211692\n",
      "tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.4\tLoss: 0.162559\n",
      "tensor(0.1770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.6\tLoss: 0.176983\n",
      "tensor(0.1738, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.8\tLoss: 0.173801\n",
      "\n",
      "Test Epoch: 51\tAttack_Accuracy: 268/412 (65%)\n",
      "\n",
      "\n",
      "Test Epoch: 51\tmaintain_Accuracy: 7360/10593 (69%)\n",
      "\n",
      "tensor(0.1361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.0\tLoss: 0.136129\n",
      "tensor(0.1542, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.2\tLoss: 0.154207\n",
      "tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.4\tLoss: 0.207233\n",
      "tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.6\tLoss: 0.199933\n",
      "tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.8\tLoss: 0.159340\n",
      "\n",
      "Test Epoch: 52\tAttack_Accuracy: 271/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 52\tmaintain_Accuracy: 7319/10593 (69%)\n",
      "\n",
      "tensor(0.1639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.0\tLoss: 0.163878\n",
      "tensor(0.1406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.2\tLoss: 0.140558\n",
      "tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.4\tLoss: 0.140818\n",
      "tensor(0.1563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.6\tLoss: 0.156321\n",
      "tensor(0.1511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.8\tLoss: 0.151136\n",
      "\n",
      "Test Epoch: 53\tAttack_Accuracy: 270/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 53\tmaintain_Accuracy: 7325/10593 (69%)\n",
      "\n",
      "tensor(0.2031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.0\tLoss: 0.203056\n",
      "tensor(0.1758, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.2\tLoss: 0.175812\n",
      "tensor(0.1527, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.4\tLoss: 0.152664\n",
      "tensor(0.1273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.6\tLoss: 0.127258\n",
      "tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.8\tLoss: 0.192265\n",
      "\n",
      "Test Epoch: 54\tAttack_Accuracy: 274/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 54\tmaintain_Accuracy: 7318/10593 (69%)\n",
      "\n",
      "tensor(0.1424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.0\tLoss: 0.142356\n",
      "tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.2\tLoss: 0.216676\n",
      "tensor(0.1536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.4\tLoss: 0.153598\n",
      "tensor(0.1420, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.6\tLoss: 0.142032\n",
      "tensor(0.1552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.8\tLoss: 0.155181\n",
      "\n",
      "Train Epoch: 55\tAttack_Accuracy: 4037/6400 (63%)\n",
      "\n",
      "\n",
      "Train Epoch: 55\tmaintain_Accuracy: 4436/6400 (69%)\n",
      "\n",
      "alpha: 0.5595545060649977\n",
      "\n",
      "Test Epoch: 55\tAttack_Accuracy: 276/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 55\tmaintain_Accuracy: 7288/10593 (69%)\n",
      "\n",
      "tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.0\tLoss: 0.200206\n",
      "tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.2\tLoss: 0.235060\n",
      "tensor(0.1672, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.4\tLoss: 0.167175\n",
      "tensor(0.1790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.6\tLoss: 0.178996\n",
      "tensor(0.1682, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.8\tLoss: 0.168160\n",
      "\n",
      "Test Epoch: 56\tAttack_Accuracy: 278/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 56\tmaintain_Accuracy: 7284/10593 (69%)\n",
      "\n",
      "tensor(0.1400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.0\tLoss: 0.139971\n",
      "tensor(0.1443, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.2\tLoss: 0.144276\n",
      "tensor(0.1782, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.4\tLoss: 0.178207\n",
      "tensor(0.1479, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.6\tLoss: 0.147907\n",
      "tensor(0.1814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.8\tLoss: 0.181449\n",
      "\n",
      "Test Epoch: 57\tAttack_Accuracy: 278/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 57\tmaintain_Accuracy: 7299/10593 (69%)\n",
      "\n",
      "tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.0\tLoss: 0.180211\n",
      "tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.2\tLoss: 0.193718\n",
      "tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.4\tLoss: 0.200726\n",
      "tensor(0.1484, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.6\tLoss: 0.148385\n",
      "tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.8\tLoss: 0.211069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 58\tAttack_Accuracy: 280/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 58\tmaintain_Accuracy: 7273/10593 (69%)\n",
      "\n",
      "tensor(0.1245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.0\tLoss: 0.124488\n",
      "tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.2\tLoss: 0.132196\n",
      "tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.4\tLoss: 0.162380\n",
      "tensor(0.1931, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.6\tLoss: 0.193087\n",
      "tensor(0.1199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.8\tLoss: 0.119939\n",
      "\n",
      "Test Epoch: 59\tAttack_Accuracy: 280/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 59\tmaintain_Accuracy: 7260/10593 (69%)\n",
      "\n",
      "tensor(0.1579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.0\tLoss: 0.157916\n",
      "tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.2\tLoss: 0.255132\n",
      "tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.4\tLoss: 0.194953\n",
      "tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.6\tLoss: 0.179908\n",
      "tensor(0.1790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.8\tLoss: 0.178956\n",
      "\n",
      "Train Epoch: 60\tAttack_Accuracy: 4101/6400 (64%)\n",
      "\n",
      "\n",
      "Train Epoch: 60\tmaintain_Accuracy: 4349/6400 (68%)\n",
      "\n",
      "alpha: 0.47514982439025505\n",
      "\n",
      "Test Epoch: 60\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 60\tmaintain_Accuracy: 7252/10593 (68%)\n",
      "\n",
      "tensor(0.1135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.0\tLoss: 0.113506\n",
      "tensor(0.1724, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.2\tLoss: 0.172357\n",
      "tensor(0.0880, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.4\tLoss: 0.087981\n",
      "tensor(0.1605, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.6\tLoss: 0.160484\n",
      "tensor(0.1158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.8\tLoss: 0.115836\n",
      "\n",
      "Test Epoch: 61\tAttack_Accuracy: 280/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 61\tmaintain_Accuracy: 7257/10593 (69%)\n",
      "\n",
      "tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.0\tLoss: 0.177227\n",
      "tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.2\tLoss: 0.134878\n",
      "tensor(0.1803, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.4\tLoss: 0.180304\n",
      "tensor(0.1573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.6\tLoss: 0.157313\n",
      "tensor(0.1640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.8\tLoss: 0.163984\n",
      "\n",
      "Test Epoch: 62\tAttack_Accuracy: 282/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 62\tmaintain_Accuracy: 7216/10593 (68%)\n",
      "\n",
      "tensor(0.1214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.0\tLoss: 0.121367\n",
      "tensor(0.1324, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.2\tLoss: 0.132411\n",
      "tensor(0.1732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.4\tLoss: 0.173190\n",
      "tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.6\tLoss: 0.171886\n",
      "tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.8\tLoss: 0.190255\n",
      "\n",
      "Test Epoch: 63\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 63\tmaintain_Accuracy: 7266/10593 (69%)\n",
      "\n",
      "tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.0\tLoss: 0.224224\n",
      "tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.2\tLoss: 0.208470\n",
      "tensor(0.1632, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.4\tLoss: 0.163194\n",
      "tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.6\tLoss: 0.218294\n",
      "tensor(0.1656, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.8\tLoss: 0.165635\n",
      "\n",
      "Test Epoch: 64\tAttack_Accuracy: 282/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 64\tmaintain_Accuracy: 7240/10593 (68%)\n",
      "\n",
      "tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.0\tLoss: 0.192522\n",
      "tensor(0.1382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.2\tLoss: 0.138155\n",
      "tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.4\tLoss: 0.215982\n",
      "tensor(0.1622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.6\tLoss: 0.162152\n",
      "tensor(0.0964, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.8\tLoss: 0.096388\n",
      "\n",
      "Train Epoch: 65\tAttack_Accuracy: 4222/6400 (66%)\n",
      "\n",
      "\n",
      "Train Epoch: 65\tmaintain_Accuracy: 4384/6400 (68%)\n",
      "\n",
      "alpha: 0.3953533468600967\n",
      "\n",
      "Test Epoch: 65\tAttack_Accuracy: 282/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 65\tmaintain_Accuracy: 7247/10593 (68%)\n",
      "\n",
      "tensor(0.1756, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.0\tLoss: 0.175589\n",
      "tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.2\tLoss: 0.152447\n",
      "tensor(0.1433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.4\tLoss: 0.143284\n",
      "tensor(0.1604, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.6\tLoss: 0.160419\n",
      "tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.8\tLoss: 0.185480\n",
      "\n",
      "Test Epoch: 66\tAttack_Accuracy: 282/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 66\tmaintain_Accuracy: 7199/10593 (68%)\n",
      "\n",
      "tensor(0.1179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.0\tLoss: 0.117859\n",
      "tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.2\tLoss: 0.162952\n",
      "tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.4\tLoss: 0.123506\n",
      "tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.6\tLoss: 0.101184\n",
      "tensor(0.1540, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.8\tLoss: 0.153964\n",
      "\n",
      "Test Epoch: 67\tAttack_Accuracy: 282/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 67\tmaintain_Accuracy: 7207/10593 (68%)\n",
      "\n",
      "tensor(0.1297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.0\tLoss: 0.129672\n",
      "tensor(0.1925, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.2\tLoss: 0.192547\n",
      "tensor(0.1532, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.4\tLoss: 0.153186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.6\tLoss: 0.193566\n",
      "tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.8\tLoss: 0.184412\n",
      "\n",
      "Test Epoch: 68\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 68\tmaintain_Accuracy: 7186/10593 (68%)\n",
      "\n",
      "tensor(0.2394, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.0\tLoss: 0.239403\n",
      "tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.2\tLoss: 0.214068\n",
      "tensor(0.1734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.4\tLoss: 0.173353\n",
      "tensor(0.1504, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.6\tLoss: 0.150413\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.8\tLoss: 0.066473\n",
      "\n",
      "Test Epoch: 69\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 69\tmaintain_Accuracy: 7200/10593 (68%)\n",
      "\n",
      "tensor(0.1990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.0\tLoss: 0.198995\n",
      "tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.2\tLoss: 0.218144\n",
      "tensor(0.1581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.4\tLoss: 0.158061\n",
      "tensor(0.0912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.6\tLoss: 0.091182\n",
      "tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.8\tLoss: 0.213489\n",
      "\n",
      "Train Epoch: 70\tAttack_Accuracy: 4266/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 70\tmaintain_Accuracy: 4350/6400 (68%)\n",
      "\n",
      "alpha: 0.48731751926102934\n",
      "\n",
      "Test Epoch: 70\tAttack_Accuracy: 286/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 70\tmaintain_Accuracy: 7188/10593 (68%)\n",
      "\n",
      "tensor(0.1806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.0\tLoss: 0.180643\n",
      "tensor(0.1037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.2\tLoss: 0.103705\n",
      "tensor(0.1495, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.4\tLoss: 0.149518\n",
      "tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.6\tLoss: 0.110180\n",
      "tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.8\tLoss: 0.180542\n",
      "\n",
      "Test Epoch: 71\tAttack_Accuracy: 286/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 71\tmaintain_Accuracy: 7167/10593 (68%)\n",
      "\n",
      "tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.0\tLoss: 0.117517\n",
      "tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.2\tLoss: 0.094445\n",
      "tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.4\tLoss: 0.188559\n",
      "tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.6\tLoss: 0.115601\n",
      "tensor(0.1706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.8\tLoss: 0.170639\n",
      "\n",
      "Test Epoch: 72\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 72\tmaintain_Accuracy: 7165/10593 (68%)\n",
      "\n",
      "tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.0\tLoss: 0.171933\n",
      "tensor(0.1398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.2\tLoss: 0.139838\n",
      "tensor(0.1539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.4\tLoss: 0.153874\n",
      "tensor(0.1411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.6\tLoss: 0.141061\n",
      "tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.8\tLoss: 0.086401\n",
      "\n",
      "Test Epoch: 73\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 73\tmaintain_Accuracy: 7187/10593 (68%)\n",
      "\n",
      "tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.0\tLoss: 0.162568\n",
      "tensor(0.1687, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.2\tLoss: 0.168693\n",
      "tensor(0.1654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.4\tLoss: 0.165391\n",
      "tensor(0.1389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.6\tLoss: 0.138943\n",
      "tensor(0.1497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.8\tLoss: 0.149688\n",
      "\n",
      "Test Epoch: 74\tAttack_Accuracy: 288/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 74\tmaintain_Accuracy: 7146/10593 (67%)\n",
      "\n",
      "tensor(0.1103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.0\tLoss: 0.110271\n",
      "tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.2\tLoss: 0.204283\n",
      "tensor(0.1257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.4\tLoss: 0.125678\n",
      "tensor(0.1378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.6\tLoss: 0.137836\n",
      "tensor(0.1046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.8\tLoss: 0.104609\n",
      "\n",
      "Train Epoch: 75\tAttack_Accuracy: 4400/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 75\tmaintain_Accuracy: 4266/6400 (67%)\n",
      "\n",
      "alpha: 0.454343616653647\n",
      "\n",
      "Test Epoch: 75\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 75\tmaintain_Accuracy: 7147/10593 (67%)\n",
      "\n",
      "tensor(0.1386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.0\tLoss: 0.138590\n",
      "tensor(0.0677, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.2\tLoss: 0.067678\n",
      "tensor(0.1770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.4\tLoss: 0.177003\n",
      "tensor(0.1506, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.6\tLoss: 0.150560\n",
      "tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.8\tLoss: 0.223189\n",
      "\n",
      "Test Epoch: 76\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 76\tmaintain_Accuracy: 7131/10593 (67%)\n",
      "\n",
      "tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.0\tLoss: 0.128941\n",
      "tensor(0.1464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.2\tLoss: 0.146449\n",
      "tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.4\tLoss: 0.141028\n",
      "tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.6\tLoss: 0.237544\n",
      "tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.8\tLoss: 0.217929\n",
      "\n",
      "Test Epoch: 77\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 77\tmaintain_Accuracy: 7143/10593 (67%)\n",
      "\n",
      "tensor(0.1283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.0\tLoss: 0.128337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.2\tLoss: 0.146739\n",
      "tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.4\tLoss: 0.266095\n",
      "tensor(0.1803, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.6\tLoss: 0.180276\n",
      "tensor(0.1477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.8\tLoss: 0.147736\n",
      "\n",
      "Test Epoch: 78\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 78\tmaintain_Accuracy: 7119/10593 (67%)\n",
      "\n",
      "tensor(0.1253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.0\tLoss: 0.125254\n",
      "tensor(0.1600, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.2\tLoss: 0.160018\n",
      "tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.4\tLoss: 0.180542\n",
      "tensor(0.1522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.6\tLoss: 0.152245\n",
      "tensor(0.1192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.8\tLoss: 0.119172\n",
      "\n",
      "Test Epoch: 79\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 79\tmaintain_Accuracy: 7115/10593 (67%)\n",
      "\n",
      "tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.0\tLoss: 0.178715\n",
      "tensor(0.1446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.2\tLoss: 0.144602\n",
      "tensor(0.1182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.4\tLoss: 0.118160\n",
      "tensor(0.1360, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.6\tLoss: 0.135998\n",
      "tensor(0.1441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.8\tLoss: 0.144108\n",
      "\n",
      "Train Epoch: 80\tAttack_Accuracy: 4437/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 80\tmaintain_Accuracy: 4338/6400 (68%)\n",
      "\n",
      "alpha: 0.5056356912860474\n",
      "\n",
      "Test Epoch: 80\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 80\tmaintain_Accuracy: 7103/10593 (67%)\n",
      "\n",
      "tensor(0.1186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.0\tLoss: 0.118642\n",
      "tensor(0.1054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.2\tLoss: 0.105404\n",
      "tensor(0.0951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.4\tLoss: 0.095146\n",
      "tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.6\tLoss: 0.205211\n",
      "tensor(0.1313, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.8\tLoss: 0.131320\n",
      "\n",
      "Test Epoch: 81\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 81\tmaintain_Accuracy: 7093/10593 (67%)\n",
      "\n",
      "tensor(0.1533, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.0\tLoss: 0.153284\n",
      "tensor(0.1608, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.2\tLoss: 0.160812\n",
      "tensor(0.1343, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.4\tLoss: 0.134255\n",
      "tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.6\tLoss: 0.123470\n",
      "tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.8\tLoss: 0.104867\n",
      "\n",
      "Test Epoch: 82\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 82\tmaintain_Accuracy: 7096/10593 (67%)\n",
      "\n",
      "tensor(0.1653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.0\tLoss: 0.165326\n",
      "tensor(0.1575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.2\tLoss: 0.157463\n",
      "tensor(0.1595, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.4\tLoss: 0.159452\n",
      "tensor(0.1584, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.6\tLoss: 0.158351\n",
      "tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.8\tLoss: 0.171997\n",
      "\n",
      "Test Epoch: 83\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 83\tmaintain_Accuracy: 7092/10593 (67%)\n",
      "\n",
      "tensor(0.1733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.0\tLoss: 0.173260\n",
      "tensor(0.1460, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.2\tLoss: 0.146029\n",
      "tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.4\tLoss: 0.177723\n",
      "tensor(0.1293, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.6\tLoss: 0.129342\n",
      "tensor(0.1140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.8\tLoss: 0.114044\n",
      "\n",
      "Test Epoch: 84\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 84\tmaintain_Accuracy: 7095/10593 (67%)\n",
      "\n",
      "tensor(0.1355, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.0\tLoss: 0.135483\n",
      "tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.2\tLoss: 0.227714\n",
      "tensor(0.1227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.4\tLoss: 0.122687\n",
      "tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.6\tLoss: 0.193673\n",
      "tensor(0.1628, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.8\tLoss: 0.162795\n",
      "\n",
      "Train Epoch: 85\tAttack_Accuracy: 4480/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 85\tmaintain_Accuracy: 4261/6400 (67%)\n",
      "\n",
      "alpha: 0.5416193455689604\n",
      "\n",
      "Test Epoch: 85\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 85\tmaintain_Accuracy: 7084/10593 (67%)\n",
      "\n",
      "tensor(0.1567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.0\tLoss: 0.156746\n",
      "tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.2\tLoss: 0.206713\n",
      "tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.4\tLoss: 0.085611\n",
      "tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.6\tLoss: 0.101885\n",
      "tensor(0.0480, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.8\tLoss: 0.048049\n",
      "\n",
      "Test Epoch: 86\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 86\tmaintain_Accuracy: 7078/10593 (67%)\n",
      "\n",
      "tensor(0.1297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.0\tLoss: 0.129712\n",
      "tensor(0.1557, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.2\tLoss: 0.155706\n",
      "tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.4\tLoss: 0.198821\n",
      "tensor(0.1020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.6\tLoss: 0.101983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1617, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.8\tLoss: 0.161693\n",
      "\n",
      "Test Epoch: 87\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 87\tmaintain_Accuracy: 7071/10593 (67%)\n",
      "\n",
      "tensor(0.1651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.0\tLoss: 0.165075\n",
      "tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.2\tLoss: 0.210329\n",
      "tensor(0.1758, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.4\tLoss: 0.175824\n",
      "tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.6\tLoss: 0.103891\n",
      "tensor(0.1514, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.8\tLoss: 0.151446\n",
      "\n",
      "Test Epoch: 88\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 88\tmaintain_Accuracy: 7077/10593 (67%)\n",
      "\n",
      "tensor(0.0746, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.0\tLoss: 0.074636\n",
      "tensor(0.1556, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.2\tLoss: 0.155565\n",
      "tensor(0.1652, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.4\tLoss: 0.165161\n",
      "tensor(0.1389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.6\tLoss: 0.138913\n",
      "tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.8\tLoss: 0.127246\n",
      "\n",
      "Test Epoch: 89\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 89\tmaintain_Accuracy: 7089/10593 (67%)\n",
      "\n",
      "tensor(0.1252, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.0\tLoss: 0.125221\n",
      "tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.2\tLoss: 0.219397\n",
      "tensor(0.1040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.4\tLoss: 0.103980\n",
      "tensor(0.1010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.6\tLoss: 0.100962\n",
      "tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.8\tLoss: 0.185569\n",
      "\n",
      "Train Epoch: 90\tAttack_Accuracy: 4601/6400 (72%)\n",
      "\n",
      "\n",
      "Train Epoch: 90\tmaintain_Accuracy: 4322/6400 (68%)\n",
      "\n",
      "alpha: 0.5786586641381972\n",
      "\n",
      "Test Epoch: 90\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 90\tmaintain_Accuracy: 7066/10593 (67%)\n",
      "\n",
      "tensor(0.1302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.0\tLoss: 0.130224\n",
      "tensor(0.1511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.2\tLoss: 0.151107\n",
      "tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.4\tLoss: 0.238560\n",
      "tensor(0.1205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.6\tLoss: 0.120491\n",
      "tensor(0.1087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.8\tLoss: 0.108663\n",
      "\n",
      "Test Epoch: 91\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 91\tmaintain_Accuracy: 7056/10593 (67%)\n",
      "\n",
      "tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.0\tLoss: 0.142728\n",
      "tensor(0.1500, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.2\tLoss: 0.150022\n",
      "tensor(0.1386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.4\tLoss: 0.138598\n",
      "tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.6\tLoss: 0.191814\n",
      "tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.8\tLoss: 0.128451\n",
      "\n",
      "Test Epoch: 92\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 92\tmaintain_Accuracy: 7064/10593 (67%)\n",
      "\n",
      "tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.0\tLoss: 0.084636\n",
      "tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.2\tLoss: 0.095324\n",
      "tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.4\tLoss: 0.092038\n",
      "tensor(0.1108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.6\tLoss: 0.110827\n",
      "tensor(0.1487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.8\tLoss: 0.148666\n",
      "\n",
      "Test Epoch: 93\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 93\tmaintain_Accuracy: 7084/10593 (67%)\n",
      "\n",
      "tensor(0.0569, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.0\tLoss: 0.056867\n",
      "tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.2\tLoss: 0.234569\n",
      "tensor(0.1437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.4\tLoss: 0.143739\n",
      "tensor(0.1487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.6\tLoss: 0.148730\n",
      "tensor(0.1574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.8\tLoss: 0.157354\n",
      "\n",
      "Test Epoch: 94\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 94\tmaintain_Accuracy: 7084/10593 (67%)\n",
      "\n",
      "tensor(0.1381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.0\tLoss: 0.138127\n",
      "tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.2\tLoss: 0.093640\n",
      "tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.4\tLoss: 0.159309\n",
      "tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.6\tLoss: 0.080295\n",
      "tensor(0.1730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.8\tLoss: 0.172980\n",
      "\n",
      "Train Epoch: 95\tAttack_Accuracy: 4613/6400 (72%)\n",
      "\n",
      "\n",
      "Train Epoch: 95\tmaintain_Accuracy: 4221/6400 (66%)\n",
      "\n",
      "alpha: 0.6150194094033974\n",
      "\n",
      "Test Epoch: 95\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 95\tmaintain_Accuracy: 7048/10593 (67%)\n",
      "\n",
      "tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.0\tLoss: 0.153040\n",
      "tensor(0.1412, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.2\tLoss: 0.141231\n",
      "tensor(0.1399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.4\tLoss: 0.139868\n",
      "tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.6\tLoss: 0.117354\n",
      "tensor(0.0785, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.8\tLoss: 0.078517\n",
      "\n",
      "Test Epoch: 96\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 96\tmaintain_Accuracy: 7060/10593 (67%)\n",
      "\n",
      "tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.0\tLoss: 0.146793\n",
      "tensor(0.1413, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.2\tLoss: 0.141329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1365, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.4\tLoss: 0.136535\n",
      "tensor(0.1104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.6\tLoss: 0.110352\n",
      "tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.8\tLoss: 0.103533\n",
      "\n",
      "Test Epoch: 97\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 97\tmaintain_Accuracy: 7056/10593 (67%)\n",
      "\n",
      "tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.0\tLoss: 0.198636\n",
      "tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.2\tLoss: 0.141046\n",
      "tensor(0.1782, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.4\tLoss: 0.178228\n",
      "tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.6\tLoss: 0.076497\n",
      "tensor(0.1767, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.8\tLoss: 0.176668\n",
      "\n",
      "Test Epoch: 98\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 98\tmaintain_Accuracy: 7047/10593 (67%)\n",
      "\n",
      "tensor(0.1419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.0\tLoss: 0.141882\n",
      "tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.2\tLoss: 0.152617\n",
      "tensor(0.1037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.4\tLoss: 0.103656\n",
      "tensor(0.0801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.6\tLoss: 0.080061\n",
      "tensor(0.1072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.8\tLoss: 0.107231\n",
      "\n",
      "Test Epoch: 99\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 99\tmaintain_Accuracy: 7058/10593 (67%)\n",
      "\n",
      "tensor(0.1276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.0\tLoss: 0.127617\n",
      "tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.2\tLoss: 0.139524\n",
      "tensor(0.1677, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.4\tLoss: 0.167694\n",
      "tensor(0.1155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.6\tLoss: 0.115489\n",
      "tensor(0.1020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.8\tLoss: 0.101965\n",
      "\n",
      "Train Epoch: 100\tAttack_Accuracy: 4625/6400 (72%)\n",
      "\n",
      "\n",
      "Train Epoch: 100\tmaintain_Accuracy: 4247/6400 (66%)\n",
      "\n",
      "alpha: 0.483214743487665\n",
      "\n",
      "Test Epoch: 100\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 100\tmaintain_Accuracy: 7055/10593 (67%)\n",
      "\n",
      "tensor(0.1636, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.0\tLoss: 0.163554\n",
      "tensor(0.1691, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.2\tLoss: 0.169104\n",
      "tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.4\tLoss: 0.090047\n",
      "tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.6\tLoss: 0.182425\n",
      "tensor(0.1295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.8\tLoss: 0.129546\n",
      "\n",
      "Test Epoch: 101\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 101\tmaintain_Accuracy: 7051/10593 (67%)\n",
      "\n",
      "tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.0\tLoss: 0.111163\n",
      "tensor(0.1869, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.2\tLoss: 0.186872\n",
      "tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.4\tLoss: 0.074165\n",
      "tensor(0.1662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.6\tLoss: 0.166241\n",
      "tensor(0.1238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.8\tLoss: 0.123803\n",
      "\n",
      "Test Epoch: 102\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 102\tmaintain_Accuracy: 7050/10593 (67%)\n",
      "\n",
      "tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.0\tLoss: 0.146839\n",
      "tensor(0.0831, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.2\tLoss: 0.083079\n",
      "tensor(0.1557, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.4\tLoss: 0.155677\n",
      "tensor(0.1377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.6\tLoss: 0.137683\n",
      "tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.8\tLoss: 0.051977\n",
      "\n",
      "Test Epoch: 103\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 103\tmaintain_Accuracy: 7048/10593 (67%)\n",
      "\n",
      "tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.0\tLoss: 0.132032\n",
      "tensor(0.0951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.2\tLoss: 0.095101\n",
      "tensor(0.1496, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.4\tLoss: 0.149634\n",
      "tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.6\tLoss: 0.183737\n",
      "tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.8\tLoss: 0.179779\n",
      "\n",
      "Test Epoch: 104\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 104\tmaintain_Accuracy: 7051/10593 (67%)\n",
      "\n",
      "tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.0\tLoss: 0.094549\n",
      "tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.2\tLoss: 0.201941\n",
      "tensor(0.1350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.4\tLoss: 0.135050\n",
      "tensor(0.1064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.6\tLoss: 0.106350\n",
      "tensor(0.1110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.8\tLoss: 0.110975\n",
      "\n",
      "Train Epoch: 105\tAttack_Accuracy: 4636/6400 (72%)\n",
      "\n",
      "\n",
      "Train Epoch: 105\tmaintain_Accuracy: 4229/6400 (66%)\n",
      "\n",
      "alpha: 0.4886855215967506\n",
      "\n",
      "Test Epoch: 105\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 105\tmaintain_Accuracy: 7050/10593 (67%)\n",
      "\n",
      "tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.0\tLoss: 0.129009\n",
      "tensor(0.1742, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.2\tLoss: 0.174181\n",
      "tensor(0.1080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.4\tLoss: 0.108046\n",
      "tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.6\tLoss: 0.180358\n",
      "tensor(0.1350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.8\tLoss: 0.135018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 106\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 106\tmaintain_Accuracy: 7050/10593 (67%)\n",
      "\n",
      "tensor(0.0922, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.0\tLoss: 0.092223\n",
      "tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.2\tLoss: 0.190882\n",
      "tensor(0.1457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.4\tLoss: 0.145726\n",
      "tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.6\tLoss: 0.189037\n",
      "tensor(0.1664, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.8\tLoss: 0.166437\n",
      "\n",
      "Test Epoch: 107\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 107\tmaintain_Accuracy: 7051/10593 (67%)\n",
      "\n",
      "tensor(0.1353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.0\tLoss: 0.135306\n",
      "tensor(0.1166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.2\tLoss: 0.116623\n",
      "tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.4\tLoss: 0.150514\n",
      "tensor(0.1183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.6\tLoss: 0.118349\n",
      "tensor(0.1225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.8\tLoss: 0.122535\n",
      "\n",
      "Test Epoch: 108\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 108\tmaintain_Accuracy: 7052/10593 (67%)\n",
      "\n",
      "tensor(0.0707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.0\tLoss: 0.070669\n",
      "tensor(0.1459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.2\tLoss: 0.145853\n",
      "tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.4\tLoss: 0.089112\n",
      "tensor(0.1192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.6\tLoss: 0.119154\n",
      "tensor(0.1367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.8\tLoss: 0.136737\n",
      "\n",
      "Test Epoch: 109\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 109\tmaintain_Accuracy: 7052/10593 (67%)\n",
      "\n",
      "tensor(0.1296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.0\tLoss: 0.129594\n",
      "tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.2\tLoss: 0.133643\n",
      "tensor(0.0980, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.4\tLoss: 0.097958\n",
      "tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.6\tLoss: 0.069958\n",
      "tensor(0.1874, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.8\tLoss: 0.187364\n",
      "\n",
      "Train Epoch: 110\tAttack_Accuracy: 4747/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 110\tmaintain_Accuracy: 4250/6400 (66%)\n",
      "\n",
      "alpha: 0.4207963308521858\n",
      "\n",
      "Test Epoch: 110\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 110\tmaintain_Accuracy: 7053/10593 (67%)\n",
      "\n",
      "tensor(0.1377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.0\tLoss: 0.137683\n",
      "tensor(0.1400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.2\tLoss: 0.139960\n",
      "tensor(0.0892, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.4\tLoss: 0.089224\n",
      "tensor(0.1695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.6\tLoss: 0.169537\n",
      "tensor(0.1381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.8\tLoss: 0.138139\n",
      "\n",
      "Test Epoch: 111\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 111\tmaintain_Accuracy: 7054/10593 (67%)\n",
      "\n",
      "tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.0\tLoss: 0.109531\n",
      "tensor(0.1367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.2\tLoss: 0.136668\n",
      "tensor(0.0541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.4\tLoss: 0.054097\n",
      "tensor(0.1356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.6\tLoss: 0.135618\n",
      "tensor(0.1509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.8\tLoss: 0.150854\n",
      "\n",
      "Test Epoch: 112\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 112\tmaintain_Accuracy: 7045/10593 (67%)\n",
      "\n",
      "tensor(0.1131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.0\tLoss: 0.113101\n",
      "tensor(0.1589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.2\tLoss: 0.158914\n",
      "tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.4\tLoss: 0.221170\n",
      "tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.6\tLoss: 0.062474\n",
      "tensor(0.1646, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.8\tLoss: 0.164615\n",
      "\n",
      "Test Epoch: 113\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 113\tmaintain_Accuracy: 7046/10593 (67%)\n",
      "\n",
      "tensor(0.1370, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.0\tLoss: 0.137040\n",
      "tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.2\tLoss: 0.085535\n",
      "tensor(0.1444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.4\tLoss: 0.144406\n",
      "tensor(0.1343, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.6\tLoss: 0.134260\n",
      "tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.8\tLoss: 0.184774\n",
      "\n",
      "Test Epoch: 114\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 114\tmaintain_Accuracy: 7047/10593 (67%)\n",
      "\n",
      "tensor(0.1149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.0\tLoss: 0.114875\n",
      "tensor(0.1425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.2\tLoss: 0.142507\n",
      "tensor(0.1387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.4\tLoss: 0.138682\n",
      "tensor(0.1439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.6\tLoss: 0.143900\n",
      "tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.8\tLoss: 0.188908\n",
      "\n",
      "Train Epoch: 115\tAttack_Accuracy: 4665/6400 (73%)\n",
      "\n",
      "\n",
      "Train Epoch: 115\tmaintain_Accuracy: 4265/6400 (67%)\n",
      "\n",
      "alpha: 0.4955533383023738\n",
      "\n",
      "Test Epoch: 115\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 115\tmaintain_Accuracy: 7042/10593 (66%)\n",
      "\n",
      "tensor(0.1192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.0\tLoss: 0.119236\n",
      "tensor(0.1195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.2\tLoss: 0.119492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1795, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.4\tLoss: 0.179513\n",
      "tensor(0.1679, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.6\tLoss: 0.167855\n",
      "tensor(0.1367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.8\tLoss: 0.136740\n",
      "\n",
      "Test Epoch: 116\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 116\tmaintain_Accuracy: 7042/10593 (66%)\n",
      "\n",
      "tensor(0.1706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.0\tLoss: 0.170595\n",
      "tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.2\tLoss: 0.065829\n",
      "tensor(0.1065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.4\tLoss: 0.106494\n",
      "tensor(0.0861, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.6\tLoss: 0.086114\n",
      "tensor(0.1195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.8\tLoss: 0.119475\n",
      "\n",
      "Test Epoch: 117\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 117\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.1517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.0\tLoss: 0.151718\n",
      "tensor(0.1344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.2\tLoss: 0.134358\n",
      "tensor(0.1388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.4\tLoss: 0.138796\n",
      "tensor(0.1614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.6\tLoss: 0.161357\n",
      "tensor(0.1405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.8\tLoss: 0.140544\n",
      "\n",
      "Test Epoch: 118\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 118\tmaintain_Accuracy: 7044/10593 (66%)\n",
      "\n",
      "tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.0\tLoss: 0.098410\n",
      "tensor(0.0897, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.2\tLoss: 0.089743\n",
      "tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.4\tLoss: 0.099370\n",
      "tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.6\tLoss: 0.097066\n",
      "tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.8\tLoss: 0.128492\n",
      "\n",
      "Test Epoch: 119\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 119\tmaintain_Accuracy: 7042/10593 (66%)\n",
      "\n",
      "tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.0\tLoss: 0.133877\n",
      "tensor(0.1110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.2\tLoss: 0.110957\n",
      "tensor(0.1309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.4\tLoss: 0.130906\n",
      "tensor(0.1463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.6\tLoss: 0.146290\n",
      "tensor(0.1082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.8\tLoss: 0.108217\n",
      "\n",
      "Train Epoch: 120\tAttack_Accuracy: 4657/6400 (73%)\n",
      "\n",
      "\n",
      "Train Epoch: 120\tmaintain_Accuracy: 4295/6400 (67%)\n",
      "\n",
      "alpha: 0.5228563373512536\n",
      "\n",
      "Test Epoch: 120\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 120\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.0\tLoss: 0.098386\n",
      "tensor(0.0979, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.2\tLoss: 0.097855\n",
      "tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.4\tLoss: 0.099042\n",
      "tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.6\tLoss: 0.089986\n",
      "tensor(0.1766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.8\tLoss: 0.176588\n",
      "\n",
      "Test Epoch: 121\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 121\tmaintain_Accuracy: 7038/10593 (66%)\n",
      "\n",
      "tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.0\tLoss: 0.139032\n",
      "tensor(0.1722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.2\tLoss: 0.172202\n",
      "tensor(0.1204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.4\tLoss: 0.120351\n",
      "tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.6\tLoss: 0.128499\n",
      "tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.8\tLoss: 0.099041\n",
      "\n",
      "Test Epoch: 122\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 122\tmaintain_Accuracy: 7039/10593 (66%)\n",
      "\n",
      "tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.0\tLoss: 0.130993\n",
      "tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.2\tLoss: 0.070104\n",
      "tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.4\tLoss: 0.128899\n",
      "tensor(0.0787, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.6\tLoss: 0.078685\n",
      "tensor(0.0853, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.8\tLoss: 0.085341\n",
      "\n",
      "Test Epoch: 123\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 123\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.1304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.0\tLoss: 0.130405\n",
      "tensor(0.1328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.2\tLoss: 0.132848\n",
      "tensor(0.1741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.4\tLoss: 0.174068\n",
      "tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.6\tLoss: 0.195020\n",
      "tensor(0.0610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.8\tLoss: 0.060953\n",
      "\n",
      "Test Epoch: 124\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 124\tmaintain_Accuracy: 7042/10593 (66%)\n",
      "\n",
      "tensor(0.1666, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.0\tLoss: 0.166628\n",
      "tensor(0.1090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.2\tLoss: 0.108957\n",
      "tensor(0.1369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.4\tLoss: 0.136890\n",
      "tensor(0.1248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.6\tLoss: 0.124780\n",
      "tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.8\tLoss: 0.159285\n",
      "\n",
      "Train Epoch: 125\tAttack_Accuracy: 4663/6400 (73%)\n",
      "\n",
      "\n",
      "Train Epoch: 125\tmaintain_Accuracy: 4264/6400 (67%)\n",
      "\n",
      "alpha: 0.504638548751377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 125\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 125\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.1465, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.0\tLoss: 0.146534\n",
      "tensor(0.1296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.2\tLoss: 0.129591\n",
      "tensor(0.1521, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.4\tLoss: 0.152149\n",
      "tensor(0.1472, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.6\tLoss: 0.147182\n",
      "tensor(0.1614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.8\tLoss: 0.161393\n",
      "\n",
      "Test Epoch: 126\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 126\tmaintain_Accuracy: 7040/10593 (66%)\n",
      "\n",
      "tensor(0.1482, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.0\tLoss: 0.148221\n",
      "tensor(0.1053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.2\tLoss: 0.105268\n",
      "tensor(0.0822, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.4\tLoss: 0.082201\n",
      "tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.6\tLoss: 0.199706\n",
      "tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.8\tLoss: 0.128943\n",
      "\n",
      "Test Epoch: 127\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 127\tmaintain_Accuracy: 7041/10593 (66%)\n",
      "\n",
      "tensor(0.1366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.0\tLoss: 0.136606\n",
      "tensor(0.1487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.2\tLoss: 0.148669\n",
      "tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.4\tLoss: 0.132292\n",
      "tensor(0.1385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.6\tLoss: 0.138546\n",
      "tensor(0.1193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.8\tLoss: 0.119252\n",
      "\n",
      "Test Epoch: 128\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 128\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.0\tLoss: 0.127244\n",
      "tensor(0.1017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.2\tLoss: 0.101667\n",
      "tensor(0.1228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.4\tLoss: 0.122772\n",
      "tensor(0.1650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.6\tLoss: 0.164979\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.8\tLoss: 0.118090\n",
      "\n",
      "Test Epoch: 129\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 129\tmaintain_Accuracy: 7042/10593 (66%)\n",
      "\n",
      "tensor(0.1365, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.0\tLoss: 0.136546\n",
      "tensor(0.1003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.2\tLoss: 0.100338\n",
      "tensor(0.1306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.4\tLoss: 0.130571\n",
      "tensor(0.0722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.6\tLoss: 0.072248\n",
      "tensor(0.1411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.8\tLoss: 0.141077\n",
      "\n",
      "Train Epoch: 130\tAttack_Accuracy: 4771/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 130\tmaintain_Accuracy: 4250/6400 (66%)\n",
      "\n",
      "alpha: 0.5571084158471655\n",
      "\n",
      "Test Epoch: 130\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 130\tmaintain_Accuracy: 7040/10593 (66%)\n",
      "\n",
      "tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.0\tLoss: 0.131960\n",
      "tensor(0.0956, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.2\tLoss: 0.095604\n",
      "tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.4\tLoss: 0.207076\n",
      "tensor(0.1594, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.6\tLoss: 0.159353\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.8\tLoss: 0.011818\n",
      "\n",
      "Test Epoch: 131\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 131\tmaintain_Accuracy: 7044/10593 (66%)\n",
      "\n",
      "tensor(0.0843, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.0\tLoss: 0.084293\n",
      "tensor(0.1197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.2\tLoss: 0.119676\n",
      "tensor(0.1101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.4\tLoss: 0.110098\n",
      "tensor(0.1363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.6\tLoss: 0.136257\n",
      "tensor(0.1723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.8\tLoss: 0.172270\n",
      "\n",
      "Test Epoch: 132\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 132\tmaintain_Accuracy: 7042/10593 (66%)\n",
      "\n",
      "tensor(0.1219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.0\tLoss: 0.121869\n",
      "tensor(0.1397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.2\tLoss: 0.139739\n",
      "tensor(0.1493, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.4\tLoss: 0.149340\n",
      "tensor(0.1038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.6\tLoss: 0.103821\n",
      "tensor(0.0743, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.8\tLoss: 0.074335\n",
      "\n",
      "Test Epoch: 133\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 133\tmaintain_Accuracy: 7045/10593 (67%)\n",
      "\n",
      "tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.0\tLoss: 0.199902\n",
      "tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.2\tLoss: 0.185477\n",
      "tensor(0.1359, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.4\tLoss: 0.135945\n",
      "tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.6\tLoss: 0.179836\n",
      "tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.8\tLoss: 0.153509\n",
      "\n",
      "Test Epoch: 134\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 134\tmaintain_Accuracy: 7044/10593 (66%)\n",
      "\n",
      "tensor(0.1305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.0\tLoss: 0.130507\n",
      "tensor(0.1306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.2\tLoss: 0.130605\n",
      "tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.4\tLoss: 0.123703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.6\tLoss: 0.114711\n",
      "tensor(0.1364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.8\tLoss: 0.136433\n",
      "\n",
      "Train Epoch: 135\tAttack_Accuracy: 4704/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 135\tmaintain_Accuracy: 4236/6400 (66%)\n",
      "\n",
      "alpha: 0.3184533230895694\n",
      "\n",
      "Test Epoch: 135\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 135\tmaintain_Accuracy: 7048/10593 (67%)\n",
      "\n",
      "tensor(0.1584, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.0\tLoss: 0.158373\n",
      "tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.2\tLoss: 0.108097\n",
      "tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.4\tLoss: 0.123532\n",
      "tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.6\tLoss: 0.184388\n",
      "tensor(0.1065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.8\tLoss: 0.106484\n",
      "\n",
      "Test Epoch: 136\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 136\tmaintain_Accuracy: 7047/10593 (67%)\n",
      "\n",
      "tensor(0.0771, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.0\tLoss: 0.077127\n",
      "tensor(0.1366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.2\tLoss: 0.136562\n",
      "tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.4\tLoss: 0.187257\n",
      "tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.6\tLoss: 0.109682\n",
      "tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.8\tLoss: 0.131448\n",
      "\n",
      "Test Epoch: 137\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 137\tmaintain_Accuracy: 7050/10593 (67%)\n",
      "\n",
      "tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.0\tLoss: 0.102908\n",
      "tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.2\tLoss: 0.132240\n",
      "tensor(0.0708, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.4\tLoss: 0.070756\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.6\tLoss: 0.117066\n",
      "tensor(0.1387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.8\tLoss: 0.138715\n",
      "\n",
      "Test Epoch: 138\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 138\tmaintain_Accuracy: 7045/10593 (67%)\n",
      "\n",
      "tensor(0.1226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.0\tLoss: 0.122641\n",
      "tensor(0.1795, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.2\tLoss: 0.179470\n",
      "tensor(0.1277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.4\tLoss: 0.127730\n",
      "tensor(0.1109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.6\tLoss: 0.110940\n",
      "tensor(0.1688, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.8\tLoss: 0.168793\n",
      "\n",
      "Test Epoch: 139\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 139\tmaintain_Accuracy: 7053/10593 (67%)\n",
      "\n",
      "tensor(0.0841, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.0\tLoss: 0.084114\n",
      "tensor(0.1244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.2\tLoss: 0.124415\n",
      "tensor(0.1142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.4\tLoss: 0.114248\n",
      "tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.6\tLoss: 0.178417\n",
      "tensor(0.0969, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.8\tLoss: 0.096862\n",
      "\n",
      "Train Epoch: 140\tAttack_Accuracy: 4734/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 140\tmaintain_Accuracy: 4235/6400 (66%)\n",
      "\n",
      "alpha: 0.5293978427088002\n",
      "\n",
      "Test Epoch: 140\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 140\tmaintain_Accuracy: 7052/10593 (67%)\n",
      "\n",
      "tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.0\tLoss: 0.133178\n",
      "tensor(0.1449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.2\tLoss: 0.144867\n",
      "tensor(0.1637, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.4\tLoss: 0.163678\n",
      "tensor(0.1423, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.6\tLoss: 0.142309\n",
      "tensor(0.1470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.8\tLoss: 0.147011\n",
      "\n",
      "Test Epoch: 141\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 141\tmaintain_Accuracy: 7058/10593 (67%)\n",
      "\n",
      "tensor(0.0831, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.0\tLoss: 0.083066\n",
      "tensor(0.1834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.2\tLoss: 0.183400\n",
      "tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.4\tLoss: 0.190334\n",
      "tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.6\tLoss: 0.128975\n",
      "tensor(0.0548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.8\tLoss: 0.054764\n",
      "\n",
      "Test Epoch: 142\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 142\tmaintain_Accuracy: 7052/10593 (67%)\n",
      "\n",
      "tensor(0.1106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.0\tLoss: 0.110645\n",
      "tensor(0.2092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.2\tLoss: 0.209223\n",
      "tensor(0.1432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.4\tLoss: 0.143250\n",
      "tensor(0.1367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.6\tLoss: 0.136705\n",
      "tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.8\tLoss: 0.108085\n",
      "\n",
      "Test Epoch: 143\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 143\tmaintain_Accuracy: 7053/10593 (67%)\n",
      "\n",
      "tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.0\tLoss: 0.184277\n",
      "tensor(0.1302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.2\tLoss: 0.130188\n",
      "tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.4\tLoss: 0.083446\n",
      "tensor(0.1044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.6\tLoss: 0.104360\n",
      "tensor(0.1328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.8\tLoss: 0.132765\n",
      "\n",
      "Test Epoch: 144\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 144\tmaintain_Accuracy: 7047/10593 (67%)\n",
      "\n",
      "tensor(0.1038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.0\tLoss: 0.103777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1869, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.2\tLoss: 0.186946\n",
      "tensor(0.0662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.4\tLoss: 0.066238\n",
      "tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.6\tLoss: 0.103886\n",
      "tensor(0.1108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.8\tLoss: 0.110762\n",
      "\n",
      "Train Epoch: 145\tAttack_Accuracy: 4706/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 145\tmaintain_Accuracy: 4236/6400 (66%)\n",
      "\n",
      "alpha: 0.48835898191043486\n",
      "\n",
      "Test Epoch: 145\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 145\tmaintain_Accuracy: 7049/10593 (67%)\n",
      "\n",
      "tensor(0.1034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.0\tLoss: 0.103450\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.2\tLoss: 0.117120\n",
      "tensor(0.1239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.4\tLoss: 0.123949\n",
      "tensor(0.1377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.6\tLoss: 0.137689\n",
      "tensor(0.1340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.8\tLoss: 0.133983\n",
      "\n",
      "Test Epoch: 146\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 146\tmaintain_Accuracy: 7051/10593 (67%)\n",
      "\n",
      "tensor(0.1522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.0\tLoss: 0.152206\n",
      "tensor(0.1540, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.2\tLoss: 0.153977\n",
      "tensor(0.1265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.4\tLoss: 0.126515\n",
      "tensor(0.1348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.6\tLoss: 0.134841\n",
      "tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.8\tLoss: 0.150680\n",
      "\n",
      "Test Epoch: 147\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 147\tmaintain_Accuracy: 7048/10593 (67%)\n",
      "\n",
      "tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.0\tLoss: 0.125437\n",
      "tensor(0.0756, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.2\tLoss: 0.075584\n",
      "tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.4\tLoss: 0.107477\n",
      "tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.6\tLoss: 0.215952\n",
      "tensor(0.0830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.8\tLoss: 0.083022\n",
      "\n",
      "Test Epoch: 148\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 148\tmaintain_Accuracy: 7053/10593 (67%)\n",
      "\n",
      "tensor(0.1203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.0\tLoss: 0.120329\n",
      "tensor(0.1409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.2\tLoss: 0.140923\n",
      "tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.4\tLoss: 0.109726\n",
      "tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.6\tLoss: 0.125506\n",
      "tensor(0.1440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.8\tLoss: 0.143981\n",
      "\n",
      "Test Epoch: 149\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 149\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.0\tLoss: 0.113639\n",
      "tensor(0.1261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.2\tLoss: 0.126103\n",
      "tensor(0.1513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.4\tLoss: 0.151326\n",
      "tensor(0.1667, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.6\tLoss: 0.166651\n",
      "tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.8\tLoss: 0.092045\n",
      "\n",
      "Train Epoch: 150\tAttack_Accuracy: 4698/6400 (73%)\n",
      "\n",
      "\n",
      "Train Epoch: 150\tmaintain_Accuracy: 4247/6400 (66%)\n",
      "\n",
      "alpha: 0.5141467009527947\n",
      "\n",
      "Test Epoch: 150\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 150\tmaintain_Accuracy: 7045/10593 (67%)\n",
      "\n",
      "tensor(0.1091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.0\tLoss: 0.109061\n",
      "tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.2\tLoss: 0.146870\n",
      "tensor(0.1435, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.4\tLoss: 0.143542\n",
      "tensor(0.1092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.6\tLoss: 0.109245\n",
      "tensor(0.1366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.8\tLoss: 0.136584\n",
      "\n",
      "Test Epoch: 151\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 151\tmaintain_Accuracy: 7049/10593 (67%)\n",
      "\n",
      "tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.0\tLoss: 0.197995\n",
      "tensor(0.1161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.2\tLoss: 0.116121\n",
      "tensor(0.0725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.4\tLoss: 0.072510\n",
      "tensor(0.1149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.6\tLoss: 0.114891\n",
      "tensor(0.1580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.8\tLoss: 0.157984\n",
      "\n",
      "Test Epoch: 152\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 152\tmaintain_Accuracy: 7052/10593 (67%)\n",
      "\n",
      "tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.0\tLoss: 0.103107\n",
      "tensor(0.1251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.2\tLoss: 0.125086\n",
      "tensor(0.1622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.4\tLoss: 0.162234\n",
      "tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.6\tLoss: 0.064292\n",
      "tensor(0.1617, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.8\tLoss: 0.161718\n",
      "\n",
      "Test Epoch: 153\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 153\tmaintain_Accuracy: 7054/10593 (67%)\n",
      "\n",
      "tensor(0.1043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.0\tLoss: 0.104321\n",
      "tensor(0.1678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.2\tLoss: 0.167808\n",
      "tensor(0.1003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.4\tLoss: 0.100264\n",
      "tensor(0.1436, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.6\tLoss: 0.143554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.8\tLoss: 0.061114\n",
      "\n",
      "Test Epoch: 154\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 154\tmaintain_Accuracy: 7053/10593 (67%)\n",
      "\n",
      "tensor(0.1458, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.0\tLoss: 0.145761\n",
      "tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.2\tLoss: 0.055537\n",
      "tensor(0.1326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.4\tLoss: 0.132625\n",
      "tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.6\tLoss: 0.065757\n",
      "tensor(0.1529, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.8\tLoss: 0.152853\n",
      "\n",
      "Train Epoch: 155\tAttack_Accuracy: 4711/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 155\tmaintain_Accuracy: 4263/6400 (67%)\n",
      "\n",
      "alpha: 0.5122902858363615\n",
      "\n",
      "Test Epoch: 155\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 155\tmaintain_Accuracy: 7051/10593 (67%)\n",
      "\n",
      "tensor(0.1179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.0\tLoss: 0.117943\n",
      "tensor(0.1635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.2\tLoss: 0.163537\n",
      "tensor(0.1565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.4\tLoss: 0.156531\n",
      "tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.6\tLoss: 0.200069\n",
      "tensor(0.0684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.8\tLoss: 0.068361\n",
      "\n",
      "Test Epoch: 156\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 156\tmaintain_Accuracy: 7045/10593 (67%)\n",
      "\n",
      "tensor(0.0487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.0\tLoss: 0.048656\n",
      "tensor(0.1137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.2\tLoss: 0.113663\n",
      "tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.4\tLoss: 0.133758\n",
      "tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.6\tLoss: 0.093815\n",
      "tensor(0.1419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.8\tLoss: 0.141923\n",
      "\n",
      "Test Epoch: 157\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 157\tmaintain_Accuracy: 7049/10593 (67%)\n",
      "\n",
      "tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.0\tLoss: 0.178398\n",
      "tensor(0.0793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.2\tLoss: 0.079331\n",
      "tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.4\tLoss: 0.079688\n",
      "tensor(0.1367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.6\tLoss: 0.136683\n",
      "tensor(0.1739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.8\tLoss: 0.173855\n",
      "\n",
      "Test Epoch: 158\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 158\tmaintain_Accuracy: 7049/10593 (67%)\n",
      "\n",
      "tensor(0.1581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.0\tLoss: 0.158146\n",
      "tensor(0.1781, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.2\tLoss: 0.178117\n",
      "tensor(0.1432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.4\tLoss: 0.143160\n",
      "tensor(0.1666, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.6\tLoss: 0.166632\n",
      "tensor(0.1297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.8\tLoss: 0.129682\n",
      "\n",
      "Test Epoch: 159\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 159\tmaintain_Accuracy: 7049/10593 (67%)\n",
      "\n",
      "tensor(0.1008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.0\tLoss: 0.100765\n",
      "tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.2\tLoss: 0.181610\n",
      "tensor(0.1540, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.4\tLoss: 0.154042\n",
      "tensor(0.1264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.6\tLoss: 0.126432\n",
      "tensor(0.1548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.8\tLoss: 0.154772\n",
      "\n",
      "Train Epoch: 160\tAttack_Accuracy: 4733/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 160\tmaintain_Accuracy: 4249/6400 (66%)\n",
      "\n",
      "alpha: 0.5317493036510761\n",
      "\n",
      "Test Epoch: 160\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 160\tmaintain_Accuracy: 7047/10593 (67%)\n",
      "\n",
      "tensor(0.1269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.0\tLoss: 0.126925\n",
      "tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.2\tLoss: 0.192282\n",
      "tensor(0.1563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.4\tLoss: 0.156334\n",
      "tensor(0.1118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.6\tLoss: 0.111797\n",
      "tensor(0.1352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.8\tLoss: 0.135232\n",
      "\n",
      "Test Epoch: 161\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 161\tmaintain_Accuracy: 7049/10593 (67%)\n",
      "\n",
      "tensor(0.0960, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.0\tLoss: 0.096042\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.2\tLoss: 0.117235\n",
      "tensor(0.1198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.4\tLoss: 0.119828\n",
      "tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.6\tLoss: 0.058036\n",
      "tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.8\tLoss: 0.185886\n",
      "\n",
      "Test Epoch: 162\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 162\tmaintain_Accuracy: 7052/10593 (67%)\n",
      "\n",
      "tensor(0.1160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.0\tLoss: 0.116049\n",
      "tensor(0.1053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.2\tLoss: 0.105280\n",
      "tensor(0.1077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.4\tLoss: 0.107659\n",
      "tensor(0.1496, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.6\tLoss: 0.149642\n",
      "tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.8\tLoss: 0.146814\n",
      "\n",
      "Test Epoch: 163\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 163\tmaintain_Accuracy: 7054/10593 (67%)\n",
      "\n",
      "tensor(0.1808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.0\tLoss: 0.180755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0756, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.2\tLoss: 0.075601\n",
      "tensor(0.1601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.4\tLoss: 0.160136\n",
      "tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.6\tLoss: 0.212243\n",
      "tensor(0.0927, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.8\tLoss: 0.092684\n",
      "\n",
      "Test Epoch: 164\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 164\tmaintain_Accuracy: 7054/10593 (67%)\n",
      "\n",
      "tensor(0.0720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.0\tLoss: 0.071955\n",
      "tensor(0.1802, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.2\tLoss: 0.180187\n",
      "tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.4\tLoss: 0.111197\n",
      "tensor(0.1337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.6\tLoss: 0.133667\n",
      "tensor(0.1370, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.8\tLoss: 0.137016\n",
      "\n",
      "Train Epoch: 165\tAttack_Accuracy: 4779/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 165\tmaintain_Accuracy: 4212/6400 (66%)\n",
      "\n",
      "alpha: 0.5118219679901415\n",
      "\n",
      "Test Epoch: 165\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 165\tmaintain_Accuracy: 7048/10593 (67%)\n",
      "\n",
      "tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.0\tLoss: 0.078371\n",
      "tensor(0.0865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.2\tLoss: 0.086528\n",
      "tensor(0.1140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.4\tLoss: 0.113970\n",
      "tensor(0.1773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.6\tLoss: 0.177337\n",
      "tensor(0.1085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.8\tLoss: 0.108524\n",
      "\n",
      "Test Epoch: 166\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 166\tmaintain_Accuracy: 7051/10593 (67%)\n",
      "\n",
      "tensor(0.1941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.0\tLoss: 0.194111\n",
      "tensor(0.1090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.2\tLoss: 0.108973\n",
      "tensor(0.1857, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.4\tLoss: 0.185713\n",
      "tensor(0.0722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.6\tLoss: 0.072166\n",
      "tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.8\tLoss: 0.061900\n",
      "\n",
      "Test Epoch: 167\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 167\tmaintain_Accuracy: 7048/10593 (67%)\n",
      "\n",
      "tensor(0.1257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.0\tLoss: 0.125729\n",
      "tensor(0.1452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.2\tLoss: 0.145189\n",
      "tensor(0.1139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.4\tLoss: 0.113872\n",
      "tensor(0.0991, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.6\tLoss: 0.099066\n",
      "tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.8\tLoss: 0.140785\n",
      "\n",
      "Test Epoch: 168\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 168\tmaintain_Accuracy: 7051/10593 (67%)\n",
      "\n",
      "tensor(0.1197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.0\tLoss: 0.119737\n",
      "tensor(0.1210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.2\tLoss: 0.120965\n",
      "tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.4\tLoss: 0.162405\n",
      "tensor(0.1393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.6\tLoss: 0.139294\n",
      "tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.8\tLoss: 0.203980\n",
      "\n",
      "Test Epoch: 169\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 169\tmaintain_Accuracy: 7050/10593 (67%)\n",
      "\n",
      "tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.0\tLoss: 0.111472\n",
      "tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.2\tLoss: 0.068115\n",
      "tensor(0.1148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.4\tLoss: 0.114842\n",
      "tensor(0.1473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.6\tLoss: 0.147265\n",
      "tensor(0.0837, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.8\tLoss: 0.083726\n",
      "\n",
      "Train Epoch: 170\tAttack_Accuracy: 4713/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 170\tmaintain_Accuracy: 4276/6400 (67%)\n",
      "\n",
      "alpha: 0.5424623175122255\n",
      "\n",
      "Test Epoch: 170\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 170\tmaintain_Accuracy: 7046/10593 (67%)\n",
      "\n",
      "tensor(0.0655, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.0\tLoss: 0.065460\n",
      "tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.2\tLoss: 0.103543\n",
      "tensor(0.1078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.4\tLoss: 0.107761\n",
      "tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.6\tLoss: 0.105969\n",
      "tensor(0.1120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.8\tLoss: 0.112012\n",
      "\n",
      "Test Epoch: 171\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 171\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.0\tLoss: 0.186158\n",
      "tensor(0.1066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.2\tLoss: 0.106561\n",
      "tensor(0.1717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.4\tLoss: 0.171683\n",
      "tensor(0.1231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.6\tLoss: 0.123074\n",
      "tensor(0.1683, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.8\tLoss: 0.168258\n",
      "\n",
      "Test Epoch: 172\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 172\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.0\tLoss: 0.076434\n",
      "tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.2\tLoss: 0.152373\n",
      "tensor(0.1501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.4\tLoss: 0.150105\n",
      "tensor(0.0467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.6\tLoss: 0.046707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0835, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.8\tLoss: 0.083538\n",
      "\n",
      "Test Epoch: 173\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 173\tmaintain_Accuracy: 7048/10593 (67%)\n",
      "\n",
      "tensor(0.1227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.0\tLoss: 0.122661\n",
      "tensor(0.1383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.2\tLoss: 0.138296\n",
      "tensor(0.0977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.4\tLoss: 0.097651\n",
      "tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.6\tLoss: 0.051447\n",
      "tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.8\tLoss: 0.074471\n",
      "\n",
      "Test Epoch: 174\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 174\tmaintain_Accuracy: 7047/10593 (67%)\n",
      "\n",
      "tensor(0.0940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.0\tLoss: 0.094017\n",
      "tensor(0.0550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.2\tLoss: 0.054996\n",
      "tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.4\tLoss: 0.079698\n",
      "tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.6\tLoss: 0.125475\n",
      "tensor(0.1214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.8\tLoss: 0.121417\n",
      "\n",
      "Train Epoch: 175\tAttack_Accuracy: 4736/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 175\tmaintain_Accuracy: 4292/6400 (67%)\n",
      "\n",
      "alpha: 0.4947564509498812\n",
      "\n",
      "Test Epoch: 175\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 175\tmaintain_Accuracy: 7046/10593 (67%)\n",
      "\n",
      "tensor(0.1845, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.0\tLoss: 0.184456\n",
      "tensor(0.1388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.2\tLoss: 0.138756\n",
      "tensor(0.0914, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.4\tLoss: 0.091366\n",
      "tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.6\tLoss: 0.093092\n",
      "tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.8\tLoss: 0.098489\n",
      "\n",
      "Test Epoch: 176\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 176\tmaintain_Accuracy: 7045/10593 (67%)\n",
      "\n",
      "tensor(0.1829, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.0\tLoss: 0.182899\n",
      "tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.2\tLoss: 0.110173\n",
      "tensor(0.1243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.4\tLoss: 0.124275\n",
      "tensor(0.0831, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.6\tLoss: 0.083120\n",
      "tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.8\tLoss: 0.144502\n",
      "\n",
      "Test Epoch: 177\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 177\tmaintain_Accuracy: 7047/10593 (67%)\n",
      "\n",
      "tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.0\tLoss: 0.088638\n",
      "tensor(0.2086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.2\tLoss: 0.208624\n",
      "tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.4\tLoss: 0.083388\n",
      "tensor(0.1317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.6\tLoss: 0.131671\n",
      "tensor(0.1193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.8\tLoss: 0.119307\n",
      "\n",
      "Test Epoch: 178\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 178\tmaintain_Accuracy: 7045/10593 (67%)\n",
      "\n",
      "tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.0\tLoss: 0.065826\n",
      "tensor(0.1201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.2\tLoss: 0.120062\n",
      "tensor(0.1639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.4\tLoss: 0.163910\n",
      "tensor(0.1368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.6\tLoss: 0.136847\n",
      "tensor(0.1207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.8\tLoss: 0.120696\n",
      "\n",
      "Test Epoch: 179\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 179\tmaintain_Accuracy: 7048/10593 (67%)\n",
      "\n",
      "tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.0\tLoss: 0.121094\n",
      "tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.2\tLoss: 0.072368\n",
      "tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.4\tLoss: 0.105590\n",
      "tensor(0.1596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.6\tLoss: 0.159588\n",
      "tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.8\tLoss: 0.190811\n",
      "\n",
      "Train Epoch: 180\tAttack_Accuracy: 4666/6400 (73%)\n",
      "\n",
      "\n",
      "Train Epoch: 180\tmaintain_Accuracy: 4284/6400 (67%)\n",
      "\n",
      "alpha: 0.4643078521884088\n",
      "\n",
      "Test Epoch: 180\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 180\tmaintain_Accuracy: 7054/10593 (67%)\n",
      "\n",
      "tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.0\tLoss: 0.229011\n",
      "tensor(0.0847, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.2\tLoss: 0.084687\n",
      "tensor(0.1088, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.4\tLoss: 0.108812\n",
      "tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.6\tLoss: 0.103908\n",
      "tensor(0.1159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.8\tLoss: 0.115945\n",
      "\n",
      "Test Epoch: 181\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 181\tmaintain_Accuracy: 7050/10593 (67%)\n",
      "\n",
      "tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.0\tLoss: 0.123746\n",
      "tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.2\tLoss: 0.090989\n",
      "tensor(0.1169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.4\tLoss: 0.116937\n",
      "tensor(0.1176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.6\tLoss: 0.117554\n",
      "tensor(0.1893, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.8\tLoss: 0.189275\n",
      "\n",
      "Test Epoch: 182\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 182\tmaintain_Accuracy: 7054/10593 (67%)\n",
      "\n",
      "tensor(0.1213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.0\tLoss: 0.121309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.2\tLoss: 0.032283\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.4\tLoss: 0.048901\n",
      "tensor(0.1242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.6\tLoss: 0.124190\n",
      "tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.8\tLoss: 0.056676\n",
      "\n",
      "Test Epoch: 183\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 183\tmaintain_Accuracy: 7045/10593 (67%)\n",
      "\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.0\tLoss: 0.117663\n",
      "tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.2\tLoss: 0.145294\n",
      "tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.4\tLoss: 0.101927\n",
      "tensor(0.1053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.6\tLoss: 0.105272\n",
      "tensor(0.1047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.8\tLoss: 0.104667\n",
      "\n",
      "Test Epoch: 184\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 184\tmaintain_Accuracy: 7045/10593 (67%)\n",
      "\n",
      "tensor(0.1230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.0\tLoss: 0.122984\n",
      "tensor(0.1045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.2\tLoss: 0.104501\n",
      "tensor(0.1707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.4\tLoss: 0.170679\n",
      "tensor(0.1026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.6\tLoss: 0.102596\n",
      "tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.8\tLoss: 0.130329\n",
      "\n",
      "Train Epoch: 185\tAttack_Accuracy: 4738/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 185\tmaintain_Accuracy: 4234/6400 (66%)\n",
      "\n",
      "alpha: 0.3887966640630396\n",
      "\n",
      "Test Epoch: 185\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 185\tmaintain_Accuracy: 7052/10593 (67%)\n",
      "\n",
      "tensor(0.1581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.0\tLoss: 0.158106\n",
      "tensor(0.1595, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.2\tLoss: 0.159545\n",
      "tensor(0.0809, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.4\tLoss: 0.080877\n",
      "tensor(0.1597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.6\tLoss: 0.159676\n",
      "tensor(0.1195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.8\tLoss: 0.119487\n",
      "\n",
      "Test Epoch: 186\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 186\tmaintain_Accuracy: 7050/10593 (67%)\n",
      "\n",
      "tensor(0.1697, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.0\tLoss: 0.169666\n",
      "tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.2\tLoss: 0.057143\n",
      "tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.4\tLoss: 0.084989\n",
      "tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.6\tLoss: 0.113410\n",
      "tensor(0.1653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.8\tLoss: 0.165348\n",
      "\n",
      "Test Epoch: 187\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 187\tmaintain_Accuracy: 7048/10593 (67%)\n",
      "\n",
      "tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.0\tLoss: 0.154086\n",
      "tensor(0.1194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.2\tLoss: 0.119393\n",
      "tensor(0.1301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.4\tLoss: 0.130091\n",
      "tensor(0.0934, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.6\tLoss: 0.093420\n",
      "tensor(0.1533, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.8\tLoss: 0.153311\n",
      "\n",
      "Test Epoch: 188\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 188\tmaintain_Accuracy: 7052/10593 (67%)\n",
      "\n",
      "tensor(0.0934, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.0\tLoss: 0.093388\n",
      "tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.2\tLoss: 0.151235\n",
      "tensor(0.0779, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.4\tLoss: 0.077916\n",
      "tensor(0.1424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.6\tLoss: 0.142382\n",
      "tensor(0.1184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.8\tLoss: 0.118441\n",
      "\n",
      "Test Epoch: 189\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 189\tmaintain_Accuracy: 7049/10593 (67%)\n",
      "\n",
      "tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.0\tLoss: 0.158320\n",
      "tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.2\tLoss: 0.145599\n",
      "tensor(0.0821, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.4\tLoss: 0.082149\n",
      "tensor(0.1713, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.6\tLoss: 0.171347\n",
      "tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.8\tLoss: 0.217084\n",
      "\n",
      "Train Epoch: 190\tAttack_Accuracy: 4709/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 190\tmaintain_Accuracy: 4301/6400 (67%)\n",
      "\n",
      "alpha: 0.5124709587823648\n",
      "\n",
      "Test Epoch: 190\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 190\tmaintain_Accuracy: 7051/10593 (67%)\n",
      "\n",
      "tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.0\tLoss: 0.053445\n",
      "tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.2\tLoss: 0.171846\n",
      "tensor(0.1205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.4\tLoss: 0.120458\n",
      "tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.6\tLoss: 0.211989\n",
      "tensor(0.1288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.8\tLoss: 0.128793\n",
      "\n",
      "Test Epoch: 191\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 191\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.1128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.0\tLoss: 0.112818\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.2\tLoss: 0.039767\n",
      "tensor(0.0675, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.4\tLoss: 0.067543\n",
      "tensor(0.1258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.6\tLoss: 0.125780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.8\tLoss: 0.173377\n",
      "\n",
      "Test Epoch: 192\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 192\tmaintain_Accuracy: 7049/10593 (67%)\n",
      "\n",
      "tensor(0.0986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.0\tLoss: 0.098626\n",
      "tensor(0.1467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.2\tLoss: 0.146673\n",
      "tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.4\tLoss: 0.093131\n",
      "tensor(0.1707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.6\tLoss: 0.170707\n",
      "tensor(0.1170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.8\tLoss: 0.116973\n",
      "\n",
      "Test Epoch: 193\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 193\tmaintain_Accuracy: 7048/10593 (67%)\n",
      "\n",
      "tensor(0.0999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.0\tLoss: 0.099861\n",
      "tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.2\tLoss: 0.152970\n",
      "tensor(0.1093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.4\tLoss: 0.109296\n",
      "tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.6\tLoss: 0.076129\n",
      "tensor(0.1330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.8\tLoss: 0.133032\n",
      "\n",
      "Test Epoch: 194\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 194\tmaintain_Accuracy: 7044/10593 (66%)\n",
      "\n",
      "tensor(0.1429, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.0\tLoss: 0.142917\n",
      "tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.2\tLoss: 0.060335\n",
      "tensor(0.1326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.4\tLoss: 0.132607\n",
      "tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.6\tLoss: 0.086828\n",
      "tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.8\tLoss: 0.108396\n",
      "\n",
      "Train Epoch: 195\tAttack_Accuracy: 4685/6400 (73%)\n",
      "\n",
      "\n",
      "Train Epoch: 195\tmaintain_Accuracy: 4277/6400 (67%)\n",
      "\n",
      "alpha: 0.5288414915715519\n",
      "\n",
      "Test Epoch: 195\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 195\tmaintain_Accuracy: 7044/10593 (66%)\n",
      "\n",
      "tensor(0.1133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.0\tLoss: 0.113267\n",
      "tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.2\tLoss: 0.125882\n",
      "tensor(0.1368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.4\tLoss: 0.136816\n",
      "tensor(0.1337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.6\tLoss: 0.133690\n",
      "tensor(0.1205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.8\tLoss: 0.120536\n",
      "\n",
      "Test Epoch: 196\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 196\tmaintain_Accuracy: 7039/10593 (66%)\n",
      "\n",
      "tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.0\tLoss: 0.112394\n",
      "tensor(0.1447, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.2\tLoss: 0.144656\n",
      "tensor(0.0860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.4\tLoss: 0.086002\n",
      "tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.6\tLoss: 0.136169\n",
      "tensor(0.0821, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.8\tLoss: 0.082100\n",
      "\n",
      "Test Epoch: 197\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 197\tmaintain_Accuracy: 7042/10593 (66%)\n",
      "\n",
      "tensor(0.1574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.0\tLoss: 0.157408\n",
      "tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.2\tLoss: 0.222204\n",
      "tensor(0.1319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.4\tLoss: 0.131918\n",
      "tensor(0.1486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.6\tLoss: 0.148573\n",
      "tensor(0.0950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.8\tLoss: 0.094961\n",
      "\n",
      "Test Epoch: 198\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 198\tmaintain_Accuracy: 7038/10593 (66%)\n",
      "\n",
      "tensor(0.1048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.0\tLoss: 0.104825\n",
      "tensor(0.0775, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.2\tLoss: 0.077510\n",
      "tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.4\tLoss: 0.137494\n",
      "tensor(0.1329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.6\tLoss: 0.132938\n",
      "tensor(0.1142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.8\tLoss: 0.114218\n",
      "\n",
      "Test Epoch: 199\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 199\tmaintain_Accuracy: 7039/10593 (66%)\n",
      "\n",
      "tensor(0.1026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.0\tLoss: 0.102559\n",
      "tensor(0.0793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.2\tLoss: 0.079293\n",
      "tensor(0.1264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.4\tLoss: 0.126363\n",
      "tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.6\tLoss: 0.128896\n",
      "tensor(0.1504, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.8\tLoss: 0.150365\n",
      "\n",
      "Train Epoch: 200\tAttack_Accuracy: 4745/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 200\tmaintain_Accuracy: 4244/6400 (66%)\n",
      "\n",
      "alpha: 0.3591010526436883\n",
      "\n",
      "Test Epoch: 200\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 200\tmaintain_Accuracy: 7042/10593 (66%)\n",
      "\n",
      "tensor(0.0483, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.0\tLoss: 0.048329\n",
      "tensor(0.1480, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.2\tLoss: 0.148029\n",
      "tensor(0.1584, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.4\tLoss: 0.158446\n",
      "tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.6\tLoss: 0.095517\n",
      "tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.8\tLoss: 0.070015\n",
      "\n",
      "Test Epoch: 201\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 201\tmaintain_Accuracy: 7041/10593 (66%)\n",
      "\n",
      "tensor(0.1295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.0\tLoss: 0.129491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.2\tLoss: 0.110181\n",
      "tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.4\tLoss: 0.134885\n",
      "tensor(0.1194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.6\tLoss: 0.119379\n",
      "tensor(0.1104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.8\tLoss: 0.110367\n",
      "\n",
      "Test Epoch: 202\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 202\tmaintain_Accuracy: 7042/10593 (66%)\n",
      "\n",
      "tensor(0.1621, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.0\tLoss: 0.162076\n",
      "tensor(0.0981, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.2\tLoss: 0.098067\n",
      "tensor(0.1600, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.4\tLoss: 0.159992\n",
      "tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.6\tLoss: 0.116755\n",
      "tensor(0.1681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.8\tLoss: 0.168093\n",
      "\n",
      "Test Epoch: 203\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 203\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.1166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.0\tLoss: 0.116588\n",
      "tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.2\tLoss: 0.128537\n",
      "tensor(0.1154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.4\tLoss: 0.115408\n",
      "tensor(0.1313, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.6\tLoss: 0.131325\n",
      "tensor(0.1087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.8\tLoss: 0.108654\n",
      "\n",
      "Test Epoch: 204\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 204\tmaintain_Accuracy: 7045/10593 (67%)\n",
      "\n",
      "tensor(0.1082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.0\tLoss: 0.108180\n",
      "tensor(0.1533, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.2\tLoss: 0.153294\n",
      "tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.4\tLoss: 0.071210\n",
      "tensor(0.0836, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.6\tLoss: 0.083556\n",
      "tensor(0.1193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.8\tLoss: 0.119314\n",
      "\n",
      "Train Epoch: 205\tAttack_Accuracy: 4769/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 205\tmaintain_Accuracy: 4202/6400 (66%)\n",
      "\n",
      "alpha: 0.5504529164206724\n",
      "\n",
      "Test Epoch: 205\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 205\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.1294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.0\tLoss: 0.129398\n",
      "tensor(0.0818, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.2\tLoss: 0.081782\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.4\tLoss: 0.055284\n",
      "tensor(0.1192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.6\tLoss: 0.119174\n",
      "tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.8\tLoss: 0.133805\n",
      "\n",
      "Test Epoch: 206\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 206\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.1069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.0\tLoss: 0.106863\n",
      "tensor(0.1352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.2\tLoss: 0.135184\n",
      "tensor(0.0830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.4\tLoss: 0.083014\n",
      "tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.6\tLoss: 0.063690\n",
      "tensor(0.1504, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.8\tLoss: 0.150379\n",
      "\n",
      "Test Epoch: 207\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 207\tmaintain_Accuracy: 7045/10593 (67%)\n",
      "\n",
      "tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.0\tLoss: 0.088603\n",
      "tensor(0.0949, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.2\tLoss: 0.094938\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.4\tLoss: 0.117250\n",
      "tensor(0.0837, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.6\tLoss: 0.083727\n",
      "tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.8\tLoss: 0.080242\n",
      "\n",
      "Test Epoch: 208\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 208\tmaintain_Accuracy: 7042/10593 (66%)\n",
      "\n",
      "tensor(0.0933, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.0\tLoss: 0.093252\n",
      "tensor(0.1578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.2\tLoss: 0.157759\n",
      "tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.4\tLoss: 0.146890\n",
      "tensor(0.1189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.6\tLoss: 0.118921\n",
      "tensor(0.1292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.8\tLoss: 0.129202\n",
      "\n",
      "Test Epoch: 209\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 209\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.1083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.0\tLoss: 0.108293\n",
      "tensor(0.1231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.2\tLoss: 0.123095\n",
      "tensor(0.1151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.4\tLoss: 0.115139\n",
      "tensor(0.1114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.6\tLoss: 0.111442\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.8\tLoss: 0.055821\n",
      "\n",
      "Train Epoch: 210\tAttack_Accuracy: 4733/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 210\tmaintain_Accuracy: 4255/6400 (66%)\n",
      "\n",
      "alpha: 0.5495711390252734\n",
      "\n",
      "Test Epoch: 210\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 210\tmaintain_Accuracy: 7041/10593 (66%)\n",
      "\n",
      "tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.0\tLoss: 0.144533\n",
      "tensor(0.1068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.2\tLoss: 0.106803\n",
      "tensor(0.2009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.4\tLoss: 0.200898\n",
      "tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.6\tLoss: 0.104916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.8\tLoss: 0.065264\n",
      "\n",
      "Test Epoch: 211\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 211\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.0\tLoss: 0.076815\n",
      "tensor(0.0975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.2\tLoss: 0.097524\n",
      "tensor(0.0702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.4\tLoss: 0.070150\n",
      "tensor(0.0969, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.6\tLoss: 0.096869\n",
      "tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.8\tLoss: 0.108363\n",
      "\n",
      "Test Epoch: 212\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 212\tmaintain_Accuracy: 7042/10593 (66%)\n",
      "\n",
      "tensor(0.1694, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.0\tLoss: 0.169420\n",
      "tensor(0.1497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.2\tLoss: 0.149652\n",
      "tensor(0.1354, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.4\tLoss: 0.135440\n",
      "tensor(0.0876, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.6\tLoss: 0.087567\n",
      "tensor(0.1213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.8\tLoss: 0.121288\n",
      "\n",
      "Test Epoch: 213\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 213\tmaintain_Accuracy: 7043/10593 (66%)\n",
      "\n",
      "tensor(0.1567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.0\tLoss: 0.156721\n",
      "tensor(0.1215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.2\tLoss: 0.121451\n",
      "tensor(0.1426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.4\tLoss: 0.142607\n",
      "tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.6\tLoss: 0.189667\n",
      "tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.8\tLoss: 0.108091\n",
      "\n",
      "Test Epoch: 214\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 214\tmaintain_Accuracy: 7040/10593 (66%)\n",
      "\n",
      "tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.0\tLoss: 0.087841\n",
      "tensor(0.1334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.2\tLoss: 0.133351\n",
      "tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.4\tLoss: 0.189698\n",
      "tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.6\tLoss: 0.201521\n",
      "tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.8\tLoss: 0.063301\n",
      "\n",
      "Train Epoch: 215\tAttack_Accuracy: 4792/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 215\tmaintain_Accuracy: 4230/6400 (66%)\n",
      "\n",
      "alpha: 0.5667166042183833\n",
      "\n",
      "Test Epoch: 215\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 215\tmaintain_Accuracy: 7039/10593 (66%)\n",
      "\n",
      "tensor(0.1461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.0\tLoss: 0.146083\n",
      "tensor(0.1040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.2\tLoss: 0.103952\n",
      "tensor(0.1023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.4\tLoss: 0.102302\n",
      "tensor(0.1638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.6\tLoss: 0.163769\n",
      "tensor(0.1372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.8\tLoss: 0.137247\n",
      "\n",
      "Test Epoch: 216\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 216\tmaintain_Accuracy: 7041/10593 (66%)\n",
      "\n",
      "tensor(0.1341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.0\tLoss: 0.134118\n",
      "tensor(0.0896, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.2\tLoss: 0.089634\n",
      "tensor(0.1217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.4\tLoss: 0.121712\n",
      "tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.6\tLoss: 0.214727\n",
      "tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.8\tLoss: 0.133331\n",
      "\n",
      "Test Epoch: 217\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 217\tmaintain_Accuracy: 7040/10593 (66%)\n",
      "\n",
      "tensor(0.1673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.0\tLoss: 0.167341\n",
      "tensor(0.1556, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.2\tLoss: 0.155550\n",
      "tensor(0.1304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.4\tLoss: 0.130387\n",
      "tensor(0.1064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.6\tLoss: 0.106435\n",
      "tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.8\tLoss: 0.086971\n",
      "\n",
      "Test Epoch: 218\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 218\tmaintain_Accuracy: 7041/10593 (66%)\n",
      "\n",
      "tensor(0.1082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.0\tLoss: 0.108174\n",
      "tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.2\tLoss: 0.207168\n",
      "tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.4\tLoss: 0.108125\n",
      "tensor(0.1500, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.6\tLoss: 0.150020\n",
      "tensor(0.1013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.8\tLoss: 0.101300\n",
      "\n",
      "Test Epoch: 219\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 219\tmaintain_Accuracy: 7040/10593 (66%)\n",
      "\n",
      "tensor(0.1131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.0\tLoss: 0.113101\n",
      "tensor(0.1452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.2\tLoss: 0.145240\n",
      "tensor(0.0962, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.4\tLoss: 0.096165\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.6\tLoss: 0.117078\n",
      "tensor(0.1437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.8\tLoss: 0.143697\n",
      "\n",
      "Train Epoch: 220\tAttack_Accuracy: 4755/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 220\tmaintain_Accuracy: 4247/6400 (66%)\n",
      "\n",
      "alpha: 0.4573257344770204\n",
      "\n",
      "Test Epoch: 220\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 220\tmaintain_Accuracy: 7041/10593 (66%)\n",
      "\n",
      "tensor(0.0975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.0\tLoss: 0.097510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0836, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.2\tLoss: 0.083607\n",
      "tensor(0.1008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.4\tLoss: 0.100801\n",
      "tensor(0.1094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.6\tLoss: 0.109425\n",
      "tensor(0.1353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.8\tLoss: 0.135339\n",
      "\n",
      "Test Epoch: 221\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 221\tmaintain_Accuracy: 7040/10593 (66%)\n",
      "\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.0\tLoss: 0.117153\n",
      "tensor(0.1528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.2\tLoss: 0.152763\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.4\tLoss: 0.117127\n",
      "tensor(0.1668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.6\tLoss: 0.166755\n",
      "tensor(0.1581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.8\tLoss: 0.158128\n",
      "\n",
      "Test Epoch: 222\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 222\tmaintain_Accuracy: 7039/10593 (66%)\n",
      "\n",
      "tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.0\tLoss: 0.112359\n",
      "tensor(0.0817, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.2\tLoss: 0.081734\n",
      "tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.4\tLoss: 0.060856\n",
      "tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.6\tLoss: 0.153489\n",
      "tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.8\tLoss: 0.152538\n",
      "\n",
      "Test Epoch: 223\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 223\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.0\tLoss: 0.159725\n",
      "tensor(0.0851, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.2\tLoss: 0.085105\n",
      "tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.4\tLoss: 0.117284\n",
      "tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.6\tLoss: 0.117260\n",
      "tensor(0.0958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.8\tLoss: 0.095778\n",
      "\n",
      "Test Epoch: 224\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 224\tmaintain_Accuracy: 7039/10593 (66%)\n",
      "\n",
      "tensor(0.1281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.0\tLoss: 0.128122\n",
      "tensor(0.0787, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.2\tLoss: 0.078747\n",
      "tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.4\tLoss: 0.092040\n",
      "tensor(0.1238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.6\tLoss: 0.123848\n",
      "tensor(0.0917, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.8\tLoss: 0.091686\n",
      "\n",
      "Train Epoch: 225\tAttack_Accuracy: 4791/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 225\tmaintain_Accuracy: 4229/6400 (66%)\n",
      "\n",
      "alpha: 0.5855952759998064\n",
      "\n",
      "Test Epoch: 225\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 225\tmaintain_Accuracy: 7038/10593 (66%)\n",
      "\n",
      "tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.0\tLoss: 0.235717\n",
      "tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.2\tLoss: 0.171860\n",
      "tensor(0.1649, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.4\tLoss: 0.164854\n",
      "tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.6\tLoss: 0.072346\n",
      "tensor(0.1726, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.8\tLoss: 0.172571\n",
      "\n",
      "Test Epoch: 226\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 226\tmaintain_Accuracy: 7040/10593 (66%)\n",
      "\n",
      "tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.0\tLoss: 0.179624\n",
      "tensor(0.1281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.2\tLoss: 0.128080\n",
      "tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.4\tLoss: 0.116736\n",
      "tensor(0.0816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.6\tLoss: 0.081649\n",
      "tensor(0.1347, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.8\tLoss: 0.134667\n",
      "\n",
      "Test Epoch: 227\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 227\tmaintain_Accuracy: 7041/10593 (66%)\n",
      "\n",
      "tensor(0.1265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.0\tLoss: 0.126482\n",
      "tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.2\tLoss: 0.108879\n",
      "tensor(0.1034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.4\tLoss: 0.103405\n",
      "tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.6\tLoss: 0.084538\n",
      "tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.8\tLoss: 0.265014\n",
      "\n",
      "Test Epoch: 228\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 228\tmaintain_Accuracy: 7039/10593 (66%)\n",
      "\n",
      "tensor(0.1197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.0\tLoss: 0.119737\n",
      "tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.2\tLoss: 0.103496\n",
      "tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.4\tLoss: 0.070138\n",
      "tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.6\tLoss: 0.079434\n",
      "tensor(0.1324, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.8\tLoss: 0.132437\n",
      "\n",
      "Test Epoch: 229\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 229\tmaintain_Accuracy: 7039/10593 (66%)\n",
      "\n",
      "tensor(0.0326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.0\tLoss: 0.032582\n",
      "tensor(0.1605, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.2\tLoss: 0.160537\n",
      "tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.4\tLoss: 0.073104\n",
      "tensor(0.1571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.6\tLoss: 0.157138\n",
      "tensor(0.1017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.8\tLoss: 0.101682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 230\tAttack_Accuracy: 4784/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 230\tmaintain_Accuracy: 4259/6400 (67%)\n",
      "\n",
      "alpha: 0.5908652670518113\n",
      "\n",
      "Test Epoch: 230\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 230\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.0\tLoss: 0.192899\n",
      "tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.2\tLoss: 0.133782\n",
      "tensor(0.1007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.4\tLoss: 0.100658\n",
      "tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.6\tLoss: 0.151209\n",
      "tensor(0.1219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.8\tLoss: 0.121920\n",
      "\n",
      "Test Epoch: 231\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 231\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.0\tLoss: 0.139960\n",
      "tensor(0.1770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.2\tLoss: 0.176998\n",
      "tensor(0.1515, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.4\tLoss: 0.151502\n",
      "tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.6\tLoss: 0.133249\n",
      "tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.8\tLoss: 0.154073\n",
      "\n",
      "Test Epoch: 232\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 232\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1634, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.0\tLoss: 0.163375\n",
      "tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.2\tLoss: 0.079695\n",
      "tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.4\tLoss: 0.146845\n",
      "tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.6\tLoss: 0.188293\n",
      "tensor(0.0438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.8\tLoss: 0.043809\n",
      "\n",
      "Test Epoch: 233\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 233\tmaintain_Accuracy: 7038/10593 (66%)\n",
      "\n",
      "tensor(0.1441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.0\tLoss: 0.144054\n",
      "tensor(0.1374, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.2\tLoss: 0.137363\n",
      "tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.4\tLoss: 0.132254\n",
      "tensor(0.1812, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.6\tLoss: 0.181175\n",
      "tensor(0.1484, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.8\tLoss: 0.148414\n",
      "\n",
      "Test Epoch: 234\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 234\tmaintain_Accuracy: 7038/10593 (66%)\n",
      "\n",
      "tensor(0.1428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.0\tLoss: 0.142772\n",
      "tensor(0.0436, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.2\tLoss: 0.043592\n",
      "tensor(0.0793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.4\tLoss: 0.079343\n",
      "tensor(0.1330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.6\tLoss: 0.132999\n",
      "tensor(0.1195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.8\tLoss: 0.119549\n",
      "\n",
      "Train Epoch: 235\tAttack_Accuracy: 4749/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 235\tmaintain_Accuracy: 4253/6400 (66%)\n",
      "\n",
      "alpha: 0.5214167542595022\n",
      "\n",
      "Test Epoch: 235\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 235\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.0\tLoss: 0.174954\n",
      "tensor(0.0727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.2\tLoss: 0.072714\n",
      "tensor(0.1643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.4\tLoss: 0.164298\n",
      "tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.6\tLoss: 0.088340\n",
      "tensor(0.1647, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.8\tLoss: 0.164693\n",
      "\n",
      "Test Epoch: 236\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 236\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.0\tLoss: 0.124164\n",
      "tensor(0.1220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.2\tLoss: 0.121984\n",
      "tensor(0.1490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.4\tLoss: 0.149033\n",
      "tensor(0.1142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.6\tLoss: 0.114225\n",
      "tensor(0.1033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.8\tLoss: 0.103286\n",
      "\n",
      "Test Epoch: 237\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 237\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.0\tLoss: 0.103735\n",
      "tensor(0.1752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.2\tLoss: 0.175180\n",
      "tensor(0.0541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.4\tLoss: 0.054113\n",
      "tensor(0.1205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.6\tLoss: 0.120453\n",
      "tensor(0.1579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.8\tLoss: 0.157889\n",
      "\n",
      "Test Epoch: 238\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 238\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.0\tLoss: 0.115343\n",
      "tensor(0.0872, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.2\tLoss: 0.087174\n",
      "tensor(0.1046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.4\tLoss: 0.104565\n",
      "tensor(0.1757, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.6\tLoss: 0.175689\n",
      "tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.8\tLoss: 0.105604\n",
      "\n",
      "Test Epoch: 239\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 239\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.0\tLoss: 0.173231\n",
      "tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.2\tLoss: 0.088226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.4\tLoss: 0.155878\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.6\tLoss: 0.040365\n",
      "tensor(0.1301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.8\tLoss: 0.130138\n",
      "\n",
      "Train Epoch: 240\tAttack_Accuracy: 4748/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 240\tmaintain_Accuracy: 4255/6400 (66%)\n",
      "\n",
      "alpha: 0.44645361505308767\n",
      "\n",
      "Test Epoch: 240\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 240\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.0\tLoss: 0.085466\n",
      "tensor(0.1051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.2\tLoss: 0.105058\n",
      "tensor(0.1105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.4\tLoss: 0.110461\n",
      "tensor(0.1184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.6\tLoss: 0.118437\n",
      "tensor(0.0652, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.8\tLoss: 0.065198\n",
      "\n",
      "Test Epoch: 241\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 241\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.0\tLoss: 0.068305\n",
      "tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.2\tLoss: 0.096598\n",
      "tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.4\tLoss: 0.186973\n",
      "tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.6\tLoss: 0.096642\n",
      "tensor(0.0875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.8\tLoss: 0.087494\n",
      "\n",
      "Test Epoch: 242\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 242\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.0\tLoss: 0.112791\n",
      "tensor(0.1529, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.2\tLoss: 0.152910\n",
      "tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.4\tLoss: 0.061814\n",
      "tensor(0.1007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.6\tLoss: 0.100654\n",
      "tensor(0.1519, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.8\tLoss: 0.151855\n",
      "\n",
      "Test Epoch: 243\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 243\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1554, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.0\tLoss: 0.155393\n",
      "tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.2\tLoss: 0.179204\n",
      "tensor(0.1397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.4\tLoss: 0.139654\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.6\tLoss: 0.118103\n",
      "tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.8\tLoss: 0.113769\n",
      "\n",
      "Test Epoch: 244\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 244\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.0\tLoss: 0.158917\n",
      "tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.2\tLoss: 0.171894\n",
      "tensor(0.0919, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.4\tLoss: 0.091884\n",
      "tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.6\tLoss: 0.073265\n",
      "tensor(0.0649, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.8\tLoss: 0.064930\n",
      "\n",
      "Train Epoch: 245\tAttack_Accuracy: 4736/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 245\tmaintain_Accuracy: 4290/6400 (67%)\n",
      "\n",
      "alpha: 0.5190366000275617\n",
      "\n",
      "Test Epoch: 245\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 245\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.0\tLoss: 0.104519\n",
      "tensor(0.1510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.2\tLoss: 0.151018\n",
      "tensor(0.1457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.4\tLoss: 0.145726\n",
      "tensor(0.1083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.6\tLoss: 0.108284\n",
      "tensor(0.0815, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.8\tLoss: 0.081499\n",
      "\n",
      "Test Epoch: 246\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 246\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.0\tLoss: 0.139242\n",
      "tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.2\tLoss: 0.123678\n",
      "tensor(0.1057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.4\tLoss: 0.105734\n",
      "tensor(0.1278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.6\tLoss: 0.127789\n",
      "tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.8\tLoss: 0.159321\n",
      "\n",
      "Test Epoch: 247\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 247\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.0\tLoss: 0.173877\n",
      "tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.2\tLoss: 0.158345\n",
      "tensor(0.1051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.4\tLoss: 0.105127\n",
      "tensor(0.1059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.6\tLoss: 0.105886\n",
      "tensor(0.1494, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.8\tLoss: 0.149379\n",
      "\n",
      "Test Epoch: 248\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 248\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.0\tLoss: 0.121273\n",
      "tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.2\tLoss: 0.116670\n",
      "tensor(0.1186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.4\tLoss: 0.118625\n",
      "tensor(0.2066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.6\tLoss: 0.206553\n",
      "tensor(0.0926, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.8\tLoss: 0.092632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 249\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 249\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.0\tLoss: 0.141874\n",
      "tensor(0.1352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.2\tLoss: 0.135231\n",
      "tensor(0.1597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.4\tLoss: 0.159658\n",
      "tensor(0.0696, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.6\tLoss: 0.069570\n",
      "tensor(0.1210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.8\tLoss: 0.121022\n",
      "\n",
      "Train Epoch: 250\tAttack_Accuracy: 4765/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 250\tmaintain_Accuracy: 4204/6400 (66%)\n",
      "\n",
      "alpha: 0.37189770641088715\n",
      "\n",
      "Test Epoch: 250\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 250\tmaintain_Accuracy: 7038/10593 (66%)\n",
      "\n",
      "tensor(0.0978, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.0\tLoss: 0.097813\n",
      "tensor(0.1247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.2\tLoss: 0.124669\n",
      "tensor(0.1098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.4\tLoss: 0.109807\n",
      "tensor(0.1485, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.6\tLoss: 0.148475\n",
      "tensor(0.1523, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.8\tLoss: 0.152270\n",
      "\n",
      "Test Epoch: 251\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 251\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.0\tLoss: 0.074133\n",
      "tensor(0.1301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.2\tLoss: 0.130085\n",
      "tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.4\tLoss: 0.190616\n",
      "tensor(0.0782, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.6\tLoss: 0.078207\n",
      "tensor(0.1494, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.8\tLoss: 0.149395\n",
      "\n",
      "Test Epoch: 252\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 252\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.0\tLoss: 0.136703\n",
      "tensor(0.1257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.2\tLoss: 0.125675\n",
      "tensor(0.1801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.4\tLoss: 0.180127\n",
      "tensor(0.1434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.6\tLoss: 0.143376\n",
      "tensor(0.1461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.8\tLoss: 0.146137\n",
      "\n",
      "Test Epoch: 253\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 253\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.0\tLoss: 0.121078\n",
      "tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.2\tLoss: 0.183792\n",
      "tensor(0.1424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.4\tLoss: 0.142371\n",
      "tensor(0.0522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.6\tLoss: 0.052187\n",
      "tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.8\tLoss: 0.111533\n",
      "\n",
      "Test Epoch: 254\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 254\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.0\tLoss: 0.095161\n",
      "tensor(0.1334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.2\tLoss: 0.133380\n",
      "tensor(0.1406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.4\tLoss: 0.140602\n",
      "tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.6\tLoss: 0.094363\n",
      "tensor(0.0801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.8\tLoss: 0.080051\n",
      "\n",
      "Train Epoch: 255\tAttack_Accuracy: 4783/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 255\tmaintain_Accuracy: 4187/6400 (65%)\n",
      "\n",
      "alpha: 0.4107214851751465\n",
      "\n",
      "Test Epoch: 255\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 255\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.0\tLoss: 0.123286\n",
      "tensor(0.1351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.2\tLoss: 0.135137\n",
      "tensor(0.1236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.4\tLoss: 0.123551\n",
      "tensor(0.1372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.6\tLoss: 0.137225\n",
      "tensor(0.1728, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.8\tLoss: 0.172786\n",
      "\n",
      "Test Epoch: 256\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 256\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.0\tLoss: 0.124376\n",
      "tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.2\tLoss: 0.134899\n",
      "tensor(0.1708, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.4\tLoss: 0.170826\n",
      "tensor(0.1047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.6\tLoss: 0.104652\n",
      "tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.8\tLoss: 0.074461\n",
      "\n",
      "Test Epoch: 257\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 257\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.0\tLoss: 0.178799\n",
      "tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.2\tLoss: 0.102919\n",
      "tensor(0.1863, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.4\tLoss: 0.186318\n",
      "tensor(0.1498, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.6\tLoss: 0.149811\n",
      "tensor(0.1449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.8\tLoss: 0.144931\n",
      "\n",
      "Test Epoch: 258\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 258\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.0\tLoss: 0.071383\n",
      "tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.2\tLoss: 0.146945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.4\tLoss: 0.169012\n",
      "tensor(0.1550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.6\tLoss: 0.154997\n",
      "tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.8\tLoss: 0.111541\n",
      "\n",
      "Test Epoch: 259\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 259\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.0\tLoss: 0.123031\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.2\tLoss: 0.081412\n",
      "tensor(0.1007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.4\tLoss: 0.100668\n",
      "tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.6\tLoss: 0.076615\n",
      "tensor(0.1279, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.8\tLoss: 0.127862\n",
      "\n",
      "Train Epoch: 260\tAttack_Accuracy: 4801/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 260\tmaintain_Accuracy: 4203/6400 (66%)\n",
      "\n",
      "alpha: 0.4988048457474559\n",
      "\n",
      "Test Epoch: 260\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 260\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.0719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.0\tLoss: 0.071914\n",
      "tensor(0.1959, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.2\tLoss: 0.195910\n",
      "tensor(0.1411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.4\tLoss: 0.141119\n",
      "tensor(0.1661, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.6\tLoss: 0.166097\n",
      "tensor(0.1306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.8\tLoss: 0.130642\n",
      "\n",
      "Test Epoch: 261\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 261\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.0\tLoss: 0.139744\n",
      "tensor(0.1150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.2\tLoss: 0.115014\n",
      "tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.4\tLoss: 0.074457\n",
      "tensor(0.1096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.6\tLoss: 0.109560\n",
      "tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.8\tLoss: 0.105986\n",
      "\n",
      "Test Epoch: 262\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 262\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.0\tLoss: 0.133871\n",
      "tensor(0.1753, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.2\tLoss: 0.175279\n",
      "tensor(0.1188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.4\tLoss: 0.118777\n",
      "tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.6\tLoss: 0.116769\n",
      "tensor(0.1098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.8\tLoss: 0.109809\n",
      "\n",
      "Test Epoch: 263\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 263\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.0\tLoss: 0.116509\n",
      "tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.2\tLoss: 0.116698\n",
      "tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.4\tLoss: 0.121116\n",
      "tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.6\tLoss: 0.225648\n",
      "tensor(0.1113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.8\tLoss: 0.111311\n",
      "\n",
      "Test Epoch: 264\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 264\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.0\tLoss: 0.116216\n",
      "tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.2\tLoss: 0.111210\n",
      "tensor(0.1325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.4\tLoss: 0.132489\n",
      "tensor(0.1108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.6\tLoss: 0.110838\n",
      "tensor(0.1340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.8\tLoss: 0.133976\n",
      "\n",
      "Train Epoch: 265\tAttack_Accuracy: 4854/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 265\tmaintain_Accuracy: 4212/6400 (66%)\n",
      "\n",
      "alpha: 0.5122618616890969\n",
      "\n",
      "Test Epoch: 265\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 265\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.0\tLoss: 0.145070\n",
      "tensor(0.1088, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.2\tLoss: 0.108845\n",
      "tensor(0.1022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.4\tLoss: 0.102194\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.6\tLoss: 0.117162\n",
      "tensor(0.1402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.8\tLoss: 0.140178\n",
      "\n",
      "Test Epoch: 266\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 266\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.0\tLoss: 0.094514\n",
      "tensor(0.1716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.2\tLoss: 0.171569\n",
      "tensor(0.1265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.4\tLoss: 0.126532\n",
      "tensor(0.1424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.6\tLoss: 0.142417\n",
      "tensor(0.1109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.8\tLoss: 0.110862\n",
      "\n",
      "Test Epoch: 267\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 267\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.0\tLoss: 0.109270\n",
      "tensor(0.1090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.2\tLoss: 0.109005\n",
      "tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.4\tLoss: 0.115242\n",
      "tensor(0.0929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.6\tLoss: 0.092882\n",
      "tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.8\tLoss: 0.128004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 268\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 268\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.0\tLoss: 0.084226\n",
      "tensor(0.1154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.2\tLoss: 0.115388\n",
      "tensor(0.1098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.4\tLoss: 0.109848\n",
      "tensor(0.1008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.6\tLoss: 0.100801\n",
      "tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.8\tLoss: 0.145308\n",
      "\n",
      "Test Epoch: 269\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 269\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.0\tLoss: 0.225262\n",
      "tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.2\tLoss: 0.114693\n",
      "tensor(0.1668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.4\tLoss: 0.166800\n",
      "tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.6\tLoss: 0.083904\n",
      "tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.8\tLoss: 0.109465\n",
      "\n",
      "Train Epoch: 270\tAttack_Accuracy: 4835/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 270\tmaintain_Accuracy: 4235/6400 (66%)\n",
      "\n",
      "alpha: 0.5188095385015637\n",
      "\n",
      "Test Epoch: 270\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 270\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.0\tLoss: 0.098456\n",
      "tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.2\tLoss: 0.078767\n",
      "tensor(0.1492, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.4\tLoss: 0.149171\n",
      "tensor(0.1218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.6\tLoss: 0.121844\n",
      "tensor(0.1754, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.8\tLoss: 0.175425\n",
      "\n",
      "Test Epoch: 271\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 271\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.0\tLoss: 0.151740\n",
      "tensor(0.1308, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.2\tLoss: 0.130785\n",
      "tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.4\tLoss: 0.133201\n",
      "tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.6\tLoss: 0.123346\n",
      "tensor(0.0907, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.8\tLoss: 0.090700\n",
      "\n",
      "Test Epoch: 272\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 272\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.0\tLoss: 0.117719\n",
      "tensor(0.0719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.2\tLoss: 0.071916\n",
      "tensor(0.1331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.4\tLoss: 0.133108\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.6\tLoss: 0.036937\n",
      "tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.8\tLoss: 0.125575\n",
      "\n",
      "Test Epoch: 273\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 273\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.0\tLoss: 0.100729\n",
      "tensor(0.1346, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.2\tLoss: 0.134599\n",
      "tensor(0.1180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.4\tLoss: 0.118037\n",
      "tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.6\tLoss: 0.186519\n",
      "tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.8\tLoss: 0.105585\n",
      "\n",
      "Test Epoch: 274\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 274\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.0\tLoss: 0.122545\n",
      "tensor(0.1499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.2\tLoss: 0.149863\n",
      "tensor(0.1210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.4\tLoss: 0.120985\n",
      "tensor(0.1407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.6\tLoss: 0.140743\n",
      "tensor(0.1154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.8\tLoss: 0.115412\n",
      "\n",
      "Train Epoch: 275\tAttack_Accuracy: 4732/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 275\tmaintain_Accuracy: 4207/6400 (66%)\n",
      "\n",
      "alpha: 0.4344208482978695\n",
      "\n",
      "Test Epoch: 275\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 275\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.0982, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.0\tLoss: 0.098166\n",
      "tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.2\tLoss: 0.189684\n",
      "tensor(0.1250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.4\tLoss: 0.125021\n",
      "tensor(0.0779, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.6\tLoss: 0.077924\n",
      "tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.8\tLoss: 0.107503\n",
      "\n",
      "Test Epoch: 276\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 276\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.0\tLoss: 0.107789\n",
      "tensor(0.0667, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.2\tLoss: 0.066666\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.4\tLoss: 0.117735\n",
      "tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.6\tLoss: 0.103467\n",
      "tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.8\tLoss: 0.132036\n",
      "\n",
      "Test Epoch: 277\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 277\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1418, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.0\tLoss: 0.141843\n",
      "tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.2\tLoss: 0.136246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.4\tLoss: 0.069813\n",
      "tensor(0.1274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.6\tLoss: 0.127420\n",
      "tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.8\tLoss: 0.104879\n",
      "\n",
      "Test Epoch: 278\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 278\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.0986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.0\tLoss: 0.098622\n",
      "tensor(0.1612, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.2\tLoss: 0.161212\n",
      "tensor(0.1076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.4\tLoss: 0.107587\n",
      "tensor(0.1694, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.6\tLoss: 0.169423\n",
      "tensor(0.0656, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.8\tLoss: 0.065583\n",
      "\n",
      "Test Epoch: 279\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 279\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1279, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.0\tLoss: 0.127864\n",
      "tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.2\tLoss: 0.088215\n",
      "tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.4\tLoss: 0.098488\n",
      "tensor(0.1220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.6\tLoss: 0.122022\n",
      "tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.8\tLoss: 0.133766\n",
      "\n",
      "Train Epoch: 280\tAttack_Accuracy: 4762/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 280\tmaintain_Accuracy: 4246/6400 (66%)\n",
      "\n",
      "alpha: 0.47893596248794906\n",
      "\n",
      "Test Epoch: 280\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 280\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.0969, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.0\tLoss: 0.096874\n",
      "tensor(0.0844, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.2\tLoss: 0.084421\n",
      "tensor(0.1128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.4\tLoss: 0.112830\n",
      "tensor(0.1079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.6\tLoss: 0.107902\n",
      "tensor(0.1286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.8\tLoss: 0.128625\n",
      "\n",
      "Test Epoch: 281\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 281\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.0\tLoss: 0.153619\n",
      "tensor(0.0879, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.2\tLoss: 0.087878\n",
      "tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.4\tLoss: 0.129081\n",
      "tensor(0.1380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.6\tLoss: 0.138011\n",
      "tensor(0.1793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.8\tLoss: 0.179315\n",
      "\n",
      "Test Epoch: 282\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 282\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1298, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.0\tLoss: 0.129805\n",
      "tensor(0.1807, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.2\tLoss: 0.180656\n",
      "tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.4\tLoss: 0.109748\n",
      "tensor(0.1361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.6\tLoss: 0.136056\n",
      "tensor(0.1462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.8\tLoss: 0.146152\n",
      "\n",
      "Test Epoch: 283\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 283\tmaintain_Accuracy: 7039/10593 (66%)\n",
      "\n",
      "tensor(0.1450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.0\tLoss: 0.144978\n",
      "tensor(0.1496, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.2\tLoss: 0.149612\n",
      "tensor(0.0960, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.4\tLoss: 0.095959\n",
      "tensor(0.1316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.6\tLoss: 0.131643\n",
      "tensor(0.1239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.8\tLoss: 0.123899\n",
      "\n",
      "Test Epoch: 284\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 284\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1576, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.0\tLoss: 0.157577\n",
      "tensor(0.1079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.2\tLoss: 0.107877\n",
      "tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.4\tLoss: 0.123714\n",
      "tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.6\tLoss: 0.112367\n",
      "tensor(0.1471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.8\tLoss: 0.147086\n",
      "\n",
      "Train Epoch: 285\tAttack_Accuracy: 4779/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 285\tmaintain_Accuracy: 4289/6400 (67%)\n",
      "\n",
      "alpha: 0.5140552176305445\n",
      "\n",
      "Test Epoch: 285\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 285\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.0\tLoss: 0.123815\n",
      "tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.2\tLoss: 0.079961\n",
      "tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.4\tLoss: 0.066875\n",
      "tensor(0.1203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.6\tLoss: 0.120253\n",
      "tensor(0.1596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.8\tLoss: 0.159615\n",
      "\n",
      "Test Epoch: 286\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 286\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.0\tLoss: 0.187477\n",
      "tensor(0.0775, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.2\tLoss: 0.077503\n",
      "tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.4\tLoss: 0.182960\n",
      "tensor(0.1744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.6\tLoss: 0.174384\n",
      "tensor(0.1076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.8\tLoss: 0.107553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 287\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 287\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.0\tLoss: 0.105977\n",
      "tensor(0.1424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.2\tLoss: 0.142399\n",
      "tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.4\tLoss: 0.067374\n",
      "tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.6\tLoss: 0.122405\n",
      "tensor(0.1693, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.8\tLoss: 0.169332\n",
      "\n",
      "Test Epoch: 288\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 288\tmaintain_Accuracy: 7038/10593 (66%)\n",
      "\n",
      "tensor(0.1402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.0\tLoss: 0.140227\n",
      "tensor(0.1296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.2\tLoss: 0.129572\n",
      "tensor(0.1086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.4\tLoss: 0.108634\n",
      "tensor(0.1520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.6\tLoss: 0.151965\n",
      "tensor(0.1228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.8\tLoss: 0.122834\n",
      "\n",
      "Test Epoch: 289\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 289\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.0\tLoss: 0.227846\n",
      "tensor(0.1214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.2\tLoss: 0.121428\n",
      "tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.4\tLoss: 0.189676\n",
      "tensor(0.1380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.6\tLoss: 0.137957\n",
      "tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.8\tLoss: 0.127217\n",
      "\n",
      "Train Epoch: 290\tAttack_Accuracy: 4746/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 290\tmaintain_Accuracy: 4179/6400 (65%)\n",
      "\n",
      "alpha: 0.5782205914564513\n",
      "\n",
      "Test Epoch: 290\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 290\tmaintain_Accuracy: 7038/10593 (66%)\n",
      "\n",
      "tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.0\tLoss: 0.060741\n",
      "tensor(0.1197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.2\tLoss: 0.119654\n",
      "tensor(0.1061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.4\tLoss: 0.106149\n",
      "tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.6\tLoss: 0.177060\n",
      "tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.8\tLoss: 0.054468\n",
      "\n",
      "Test Epoch: 291\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 291\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.0\tLoss: 0.117494\n",
      "tensor(0.1165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.2\tLoss: 0.116477\n",
      "tensor(0.1282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.4\tLoss: 0.128238\n",
      "tensor(0.1122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.6\tLoss: 0.112226\n",
      "tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.8\tLoss: 0.136154\n",
      "\n",
      "Test Epoch: 292\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 292\tmaintain_Accuracy: 7038/10593 (66%)\n",
      "\n",
      "tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.0\tLoss: 0.171940\n",
      "tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.2\tLoss: 0.090375\n",
      "tensor(0.1597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.4\tLoss: 0.159750\n",
      "tensor(0.1277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.6\tLoss: 0.127681\n",
      "tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.8\tLoss: 0.114687\n",
      "\n",
      "Test Epoch: 293\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 293\tmaintain_Accuracy: 7038/10593 (66%)\n",
      "\n",
      "tensor(0.1107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.0\tLoss: 0.110723\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.2\tLoss: 0.118451\n",
      "tensor(0.0995, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.4\tLoss: 0.099469\n",
      "tensor(0.1767, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.6\tLoss: 0.176741\n",
      "tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.8\tLoss: 0.204571\n",
      "\n",
      "Test Epoch: 294\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 294\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.0\tLoss: 0.138821\n",
      "tensor(0.1053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.2\tLoss: 0.105342\n",
      "tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.4\tLoss: 0.199268\n",
      "tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.6\tLoss: 0.133604\n",
      "tensor(0.1536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.8\tLoss: 0.153573\n",
      "\n",
      "Train Epoch: 295\tAttack_Accuracy: 4724/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 295\tmaintain_Accuracy: 4169/6400 (65%)\n",
      "\n",
      "alpha: 0.5297125260904942\n",
      "\n",
      "Test Epoch: 295\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 295\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.0\tLoss: 0.139220\n",
      "tensor(0.1733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.2\tLoss: 0.173311\n",
      "tensor(0.0840, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.4\tLoss: 0.083968\n",
      "tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.6\tLoss: 0.068941\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.8\tLoss: 0.028910\n",
      "\n",
      "Test Epoch: 296\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 296\tmaintain_Accuracy: 7037/10593 (66%)\n",
      "\n",
      "tensor(0.1048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.0\tLoss: 0.104807\n",
      "tensor(0.1752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.2\tLoss: 0.175247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.4\tLoss: 0.117502\n",
      "tensor(0.1464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.6\tLoss: 0.146423\n",
      "tensor(0.0860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.8\tLoss: 0.086042\n",
      "\n",
      "Test Epoch: 297\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 297\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1545, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.0\tLoss: 0.154496\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.2\tLoss: 0.117098\n",
      "tensor(0.1122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.4\tLoss: 0.112159\n",
      "tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.6\tLoss: 0.123502\n",
      "tensor(0.1209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.8\tLoss: 0.120858\n",
      "\n",
      "Test Epoch: 298\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 298\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.0\tLoss: 0.100993\n",
      "tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.2\tLoss: 0.213802\n",
      "tensor(0.1477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.4\tLoss: 0.147672\n",
      "tensor(0.1103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.6\tLoss: 0.110311\n",
      "tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.8\tLoss: 0.184710\n",
      "\n",
      "Test Epoch: 299\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 299\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.0992, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.0\tLoss: 0.099194\n",
      "tensor(0.1363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.2\tLoss: 0.136259\n",
      "tensor(0.1622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.4\tLoss: 0.162165\n",
      "tensor(0.1509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.6\tLoss: 0.150946\n",
      "tensor(0.1465, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.8\tLoss: 0.146468\n",
      "\n",
      "Train Epoch: 300\tAttack_Accuracy: 4782/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 300\tmaintain_Accuracy: 4267/6400 (67%)\n",
      "\n",
      "alpha: 0.5266938837641665\n",
      "\n",
      "Test Epoch: 300\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 300\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.0833, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.0\tLoss: 0.083292\n",
      "tensor(0.0992, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.2\tLoss: 0.099243\n",
      "tensor(0.1021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.4\tLoss: 0.102098\n",
      "tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.6\tLoss: 0.193493\n",
      "tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.8\tLoss: 0.179354\n",
      "\n",
      "Test Epoch: 301\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 301\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.1226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.0\tLoss: 0.122612\n",
      "tensor(0.1669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.2\tLoss: 0.166878\n",
      "tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.4\tLoss: 0.110226\n",
      "tensor(0.1416, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.6\tLoss: 0.141616\n",
      "tensor(0.1054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.8\tLoss: 0.105420\n",
      "\n",
      "Test Epoch: 302\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 302\tmaintain_Accuracy: 7036/10593 (66%)\n",
      "\n",
      "tensor(0.0479, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.0\tLoss: 0.047932\n",
      "tensor(0.1397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.2\tLoss: 0.139726\n",
      "tensor(0.1307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.4\tLoss: 0.130713\n",
      "tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.6\tLoss: 0.199505\n",
      "tensor(0.0824, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.8\tLoss: 0.082366\n",
      "\n",
      "Test Epoch: 303\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 303\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.0\tLoss: 0.167971\n",
      "tensor(0.1234, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.2\tLoss: 0.123430\n",
      "tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.4\tLoss: 0.137543\n",
      "tensor(0.0751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.6\tLoss: 0.075082\n",
      "tensor(0.1367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.8\tLoss: 0.136656\n",
      "\n",
      "Test Epoch: 304\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 304\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.0\tLoss: 0.133564\n",
      "tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.2\tLoss: 0.130320\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.4\tLoss: 0.081381\n",
      "tensor(0.0640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.6\tLoss: 0.063998\n",
      "tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.8\tLoss: 0.056473\n",
      "\n",
      "Train Epoch: 305\tAttack_Accuracy: 4755/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 305\tmaintain_Accuracy: 4213/6400 (66%)\n",
      "\n",
      "alpha: 0.4299499570395445\n",
      "\n",
      "Test Epoch: 305\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 305\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.0\tLoss: 0.205378\n",
      "tensor(0.0901, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.2\tLoss: 0.090061\n",
      "tensor(0.1481, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.4\tLoss: 0.148121\n",
      "tensor(0.1560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.6\tLoss: 0.155998\n",
      "tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.8\tLoss: 0.193917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 306\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 306\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.0\tLoss: 0.125706\n",
      "tensor(0.0773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.2\tLoss: 0.077346\n",
      "tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.4\tLoss: 0.057246\n",
      "tensor(0.1357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.6\tLoss: 0.135706\n",
      "tensor(0.0899, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.8\tLoss: 0.089899\n",
      "\n",
      "Test Epoch: 307\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 307\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1749, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.0\tLoss: 0.174887\n",
      "tensor(0.1417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.2\tLoss: 0.141737\n",
      "tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.4\tLoss: 0.170961\n",
      "tensor(0.1442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.6\tLoss: 0.144175\n",
      "tensor(0.1119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.8\tLoss: 0.111933\n",
      "\n",
      "Test Epoch: 308\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 308\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.0\tLoss: 0.064293\n",
      "tensor(0.1137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.2\tLoss: 0.113685\n",
      "tensor(0.1640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.4\tLoss: 0.164040\n",
      "tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.6\tLoss: 0.089977\n",
      "tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.8\tLoss: 0.180537\n",
      "\n",
      "Test Epoch: 309\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 309\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.0\tLoss: 0.109095\n",
      "tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.2\tLoss: 0.133942\n",
      "tensor(0.1388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.4\tLoss: 0.138766\n",
      "tensor(0.0913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.6\tLoss: 0.091321\n",
      "tensor(0.1725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.8\tLoss: 0.172484\n",
      "\n",
      "Train Epoch: 310\tAttack_Accuracy: 4788/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 310\tmaintain_Accuracy: 4291/6400 (67%)\n",
      "\n",
      "alpha: 0.31029349526369754\n",
      "\n",
      "Test Epoch: 310\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 310\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.0\tLoss: 0.112180\n",
      "tensor(0.1070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.2\tLoss: 0.107030\n",
      "tensor(0.1930, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.4\tLoss: 0.192963\n",
      "tensor(0.1014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.6\tLoss: 0.101382\n",
      "tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.8\tLoss: 0.100161\n",
      "\n",
      "Test Epoch: 311\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 311\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.0\tLoss: 0.138742\n",
      "tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.2\tLoss: 0.197141\n",
      "tensor(0.1042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.4\tLoss: 0.104150\n",
      "tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.6\tLoss: 0.112862\n",
      "tensor(0.0970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.8\tLoss: 0.097009\n",
      "\n",
      "Test Epoch: 312\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 312\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.0\tLoss: 0.112119\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.2\tLoss: 0.118506\n",
      "tensor(0.1492, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.4\tLoss: 0.149166\n",
      "tensor(0.0746, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.6\tLoss: 0.074629\n",
      "tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.8\tLoss: 0.060729\n",
      "\n",
      "Test Epoch: 313\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 313\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.1502, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.0\tLoss: 0.150165\n",
      "tensor(0.1243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.2\tLoss: 0.124332\n",
      "tensor(0.0948, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.4\tLoss: 0.094796\n",
      "tensor(0.1128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.6\tLoss: 0.112784\n",
      "tensor(0.0962, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.8\tLoss: 0.096233\n",
      "\n",
      "Test Epoch: 314\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 314\tmaintain_Accuracy: 7035/10593 (66%)\n",
      "\n",
      "tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.0\tLoss: 0.093088\n",
      "tensor(0.0954, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.2\tLoss: 0.095375\n",
      "tensor(0.1492, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.4\tLoss: 0.149169\n",
      "tensor(0.1715, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.6\tLoss: 0.171480\n",
      "tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.8\tLoss: 0.069084\n",
      "\n",
      "Train Epoch: 315\tAttack_Accuracy: 4787/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 315\tmaintain_Accuracy: 4306/6400 (67%)\n",
      "\n",
      "alpha: 0.52021263509659\n",
      "\n",
      "Test Epoch: 315\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 315\tmaintain_Accuracy: 7034/10593 (66%)\n",
      "\n",
      "tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.0\tLoss: 0.122365\n",
      "tensor(0.0824, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.2\tLoss: 0.082424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.4\tLoss: 0.114024\n",
      "tensor(0.1131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.6\tLoss: 0.113088\n",
      "tensor(0.1143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.8\tLoss: 0.114288\n",
      "\n",
      "Test Epoch: 316\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 316\tmaintain_Accuracy: 7034/10593 (66%)\n",
      "\n",
      "tensor(0.0959, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.0\tLoss: 0.095860\n",
      "tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.2\tLoss: 0.054375\n",
      "tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.4\tLoss: 0.136246\n",
      "tensor(0.0853, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.6\tLoss: 0.085335\n",
      "tensor(0.1383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.8\tLoss: 0.138337\n",
      "\n",
      "Test Epoch: 317\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 317\tmaintain_Accuracy: 7034/10593 (66%)\n",
      "\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.0\tLoss: 0.028803\n",
      "tensor(0.1288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.2\tLoss: 0.128798\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.4\tLoss: 0.051202\n",
      "tensor(0.1582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.6\tLoss: 0.158168\n",
      "tensor(0.1494, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.8\tLoss: 0.149446\n",
      "\n",
      "Test Epoch: 318\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 318\tmaintain_Accuracy: 7034/10593 (66%)\n",
      "\n",
      "tensor(0.0705, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.0\tLoss: 0.070477\n",
      "tensor(0.1003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.2\tLoss: 0.100296\n",
      "tensor(0.1085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.4\tLoss: 0.108549\n",
      "tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.6\tLoss: 0.114719\n",
      "tensor(0.1611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.8\tLoss: 0.161110\n",
      "\n",
      "Test Epoch: 319\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 319\tmaintain_Accuracy: 7034/10593 (66%)\n",
      "\n",
      "tensor(0.1210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.0\tLoss: 0.121044\n",
      "tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.2\tLoss: 0.178434\n",
      "tensor(0.1080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.4\tLoss: 0.107985\n",
      "tensor(0.1649, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.6\tLoss: 0.164869\n",
      "tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.8\tLoss: 0.187058\n",
      "\n",
      "Train Epoch: 320\tAttack_Accuracy: 4783/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 320\tmaintain_Accuracy: 4239/6400 (66%)\n",
      "\n",
      "alpha: 0.4663551443560106\n",
      "\n",
      "Test Epoch: 320\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 320\tmaintain_Accuracy: 7034/10593 (66%)\n",
      "\n",
      "tensor(0.1722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.0\tLoss: 0.172170\n",
      "tensor(0.1298, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.2\tLoss: 0.129842\n",
      "tensor(0.1306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.4\tLoss: 0.130613\n",
      "tensor(0.1490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.6\tLoss: 0.148999\n",
      "tensor(0.1176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.8\tLoss: 0.117625\n",
      "\n",
      "Test Epoch: 321\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 321\tmaintain_Accuracy: 7034/10593 (66%)\n",
      "\n",
      "tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.0\tLoss: 0.158256\n",
      "tensor(0.1005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.2\tLoss: 0.100450\n",
      "tensor(0.0585, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.4\tLoss: 0.058531\n",
      "tensor(0.1577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.6\tLoss: 0.157659\n",
      "tensor(0.1666, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.8\tLoss: 0.166569\n",
      "\n",
      "Test Epoch: 322\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 322\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.0968, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.0\tLoss: 0.096777\n",
      "tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.2\tLoss: 0.172139\n",
      "tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.4\tLoss: 0.128377\n",
      "tensor(0.0529, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.6\tLoss: 0.052943\n",
      "tensor(0.1092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.8\tLoss: 0.109156\n",
      "\n",
      "Test Epoch: 323\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 323\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.0\tLoss: 0.198897\n",
      "tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.2\tLoss: 0.088322\n",
      "tensor(0.1405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.4\tLoss: 0.140524\n",
      "tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.6\tLoss: 0.194160\n",
      "tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.8\tLoss: 0.129076\n",
      "\n",
      "Test Epoch: 324\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 324\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1742, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.0\tLoss: 0.174176\n",
      "tensor(0.1064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.2\tLoss: 0.106445\n",
      "tensor(0.0790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.4\tLoss: 0.079039\n",
      "tensor(0.0858, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.6\tLoss: 0.085762\n",
      "tensor(0.0826, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.8\tLoss: 0.082626\n",
      "\n",
      "Train Epoch: 325\tAttack_Accuracy: 4803/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 325\tmaintain_Accuracy: 4205/6400 (66%)\n",
      "\n",
      "alpha: 0.4758235922872007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 325\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 325\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.0\tLoss: 0.025002\n",
      "tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.2\tLoss: 0.112435\n",
      "tensor(0.0932, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.4\tLoss: 0.093202\n",
      "tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.6\tLoss: 0.113830\n",
      "tensor(0.1527, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.8\tLoss: 0.152730\n",
      "\n",
      "Test Epoch: 326\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 326\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.0573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.0\tLoss: 0.057272\n",
      "tensor(0.1716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.2\tLoss: 0.171643\n",
      "tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.4\tLoss: 0.200504\n",
      "tensor(0.1197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.6\tLoss: 0.119694\n",
      "tensor(0.1516, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.8\tLoss: 0.151591\n",
      "\n",
      "Test Epoch: 327\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 327\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.0\tLoss: 0.118082\n",
      "tensor(0.1434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.2\tLoss: 0.143399\n",
      "tensor(0.1670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.4\tLoss: 0.166978\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.6\tLoss: 0.118125\n",
      "tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.8\tLoss: 0.098508\n",
      "\n",
      "Test Epoch: 328\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 328\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.0\tLoss: 0.110915\n",
      "tensor(0.0730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.2\tLoss: 0.072983\n",
      "tensor(0.1098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.4\tLoss: 0.109777\n",
      "tensor(0.1151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.6\tLoss: 0.115090\n",
      "tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.8\tLoss: 0.094169\n",
      "\n",
      "Test Epoch: 329\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 329\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.0\tLoss: 0.117878\n",
      "tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.2\tLoss: 0.128367\n",
      "tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.4\tLoss: 0.145562\n",
      "tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.6\tLoss: 0.085488\n",
      "tensor(0.0728, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.8\tLoss: 0.072808\n",
      "\n",
      "Train Epoch: 330\tAttack_Accuracy: 4773/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 330\tmaintain_Accuracy: 4267/6400 (67%)\n",
      "\n",
      "alpha: 0.4884221311910004\n",
      "\n",
      "Test Epoch: 330\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 330\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.0\tLoss: 0.132563\n",
      "tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.2\tLoss: 0.127229\n",
      "tensor(0.1442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.4\tLoss: 0.144215\n",
      "tensor(0.1287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.6\tLoss: 0.128699\n",
      "tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.8\tLoss: 0.077165\n",
      "\n",
      "Test Epoch: 331\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 331\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.0\tLoss: 0.144429\n",
      "tensor(0.1480, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.2\tLoss: 0.148004\n",
      "tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.4\tLoss: 0.103091\n",
      "tensor(0.1207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.6\tLoss: 0.120729\n",
      "tensor(0.0898, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.8\tLoss: 0.089782\n",
      "\n",
      "Test Epoch: 332\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 332\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.0\tLoss: 0.115103\n",
      "tensor(0.1428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.2\tLoss: 0.142839\n",
      "tensor(0.1058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.4\tLoss: 0.105790\n",
      "tensor(0.1007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.6\tLoss: 0.100734\n",
      "tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.8\tLoss: 0.133752\n",
      "\n",
      "Test Epoch: 333\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 333\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.0\tLoss: 0.110178\n",
      "tensor(0.1679, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.2\tLoss: 0.167886\n",
      "tensor(0.1385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.4\tLoss: 0.138455\n",
      "tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.6\tLoss: 0.102523\n",
      "tensor(0.1130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.8\tLoss: 0.113024\n",
      "\n",
      "Test Epoch: 334\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 334\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.0\tLoss: 0.131627\n",
      "tensor(0.1801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.2\tLoss: 0.180057\n",
      "tensor(0.1449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.4\tLoss: 0.144876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.6\tLoss: 0.105631\n",
      "tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.8\tLoss: 0.108865\n",
      "\n",
      "Train Epoch: 335\tAttack_Accuracy: 4780/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 335\tmaintain_Accuracy: 4245/6400 (66%)\n",
      "\n",
      "alpha: 0.5176485686688771\n",
      "\n",
      "Test Epoch: 335\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 335\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.0\tLoss: 0.103814\n",
      "tensor(0.0813, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.2\tLoss: 0.081338\n",
      "tensor(0.0927, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.4\tLoss: 0.092737\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.6\tLoss: 0.039422\n",
      "tensor(0.1052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.8\tLoss: 0.105242\n",
      "\n",
      "Test Epoch: 336\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 336\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.0716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.0\tLoss: 0.071638\n",
      "tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.2\tLoss: 0.079244\n",
      "tensor(0.1141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.4\tLoss: 0.114070\n",
      "tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.6\tLoss: 0.095489\n",
      "tensor(0.1150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.8\tLoss: 0.114994\n",
      "\n",
      "Test Epoch: 337\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 337\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.0\tLoss: 0.114454\n",
      "tensor(0.1548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.2\tLoss: 0.154819\n",
      "tensor(0.0763, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.4\tLoss: 0.076292\n",
      "tensor(0.1058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.6\tLoss: 0.105836\n",
      "tensor(0.1010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.8\tLoss: 0.101041\n",
      "\n",
      "Test Epoch: 338\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 338\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.0755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.0\tLoss: 0.075507\n",
      "tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.2\tLoss: 0.150740\n",
      "tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.4\tLoss: 0.050932\n",
      "tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.6\tLoss: 0.115154\n",
      "tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.8\tLoss: 0.090352\n",
      "\n",
      "Test Epoch: 339\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 339\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.0\tLoss: 0.090966\n",
      "tensor(0.1058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.2\tLoss: 0.105764\n",
      "tensor(0.1485, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.4\tLoss: 0.148470\n",
      "tensor(0.1735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.6\tLoss: 0.173486\n",
      "tensor(0.0684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.8\tLoss: 0.068407\n",
      "\n",
      "Train Epoch: 340\tAttack_Accuracy: 4852/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 340\tmaintain_Accuracy: 4181/6400 (65%)\n",
      "\n",
      "alpha: 0.5690567465154206\n",
      "\n",
      "Test Epoch: 340\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 340\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.0\tLoss: 0.138116\n",
      "tensor(0.1420, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.2\tLoss: 0.141999\n",
      "tensor(0.1434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.4\tLoss: 0.143411\n",
      "tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.6\tLoss: 0.125589\n",
      "tensor(0.1087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.8\tLoss: 0.108723\n",
      "\n",
      "Test Epoch: 341\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 341\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.0\tLoss: 0.146292\n",
      "tensor(0.0747, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.2\tLoss: 0.074729\n",
      "tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.4\tLoss: 0.066818\n",
      "tensor(0.1091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.6\tLoss: 0.109117\n",
      "tensor(0.1128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.8\tLoss: 0.112802\n",
      "\n",
      "Test Epoch: 342\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 342\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.0\tLoss: 0.139089\n",
      "tensor(0.1261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.2\tLoss: 0.126137\n",
      "tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.4\tLoss: 0.123334\n",
      "tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.6\tLoss: 0.213576\n",
      "tensor(0.1800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.8\tLoss: 0.180001\n",
      "\n",
      "Test Epoch: 343\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 343\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1713, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.0\tLoss: 0.171341\n",
      "tensor(0.1133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.2\tLoss: 0.113277\n",
      "tensor(0.0919, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.4\tLoss: 0.091864\n",
      "tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.6\tLoss: 0.090253\n",
      "tensor(0.1388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.8\tLoss: 0.138761\n",
      "\n",
      "Test Epoch: 344\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 344\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.0\tLoss: 0.140855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.2\tLoss: 0.072432\n",
      "tensor(0.1273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.4\tLoss: 0.127327\n",
      "tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.6\tLoss: 0.199824\n",
      "tensor(0.1204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.8\tLoss: 0.120433\n",
      "\n",
      "Train Epoch: 345\tAttack_Accuracy: 4837/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 345\tmaintain_Accuracy: 4223/6400 (66%)\n",
      "\n",
      "alpha: 0.3615504758682252\n",
      "\n",
      "Test Epoch: 345\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 345\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.0\tLoss: 0.193990\n",
      "tensor(0.1787, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.2\tLoss: 0.178660\n",
      "tensor(0.1701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.4\tLoss: 0.170058\n",
      "tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.6\tLoss: 0.093949\n",
      "tensor(0.1385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.8\tLoss: 0.138529\n",
      "\n",
      "Test Epoch: 346\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 346\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.0\tLoss: 0.115913\n",
      "tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.2\tLoss: 0.060612\n",
      "tensor(0.1367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.4\tLoss: 0.136655\n",
      "tensor(0.1208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.6\tLoss: 0.120768\n",
      "tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.8\tLoss: 0.061526\n",
      "\n",
      "Test Epoch: 347\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 347\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.0\tLoss: 0.059275\n",
      "tensor(0.1347, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.2\tLoss: 0.134734\n",
      "tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.4\tLoss: 0.113358\n",
      "tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.6\tLoss: 0.093558\n",
      "tensor(0.1607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.8\tLoss: 0.160734\n",
      "\n",
      "Test Epoch: 348\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 348\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.0\tLoss: 0.205577\n",
      "tensor(0.1639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.2\tLoss: 0.163915\n",
      "tensor(0.1460, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.4\tLoss: 0.146045\n",
      "tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.6\tLoss: 0.115221\n",
      "tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.8\tLoss: 0.107474\n",
      "\n",
      "Test Epoch: 349\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 349\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.0\tLoss: 0.057168\n",
      "tensor(0.0702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.2\tLoss: 0.070153\n",
      "tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.4\tLoss: 0.107543\n",
      "tensor(0.1435, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.6\tLoss: 0.143536\n",
      "tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.8\tLoss: 0.117256\n",
      "\n",
      "Train Epoch: 350\tAttack_Accuracy: 4884/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 350\tmaintain_Accuracy: 4231/6400 (66%)\n",
      "\n",
      "alpha: 0.5603101014451458\n",
      "\n",
      "Test Epoch: 350\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 350\tmaintain_Accuracy: 7034/10593 (66%)\n",
      "\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.0\tLoss: 0.117817\n",
      "tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.2\tLoss: 0.130271\n",
      "tensor(0.1396, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.4\tLoss: 0.139610\n",
      "tensor(0.1622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.6\tLoss: 0.162236\n",
      "tensor(0.1071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.8\tLoss: 0.107096\n",
      "\n",
      "Test Epoch: 351\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 351\tmaintain_Accuracy: 7034/10593 (66%)\n",
      "\n",
      "tensor(0.1907, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.0\tLoss: 0.190677\n",
      "tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.2\tLoss: 0.103128\n",
      "tensor(0.1498, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.4\tLoss: 0.149787\n",
      "tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.6\tLoss: 0.103482\n",
      "tensor(0.1107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.8\tLoss: 0.110699\n",
      "\n",
      "Test Epoch: 352\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 352\tmaintain_Accuracy: 7034/10593 (66%)\n",
      "\n",
      "tensor(0.1939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.0\tLoss: 0.193879\n",
      "tensor(0.1366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.2\tLoss: 0.136584\n",
      "tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.4\tLoss: 0.219351\n",
      "tensor(0.0782, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.6\tLoss: 0.078154\n",
      "tensor(0.1240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.8\tLoss: 0.124029\n",
      "\n",
      "Test Epoch: 353\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 353\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.0591, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.0\tLoss: 0.059083\n",
      "tensor(0.1360, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.2\tLoss: 0.135957\n",
      "tensor(0.1684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.4\tLoss: 0.168374\n",
      "tensor(0.1133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.6\tLoss: 0.113282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.8\tLoss: 0.160060\n",
      "\n",
      "Test Epoch: 354\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 354\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.0\tLoss: 0.114583\n",
      "tensor(0.1079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.2\tLoss: 0.107942\n",
      "tensor(0.0640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.4\tLoss: 0.064013\n",
      "tensor(0.1582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.6\tLoss: 0.158165\n",
      "tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.8\tLoss: 0.062382\n",
      "\n",
      "Train Epoch: 355\tAttack_Accuracy: 4837/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 355\tmaintain_Accuracy: 4251/6400 (66%)\n",
      "\n",
      "alpha: 0.49850505815392615\n",
      "\n",
      "Test Epoch: 355\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 355\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.0\tLoss: 0.176626\n",
      "tensor(0.0717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.2\tLoss: 0.071703\n",
      "tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.4\tLoss: 0.098537\n",
      "tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.6\tLoss: 0.103144\n",
      "tensor(0.1206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.8\tLoss: 0.120576\n",
      "\n",
      "Test Epoch: 356\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 356\tmaintain_Accuracy: 7034/10593 (66%)\n",
      "\n",
      "tensor(0.1481, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.0\tLoss: 0.148082\n",
      "tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.2\tLoss: 0.095527\n",
      "tensor(0.1775, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.4\tLoss: 0.177458\n",
      "tensor(0.1288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.6\tLoss: 0.128799\n",
      "tensor(0.1061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.8\tLoss: 0.106134\n",
      "\n",
      "Test Epoch: 357\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 357\tmaintain_Accuracy: 7034/10593 (66%)\n",
      "\n",
      "tensor(0.1546, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.0\tLoss: 0.154648\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.2\tLoss: 0.031797\n",
      "tensor(0.0273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.4\tLoss: 0.027258\n",
      "tensor(0.1320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.6\tLoss: 0.131994\n",
      "tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.8\tLoss: 0.073596\n",
      "\n",
      "Test Epoch: 358\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 358\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.0\tLoss: 0.156412\n",
      "tensor(0.1553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.2\tLoss: 0.155251\n",
      "tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.4\tLoss: 0.092978\n",
      "tensor(0.1421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.6\tLoss: 0.142125\n",
      "tensor(0.1633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.8\tLoss: 0.163312\n",
      "\n",
      "Test Epoch: 359\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 359\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.0\tLoss: 0.103933\n",
      "tensor(0.0819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.2\tLoss: 0.081902\n",
      "tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.4\tLoss: 0.073254\n",
      "tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.6\tLoss: 0.154073\n",
      "tensor(0.0816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.8\tLoss: 0.081606\n",
      "\n",
      "Train Epoch: 360\tAttack_Accuracy: 4802/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 360\tmaintain_Accuracy: 4214/6400 (66%)\n",
      "\n",
      "alpha: 0.5373723311308428\n",
      "\n",
      "Test Epoch: 360\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 360\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.0\tLoss: 0.135618\n",
      "tensor(0.1032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.2\tLoss: 0.103193\n",
      "tensor(0.0999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.4\tLoss: 0.099927\n",
      "tensor(0.1220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.6\tLoss: 0.121969\n",
      "tensor(0.1678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.8\tLoss: 0.167756\n",
      "\n",
      "Test Epoch: 361\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 361\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.0\tLoss: 0.151837\n",
      "tensor(0.0739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.2\tLoss: 0.073898\n",
      "tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.4\tLoss: 0.155934\n",
      "tensor(0.1119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.6\tLoss: 0.111873\n",
      "tensor(0.1078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.8\tLoss: 0.107835\n",
      "\n",
      "Test Epoch: 362\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 362\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.0\tLoss: 0.108869\n",
      "tensor(0.0751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.2\tLoss: 0.075142\n",
      "tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.4\tLoss: 0.094172\n",
      "tensor(0.1214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.6\tLoss: 0.121419\n",
      "tensor(0.1539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.8\tLoss: 0.153950\n",
      "\n",
      "Test Epoch: 363\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 363\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.0\tLoss: 0.167250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.2\tLoss: 0.113240\n",
      "tensor(0.1655, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.4\tLoss: 0.165530\n",
      "tensor(0.1329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.6\tLoss: 0.132932\n",
      "tensor(0.1509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.8\tLoss: 0.150911\n",
      "\n",
      "Test Epoch: 364\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 364\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.0998, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.0\tLoss: 0.099847\n",
      "tensor(0.1111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.2\tLoss: 0.111142\n",
      "tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.4\tLoss: 0.113619\n",
      "tensor(0.1387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.6\tLoss: 0.138679\n",
      "tensor(0.1295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.8\tLoss: 0.129537\n",
      "\n",
      "Train Epoch: 365\tAttack_Accuracy: 4800/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 365\tmaintain_Accuracy: 4259/6400 (67%)\n",
      "\n",
      "alpha: 0.5136657623066057\n",
      "\n",
      "Test Epoch: 365\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 365\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.0\tLoss: 0.158214\n",
      "tensor(0.1077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.2\tLoss: 0.107749\n",
      "tensor(0.1740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.4\tLoss: 0.174003\n",
      "tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.6\tLoss: 0.090345\n",
      "tensor(0.1225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.8\tLoss: 0.122542\n",
      "\n",
      "Test Epoch: 366\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 366\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.0\tLoss: 0.089417\n",
      "tensor(0.0874, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.2\tLoss: 0.087442\n",
      "tensor(0.0857, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.4\tLoss: 0.085680\n",
      "tensor(0.1317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.6\tLoss: 0.131738\n",
      "tensor(0.1044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.8\tLoss: 0.104416\n",
      "\n",
      "Test Epoch: 367\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 367\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.0865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.0\tLoss: 0.086532\n",
      "tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.2\tLoss: 0.194418\n",
      "tensor(0.1577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.4\tLoss: 0.157695\n",
      "tensor(0.1015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.6\tLoss: 0.101499\n",
      "tensor(0.1614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.8\tLoss: 0.161445\n",
      "\n",
      "Test Epoch: 368\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 368\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1545, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.0\tLoss: 0.154489\n",
      "tensor(0.1030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.2\tLoss: 0.103010\n",
      "tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.4\tLoss: 0.061562\n",
      "tensor(0.0592, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.6\tLoss: 0.059155\n",
      "tensor(0.1555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.8\tLoss: 0.155528\n",
      "\n",
      "Test Epoch: 369\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 369\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.0\tLoss: 0.140478\n",
      "tensor(0.1118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.2\tLoss: 0.111797\n",
      "tensor(0.1746, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.4\tLoss: 0.174650\n",
      "tensor(0.1127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.6\tLoss: 0.112664\n",
      "tensor(0.1411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.8\tLoss: 0.141148\n",
      "\n",
      "Train Epoch: 370\tAttack_Accuracy: 4777/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 370\tmaintain_Accuracy: 4239/6400 (66%)\n",
      "\n",
      "alpha: 0.5009162587223434\n",
      "\n",
      "Test Epoch: 370\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 370\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.0\tLoss: 0.069724\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.2\tLoss: 0.046962\n",
      "tensor(0.1209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.4\tLoss: 0.120919\n",
      "tensor(0.1220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.6\tLoss: 0.122021\n",
      "tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.8\tLoss: 0.130312\n",
      "\n",
      "Test Epoch: 371\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 371\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.0\tLoss: 0.125960\n",
      "tensor(0.0515, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.2\tLoss: 0.051486\n",
      "tensor(0.1604, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.4\tLoss: 0.160417\n",
      "tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.6\tLoss: 0.183839\n",
      "tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.8\tLoss: 0.203904\n",
      "\n",
      "Test Epoch: 372\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 372\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.0\tLoss: 0.121925\n",
      "tensor(0.1105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.2\tLoss: 0.110548\n",
      "tensor(0.1250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.4\tLoss: 0.125017\n",
      "tensor(0.1264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.6\tLoss: 0.126422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.8\tLoss: 0.083188\n",
      "\n",
      "Test Epoch: 373\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 373\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.0\tLoss: 0.113697\n",
      "tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.2\tLoss: 0.091022\n",
      "tensor(0.0725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.4\tLoss: 0.072460\n",
      "tensor(0.1544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.6\tLoss: 0.154405\n",
      "tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.8\tLoss: 0.100195\n",
      "\n",
      "Test Epoch: 374\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 374\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.0\tLoss: 0.102971\n",
      "tensor(0.1009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.2\tLoss: 0.100903\n",
      "tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.4\tLoss: 0.150675\n",
      "tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.6\tLoss: 0.125850\n",
      "tensor(0.0921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.8\tLoss: 0.092138\n",
      "\n",
      "Train Epoch: 375\tAttack_Accuracy: 4802/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 375\tmaintain_Accuracy: 4243/6400 (66%)\n",
      "\n",
      "alpha: 0.45508126804704346\n",
      "\n",
      "Test Epoch: 375\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 375\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.0\tLoss: 0.150496\n",
      "tensor(0.0758, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.2\tLoss: 0.075756\n",
      "tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.4\tLoss: 0.084759\n",
      "tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.6\tLoss: 0.073347\n",
      "tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.8\tLoss: 0.136205\n",
      "\n",
      "Test Epoch: 376\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 376\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.0897, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.0\tLoss: 0.089703\n",
      "tensor(0.1470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.2\tLoss: 0.147033\n",
      "tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.4\tLoss: 0.080016\n",
      "tensor(0.0530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.6\tLoss: 0.052972\n",
      "tensor(0.1500, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.8\tLoss: 0.150029\n",
      "\n",
      "Test Epoch: 377\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 377\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1482, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.0\tLoss: 0.148161\n",
      "tensor(0.1227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.2\tLoss: 0.122700\n",
      "tensor(0.1573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.4\tLoss: 0.157259\n",
      "tensor(0.0828, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.6\tLoss: 0.082760\n",
      "tensor(0.1101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.8\tLoss: 0.110101\n",
      "\n",
      "Test Epoch: 378\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 378\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.0\tLoss: 0.128711\n",
      "tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.2\tLoss: 0.080510\n",
      "tensor(0.0853, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.4\tLoss: 0.085301\n",
      "tensor(0.1720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.6\tLoss: 0.172002\n",
      "tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.8\tLoss: 0.065295\n",
      "\n",
      "Test Epoch: 379\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 379\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.0\tLoss: 0.111157\n",
      "tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.2\tLoss: 0.074081\n",
      "tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.4\tLoss: 0.145594\n",
      "tensor(0.1052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.6\tLoss: 0.105160\n",
      "tensor(0.1546, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.8\tLoss: 0.154553\n",
      "\n",
      "Train Epoch: 380\tAttack_Accuracy: 4837/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 380\tmaintain_Accuracy: 4200/6400 (66%)\n",
      "\n",
      "alpha: 0.4798739093163634\n",
      "\n",
      "Test Epoch: 380\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 380\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.0\tLoss: 0.134113\n",
      "tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.2\tLoss: 0.146909\n",
      "tensor(0.1498, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.4\tLoss: 0.149814\n",
      "tensor(0.1392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.6\tLoss: 0.139220\n",
      "tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.8\tLoss: 0.131020\n",
      "\n",
      "Test Epoch: 381\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 381\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.0\tLoss: 0.103543\n",
      "tensor(0.1249, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.2\tLoss: 0.124864\n",
      "tensor(0.1042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.4\tLoss: 0.104223\n",
      "tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.6\tLoss: 0.125542\n",
      "tensor(0.1267, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.8\tLoss: 0.126701\n",
      "\n",
      "Test Epoch: 382\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 382\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1599, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.0\tLoss: 0.159924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.2\tLoss: 0.130318\n",
      "tensor(0.0820, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.4\tLoss: 0.082007\n",
      "tensor(0.1181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.6\tLoss: 0.118095\n",
      "tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.8\tLoss: 0.196840\n",
      "\n",
      "Test Epoch: 383\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 383\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.0\tLoss: 0.065737\n",
      "tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.2\tLoss: 0.133323\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.4\tLoss: 0.081437\n",
      "tensor(0.1481, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.6\tLoss: 0.148140\n",
      "tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.8\tLoss: 0.202696\n",
      "\n",
      "Test Epoch: 384\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 384\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.0877, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.0\tLoss: 0.087669\n",
      "tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.2\tLoss: 0.140847\n",
      "tensor(0.0976, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.4\tLoss: 0.097619\n",
      "tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.6\tLoss: 0.107524\n",
      "tensor(0.1579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.8\tLoss: 0.157904\n",
      "\n",
      "Train Epoch: 385\tAttack_Accuracy: 4864/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 385\tmaintain_Accuracy: 4255/6400 (66%)\n",
      "\n",
      "alpha: 0.5814026711091995\n",
      "\n",
      "Test Epoch: 385\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 385\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.0\tLoss: 0.117016\n",
      "tensor(0.0453, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.2\tLoss: 0.045333\n",
      "tensor(0.1406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.4\tLoss: 0.140635\n",
      "tensor(0.1220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.6\tLoss: 0.122025\n",
      "tensor(0.1226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.8\tLoss: 0.122635\n",
      "\n",
      "Test Epoch: 386\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 386\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.0\tLoss: 0.168359\n",
      "tensor(0.0835, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.2\tLoss: 0.083514\n",
      "tensor(0.1087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.4\tLoss: 0.108665\n",
      "tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.6\tLoss: 0.215878\n",
      "tensor(0.1878, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.8\tLoss: 0.187798\n",
      "\n",
      "Test Epoch: 387\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 387\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.0\tLoss: 0.140651\n",
      "tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.2\tLoss: 0.133762\n",
      "tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.4\tLoss: 0.094340\n",
      "tensor(0.1311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.6\tLoss: 0.131095\n",
      "tensor(0.1154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.8\tLoss: 0.115396\n",
      "\n",
      "Test Epoch: 388\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 388\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.0\tLoss: 0.106385\n",
      "tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.2\tLoss: 0.059648\n",
      "tensor(0.1225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.4\tLoss: 0.122456\n",
      "tensor(0.0574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.6\tLoss: 0.057410\n",
      "tensor(0.1094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.8\tLoss: 0.109402\n",
      "\n",
      "Test Epoch: 389\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 389\tmaintain_Accuracy: 7033/10593 (66%)\n",
      "\n",
      "tensor(0.1735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.0\tLoss: 0.173550\n",
      "tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.2\tLoss: 0.084247\n",
      "tensor(0.1178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.4\tLoss: 0.117764\n",
      "tensor(0.1413, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.6\tLoss: 0.141331\n",
      "tensor(0.1406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.8\tLoss: 0.140562\n",
      "\n",
      "Train Epoch: 390\tAttack_Accuracy: 4774/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 390\tmaintain_Accuracy: 4236/6400 (66%)\n",
      "\n",
      "alpha: 0.5067669826209839\n",
      "\n",
      "Test Epoch: 390\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 390\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.0\tLoss: 0.154857\n",
      "tensor(0.1281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.2\tLoss: 0.128086\n",
      "tensor(0.0975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.4\tLoss: 0.097531\n",
      "tensor(0.1051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.6\tLoss: 0.105069\n",
      "tensor(0.1571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.8\tLoss: 0.157068\n",
      "\n",
      "Test Epoch: 391\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 391\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.0965, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.0\tLoss: 0.096485\n",
      "tensor(0.0947, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.2\tLoss: 0.094725\n",
      "tensor(0.0929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.4\tLoss: 0.092868\n",
      "tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.6\tLoss: 0.170953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.8\tLoss: 0.191172\n",
      "\n",
      "Test Epoch: 392\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 392\tmaintain_Accuracy: 7032/10593 (66%)\n",
      "\n",
      "tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.0\tLoss: 0.109523\n",
      "tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.2\tLoss: 0.084177\n",
      "tensor(0.1307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.4\tLoss: 0.130737\n",
      "tensor(0.1416, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.6\tLoss: 0.141613\n",
      "tensor(0.1407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.8\tLoss: 0.140714\n",
      "\n",
      "Test Epoch: 393\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 393\tmaintain_Accuracy: 7031/10593 (66%)\n",
      "\n",
      "tensor(0.1421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.0\tLoss: 0.142075\n",
      "tensor(0.0798, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.2\tLoss: 0.079820\n",
      "tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.4\tLoss: 0.089394\n",
      "tensor(0.1058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.6\tLoss: 0.105821\n",
      "tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.8\tLoss: 0.105611\n",
      "\n",
      "Test Epoch: 394\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 394\tmaintain_Accuracy: 7031/10593 (66%)\n",
      "\n",
      "tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.0\tLoss: 0.154082\n",
      "tensor(0.1191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.2\tLoss: 0.119142\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.4\tLoss: 0.081450\n",
      "tensor(0.1378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.6\tLoss: 0.137767\n",
      "tensor(0.1475, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.8\tLoss: 0.147531\n",
      "\n",
      "Train Epoch: 395\tAttack_Accuracy: 4833/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 395\tmaintain_Accuracy: 4265/6400 (67%)\n",
      "\n",
      "alpha: 0.5636036173775573\n",
      "\n",
      "Test Epoch: 395\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 395\tmaintain_Accuracy: 7031/10593 (66%)\n",
      "\n",
      "tensor(0.1554, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.0\tLoss: 0.155416\n",
      "tensor(0.1419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.2\tLoss: 0.141937\n",
      "tensor(0.1042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.4\tLoss: 0.104158\n",
      "tensor(0.1011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.6\tLoss: 0.101123\n",
      "tensor(0.1001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.8\tLoss: 0.100103\n",
      "\n",
      "Test Epoch: 396\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 396\tmaintain_Accuracy: 7031/10593 (66%)\n",
      "\n",
      "tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.0\tLoss: 0.184030\n",
      "tensor(0.0781, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.2\tLoss: 0.078068\n",
      "tensor(0.1506, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.4\tLoss: 0.150589\n",
      "tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.6\tLoss: 0.088151\n",
      "tensor(0.1159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.8\tLoss: 0.115942\n",
      "\n",
      "Test Epoch: 397\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 397\tmaintain_Accuracy: 7030/10593 (66%)\n",
      "\n",
      "tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.0\tLoss: 0.184572\n",
      "tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.2\tLoss: 0.086628\n",
      "tensor(0.1305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.4\tLoss: 0.130510\n",
      "tensor(0.1186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.6\tLoss: 0.118607\n",
      "tensor(0.1367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.8\tLoss: 0.136739\n",
      "\n",
      "Test Epoch: 398\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 398\tmaintain_Accuracy: 7030/10593 (66%)\n",
      "\n",
      "tensor(0.1555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.0\tLoss: 0.155537\n",
      "tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.2\tLoss: 0.133627\n",
      "tensor(0.0656, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.4\tLoss: 0.065608\n",
      "tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.6\tLoss: 0.179772\n",
      "tensor(0.1027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.8\tLoss: 0.102730\n",
      "\n",
      "Test Epoch: 399\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 399\tmaintain_Accuracy: 7031/10593 (66%)\n",
      "\n",
      "tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.0\tLoss: 0.133756\n",
      "tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.2\tLoss: 0.113807\n",
      "tensor(0.1352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.4\tLoss: 0.135198\n",
      "tensor(0.1723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.6\tLoss: 0.172320\n",
      "tensor(0.1239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.8\tLoss: 0.123940\n",
      "\n",
      "Train Epoch: 400\tAttack_Accuracy: 4766/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 400\tmaintain_Accuracy: 4211/6400 (66%)\n",
      "\n",
      "alpha: 0.6137211766560486\n",
      "\n",
      "Test Epoch: 400\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 400\tmaintain_Accuracy: 7030/10593 (66%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#method: DTA\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "model = torch.load('model.pkl')\n",
    "\n",
    "\n",
    "log_interval = 20\n",
    "n_epoch = 400\n",
    "threshold_epoch = 1001\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "losses_t=[]\n",
    "losses_nt = []\n",
    "losses_epoch = []\n",
    "losses_t_epoch=[]\n",
    "losses_nt_epoch = []\n",
    "losses_test_t_epoch = []\n",
    "losses_test_nt_epoch = []\n",
    "delta_wav = []\n",
    "delta_sum = []\n",
    "attack_ = []\n",
    "maintain_ = []\n",
    "error_ = []\n",
    "lr = 0.001\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data_size = data.size(1)\n",
    "delta = torch.rand(1,data_size, 16000)-0.5\n",
    "delta = delta.to(device)\n",
    "delta.requires_grad = True\n",
    "optimizer = optim.Adam([delta],lr = 0.00007)\n",
    "kpi = 0.5\n",
    "\n",
    "p_index = label_to_index('left').item()\n",
    "t_index = label_to_index('learn').item()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.2)  # reduce the learning after 20 epochs by a factor of 10\n",
    "\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        if epoch%threshold_epoch == 0 and epoch != 0:\n",
    "            threshold = 0.2 + (epoch // threshold_epoch  -1 ) * 0.07\n",
    "            delta_data = delta.data\n",
    "            delta_ = threshold*torch.tanh(delta)\n",
    "            delta_data = torch.arctanh(delta_ / (threshold+0.07))       \n",
    "            optimizer = optim.Adam([delta],lr = 0.001)\n",
    "            print(optimizer.state)\n",
    "        delta = train_attack(model, epoch, log_interval, threshold_epoch, delta)\n",
    "        delta_sum.append(delta.abs().mean())\n",
    "        kpi = test_attack(model, epoch,threshold_epoch, delta=delta)\n",
    "        '''\n",
    "        if epoch % 30 ==0:\n",
    "            delta.data = 0.5 * delta\n",
    "            print('delta',delta.abs().mean())\n",
    "\n",
    "            delta.requires_grad = True\n",
    "            optimizer = optim.Adam([delta],lr = 0.001)\n",
    "        '''\n",
    "\n",
    "        scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.4989e-07, -7.6712e-02, -5.4888e-07,  ..., -3.1173e-08,\n",
      "          -7.4913e-08,  1.1793e-07]]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAy6UlEQVR4nO3dd5hU9dn/8ffN0qXDikhxQQEBUdAVxYIgqFgimmhEfRJi+RET9XmMiRHUGGMllmiKiRI1UWNsxCgKioBgpbg0KYIsHaQsHem7+/39MWeX2dnpc2Zml/28rmsvzpx6c3bn3Od82zHnHCIiUrPVynYAIiKSfUoGIiKiZCAiIkoGIiKCkoGIiKBkICIiKBmI+MrM+pvZ2mzHIZIoJQOREGa20sz2mtkuM9tuZl+Y2U1mlvD3xdvXoHTEKeInJQOR8L7nnGsMHAOMAu4Ens9uSCLpo2QgEoVzbodzbixwFTDMzE4ws3pm9riZrTazjWb2jJk1CN3WzF4GOgDvmtl3ZvZrb/6bZrbBzHaY2Sdm1iOz/yuRypQMROLgnJsJrAXOJvCk0AXoBRwHtAXuDbPNj4DVBJ4yGjnnHvUWvQ90Bo4EZgOvpDt+kViUDETi9y3QAhgO/MI5t9U5twt4GBga706ccy8453Y55/YD9wEnmVnTdAQsEq/a2Q5ApBppS+A70xCYZWZl8w3IiWcHZpYDPARcCeQCpd6iVsAOP4MVSYSeDETiYGanEkgGbwN7gR7OuWbeT1PnXKMIm4YOC3wNMAQYBDQF8soO4XvQIglQMhCJwsyamNklwGvAv5xz84C/A0+a2ZHeOm3N7IIIu9gIdAr63BjYD2wh8ITxcNqCF0mAkoFIeO+a2S5gDXA38AfgOm/ZnUAhMN3MdgKTgK4R9vMIcI/XX+FXwEvAKmAdsAiYnr7/gkj8TC+3ERERPRmIiIiSgYiIKBmIiAhKBiIiQjXtdNaqVSuXl5eX7TBERKqVWbNmbXbO5YZbVi2TQV5eHgUFBdkOQ0SkWjGzVZGWqZhIRESUDERERMlARERQMhAREZQMREQEJQMREUHJQEREUDJI2hfLNrOs6LtshyEi4gslgyRd8/cZDHzi46jr3PTyLO59Z0GGIhIRSZ6SQRp9sHADL02L2OFPRKTKUDIQERElA7/d+uochjz9ebbDEBFJSLUcqK4qe3fet9kOQUQkYXoyEBERJYNsWbN1T7ZDEBEpp2SQBe/O+5azH53Cp0uLsh2KiAigZJAxnxduJm/EOFZv2cO8NdsBWLx+l6/HOFBcymVPf8705Vt83a+IHP6UDFK090AJD7y3iD0HiqOuN2bWWgAKVm1NWyxrtu1h7prt3PXW/LQdQ0QOT0oGKXrh8xU8/9kKnvt0RdT1nHNpj0UtmUQkWb4kAzMbbGZLzKzQzEaEWf6kmc31fr4xs+1By0qClo31I55MOlhSCkBxaXwXe7P0xfLUpKXp27mIHNZS7mdgZjnA08B5wFrgSzMb65xbVLaOc+4XQevfCvQO2sVe51yvVOOoyt6es46S9D8YiIgkzY9OZ32AQufccgAzew0YAiyKsP7VwG99OG6VEE/pz22vz63w+ZtNgdFOHcoQIlI1+FFM1BZYE/R5rTevEjM7BugIfBQ0u76ZFZjZdDO7LNJBzGy4t15BUVHVa5IZb+nPzr3FfPJNIP4dew+mL6Akrdy8m/U79oZdtuW7/RmORkQyJdMVyEOBMc65kqB5xzjn8oFrgKfM7NhwGzrnRjvn8p1z+bm5uZmINSHx3uPPX7ejfPrpKcsoCVPXsGnXPvJGjGPKkk0+RRe//o9Ppe8jH1WaP3/tDk55cBJvzV6b8ZhEJP38SAbrgPZBn9t588IZCrwaPMM5t877dzkwlYr1CVXeKzNWh50/+pNlYeeHPkF8sWxz+fRbs9dSsHIr89cGEsbLVWj466837ATgi2XqwyByOPIjGXwJdDazjmZWl8AFv1KrIDM7HmgOTAua19zM6nnTrYAziVzXUCVtjlB08vD4xXFtH/xgcPsb87jimWnlLY5Kk2yOunzzbop2qUhHROKXcgWyc67YzG4BJgA5wAvOuYVmdj9Q4JwrSwxDgddcxQb33YBnzayUQGIaFdwKqTqJt87gzVmxi1nMywbx5oLx89ezM6T+4aFxi3hqaHwPWZt27WPn3mJemrYyvgOKVGNbdx9gz4Fi2jVvmO1QqhRfhrB2zo0HxofMuzfk831htvsC6OlHDJkUqbfx7NXbEt7XsBdmsuTBwdSrnVM+r5aXDOJ9Mvj5K7MrzbMEOjT0eWhy3OtWJ845du0vpkn9OkCgcnzjzn2c1qllhfX2HSyhaNd+2rfQxeFwNODxqVxxSjtuHnAcACc/MBGAlaMuzmZYVY56ICdhxvLwQ0p8/69fJLW/uau389Skb8o/1/Ku4xnotBzR3gMllIap3B4zay2FZU1jnePxCUtYtWV3WmIYO+9b8kaMY+e+5Fpd/Xvmak6870OWFQXi7f/4VK4aPb3Serf8ew5nPzol7P9Xqr8Vm3fz2IQl2Q6jylMySMI7cyPVjyfnd+8uqtB72Aj/ZFBa6uK+YKU6/EW3ez/giYmHvkBTFh9q2fSzf82iuKSU/85Zx1+mFHLDiwUpHSuSZ6YGKuFXb0luuO+Pvg7EvKIocrI66XcfMunrjUD8LcJEDkdKBgma/PVG3p7r7xhAew+WVPgc6cmg013jueTPn/l67GjennPo//n+gg0Vlv1x8lJuf2MecGhIjuoo3r4ec9dsr9b/T5FYlAwSVLAq8XqBhEVpTbRo/c4q8WKcr30efrsqW7pxF5c9/TkPj/8626FInAY+MZXbXpuT7TCqFSWDKqismGjGiq0s3Vj5ojvXex9CJuw9UMI3YWIItXrLnoR7VL9ZsIa8EePYFaNO4Itlm5mVxqG/y0QqWtuy+wAAC7/dmfYYonl33rc8/1n00XFrsgPFpTw+YQm79xezrGi370/whzslA5+kMhpptE1f+Hxl8jsOo6TU8facdXHVPZjBra/O5vwnP4m5br/HpjD4qdjrBfv7p8sB+Hb7vqjrPTx+MT/427So66TTB14RWWifkh17D7J2W+ae0m59dQ4PvFctW15nxBsFa/jLlEL+9JFG702GL01Lq7vr/jGTlo3q8fiVJ2Xl+Ms3R67gXLJhJweKS6lbO7W8vXHnPk57eDI9jm7Cwm93sr+4hKtO7RBzu0gtp4KV3VCv3xH9ol7VRWqOW9b/YnlIRfTgpz5h/Y59aqKYRVu+28+i9Ts5u3MuB4oDdTr7D6puJxl6MgCmLCkqfxNZVTN79XYeHFfxbtABxQlWZpY1By0r6ti6279B8lanWIdRXQfAq0rJr2Dl1hrZNPba52bwo+dnUlxSWt4abOKijVmNqbpSMkhQGt9NE9GskErrZ6Yu47i734/a/j6ey8KKzbsZ+MTUiMvXbtvLrv3RX+eZirK6kWuem1H+Xuho/jV9FRf/6VPmrN5G3ohx5WM4Jeq+sQvDXjgj1Rkk0oEvGz5dWsQVz0zjuc+WZzuUhHxeuJndKf59lfd5CZq3bnv4UXclOiWDOKzbvpeNO6PfBX5R6N8AbhMWboi6fNH6wN39g3GUH786czVzIvSMHv3JcpZFaYMfSTruP5fEUUl9z9sLWPjtzvKnuE+WJjeU+T+/WMmi9Tsp3OR/i6j/zlnLyQ9MTPjJLRXfehe/sgtjLJu/2x/znd3ptmbrHq59bga/HvNVxo6572BJRhtfVDdKBnE4c9RHnPZwYMiGSBfCmSv9a+3yzy9WxrXeGwWxi7ZGvjWfy5PsGR1J4abvyjtqRXKguDSlJrCFm74rT3qhpnkjpy5YF/3JIFbSGvSH+Cq8E3kuuPfthYGxb0L6jsTj2+17yRsxjsFPfcL+4sS3j1f+g5Pofu8ElhfFlzwicc4x+euNYYdhj2W3l4ziTWB+GPnWfC57+vOMHa+6UTKoBpLtTBxpRFUItBR6dWb44bf9cNd/53P2o1OiNhuNVvoy6A8fR1xWVuEe2hEOUut5fSCBu/l0XKw/9Z50Fm/YxXvz1pfP//krszj9Yf/Hj3rtyzWxVwrxl4+Wcsebgc6GHyzYwA0vFvB8jOKpol37+fsny8P+bpJ5299nSzeTN2JchZuNSL/24N/TV2u3J3ysmkTJ4DC1Zusevo5wZ50JH3tvc9t7IL6L5jcbdjF+/vrYK0Yxb812Oo4cz+eFgXdEJFrSf/+74YvdgpNWWRFL13s+iLqvRHLS54WbWbKhYpFV8DHHz9/AhhjFlMHH3LH3IN/782flYzL56fEPvykfebes6HTdtuhl9Le9PoeHxn9doZ+GRfjtFJeUxnzSeHNWIImF1qWFc9EfP425jgTUuGRQtGt/1Dvm9Tv2sihK56KqXZV4yOzV2yt8ropxBxcRPPfZirCjryZi+vJA8VFZIipz40sFcT0FxZM8Py/czM69FcvbK9TJeCf6kfFfkzdiXNiK6tB51z43gwtC+mi8NTv+8a9CL6z9H5vC/HU7+NPk7La3Lxu+Y9e+wPkKd5EPTZq9H5jIqQ9NAgJDTa8M0+w6x8uUxaWOYm+fZoQt9kqmTqymqnHJ4NSHJpH/4KSIy/s+8hEX/alq3U1EKjuP5UfPzyyfzlSjw9C7+2jHLU5TU8hwzYRHvjW/wueiMDcE+w6W0uehSTw2YTEfLd7Ipp2B148eLIkeZ7g6mbIimNAtvyjcTKe7xsesyPyscHPU5dFs25P9d2t/uHADne9+P2KCDVdEeLCklF37itnq9fju9+gU+j8+tdJ6Od7gXcFjRZWUuohvHTx0zKp4S1R11LhkkIpkR89Mp673vJ/tECoY8Z9A65BoX7vtew5UunsPtiHF9vtlF5Nol/Dr/vFlpXlrtu1h0679PD1lGdf/syBsZ8BF3+6MXhcT5ZiFm3Yx2ut1PWN55dZn4e5ik20+C/BOCsMxlJQ6fvjMtKi/p0iWbNhV3ggitJz+gwXrufu/89njFR8u3fQds1dv463Za+l8d8W/5e8iNDstSwaPfnDobYKPaNyolKkHcgL6PTaFn/c/NtthVLC/OL5Kz3+HFJOk6x4p1t3+zn0H6XX/xKjrvPC5P+PvJNpaJrTIItwY+M9+spxnP6lcYbpjz0FWxnivQ6zWS6PD7Pd7f4l/lFpHoJjTDzv3HmTmyq1889oc5t57fkLbBhd5zVxRsVz/pn8FigKD7+LDvQckWv+DsmQQ/ASUypOUBNT4J4NEK9nGpVjJmaxU32k87quKcYe7oPkh9IIa+vnOGO3KEx0m+nt//qy8iWnwod6d9y0rE3ySC23ZEk8FZZn/eX4GQ57+nJ37Kl/EiktK0zv8tZfZJyzYwMad8f+dRLoh+HLl1oTa46/csocnPlwStn7kP7OT69n/m3cWRFxWlgzEX74kAzMbbGZLzKzQzEaEWf4TMysys7nez41By4aZ2VLvZ5gf8SRi4BORmzAC3P763AqfV2WpqGjYCzNjr5SAsqKUdIlUPBuuOWiwn748K6HmofPX7eDBcYvYsfcgo94/VGyQTD3LvhTGtJkfpc/D6Y9Mpud9EyrMe2rSUjbt2pdUG/1Idu0v5rEJi8Mu23ewhPcj1OeUlDryRowjb8Q4Hh7/NVc+M43r/lm5GC2Sj78p4s8fFdLprvG8PcefFz9Fq0BPNhUohUSXcjGRmeUATwPnAWuBL81sbJgX27/unLslZNsWwG+BfAJ/m7O8bTPw0oDoVm/Zw5uz1vCWT3/cqaoK7zCIx96DJXy4cEPSF7mPFm/i2NyOCW1TUup4Kc6Oepn23f5iNn9XOfHuPVgS893TeSPGRV1+xd++oFubJvRs17R83ucResKPen8x//xiJa8NP73SsuC2+KFFVdv3HGTPgWLmrtnOGce2Kp//8rSVlVqsARVe3xoqlbS3a99BbnixgMeuODHpfYQev2jXfnIb10shqsOLH3UGfYBC59xyADN7DRgCxDPW7gXAROfcVm/bicBg4FUf4krYgaDy936PTclGCBGlc4wgvw1/eVb5dPBb3PrHeU4TbfXx5cptfLky6/cPYZ30uw/Ttu+CVdsoWLWNR+O4QK71+gLsDHrnRLQm1MF63T+RA8WlfPrrAeXzfvPOwrjjDO1DkYzJX29i5oqt/GHiNzRrUKfS8mSakP5h4jc88v2eKcd2uPCjmKgtENyVca03L9QPzOwrMxtjZu0T3BYzG25mBWZWUFSU3Jg0oRZvqPhlKBuqWPwz4PGp5e3t4y3DT/X9zQCzM/FGuix5a/baCk8N0cb3WbBuB3kjxoV9OVC8la5lN0m7kxzPKN5GDpE8+sFibvOKa0sdvDhtVVL7Cb3FSGcP/OooUxXI7wJ5zrkTgYnAi4nuwDk32jmX75zLz83N9SWo0DujPXH2lpXExWpp47cZK9L/ZrRseW1m/MNITF2yCchc34NEK+3j8depy8qnv01hRNISH24yDmd+FBOtA9oHfW7nzSvnnAsuyHwOeDRo2/4h2071Iaa46G8jc65PoELSz3ctHI7CvRs7ksc/jFyGD/D0lMK4Wzq9GqNTVyxlfVBSkUgLr1ChLyeSivxIBl8Cnc2sI4GL+1DgmuAVzKyNc66sKcOlQFkPkQnAw2bW3Pt8PjDSh5ikignX5DKSZJsj1hQFKVwQ14SMIxSuL0UkyRbPlFnsQ92BpE/KycA5V2xmtxC4sOcALzjnFprZ/UCBc24s8L9mdilQDGwFfuJtu9XMHiCQUADuL6tMzoZMF2XUJOluyirx0TuUJRJfeiA758YD40Pm3Rs0PZIId/zOuReAF/yIIxFbvtvPjBUVm+ElMjiYiMjhpMYOR3Hls9NUhigi4qmxw1EoEYiIHFJjk4GIiByiZCAiIkoGIiKiZCAiIigZiIgISgYiIoKSgYiIoGQgIiIoGYiICEoGIiKCkoGIiKBkICIiKBmIiAhKBiIigpKBiIjgUzIws8FmtsTMCs1sRJjlt5vZIjP7yswmm9kxQctKzGyu9zPWj3hEROKRN2Ic+w6WZDuMKiHlZGBmOcDTwIVAd+BqM+sestocIN85dyIwBng0aNle51wv7+fSVOMREUmE3s8d4MeTQR+g0Dm33Dl3AHgNGBK8gnNuinNuj/dxOtDOh+OKiKTMZTuAKsKPZNAWWBP0ea03L5IbgPeDPtc3swIzm25ml0XayMyGe+sVFBUVJRXogeLSpLYTETnc1c7kwczsf4B84Jyg2cc459aZWSfgIzOb75xbFrqtc240MBogPz8/qWR+9d+nJ7OZiMhhz48ng3VA+6DP7bx5FZjZIOBu4FLn3P6y+c65dd6/y4GpQG8fYgpr1qpt6dq1iEi15kcy+BLobGYdzawuMBSo0CrIzHoDzxJIBJuC5jc3s3redCvgTGCRDzGJiEgCUi4mcs4Vm9ktwAQgB3jBObfQzO4HCpxzY4HHgEbAm2YGsNprOdQNeNbMSgkkplHOOSUDEZEM86XOwDk3HhgfMu/eoOlBEbb7AujpRwwiIslwTu2JQD2QRUQEJQMREUHJQEREUDIQERGUDEREBCUDEanh1JgoQMlARESUDERERMlARGq4UpUTAUoGIlLD/Wv6qmyHUCUoGYhIjbZFbzoDlAxEpKZTKRGgZCAiNZzqDAKUDESkRlMqCFAyEJEaTQ8GAUoGIlKjqZgoQMlARGo0pYIAJQMRqdmUDQCfkoGZDTazJWZWaGYjwiyvZ2ave8tnmFle0LKR3vwlZnaBH/GIiMRLxUQBKScDM8sBngYuBLoDV5tZ95DVbgC2OeeOA54Efu9t2x0YCvQABgN/9fYnIpIRSgYBtX3YRx+g0Dm3HMDMXgOGAIuC1hkC3OdNjwH+YmbmzX/NObcfWGFmhd7+pvkQl4hITBMWbuTcx6dmO4y4/fO6PnRo2dD3/fqRDNoCa4I+rwVOi7SOc67YzHYALb3500O2bRvuIGY2HBgO0KFDBx/CFhGBQd2OpEFdPy6FmVG3dnqqeqvNGXDOjQZGA+Tn5+u5TkR88dywU7MdQpXgR4pZB7QP+tzOmxd2HTOrDTQFtsS5rYiIpJkfyeBLoLOZdTSzugQqhMeGrDMWGOZNXwF85Jxz3vyhXmujjkBnYKYPMYmISAJSLiby6gBuASYAOcALzrmFZnY/UOCcGws8D7zsVRBvJZAw8NZ7g0BlczFws3OuJNWYREQkMb7UGTjnxgPjQ+bdGzS9D7gywrYPAQ/5EYeIiCRHPZBFRETJQERElAxERAQlAxERQclARERQMhAREZQMREQEJQMREUHJQEREUDIQERGUDEREBCUDERFByUBERFAyEBERlAxERAQlAxERQclARERIMRmYWQszm2hmS71/m4dZp5eZTTOzhWb2lZldFbTsn2a2wszmej+9UolHRESSk+qTwQhgsnOuMzDZ+xxqD/Bj51wPYDDwlJk1C1p+h3Oul/czN8V4REQkCakmgyHAi970i8BloSs4575xzi31pr8FNgG5KR5XRER8lGoyaO2cW+9NbwBaR1vZzPoAdYFlQbMf8oqPnjSzelG2HW5mBWZWUFRUlGLYIiISLGYyMLNJZrYgzM+Q4PWccw5wUfbTBngZuM45V+rNHgkcD5wKtADujLS9c260cy7fOZefm6sHCxERP9WOtYJzblCkZWa20czaOOfWexf7TRHWawKMA+52zk0P2nfZU8V+M/sH8KuEohcREV+kWkw0FhjmTQ8D3gldwczqAv8FXnLOjQlZ1sb71wjUNyxIMR4REUlCqslgFHCemS0FBnmfMbN8M3vOW+eHQD/gJ2GakL5iZvOB+UAr4MEU4xERkSTELCaKxjm3BRgYZn4BcKM3/S/gXxG2PzeV44uIiD/UA1lERJQMREREyUBERFAyEBERlAxERAQlAxERQclARERQMhAREZQMREQEJQMREUHJQEREUDIQERGUDEREBCUDERFByUCkxmjWsE62Q5AqTMlARCq45+Ju5B/TPNthSIbVqGRw8YltKs1r3aReFiIRyTzn4l93zM/OSF8gVchpHVtkO4Qqo0YlA5Hq7vu922Y7hCrr2tM6JLzNbYO6pCGS6imlZGBmLcxsopkt9f4N+2xpZiVB7z8eGzS/o5nNMLNCM3vdzOqmEk8sl/Ss/GQgh58LerTOdggRnVIDi19+2q9TRo7z0OU9E97GkcDj0mEu1SeDEcBk51xnYLL3OZy9zrle3s+lQfN/DzzpnDsO2AbckGI8UV3Ysw0rR11cYV7tWtFPQcdWR5RP3zzg2LTEJf7KqWXZDiGiFkek9X4HgA4tGoadf3qn6EUiXVs3BiCv5RFR1wN49IoT44pl9I9OwSz67+PKU9rFtS9Jr1STwRDgRW/6ReCyeDe0wF/IucCYZLb3w/B+nRh6avuo65S1wGjbrAF3XHB8JsI6LM28eyB/u/Zk/ndg57QfK9bFJ5uildv37tAs9vZxHKN3h2b8X8h5fvSKE/nj0N68dH2fiNu1bd4AgHCn74Wf5PPb73Uv/3xiu6Yx41g56mLO73FUzPUa11crp6og1WTQ2jm33pveAER6Pq9vZgVmNt3MLvPmtQS2O+eKvc9rgYgFomY23NtHQVFRUYphB9x1UTfq1o5+Ch4YcoIvx6pJxtzUt8LnHkc34cjG9bmwZxuaNfD3i39VfuVknu1U0KBOTtzrDup26Cvz8g2npSMcAH6Y3576dXLo1yU34aeTk9o349zjW3PdmR358Bf9mDbyXFo3ru9bbCqqqRpiJgMzm2RmC8L8DAlezznniHzjcoxzLh+4BnjKzBIub3HOjXbO5Tvn8nNzcxPdvIJX/9/pfHLHgJjrff/ktjTx7lqq8M1mldOsYR1+1v/Qrzjcuet8ZKOUjzPjroE8eHnFZD2o25HcNij9Tx+heraNfacczr2XdI+9ks9cIs2KQnRp3Zg2TRvQ3MfirkTCSfY8S2wxk4FzbpBz7oQwP+8AG82sDYD376YI+1jn/bscmAr0BrYAzcystrdaO2Bdyv+jOPQ9tiUdWoYvVw1VdteiZJAI487Bh4rUrulzzKEl3nn0owNU6yb1qZNT8U/48t7tOO7IxknvM7goJJbpIweWTz92ZXxl6ADP/uiU8un2LRrEvV0sT13VK6Xtm3pPbbGelqO566LKRal+fncuPenosPOTTRLNGqS/Dqe6SLWYaCwwzJseBrwTuoKZNTezet50K+BMYJH3JDEFuCLa9tlkQQUOtZQNElDxVu+aME3+Wh6Rnv4dea3iS/I/zA9fadk0jmKs3MaB2CP9Sdxy7nFRt78gqBw9kfqNSbefE/e60XYb6Ub8d0N6cM/F3TjruFYV9xVh/d//oHLrnct7J14ZHOtJZeqv+kddPvLC43n31rMSPi5A96ObJLXd4SjVZDAKOM/MlgKDvM+YWb6ZPeet0w0oMLN5BC7+o5xzi7xldwK3m1khgTqE51OMJ2EDjj8y6vIOLRpy41kdeX7YqWGX/6eGdM7xS9mFpXWTegndMb4Xx5d9+siB9Dg6vjvE4LL6Mie2a5pQkYURKE8P1rV1Y24eED0ZRFI7pBXUkgcHl0/feu5xHBemaO3NkPqZeET6PzapX4cbz+5UKUFFOiXndDn03fn7j/Pp2OoImjesU6EFXqTjBderhC6+vHdbBnU7tO/mR9Qtr7D280mqexslgmC1Y68SmXNuCzAwzPwC4EZv+gsgbANgr9gocvOGDOjSujErR11M3ohxlZaZBe7c7olSrtutTfJFErFce1oHXpmxOm37T5/IV/k2zQJf5g4tj2Deb89nz/4STn9kcoV1jmxcj4HdWlM3x3hx2ip+c0l3ToijGOCopvFXajYJ8wRw+3ld2HugJOa2f7m6N3/7eBktG9XjPzf1pdTB8s3fxX1sgL9de3L5uShTv04OY27qyxXPTAOgXu1DF8zbz6vcOSq0mXQ4tWsZxaUVL7fx1hn88rwuPDHxm5jrtW5Sj/O6t+a87oEE+8FtZ1NSGvkYX913PjlmfPJNETNXbqW4pOK6TRvU4cmretHzvgns2hdoX/LOzWcya9U28vNaUHDPIPIfnARA4/q1w44sEI/f/yD+or2aIKVkcDi5/syOvPD5ipjrffTLczj3iY8zEBE0qle9fj292jejf9dcjs2N3E79/O6teeXG0+jbqSW1all5BX2wx648iXO6BBoJ/C5NrblO79SS5g3rsG3PwfJ5ZsYFPY7it9/rzrG5jfjxCzPDbntap5ac1qll2VYA5DYKFB2FuzDVq12L/cWlQGDcHwj0eSnTrnkD1m7bi3OO/LwWvP9/Z5evHxzboaNV9NmdA9i9v4Sv1++stOznA46rlEjiffg5q3OruJJBqOAkBpWLrMp+5xf2bMOFPdswZckmXp6+Kuo+zYz8vEA/iVaNDhUxzr/vgoTjK9MzjuaxNYmGo/CEK9f+1fldK81L5O4zVacf27J8evIvz6FNBo+djLbNG3DboC5Ry8HNjDOPa0WtKB3DEh0vqk+S48u8c/NZPHnVSZzd+VAZea1axnVndqRfl8RarLVsVI8Fv7uAW0PqC+64oCuPX3kSEOj0ldeqcqIcc9MZPPM/J5eft25tmtArpPgpmnbNG9L1qMYMPuEohvQ6mrsu6hZ9Ay8bDOiaG9fTReTdxJdWgn/TDwzpUWn5gK7Ri2olM5QMylX8wx56avuMXfjDjTcz655BFb4ktWsZ00YO5Jchd3kX92xDvy65/OO68HUawWb/5jzm33d+6gGn2fFHJVaW++8bT2PxA4NjrxiiQ8uGXN67XXl59JGNIyeheMrmG9WrXSkR3jzgOFo2it5i5aim9Rl8QnxFHcE3CKHq18nhj0N707pJ/fKnykb1Kvd5KPtL/+PVveM6ZiwWo2dH8DfrR33zoq7bqlFdftT3mMobxmnCbf0q1VlIfJQMIih7JI1XIh2NQoV+we+66HhaNgp/Ybo1pGfp09eezEvX94l6d/XTfp0Y0DXQ2ahx/Tp8+usB3JJkJWc6XN2nfdSipVhq59Sifsj5n/zLc5h510BeubFyR67gykmA28/rynu3nkW3CBWK7916Fqcm+PcA0NJri1/WyatL69Trl35wcnytdYadkcc9F3fjujM7VlpWVmcQq/6+S+vGtGpUl19fUPkJObCfuEJJSME953FsbsWK8kQaGpQ9IUniqlehdAYcm3sEr9x4esSnglh3QanKa9mQ4f38HQPpx2fk0TaosrJ9i4Z0SuHiG0mkMXFieeT7gYq8vBHjysfHSVXZBeXIJpV/jx1aVPy/59SyqBXU8VRehxpzU9/y83H8UU14ffjp9IpjuAm/1MmpxY1nhx8grnH9Ouw+UBKzWesR9WpTcM95EZeX5YKq1uq6ioVTbSgZeFp47d4vPKFN0sVD7916Fpf8+bOEt0v2j/ejX8bf7txPl5zYhve+Wl9pfrgWL4lYdP8FMQcOhEDZ+76DpTHXC9atTZOwFayJCDSfjC/hhT5ZHqpwzr7Xhp/O5MWbUm6gEO8TRro0qa/Ll590Nj0tjqjLvHvPp3EKf2DJ3EGmolNufEM6hGtKGM/d3IvX92FYmBY1PzkjL2wyCO0N/L8DO9O/a/wVsQ3rxnfuXxueWNv6laMu5tvtezlj1EcJbReqrOlkdZfX6ghuOKty8VGyYj1hnHlsK/42dRl+DiY75zfnUSeFntJSmZJBkKZxDJEQ+ndf17sAXndmXhoiyq5+nVuFbWseb7FAqk8KfqpqRRmHg+YNA3UhV8UY+feszq1479azwrakSvrYGRgKvKZRMkhR7ZxaKTXPi1fbZv71vIyXmYVt0JGOisN0C4753Bi9zsuc0yW3RgxX8MZP+7J0066EtzuiXm2WPXxRXHf8mX5qlsQpGSQoWxfC2jlV85G4fp1aCZffZ1ObpvU5q3Or2CsSKCarCfp0bJF0X42q/CIhSYySwWGuVaO65QOrBQttFVUnxzhYknimW/zAhTw+YQlHJthRLBn/+dkZrNqyO+3Hqcp08Y2trEjwlGOaM2vVtuwGU40oGSQoHWXP0Srgbh5wbIUBwRIVrWlgsHsu7s5vxy6sHFsc2/4qQjt0v51yTPMa+Q5hSc6ArrlKBgmommUPNUy0gcPuuOD4pB/h43F6pxb075rL5SdHfMlcubJx7lUZK3678pR2XB6mJ34yBnoj0qZyE1UT6ckgQdWx8jSaIxvX509RhiUo++9e1PMoNuzYx+zV2zMSl9Qsj3njNwX70zW9efqjQhrF2eS4zMkdmmekUcfhRskgBeHGxE9GcDFRpl7mnuhhjs1txIYd+8o/j/p+T75cWX0ewY9qUp8hvY72tX19NkUbR+lwMaDrkWkbxO7mAf728j8cKBkkKPgiGu5lIynv34d9RHo/QyzXnZnHPz5fGde6Q/t0YGifyiO9VlW1ahl/HOrPwGyZNP5/z2bOmopJ95UbT0vL357UbKozqAIq9HrOYnn8b7/XI+r7bw+zErJqofvRTbj2tGMqzDvzuFa0DjPmksTvrOMSG6K8JkgpGZhZCzObaGZLvX8rNfUwswFmNjfoZ5+ZXeYt+6eZrQha1iuVeDIhHXUG53dvzU/PCQwqFvpikHQpewdxu+YVO7MFv58X4AentOOoJvX5YX5wL1PVIEv1Evpe575RhgKvqVItJhoBTHbOjTKzEd7nO4NXcM5NAXpBIHkAhcCHQavc4Zwbk2Ic1ZqZMWLw8dTLqcWV+dG79vvlrM6teO7H+ZwTMnbQE1eexLvzvi3/3LZZA6bfVenNpiLVynPD8pm5YmvEt9dJ6sVEQ4AXvekXgctirH8F8L5zbk+Kx80av+t3rzylnbdf4/bzu9I+yWGgkzGoe+tKg8tFKyYSqa7q18kpf6+EhJfqk0Fr51zZ8JUbgFjNa4YCfwiZ95CZ3QtMBkY45/anGFO1Eq5JnR9O69iC/zn9mNgrihzGPvxFP7buPpDtMKqFmMnAzCYB4V4ddHfwB+ecM7OIJepm1gboCUwImj2SQBKpC4wmUMR0f4TthwPDATp0qD6tWLLl9Z8mNsxzsIm/6EdBmJ6bZSO0qtOZVBd+vF2upoiZDJxzgyItM7ONZtbGObfeu9hvirKrHwL/dc4dDNp32VPFfjP7B/CrKHGMJpAwyM/PrxINWw7Xi2Ln1o3pHOZL9NTQXrw8bRW92jXLfFAiklapFhCPBYZ508OAd6KsezXwavAML4FggZ5WlwELUoxH0qhN0wb8evDx1NJgaSKHnVSTwSjgPDNbCgzyPmNm+Wb2XNlKZpYHtAc+Dtn+FTObD8wHWgEPphhPtfC7S3tkOwQRkQpSqkB2zm0BKrU7dM4VADcGfV4JVBqFyjl3birHzwY/ioaGnZEXdoTQRBylTkci4iMNR5GgerVzOLlDs5QHbPvJGXnUyUkus3z4i37kNjr8x6YRkcxRMkjCwG6tIyaDTq2O4LwerXn24+VR93FfCkVFaiEhIn5TMkhBuKEpPvpVfwC6tm7M7W/My2g8d1zQlWWbvsvoMUWqi6YN6mQ7hCpNySAJidYb9O+ay8rNu1m5Jb0dr28ecFxa9y9SnWWyd391pGSQAX+79hQa1M1JalhpEZFM0EA0aXZ577Y0qJuZkUhFRJKlZCAiIiomSkay7zQYeeHxagkkIlWSkkEKolUkH9MyUFl1Qtum5fN+eo7euyqSTS9d34e8lkdkO4wqSckgTU45pgUTbutHl9Z6V61IVdGvi153GYmSQRp1PUpFQiJSPagCWURElAxERETJQEREUDIQERGUDEREBCUDERFByUBEREgxGZjZlWa20MxKzSw/ynqDzWyJmRWa2Yig+R3NbIY3/3Uzq5tKPJlS9oayOnoxvIgcJlJ9MlgAfB/4JNIKZpYDPA1cCHQHrjaz7t7i3wNPOueOA7YBN6QYT0b8uG8eP+3XiZv6a3gJETk8pJQMnHNfO+eWxFitD1DonFvunDsAvAYMMTMDzgXGeOu9CFyWSjyZUr9ODiMv6kbDuurALSKHh0zUGbQF1gR9XuvNawlsd84Vh8wPy8yGm1mBmRUUFRWlLVgRkZoo5q2tmU0Cjgqz6G7n3Dv+hxSec240MBogPz8/yUGkRUQknJjJwDk3KMVjrAPaB31u583bAjQzs9re00HZfBERybBMFBN9CXT2Wg7VBYYCY51zDpgCXOGtNwzI2JOGiIgckmrT0svNbC3QFxhnZhO8+Ueb2XgA767/FmAC8DXwhnNuobeLO4HbzayQQB3C86nEIyIiyTGX7Dscsyg/P98VFBRkOwwRkWrFzGY558L2CVMPZBERUTIQEZFqWkxkZkXAqiQ3bwVs9jEcvyiuxCiuxCiuxByucR3jnAv7IuhqmQxSYWYFkcrMsklxJUZxJUZxJaYmxqViIhERUTIQEZGamQxGZzuACBRXYhRXYhRXYmpcXDWuzkBERCqriU8GIiISQslARERqVjKI9PrNNB2rvZlNMbNF3qtB/8+b38LMJprZUu/f5t58M7M/ebF9ZWYnB+1rmLf+UjMb5lN8OWY2x8ze8z6HfQWpmdXzPhd6y/OC9jHSm7/EzC7wIaZmZjbGzBab2ddm1rcqnC8z+4X3O1xgZq+aWf1snS8ze8HMNpnZgqB5vp0jMzvFzOZ72/zJzOJ6t2uEuB7zfpdfmdl/zaxZrHMR6Tsa6XwnE1fQsl+amTOzVlXhfHnzb/XO2UIzezSj58s5VyN+gBxgGdAJqAvMA7qn8XhtgJO96cbANwRe+/koMMKbPwL4vTd9EfA+YMDpwAxvfgtgufdvc2+6uQ/x3Q78G3jP+/wGMNSbfgb4mTf9c+AZb3oo8Lo33d07h/WAjt65zUkxpheBG73pukCzbJ8vAi9cWgE0CDpPP8nW+QL6AScDC4Lm+XaOgJneuuZte2EKcZ0P1Pamfx8UV9hzQZTvaKTznUxc3vz2BAbPXAW0qiLnawAwCajnfT4yk+crLRfCqvhDYGTVCUGfRwIjM3j8d4DzgCVAG29eG2CJN/0scHXQ+ku85VcDzwbNr7BekrG0AyYTeO3oe94f8uagL275ufK+MH296dreehZ6/oLXSzKmpgQuuhYyP6vni0Nv6mvh/f/fAy7I5vkC8kIuIr6cI2/Z4qD5FdZLNK6QZZcDr3jTYc8FEb6j0f4+k42LwOt2TwJWcigZZPV8EbiADwqzXkbOV00qJor0+s2084oKegMzgNbOufXeog1A6xjxpSPup4BfA6Xe52ivIC0/vrd8h7e+33F1BIqAf1ig+Oo5MzuCLJ8v59w64HFgNbCewP9/Ftk/X8H8Okdtvel0xHg9gTvnZOJK6BW5sZjZEGCdc25eyKJsn68uwNle8c7HZnZqknEldb5qUjLICjNrBPwHuM05tzN4mQuk7Yy27TWzS4BNzrlZmTxuHGoTeGz+m3OuN7CbQJFHuSydr+bAEALJ6mjgCGBwJmNIRDbOUSxmdjdQDLxSBWJpCNwF3JvtWMKoTeAJ9HTgDuCNeOsg/FCTkkGk12+mjZnVIZAIXnHOveXN3mhmbbzlbYBNMeLzO+4zgUvNbCXwGoGioj/ivYI0zDHKj+8tb0rglaV+x7UWWOucm+F9HkMgOWT7fA0CVjjnipxzB4G3CJzDbJ+vYH6do3XetG8xmtlPgEuAa71ElUxc5a/I9SGuYwkk9nned6AdMNvMjkoiLr/P11rgLRcwk8CTe6sk4krufCVTZlkdfwhk3eUE/hDKKlt6pPF4BrwEPBUy/zEqVvY96k1fTMXKq5ne/BYEytKbez8rgBY+xdifQxXIb1Kxwunn3vTNVKwQfcOb7kHFSq3lpF6B/CnQ1Zu+zztXWT1fwGnAQqChd6wXgVuzeb6oXNbs2zmicoXoRSnENRhYBOSGrBf2XBDlOxrpfCcTV8iylRyqM8j2+boJuN+b7kKgCMgydb7SciGsqj8EWgt8Q6AG/u40H+ssAo/rXwFzvZ+LCJTnTQaWEmg5UPZHZcDTXmzzgfygfV0PFHo/1/kYY38OJYNO3h92ofeHVNaiob73udBb3ilo+7u9eJcQZyuKGPH0Agq8c/a298XL+vkCfgcsBhYAL3tfyqycL+BVAnUXBwncSd7g5zkC8r3/5zLgL4RU6CcYVyGBC1rZ3/8zsc4FEb6jkc53MnGFLF/JoWSQ7fNVF/iXt7/ZwLmZPF8ajkJERGpUnYGIiESgZCAiIkoGIiKiZCAiIigZiIgISgYiUZlZSzOb6/1sMLN13vR3ZvbXbMcn4hc1LRWJk5ndB3znnHs827GI+E1PBiJJMLP+duhdEPeZ2Ytm9qmZrTKz75vZo9449x94w5KUjX3/sZnNMrMJZUNIiFQFSgYi/jiWwDhPlxLoRTrFOdcT2Atc7CWEPwNXOOdOAV4AHspWsCKhasdeRUTi8L5z7qCZzScwbswH3vz5BMag6QqcAEz0BqLMITAcgUiVoGQg4o/9AM65UjM76A5VxpUS+J4ZsNA51zdbAYpEo2IikcxYAuSaWV8IDG9uZj2yHJNIOSUDkQxwzh0ArgB+b2bzCIzieUZWgxIJoqalIiKiJwMREVEyEBERlAxERAQlAxERQclARERQMhAREZQMREQE+P/eNYpfwd1XqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABPEElEQVR4nO2dd3gVRdfAf3NvOgktCTVURQVEEBA7omJX1FdfsQuKXT59rfjaERVFX7FgV0BQsaGggCiIAor0jjSpoSaBBALpme+P3Zvb9pYk9+aGm/N7njzZnZ3ZObt398yZMzNnldYaQRAEIfqxRVoAQRAEoWYQhS8IglBHEIUvCIJQRxCFLwiCUEcQhS8IglBHEIUvCIJQRxCFLwiCUEcQhS8IgFJqi1Kqb6TlEIRwIgpfEAShjiAKXxB8oJSKV0qNVErtNP9GKqXizWNpSqkflVK5Sql9Sqk5SimbeewxpdQOpdRBpdQ6pdS5kb0SQTCIibQAglCLeQI4BegGaGAS8CTwFPAQkAmkm3lPAbRS6ljgPuAkrfVOpVRbwF6zYguCNWLhC4JvbgCGaq33aq2zgOeAm8xjJUBzoI3WukRrPUcbganKgHigk1IqVmu9RWv9T0SkFwQPROELgm9aAFtd9reaaQAjgI3Az0qpTUqpIQBa643AA8CzwF6l1ASlVAsEoRYgCl8QfLMTaOOy39pMQ2t9UGv9kNa6PdAPeNDhq9daf661PsMsq4GXa1ZsQbBGFL4gOIlVSiU4/oAvgCeVUulKqTTgaWA8gFLqUqXU0UopBeRhuHLKlVLHKqXOMQd3C4ECoDwylyMI7ojCFwQnUzEUtOMvAVgErABWAkuAYWbeDsAMIB+YB7yjtZ6F4b8fDmQDu4EmwOM1dwmC4BslH0ARBEGoG4iFLwiCUEcQhS8IglBHCInCV0pdaK4o3OiYnuZxvLVSapZSaqlSaoVS6uJQ1CsIgiAET7V9+EopO7AeOA9j5eFC4Dqt9RqXPB8AS7XW7yqlOgFTtdZtq1WxIAiCUClCEVqhF7BRa70JQCk1AbgcWOOSRwP1ze0GmHOZ/ZGWlqbbtm0bAvEEQRDqDosXL87WWqdbHQuFwm8JbHfZzwRO9sjzLMaKxMFAPcAyDK1S6g7gDoDWrVuzaNGiEIgnCIJQd1BKbfV1rKYGba8DxmitM4CLgXGOyIKuaK0/0Fr31Fr3TE+3bKAEQRCEKhIKhb8DaOWyn2GmuXIb8BWA1noexoKWtBDULQiCIARJKBT+QqCDUqqdUioOuBaY7JFnG3AugFKqI4bCzwpB3YIgCEKQVNuHr7UuVUrdB0zHiPv9idZ6tVJqKLBIaz0ZI3b4h0qp/2AM4A7QssRXEIQgKSkpITMzk8LCwkiLUmtISEggIyOD2NjYoMvU2tAKPXv21DJoKwgCwObNm0lJSSE1NRUjXl3dRmtNTk4OBw8epF27dm7HlFKLtdY9rcrJSltBEGo9hYWFouxdUEqRmppa6R6PKHxBEI4IRNm7U5X7EZ0Kf9t82L0q0lIIgiDUKqJT4X9yPrx3OuRlRloSQRCihOTk5EiLUG2iU+E7eL1zpCUQBEGoNUSfwi8+7L6fu906nyAIQhXQWvPII49w/PHH06VLF7788ksAdu3aRe/evenWrRvHH388c+bMoaysjAEDBlTkff311yMqeyhi6dQuig667488Hp7Ni4wsgiCEnOd+WM2anQdCes5OLerzzGXBeQQmTpzIsmXLWL58OdnZ2Zx00kn07t2bzz//nAsuuIAnnniCsrIyDh8+zLJly9ixYwerVhljirm5uSGVu7JEn4VP7VxXIAhCdDB37lyuu+467HY7TZs25ayzzmLhwoWcdNJJjB49mmeffZaVK1eSkpJC+/bt2bRpE4MHD+ann36ifv36gSsII9Fn4QuCENUEa4nXNL1792b27NlMmTKFAQMG8OCDD3LzzTezfPlypk+fznvvvcdXX33FJ598EjEZo9DCryalRbDp90hLIQhCLeXMM8/kyy+/pKysjKysLGbPnk2vXr3YunUrTZs25fbbb2fQoEEsWbKE7OxsysvLueqqqxg2bBhLliyJqOzRZ+FXN1TE9Cdg4Ydw52xo3jU0MgmCEDVceeWVzJs3j65du6KU4pVXXqFZs2aMHTuWESNGEBsbS3JyMp9++ik7duxg4MCBlJeXA/DSSy9FVPboU/i+fPj//ApTH4G7/4SYeN/Fs9cZ/wv2h140QRCOWPLz8wFjheuIESMYMWKE2/FbbrmFW265xatcpK16V6LPpePLwp/6KORshP0+PwYjCIIQ1USfwg+ELgOze2V9XGb5CIIQnUShwrdQ2CUFThfNO6fA+2cGcR4J1CQIQnQRhQrfgrd6wOFs5/4eCawmCELdo24o/AOen9gVBEGoe0SfwhcfvCAIgiXRp/BDFVpBPrYgCEKUEX0KXyx8QRDCQLjj4Y8ZM4adO3eGtY7oU/jBsn8LTP4/KCu1Pj5vVI2KIwhC3aYmFH7dWWnryfirIWcDdL0W2pzmUtwsv/6n0IsmCEL1mTYEdq8M7TmbdYGLhgeVVWvNo48+yrRp01BK8eSTT9K/f3927dpF//79OXDgAKWlpbz77rucdtpp3HbbbSxatAilFLfeeiv/+c9/vM75zTffsGjRIm644QYSExOZN28eiYmJob1GolHhB+vSydlg/B99kcTLFwQhaMIRD//qq6/m7bff5tVXX6Vnz55hkz36FL7EwxeE6CZISzxc+IuHf+utt1JSUsIVV1xBt27d3OLhX3LJJZx//vkRlb3u+vB9Ig2GIAiVxxEPv2XLlgwYMIBPP/2URo0asXz5cvr06cN7773HoEGDIiqjKHyA/KxISyAIwhFCuOLhp6SkcPDgQZ/HQ0H0uXSqMi3z1aPFjy8IQlCEKx7+gAEDuOuuu8I6aKt0LZ233rNnT71o0aLKF8z5B97qXvlyDoU/+hLYOtc9TRCEiPL333/TsWPHSItR67C6L0qpxVpry5Hf6HPpxNWr5glcGsCi/GqeSxAEofYQfQrfHle1cnkWAdZealk9WQRBEDy499576datm9vf6NGja6Ru8eE72LkEGoiCFwQhvIwaFblV/NFn4Vd3WmUtHdMQBEGoLlFo4fv5fKE/vrzR+N/6NP/5BEEQjlCiz8IXC10QBMGSkCh8pdSFSql1SqmNSqkhPvJco5Rao5RarZT6PBT1WlJVC9/Btj9DI4cgCEIto9oKXyllB0YBFwGdgOuUUp088nQAHgdO11p3Bh6obr0+qa7CFwRBsCDc8fB9sWzZMqZOnRqSc4XCwu8FbNRab9JaFwMTgMs98twOjNJa7wfQWu8NQb3WiMIXBCGKCKXCD8WgbUtgu8t+JnCyR55jAJRSfwB24FmttVfAeaXUHcAdAK1bt66iOOLDF4Ro5uUFL7N239qQnvO4xsfxWK/Hgsobjnj4AH369OHkk09m1qxZ5Obm8vHHH3PyySfz9NNPU1BQwNy5c3n88cfp379/la+zpmbpxAAdgD5ABjBbKdVFa53rmklr/QHwARihFapUUzgHbXO3w+EcaNEtfHUIglCrCUc8fAelpaUsWLCAqVOn8txzzzFjxgyGDh3KokWLePvtt6steygU/g6glct+hpnmSiYwX2tdAmxWSq3HaAAWhqB+d8Lh0plwg6Hkfx1m7EuMHUGIGMFa4uEinPHw//WvfwHQo0cPtmzZEnLZQ+HDXwh0UEq1U0rFAdcCkz3yfI9h3aOUSsNw8WwKQd3eNGgVOE9l2DgT1v7oVPaCIAgWhCIefnx8PAB2u53SUh/f264G1Vb4WutS4D5gOvA38JXWerVSaqhSqp+ZbTqQo5RaA8wCHtFa51S3bkvsIfZSjf9XaM8nCMIRTbji4fsilHHyQ6IdtdZTgakeaU+7bGvgQfNPEAThiCVc8fB9cfbZZzN8+HC6detW7UHb6IuHD/Bsg9AK43V+8eELQk0i8fCtkXj4giAIgiXRFzxNEAShFnPvvffyxx9/uKXdf//9DBw4MOx1i8IXBOGIQGuNUirSYlSbUMXDr4o7Xlw6giDUehISEsjJyamSkotGtNbk5OSQkJBQqXJi4QuCUOvJyMggMzOTrKysSItSa0hISCAjI6NSZUThC4JQ64mNjaVdu3aRFuOIR1w6giAIdQRR+IIgCHUEUfiCIAh1BFH4giAIdQRR+FVh02+RlkAQBKHSiMKvCqLwBUE4AolOhX/Np+E9vyz+EAThCCQ6Ff6xl4S5AlH4giAceUSnwg/1R1AEQRCigOhU+ADnPhO+c5cWe6ft2wxzXgtfnYIgCNUkek3hDMv4/6Fh/rvQrAss+RSadoZLXoPRF8HBXdD1eqjfPHx1C4IgVJHoVfiEOYzqpHuM/9v/giYdDWUPiH9fEITaSvS6dGoybvbaH2uuLkEQhCoSvQo/3BZ+JRgxfS1/bMyOtBiCINRxolfh1+iXcfzXNWrWP9zw0fwakkUQBMGa6FX4NWnhZ62ruboEQRCqSPQq/Jq08A/urLm6BEEQqkj0Kvxa5MMXBEGoDUSlwi8uLac0YvFupKERBKF2EpUK/5gnp/H4xFWRFkMQBKFWEXUKv7zcsOw37D0UWUHKSiNbvyAIggdRp/D3HiwCIrzedfsCeD4VNv0eSSkEQRDciDqF7+Af3SIyFS8dB59dbWxvmhUZGQRBECyIOoWvTds+n6TICLBmEhTmRaZuQRAEP0SdwhcEQRCsEYUfclymZWrNb+v2Rk4UQRAEF+qEwj+r6H81V9mBHW67KzLFvSMIQu0gJApfKXWhUmqdUmqjUmqIn3xXKaW0UipsXyexWm+1WzcOV3XeFOxzbtdoADdBEAT/VFvhK6XswCjgIqATcJ1SqpNFvhTgfqBOhY1UgI1yUjgcaVEEQajjhMLC7wVs1Fpv0loXAxOAyy3yPQ+8DBSGoM5KoSI1K19rlIKhMaNZmTAISosiI4cgCAKhUfgtge0u+5lmWgVKqe5AK631FH8nUkrdoZRapJRalJWVFQLRzPNG+LODV9j/MDbKLD5+LgiCUEOEfdBWKWUD/gc8FCiv1voDrXVPrXXP9PT00MkQsjNVoW6lSFY13qkRBEHwIhQKfwfQymU/w0xzkAIcD/ymlNoCnAJMDufArSAIguBNKBT+QqCDUqqdUioOuBaY7Diotc7TWqdprdtqrdsCfwH9tNaLQlB3UETWoeOKRV+j8ACs+rbmRREEoc5RbYWvtS4F7gOmA38DX2mtVyulhiql+lX3/JWWx2X7/4rv48PSiykggUdK7qhpUQBofHiT/wyT7oVvboU9a2pGIEEQ6iwxoTiJ1noqMNUj7WkfefuEos5gmFx+GpPLTwPg67I+jIj9oKaqruC6hf/2nyEv0/hfUhB+YQRBqNPUiZW2EeOPke77wS7EyvkHPr0CiiMc018QhKhCFH7EsRhh+PlJI7Typt9qXBpBEKKXqFP4sfYjNJzBESq2IAhHDlGn8OsnxEZaBN+86PJRluJDkLUeysvMBNH4giCEl5AM2gqVYP3PcMz58FpHKHKJpCmB1gRBCDNRZ+FbRct08FTJgBqTwyd7zemXRRI2WRCEmiXqFH65H42frRvUoCR+2DI30hIIglAHqVMKX9cGP7lSMOYSqwM1LoogCHWLqFP4yfG1fVhCFLsgCJEh6hS+8jP4WSti6viSzyrd34CEEB2UlUJ5eaSlEOoIUafwaz0/P+njgIKCXPhnFtILiHLKy43fGuD5VBh7aUTFEeoOdUrhzyk/gfnlx3Ft8ZMsLu8AQLmuRcr1yxth3BVQmBtpSYRw8utQeLkNFOw39rf+EVl5hDpDbXd4h5TDJNC/2Ijptl8nA7XEzeNgyxzjv3wZK7pZNdH477DyBaGGqFMWfq3Gl2+/+BDsXlmzsgiCEJXUWYX/VumVZOv6fFd+ZqRFMSgvdW5nLnRuv9gC3jsD9q6teZmEMFGr+pVCHaLOKvzl+mh6Fr3H8vL2kRbF4IM+3mmrvnFu71hcY6IIYcah7yWchlDDRKXCX/b0eUHnHV/WlxuKHwfg97IT+KT0wnCJVXlWf+e+v+wLIxZPJNEa1k4xphMK1UQUvlCzRKXCt9uCf5E0Nv4o70Lnwo+5reRhhpbeHEbJqoOG7++CzwN8QevZBvDjf8InxrppMOF6mPu/8NUR9YhLR4gMUanwUxJiue2MdpUqc4hESo+kSUta+16YtegT3+VGXwIf9a1yteX5ewEo3b+tyuc4Ujn1pZn83xdLQ3dCcekINUxUKnyAy7u1CJzpSGLqI+77r7SHN7oGXVxrTXFpOWyd6z4oHAxb/4TsjQCszMwFYNWO8Eb7vP3TRbz8U+0aqN6VV8jk5Turf6KKhloUvj/yi0p5a+YGysqlRxQqolbhR11UgpLD7vsF+yB3q+/8zzaArHUVu8/9sIZjnpxWtbpHXwRv9wCgqNQIA1BcGoJwAAW5MOEGOJTjdeiXNXt497d/ql9HCEnhMPGEYo2E+XDWUQu/rFyz50BhwHzDp/3Na7+sZ+rKXTUgVc2gtabcogHTWvP1ou0cKgrv2FjUKvy6wk+rdlNS5kP5/vNrxeb4v/w0DqFGa5cveXmz/1AxPyzfabie1v4If75ZufOXl0H2hmoKWXlWJgzi57hH3dJy8otYt/ugZf68ghL+2Jgd1Lnzi0rJD/PLXlt4aerfnPziTHLyi/zmO1xkPEMhMS5qCQ98uYz2/53qlb54634e+WYFT01aFdb6o1bhJ8XZIy1C+HCZk3/X+MW89etGv9kPFZVSGopucdZ62u74wbmvNeRa+PIn3QtDG/s8zeAvljL4i6XkFpRUTY7fX4a3e7r1YMJG9gajt2R+w6CNzRjDIC8TNs/hvNdnc8HI2ZZF7/h0ETd8NJ88z+u06H4e/8x0jn9mekhFjzglhZaLBmeuNe6h476Mm7eFbD/KP5o665OWWbsEDxUbjVvWQf+NYHWJWoXfoWlKlcse1vEhlCQMvHNyxWZv23J25hZY5zMVy+MTQ7RSd9RJNNm/xLm/eDSM7AKZLmsEykph2Wd+T5O3P5tzbYsps4gSeaioFB3IH7dtnvH/YPBd/X5vz6X3K7OCzl/B5t+N/6u+dU9/+yQYeyn7Drm7eApLyhg4egGbsw+xYW8+AKWuPbBV38JhhwsrTC4dx9TZSEfhnDzYWDR4yLqXszXnMAs27+OpSau557Ml3hlCfXvKy6A0vAo1WL5dnOm2X1jiu0ccSqJW4VeHTkWj6VP0WqTFCIrHY74ImKf+nr9YFH8XSbj4TV0e/Hn/5NB2yBR25floOHyx7S/jf47TvbJ78eSAxZ4ofI2P414j5uAOI8H0Ze89WEjnZ6bz3u+bKidHEKzIzGPPvlzKx/Sj/9CPmL56t/8CWsOMZ2HXcmPfc02E55iKydwN2cxal8WwH9c4T+XYyNsB39wKZea9d/Hht1W7aKdC5Kte9rkxdXaxn9lagSjMMyz06rB9vvG/yNrlNXDMQq5532i89x/yHhvJKFjL+vibiC/YWz05HHx1MwxrEppzVZOHvl7utn/X+JpZWFknFP5Np7SpdJktunkYJAk9HW3bOO6g8WJZDQY9+f1KhuUOIU0doL/dxcJ1efDHzzf8+4u27K+2PLtynYqwpKycD2b/4+WDbVluKDZV6mxgduQW0OuFmQBMWRlgJkyAHsAX87dy7JDvOFjo7krpbtuAbcvv3F/yMS9M+dt/HYeyYO7rsORTY78g8L3ZlJXPd8t2VOw71HmFuKW+Fehv8Q8xK/4hdxGKStlo9hL8sTO3gN15hRVliveb1uOBys8o+n19ljFwOLw1fFz16bv+sOrBWf2ivfdNJE6V0TT7z4DnfO/3fzjlxZn+M639MUgJQ0hRPkx9FIqtDQQHDfUBtiRcT5eCRWEVp04o/HvOPqpK5ZaVV61cTTNo2yOsnjjcezBo5xLG/+X0sfe0+fZ5p7OfxPxthlVXEtjS77X/R1jxpbFTkAs53jNqxv+1lRenruWjue4Wu3dPXfHlwu0Ve8HPsLLu8xf8+grrEgawZ4/TYr7AtoDLbcGFIV68dR9LtnjPHArE+a/PZsoKZ52BJ+H4zrDvUDGdn5lO3//9HrDe04b/yikvzeTUl2bS+ZnpvDHT/5iOL7bvO8wtnyzgYYf1WdmgfQd2GuMd6z3HIqx/0Abkc6nNsPD9ufGCeR6GT1vLbh8zfz6as4ltOf4V7rh5W3wOvleLP9+EBe/D/Pf8Zuti2wzAhfnf+s1XXeqEwk9JiK1SuWxdP8SShI/OK17yTlz5NS3Jqti9xL7AK8sfG7OZsmIXCxPupe8vF8ALTeGFZvz5TzY7cgs4UBjEwOpPj8Fb3bnsrbm84zKV0jHFLL/QevbJL2tMt4qHZnR9wbXWvPf7P5buplU73dcCrNqRR9shU+hdYMxOsh82fceTB/N+3EiujfkNgNPsa7ix5Gufl3PVu/O4swpdbNeBcVcdpTEXyXlY3N+79AYcfLlwGwcLS3j0m+Vex9g4wxlaGeDtXjD9iYrdXXmFxFNMnKrabJ9DxUa5TVmHKl227ZApfPuDOaC/eIzx30eLZ9NlNOYAb8W+xdtxb/Fp7EtklGVa5vXk2cmrmWRx33yRd7iEYVP+5p4PfvKb76lJq30OvlcLR1BEl1lrjTlAMu4NkONO5R4q5pgnpnn1TkNFnVD4ibF2GiXFctpRqZEWJawk4m3h1Fe+LZvl23O54aP5lscSxl7AXS9/xEUj5wRd/8odeSgXVef43KQG2L7Q8GEDZaZGd6oDxRoX5a2BOEqIoZTN2YcYPm0td41zKuD8IuNleGHqWrdFOT+v2eMmj3bI4nDLuHBHicvAcu422LPa7Xgoxwsz9xfA0nFeX7Z6Yar3wrLHvl3JfZ8vZcbfTr91hatu/FXwzUA+nruZTVn5kL0O5r1tylvOUWoH6xIGcH+Mo1Ewr2LzbMPyzgyuEVu3x93SXbUjL6hBxZ/McZGi0jIufP33immmv651/10GlYxnScJddLZtAaC3fSVPF77izFBeDiu/qXiWlPm8fP7354xdsIz7JywL6joAys2yTxcM95svoeU4YpJX+82Tk1/kZXiUl2temvq374kTFk/SkoS7mBc/2DK3RlFcVl4x4B9q6oTCt9sUS58+nwGntY20KGHl6Zhxlco/188c8e62jbwZ+xY7fD7IgXGsD9Aawx/8ZjcA75WTc17lo82GvziNPNbuymV9wi1MjXuc0nJNG7Wbh3OHVSjl1TsOVBTVWpN1sMh9JozLMX9zvSt6LyO7wLunuR1TIZgMmJ1vDETeOW6xsVrZC+tm5ff1WW77PV+YwcDRzt7Z8z+u4fJR7u6p2+1TmBnvvhq76PABOj39EzsWTDLkWT0Tdq3w60/uodZxgc25EnvvwUIufWsut39q+JYnLNjGp/O2sDuvkHn/GG6vf7LcldPO3EJ+yutH8mHDan/uhzVux88sNYyMhjjLFZeWO9eTLPsMvr2NHnnOQIHZBdm8tOAlGrf27xrJyS/iwyevMxo4nJ2MVJzPTMenvK392PqrSWzl//3pMWwGp770q1va8sxc3p+9iQdcGqHN2YcsXFTu+ymqwC2P43mzUR66wXsLolrh//Kf3oy9tVekxagxutkqtzL1259nsSXhetr6eMDa2fbQkKr7NUfOMGbv7DtkKt0AX/Jqyj4WJdzNA6aFeoxtB62/6MPv8Q9yZuk8+P5uADqqzRVlDhSWctILMxjmMgirTUWqtabHsBk+63v06xU+j1Vd4Wtusv9M0SFnj6W6C4f2HSpm1jr3RuCgh5vsRJu3375k01wOF5fxo7lS9as5K+H9M/l1+L9oO2RKRb7t+w7z7OTVlJVrvo1/jvfjXq845hhIn7Mhm0FjFzJk4kqenrSa81//nQEfzmb132s49zVjnMHXPfNMt86nmLV2L1prVq73vJZyykyXSEN7NiNj34bFYy3rWr8nn9tjvBc2udZZUFLG/E057D1QWOnfxkY5ZC7mmUmraDtkCmXlmnT2U5y9ibZDpnDrmIWc/epvfLlwOzlTX4A5r/o8193jl3g1DGfaVzEr/iHiD4QnVlVUK/wOTVM465j0iv1oWsBhRUeb90OSqg5Y5DS4wm4sJupnDpxZsSzhzqDrV5Rzk/0Xr/SvFln7Zz1f/KbKmAnTx7asIi0h1+Pl372K+srZ68g9bDQiY/7cwpsz3VffHpw21K+8ew+6u8CKSt3dFrk2GzOTEv2ew5PTbat4PnYMV+5+wy291GJOvA6R46iL2sTxaotXeuy+DTwd82lFLYkYDW/HMvfB+/snLGXMn1tYkekdHykWZ8Pi6mY6UFjKO7Fv0PnLU9mScL1bGc+ZRQq4fNQfXr1F1+vvaNvGCfP+jwWb9zHNI5RCQXG525qNK+x/wg//5yWrcU7nM9V2yBTOGvGbZb7+H/xFrxdn8vDXy/lrk3OAfvn2XP71zh+0HTKFqSt3scHDvXWf/Xv46BxW/GUYEh/M3sTChHv5vvQeAH41F5UNmbiS1AVON9WXC7d5LS77afVuPpjtmNDg/i6U7fZtjFSHqFb41WVB+XGRFqHaHKt8WwptlPFw3hfznc88vshXitmJCW5p19lncabdfWl4A/K51u7sBr8xw6mUe9ncfdiDLCwzN3YtpzjPfeDTMaOkndrFuNgXsVNGB5sxVnBivv9BOE8DYMiEBegthqtEAfc3TeOBpunk2AK/Jt2fNxq6RDPWTgMXd0VZuWb+pn0B6/dEUc4VtrmGVemHH+KfpJUtyys9XpVwa8xPtFDurrt4imlODn9uzGbj3oOUmYJYzYZ50o+b8Fy7e+RQXw2YQtN4xyw+nr2ewry9ZGhDocco9+tqljmdw8XeYwU/rtzJ8Gne4x3b97m7puqTz4cfu7t88gqK6WNb6rP3MX31bq794K+K/YFjFrJkWy4A93y2hPNen80LU9ZU9Ig62YwpzE1M48Rz3MgXO/YX0NOit/nStLUc99Q0xsSNcEs/eu5DXnlDQUgUvlLqQqXUOqXURqXUEIvjDyql1iilViilZiqlKj8xPgTEx7hf7qv/9h9t8oOySzmjaCS7tO8wAbWdJHz7sLsqwwUUpyq/yu+/6anc26wJmTHOEBYvxn7skUszJ/5+hsd+VJHy+oz1tLcZg3stlfvUx3523z0NB4PGus9Tdrycs+If4kz7Kv5JuCnoa9AaFm1xKuJL1j2OGnMxZ9pWcJRtJ5kxRrjsEqXYGOuc6eXqDnGw71Ax8RSTpryt5Pyi0qDnxKeTW7H9b/vvjIx7h4F2/zNMAuOuiBurfOYlDOb6j+bT93+z2bw9k5ZkuVnHDk6wbaY5Odip+krQc2xLGR03gjN2j2fpq5dXRtQKfljh7Xa86I05tB0yha05h7BRztL4OxntoTj/ZZvDmLgRtLM5FbMtfgf2ROvFfQUWDc6Hc5wuxOqO7dxp/8ErrbDEu0GP16EI0udNtRW+UsoOjAIuAjoB1ymlOnlkWwr01FqfAHwDvEIEOOuYdJ68pGPF/tU9MkhL9hdGQZGpa8fKvKryUOw3Po+1tQVnnVixLdZQhoXK9yN0tX22m/sF4DZ7ACse/5ZvYiWjVX4Q63vFtAaufs/ZyPQ1LdZxccMZH+ec5vpV/WSuzGjOwgT/ITc+jH3NpXFz11yn271ngFhZxDPjH67YTjXHT9JVHnG4TtMrJaXjEL5LrudXHgeX2g0LNhn336Kr2sgzMWNZkXAHfyTcz9DvvMMbNOIg8xIG81QQEwIcyvA8u/tsoDbKeM7qF+3iVPsar3Lu5/B9Xk8cs4DOGvEbmxJuxK688zVT3j2reu3fIqntB0AZ2NynoBYEGeKgmdrPloTruczmHIzvrLawJeF6psU95rPc47GBV8aHk1BY+L2AjVrrTVrrYmAC4NaMa61naa0d/a+/gIwQ1FtplFIMOtP9G7ZzHzs7YLkj0fefZbdRFOHou92Vd0TLp2LHByx3rPI9J9t1QDEYzrf7noq4fHuuz2MaOGy6ctbExQGwPcb/B3J62yu3UGlJwl0V2wdsioNKmdNoy4lJWeFiU2tGxTojiiq7MfYwsnHDStX37xh3F9ek+KcZGONcJJUR/zcHPL4W10gZjc6AmJ85SgU//92Vm2IMV8aGPYGnGlq5lRTwgN16QVIbtZvb7VVbQRvfbBJxRz0HKvg57xfYjR7mc7HGoPFtMc6Q41Pi/wtAR9t2r3JH2XayIP6eoOsJ1fiOJ6FQ+C0B1yvMNNN8cRtgGZhdKXWHUmqRUmpRVpa3TzKUZDQyBuMSYp0uibeuOzGsddYk57TO4IEm6YEzmqyLiw15AxGvqtYtTQyyXAxl2CnzGjR0ZY/dTp9WLdlioawXxt9tzPgw0cDsxATKgfca1iffh+/edSDTF71tlRt0O71NK05r28o4f6N5JGZ8zqb6xhhLPCUeVnN4TJC97b/g+hbNfB4f59Lr8cROWUAVFYzUn/yx2XLM4toY68B3v8c/yBOxnwNQCvyclOhWz6OxX/msK7a+ubjNh0szhlISKKK7Wk9HtZX/xb4TxBVYc7n9T5qoXLe0e+zfh3UKphU1OmirlLoR6AmMsDqutf5Aa91Ta90zPT14ZVVZ1g27kFkP9/FKv6yr/69k/af47jBJVH2KFGyKdVdqc4OcYZJtt3F1y+YMTTXGKg7YFJ/VT662WrGaOVIdNDClXlKFc2Nc3PCAynd6vSRyYux8WT8ZgBLg5uZNWJgQT7rKM2Z8mEytl8S9zZowISWZafV8u0teiX3fS7JrXOIU3dqsCZ83TMBebz2Jbd6FAIOunqgYY2ZVgd24NlcrHHAPghditsa6r0pv4LJwz+byRKR4rBT9J+GmgL2v+CAs6Tkbsnk41n0VtLIcXfBmbIMUHmqazk/1koLIDVZNUAqHSaCIa+2/8lXcUNYmDGRi/LNMi3+cf5mz2lzxNRX6JBX4a22Pxn7FF3HDfEhWey38HUArl/0MM80NpVRf4Amgn9Y6ojFK42PsxNrdL71nm0Y+8ztu/kGCfZBCRwmGlRqIp9JSuTyjBflV+IrSQdOSXRFv+KifT23M8NTGLImPTJjoqfWSeL1RA6/0n5MSGdIkjY8aOkNetFMBol56sDsmhqUJCTyd5j0Qv8ccgN4dwHVzpd256Om3uP/wWtxI7kkcXZG2MDGB/zVuRFKr0cQkbeW0WGMhU5bdRnYQM34cfuez7cssjx+lQvCZxSrQzJyZ0oJsViYMqnT5DY220aVda789yXvs33ulXWmhaAE62DZzyOV532M3frd9dhufpyTTvkFw3xd42u4cn1BoHo/5nOGxH9HdYm2DFXvsdg57vHdfxxtTgicl1/OazeagDJjSsJTWFtOpw+VGDoXCXwh0UEq1U0rFAdcCbjFylVInAu9jKPsQxToNHZtevJiv7zrV5/FCHVeD0rjzZHoqfVu3JJBtNM0cwDsYhELJ82PBj6mfwgLzAS0yH+IdMXa2BVCCVhxrCy4+iiePNUnjk4beCj/PbPiyXBrAafGPV+rcDls7M9Y7vlJVXrJ9ibk8e9QeLmtl0Ts0BxEfSjKmCp7TOoOz2wQevuplBrl7w4eP/kKLmEjhpBwY2agBu+12Po1/jj8TrOfAB2JaA8N1ctDHQP+OGDvjjvmLVXHu79vJNmtr+XC7MZzS1mlrVkQnRfFSWmOyWjh7Xdc3b8qY+u7fyIgzexz9zRhLANfZf+WWGO+1JP7o27olA5o3tTz2pDmbzYpf6iUxsnEjLmj+stexqsycC4ZqK3ytdSlwHzAd+Bv4Smu9Wik1VCnVz8w2AkgGvlZKLVNKBQ6aXoPYbKoi7osVA0oe5dWSf0dkeuYs0y1TEqTl/mu9wG6c59JSGZ7amKUeFrxW8FpqI/Z59CgubNWSS6wUWoSojvVzqZ/rcO1GB1vHLS2sX3RXimzB97peDWIg9poYc2VrDc0mWJwQz8cNG3Be65bc2z74UBszkhK5OKO50+kW4DbMTTSe3e9SvN1prkX3ms/ngbgiyzxWt2VlQjyvpbr34mPMYXFXI+n2mCkcUoofg3ALzU+IZ545c+vv+MobhQ6DytE7KAEeSU+lS7vWLKvC+YIhJD58rfVUrfUxWuujtNYvmGlPa60nm9t9tdZNtdbdzL9+/s8YOV648nge6NuBo5skV6Rt1015u+xKwvaFoiAI9t2ek5homXeX3c4PycZDfMB8wPNtiq9T6rHLh/X+cmojprk8+C82bsQTFq6QylIO/FQvqWIWyvfJ9VgdF/gBLzZfjG88LLVgmBrkFEbwngb4RyVX23ri6cH/JzbGZ49tbIPAEVqDeRY2x8ZwbqsW3ObDunSlUCnm+5lyWlVb85m0xmyPjeWQZ68zwGvk7/r2xsRwbuuW/Grxmzh+t8q2g+e1ds4xSaCYYWmNebxJGis9nklPd+mg5k25w4dlXxU+r5/CT+ZzuiDB2g1UXWSlrQc3nNyGB/oew7T7z/Q6tkf79vOHC3/vxmGl2OfxMv2RlMjPFi/DzS2a8t/0NCYn12O/WebeZk0YmpbKnT6Uwqa4WB5tklax/0WDFCanJLvlsZqbXgb8kJzkc6hyUnI9HmmSxocN6zOwWROeSk/l2pbes0NmJiXSpV1rBjdJ46BSFLi8cGe19jcRzInj5ffstQTC132fWi+JG3y85Dc0b2rpo//IQ4lfkdGC4am+n6VWKrgZav6ejX4ZLdgbE1PhnvPHsNRGDKqG4jqoFLv83N93GjZA4/0brI+NZbdLmuv1lOPeUHoq8VWVsIDn+rgHVg3DuEZxFT73Apee2cKEeE5t24o/grifweJZ//cWPZtQIwrfB56DugDZNOCEwg/d0l4t+XdY6s9XihdSG1V0+55KT+XT+inc76KA/92yGWdZ+IT3Wljs2eaL9UR6Kut9vCyVsYwcr8KLaY3Z6lHf5/VT+G96GhN9PMC7zcHRUY0assjPC/S2OXD7W70k3mnUgDdd3B2VVeAAi4MchPalSHfHxPBYkzRW+LCGVyTEM9GjQQRYbHGNS13O4Ush+cJqBse8hHjWxVl/98Fz9pYnG32Uc9bnn2taNuN8Pw3w5w1SyHZ5nxznuyqjuZt17Xq8T+uWnNPKOPZnQgJXZLh/gc6fwneVt0u71tztw6Cxuq53GjXkgMWz5XB/vmY+g1YDsdOr2RPc6NKjCJcvQRR+JTlAPY/94GbubI6NsYzJsiYu1i08gYMPG9ZnQv0UykyF/0u9JEakNuJXFxfLNouBR6j5hWKDmru/UDnmyz00tbHPl8oXvlazjvfj6siz2XgyrbHXTAlPBnj4211nIW2PialwGYG7defgXYuZQ54E+0I5/O8bY2N9KiQrDtgUb5hyuLqe7mjelKtbNifXZmOkh5yvNnbvTZRBhWUdigX8jgHwmUmJIbOA99vt5JjvxZ3Nm3i5heYlWrl0ws8GUylbDcQ+3DS4qeT/xMYwLyE+Ig7iyk+9EKpEv4wWxJVrFm91X4XXv6Vhuazc7D41qzzEj0MoG4EXUhu5WSOe0xgddWml2Gu307QsOC/w5tiYivg1wVCgFIla827DBkxKSWZSSjJJ5eXM3xrc7KBbWjTlrv15jGuQ4qZQxjSoX+W7H2yslXJlDNL9He/daLvW3aVda1Zu3kaRgg2xcXyTklzhVrOS8aXURl7jFXOSEhlfP4UrD+aTpDUPN0ljRr0kBu/L5a1Krtb1xwOmwnM8y66W8hSXdQ3T69Wj/wHfYbf3V6H3Bs778a1FLyvSdGnXmu8zd1KsFNeY7/ztud5xl8KNKPwqcF3xEzwe8zkn2DYHpRgcKqC4ErM1dDX0fbgt/AkBBk2Lq7AWAODPxARKK6Fqe7VtxfLN29yu93AQ01Jdec/Cai9TCnvwH9Z1w5f0nmEZNsbF0b1da8u8f1sMYD+XmsoPHi6yvTExPNgkjX4HnfFgfA1Ov5zaiNcaN2RIzn5mmL1EX8r+mbTGPJftHYPGwW+JiXxRP5ljiktYa9FgrYuL9XKfuc6QeTm1EXkWv5OjsZwZ9MIpJ3vsdhaaA52bA7ioHARa3KR8bFeVVxs3clsM+aE59XhdXJzXmhdx6USAFg2su6fzyjuzpLwDEJxFd3MQA2LZNhvj66fwaRAzUKYEeCFyLcYfgiFUDYU/90sgXvUzmGnFqvg4yj3eDlfXzm4Ld1kwlFWx0Xq9sbX8L1fiuqxWSHsqewe/1EticLPgXAmlSrEsQAA4wG0c4oBNec1EGdwsnT+TEhnTsD5/WbhWrm7ZnJcCzObKcvldvjLry7aw7D1nyvji6pbNKj01MpBR9UajhmyPsZNnUyx3uW/BvCezExPo4tGg+1r5vi4+LqjpvaFALHw/dGrRgJ151svYHdZBMAo/mJfsxhbN2GEOrt184KDfOdZDmqTRIdN3DI6PXBYtTU9KZE8VFk1VhdNbt+TkQve50fMSE7gi32mB+gtA5mlxFfiJxOngBovYLxNTkrnRdBlUp/EJJb9Xc0AvVPxYiempYLiRwoFr+IPn0xpzUf4hy7Gd6y1mb3lSAuQG6QZyDcQRaG3L8oR4Lm7lPah8go+eGRium9ty8/jYYuFgbUAsfL+4a91zjgtNqOR9NhsfNajPSS4zbHZ4zKQIZH0Ea7k+3DSdEamNgrJYqztucMBu5xeP3sdT6akV3fcJKclc7Gfh0yEPl5fnPQkWhzX9ZRh9uTU5MN6vZfPAmUKMp3UaajwHYU9r28pHzsD4co1ZUZmeVlWprcoexML3y+BzOrAiM4/xg05m/qYcMholVXzCzEFVVOQzaY35LYBbZkWA7qnrLIHCKrofPKmqgg3EGW0yeCRnPyMCvGxv+5m9U1n222wMC8EiMV9o4CGXKbLhJFifdKgJt9KPBNOrMD4QCar7oRVfiML3Q9dWDVnwRF8AjmmawqYsZzzvy7q1hFW+SjrxjOU4LyE+oLJfFxfL2iB9lwAnVcM6ChWOVby+CKTsQ03vIGLWVIf5CfFevRmh9lPVGUA1zcSUZG4Lw3lF4VeC9unJvHdjD04/OpWEGb8HVeZ9j+5dMEuxr45AF766/De9Zqzd2kIol9QLgie+1thUF/HhV5ILj29GSkIsxd1vZa9uyJSykwFjEY9VGON/ItQdFwRB8EQs/CpiT+9Ar6J3iDOnQN7Soin1y8r4Y1vVPgMnCIIQbkThV5GEWDs/Dj6Ddmn1wPzy2wG7nXkJ8ey32zmloBAF4ucVBKHWIAq/Ghzf0nv6lfh2BUGorYgPXxAEoY4gCr+alJQF/jCzIAhCbUAUfjXYfmA73cd3Z3Ill6sLgiBEAlH41WBD7gYAfqklcVIEQRD8IQq/imituX/W/QABV84KgiDUBkThV5EDxQciLYIgCEKlEIXvh92HdlOuyykoLWDp3qVuxzbs3xAhqQRBEKqGzMP3wZa8LVz2/WW0qNeCnYd2AjDj6hk0rWfMs/9568+RFE8QBKHSiIXvA4eSd/wHOFx6GDDcOV+s/SIicgmCIFSVOqfwu4ztwptL3qxS2Zfmv8SEtRM4/YvTQyyVIAhC+KlzCh/gw5UfVqncvF3zeGH+CyGWRhAEoWaokwo/EGXlZXyz/ptIiyEIghBSROGbDP51MC/NN8JePv3n0/yy9ZcISyQIghBa6uwsnRVZK4ixxbAyayXHND6G37b/BsCtx9/K5H8mR1Q2QRCEcFCnFL7Wzg8D3zD1Bss8RWVFNSWOIAhCjVKnXDo6iC/Bz9kxpwYkEQRBqHnqlsLXgRX+8AXDa0ASQRCEmqduKfwgLHxBEIRoRRS+IAhCHSEkCl8pdaFSap1SaqNSaojF8Xil1Jfm8flKqbahqLeyBOPSEQRBiFaqrfCVUnZgFHAR0Am4TinVySPbbcB+rfXRwOvAy9WtNxD5xfl0GduFz/7+DIA/d/xJj/E9wl2tIAhCrSUUFn4vYKPWepPWuhiYAFzukedyYKy5/Q1wrlJKhaBun2QVZAEwYe0EACZunBjO6gRBEGo9oVD4LYHtLvuZZpplHq11KZAHpHqeSCl1h1JqkVJqUVZWVghEczJ9y/SQnk8QBOFIo1YN2mqtP9Ba99Ra90xPT6/WuTIPZgJwuOQwY1aNCYF0giAIRzahUPg7gFYu+xlmmmUepVQM0ADICUHdlmzcv5F7Zt4DwN6Cvby2+LVwVSUIgnDEEAqFvxDooJRqp5SKA64FPIPRTAZuMbevBn7VYZwy4/rREkEQBMGg2rF0tNalSqn7gOmAHfhEa71aKTUUWKS1ngx8DIxTSm0E9mE0CoIgCEINEpLgaVrrqcBUj7SnXbYLgX+Hoi5BEAShatSqQdtQsSZnTaRFEARBqHVEpcIftWxUpEUQBEGodUSlwhcEQRC8EYUvCIJQRxCFLwiCUEeIOoWfX5wfaREEQRBqJVGn8PcX7o+0CHWS3ocLAuYZtXsvAFcclEY5EA/nHDnPcf2yskiLIARJ1Cl8oeZpUlrKgLwDAfP1Lihk5eZtPJ+9L2R1n3focMjOVR1mbPOMJlI9OhUXB5135eZtfo+fUFhUXXH8cm4QjX1NMTSrehFbrj5wsFrlF2/exoIt2wNn9GDu1sxq1RssovCjgM5Fzhf6+NTjLfNcnH/I7znaF5dUuf6ft0culMWQEFvCl7rcp9MqocialpWxsoovuxUneSjpmGpEIgm2ZHJ5udv+3fvzgirXpDQ0Fv71edVTtgBXBnjOA1FdhRgHJFbht2rgce/DhSj8KKBXgaEcLmt/GW+f+7bbsadOeYqbOt1EytEX+D3HB6a7pbJcc8w12Jt1oVmIXvpgmbBjFyvPHU2TsjLG7dzNHfvzuH9fLo/l7OfFrOyA5W/LtVZmzUtL3fZ/2m5tufcqKOT1Pd4hvK1e9luC6P0EYumW7XQtLOK+/bnVOs+Vftxp07bvZOnmbQzMPcBXO3ZR348SautiINyZm8fRxcXElftWdMcWBe6x3Lc/l2Ye939YVg7DsnLoUVAYsLyDR6thBATzkY5Pd+4O+nzh7l1VFlH4tZjLj/L8jow19x97A5P6TeTFM18kNdH9MwPXHHsNj570KDRwfqLg9MMFzHexROee8gpN717gVu6rS7/yqmfWNbO80p469SnQmlalpfzc+01+CbFrA+DBfd4vcKLWkNYBgG5FxQzOzWNQ3gFuPHCQy/IPc/++XL/nHByE9aqAlqVlzIg9ju6F7grn49176RtkD+BhF1m+2rGrYjuQK8aBo2EZ3/s17nxgOxe2ODOocg5cldg5l4+2zPPrtkwalpcTAzy4P5eOHj2+OzzuV7J2NgaxwHc7drN463Zmb83k6x276FpYxDyXZ8yzIfXk+awcUrTm1b3OxvqTXXvol3+IyxscR7xHQzop07tXOcXsad504CDPV8K1Y3Uuf5xYVMy7vgykrtcDzt/sOBfX3KsWBoIrv9eAW0cUfi3lwR4PMuyMYUHltV/4Iu0bdfCb5/rjrq/YfqrPCJJcXqAGx14EaUe75e+Y2rFiO9609OrF1rM+ufnyN09Mp1mQA3j1LKzHqdt3MHJPFs0T3ButxmXeedP99Sh6P8qgvAOMc7HE3t+1lxXXL6rYtwPzt2y3lMOTpm3OYMwd65n6r6lex+7en8cFHm6EITm+xyhitLfrxIFno+Kg7xlPGBsN2wDQu/1FAWWOdfl9X87K5vTDBZxcUMjJzU92yzdnayaTMneSbnGPHdyQ2oO2Je4NwH9OetQyb6Pyco4rLmH8rj0ka81djoaiVS+/8l5h3sOuRcWcZFrzJxUWGY3VoJlelnf7klKURyPQuqXz2oJVbENy9tG+xNkYnenSiK/cvM3NXerKGR49jnd27+XO4wfBle8C0PdwASs3b6OT2bN5YN9+LghgIDQuL+foSozdVIXoU/hh/XBi1fjjuj/8Hk+wJ1Rs//sY9xhz7/Z9t2L7ld6vMO1f05jYbyIzrp7B+W3O5+ZONwclQ/uG7Wler7mxY758b+3O4stLvwxYdlzPJxnYeaCbnG5c/ja0PxvSjglKFoCJO3YRV665zsVv2yqtM+ceLqB/Rl+v/F+Vun8QJ8XTdXLyXc7tlt0Bw/J3cFphISo23q1IktbYld39PC7X0LCxsxFVStEqpRXjLhrH2y7W3T25ebzqsCbrNYGrP+GGgX9yVLLrJyKgnWkxKwxLdLJpVR5XVMzA4wcyqMsgPtrlw2o89T74v6XQ/AQALm1/KacdLuCaAwfdGjWADrENAOhiKqo3bC3J6HwN7+3J4qNjBpAYk1iRd8KO3TQsL3dTeJakNPN6r07ociOjzh1l6dZy5Y7cPK46kM+T54z0X4cLn+ze69778fE11FaevYaMk5xFfIxceCrUi/Odg/5x5ZqzCgp5d/deXjE9XxN27qGjD3fUj1f+yBPJnVixeRtnnjSY+3rc75XnX/mH+Gznbm4zn/PvM3cysteTFcdnbctkzinDITYJMHpK4ST6FH4t4/nTn6d+XH2fx1untGbA8QMq9h1WtDYf2PYN2lccu6jdRWSkZNChUQea1mvKa31e45GTHglaljh7HADKfHv7FBTQKdXze/Mw99q5ALze53Um9ptIxy7X8WDPB/H5GeKWPeDm7yHGOH9biwHgPocOQwfnOEKL6yeyeOt2/rtvP6POHcVDPR7yKbcCOnZ2NoQpFdaoizzNTvBZ3h8qwfdv82RP896271OR1q1JN87y5U9+ZAMcfxU0agPmvfaqr+etNC4vp52pZL/euZsHezzI/d3vJ9Yj7/u79/LiGS8aCq+x8zlQSvH+JZ/xVM5+t0YNYOzV05h0xSRofBQADZLS4FizR9DhfAB+aHQ6P23fQedgrcnEhuhL33BLsikbvTN6O91aj26GKz+A4y51yxcLPJuzj6b1mgZXV7AM+pXRB+0VU3yH782GDudVHFY+hhOuOmg9qPvxrj38aDbCZxQUclGgOQxHnUOb+m249srPUTdPhnOcSpxLnB9cUsAJRcVw52yjWLmdczv2rzieVlZOw2MvcZY92nkN4UAUfpi54ugr3PZbpbhbflP+NYUW9VpU7KsQdFHm9J9jmf7Oue9wxwl3OC19HzSIN6zEvm360sGHq2jU7r18fdnX3gdOvJFvdu7ySn59bzY072rs9PmvmxLtndHbrdE7p4lhoR9jKjPPdzcWDReNAFdl3fU6b1nqufQKTAV4XpvzGHq0d953Ohs9hDMaOK83+ahz4Nk8p9z+6G7d07qzPMXtGlSvOwzl6ODBv32e8rSCQi476jLrg61PhvuXeyWnxKUYRkJSmpFw4s3Q6XJ4bAu0Mizgts160NKXS+zovtDrDmh8FOfesZAYWwxXdbgKPHpCcZ4NWlJj6Nofrv3M5/U4eK/vexXbkzJ3Go1aAO7MzSOlrJyTY1M5vcXpkNGDJgOm8Hyv/7L0pqVc8sguaHsGPJ4Jj+9ApVk/tw4XXufGneic0rZiYLpXYTHNlXUjfb6/qb82O7Q/yz0toaH7/lmPGc/QrT8bPTXwcq3h6LFeMxaAoxu6u1hDRUji4QuBibPFUVxezPAzh2NXdq6d4vwGTPuG7b22W6e0divfNCl4C6lhQkN+ufoXYmzuP2/r+q0ZfOJgY6fzlZC52O34D1f8wKHSwNPaTj9cQO/THoXGx3kfvOxN4i96Bb44xS05BgwLc/YrcPS51ic2exDt6jVnZWpfnti3kPXa9AHXS+e1s17jjfkv8Vb3h6GDaRVdOhK2zAWbi+3SqK0p6P2w4QNj+z7Df/+/Pv+Df7wHn7scfwMr67WGDhdw6/JRtK3f1vcN6PcWTB4MR50D102A/D2QYt2IXqiT3BNsNkM5PrDS6MbXS3MeS2nOCYVFrEgwXU+uDYMVjdpCtxtgmbeSTU4wGu2YFPO5SWzkPHjSIJj6sPU5r/kU4oxeZnNg6U2Gglqzd1lFljibtWIMRGJMIgWlBZze8vSKtPYlpbR3bdS6XAMrvScMnFhUzJ/bMqHXxXDeCCOxUVvodbu7Eos3GljbqffB/Oe9ztMv/xD5TTvR/+JxRqN19hZ4o6vx7A1eDF/eADuXOguktOC2vJ10KypiYHOXd7Blj8rfgNZOJf9+3/cpH9rY5WCFScD86+cTa/Ps74UGUfg1xOQrJ/PVuq/oktbFyzXSNb0rU66cQvN6zYmxxXB0w6M5Ps2YT5+emE6b+m14pGfwrhuAZvWa+c/w7zFeSW0btA143p+u+onUhFSI8eHPt9khrh6v9H6F0vJS+rTqw779myE22XBLPOtndkzzrrBrOSQ0gEtf57RNU5g8ZwjHFheDUpzf9nzOb3u+e5meA40/MJTuwV3QpKOhUBu0cip8WxCd2Y6G4vlPj//4z5dkDirHJEBMPDRs7ZXlti638d+5/6W5Ml6xE4uK2BIXS0qsoZCsygCM2bWHkpu+gyuPMxqGQDRuZ5k87PRhTNo4iRPSLFxdvlxzUKHsPSl3GTPp2iSIHg/AwGkw2jnAPPmKyezMDzAj5sQbDIXf9kzYYtFTPeXuoKpW8Ubvr2NRMffsz2NachJTk+thB26yNXa63Bq49LgbtIQLX4ZPzjfGpJaMhU79UPPfo6c5vfKsjLPgwrsh3cLYceDZGCSleWWx2+zYz33GcP8BJDeF3K2gbCTF+ni3QoAo/DAw99q5LN6zmB5NnT98y+SWborkrIyz+D3z94r91vWdCsCh7AFi7bH8eOWPYZY4eFomtwycCWO8wUFKUx/+9YE/QXyyc//iV6H7LRX+6kvaX0LvKU+REuyisNtnQfY6Y9uHQnWjXW+gCnO2250FLXvCuU/7zHLZUZcZ7pipj8LWeTyZvY+bTn2C9KR0n2XA8HnHph0L9Vv4zVfBGQ9CixPhD/dGqlFCIzc3mRf3LTKs4deODa4em+HSOSauMW+d85b/vK1PhW3zjO2bvoN8Y2C3Wb1m3oaI2fOiRXfD9eTLpXne84YidRnL8IejnrO7DaLPql85a9ufvOQYXHdt8DwH/1ufbBgl+VmQudBoYOYbLqjZ/WeTHJsM9gDWd3IT4789Hvq9CV18fOzvzAed2wOnwuY5EEZlD9Go8MP2afTAxNni+K3/b6TEpXBO63P85n29z+scLq0dYQEiRptT3fdj4iGjp1tSyiWvw6f9oJWHz9OK+s2Nv0C4vPBt6rdhRdYK7Da7nwIexCfD7TODy3v+MCg6SNzyz+nQ6oxAggUvgwOb3fC7/2GMTwSNDx+3T5TRQ+rY6kz36bmpHdxcFV4cZf0edG/SnXh7vFOOO0w32y5zXKJRW3cL//T/q5S43Zp0Y/zF442V5+v/QhHo7nocTU6He8xGq1E7SEqlUUIj72L+iE2ArkF+vrtBBnSzGIcKMdGn8CPI+W3PJyUuJai8sfZYGtgbhFmiKKD9Wf7dQAGY+e+ZlJb7nnY46pxRrMheEfTvVmli4uCKd+CCF4Jz0VSRedfNI8GXmy0Ybp4MORt8Hk6OM3pingv7GLzIIndgxl401vpA865w3ZdG76v4EJxwTZXOD4ar1BoL1R+X7J3m4P5llas4rh6c/QR07Fe5cjVA1Cn8aj30Abiqw1V8u+Fby2O/XP2L4dsWahVNkpp4JzoGxOKSaZjQkN4ZvcMrhFJhVfbgVMiV5vJRhqukSUfv2SYu9G3dl2dPfdb3rCFXHLOjqvouHnuh8f/f1quCq0z/z2DNJHdXnD0GLngx9NMhz7JemBZpok7hx8fEB85URR7r9ZhPhR9wkFSoPbQ5zXjpuw+ItCSR58Qbg8qmlOKqY64K7pz93jLcTOYCuIjjGA9JSoWrPvQ+fuq9NStPBIk6hR8uGsQ3cFulKBzBKAVn+l7oJVSTxIbQ45ZIS+HkwpeNgXbPMaM6SNQpfF2NMLKeXHn0lSTGJPL52s85u9XZXsePbng0z532nF8fsSAIESYuCbpcHWkpagWy0tbk5GYnc2l792XhQ08fynEei4uGnjYUMBZCfXf5d5yQfgLdm9aSrqtwZNPnMeN/mP39Qt0l6iz8YHmv73vcNeMuHuj+ADG2GG7pbHRBf9zkPudde8zzPKW5sYLUZ1wZQagqPQYYf4IQJqJO4Qfr0jm95enMu25e0LMbQhHjRhAEIZJEncL3CurkwTeXfVPhc/en7OdfP98y3THts0talypKKAiCEBmiTuEnxSbxft/3uXPGnV7Hbu50M8c29r+UfGK/iaQnppNkxqc+K+Ms0hPTuanTTYCxZH3CpRPcwhYLgiAcCahQzmoJJT179tSLFlVtFR/A2NVjeXXRqxX7S25aQoyKEd+7IAhRjVJqsda6p9WxqLPwHdzS+RZapbRCoTi7tfeUSkEQhLpG1Cp8IGAAM0EQhLqEzMMXBEGoI4jCFwRBqCNUS+ErpRorpX5RSm0w/3sFjFZKdVNKzVNKrVZKrVBK9bc6lyAIghBeqmvhDwFmaq07ADPNfU8OAzdrrTsDFwIjlVINq1mvIAiCUEmqq/AvBxxfMhgLXOGZQWu9Xmu9wdzeCewF/H/nTRAEQQg51VX4TbXWu8zt3UBTf5mVUr2AOOAfH8fvUEotUkotysrKqqZogiAIgisBp2UqpWYAVl/3eMJ1R2utlVI+V3EppZoD44BbtNblVnm01h8AH4Cx8CqQbIIgCELwBFT4Wuu+vo4ppfYopZprrXeZCn2vj3z1gSnAE1rrv6osrSAIglBlqhVaQSk1AsjRWg9XSg0BGmutH/XIEwdMA37QWo+sxLmzgK1VFg7SgOxqlA8XIlflELkqh8hVOaJRrjZaa8tx0uoq/FTgK6A1hnK+Rmu9TynVE7hLaz1IKXUjMBpY7VJ0gNZ6WZUrDk62Rb7iSUQSkatyiFyVQ+SqHHVNrmqFVtBa5wDnWqQvAgaZ2+OB8dWpRxAEQag+stJWEAShjhDNCv+DSAvgA5GrcohclUPkqhx1Sq5aGw9fEARBCC3RbOELgiAILojCFwRBqCNEncJXSl2olFqnlNporg2oiTq3KKVWKqWWKaUWmWmWkUSVwZumfCuUUt1dznOLmX+DUuqWKsjxiVJqr1JqlUtayORQSvUwr3OjWTao70X6kOtZpdQO854tU0pd7HLscbOOdUqpC1zSLX9bpVQ7pdR8M/1Lc+1HMHK1UkrNUkqtMaO53l8b7pkfuSJ6z5RSCUqpBUqp5aZcz/k7l1Iq3tzfaB5vW1V5qyjXGKXUZpf71c1Mr7Fn3yxrV0otVUr9GPH7pbWOmj/AjhGnpz1GzJ7lQKcaqHcLkOaR9gowxNweArxsbl+MsRBNAacA8830xsAm838jc7tRJeXoDXQHVoVDDmCBmVeZZS+qhlzPAg9b5O1k/m7xQDvz97T7+20x1oJca26/B9wdpFzNge7mdgqw3qw/ovfMj1wRvWfmNSSb27HAfPPaLM8F3AO8Z25fC3xZVXmrKNcY4GqL/DX27JtlHwQ+B370d+9r4n5Fm4XfC9iotd6ktS4GJmBE9IwEviKJXg58qg3+AhoqIyzFBcAvWut9Wuv9wC8Y4aSDRms9G9gXDjnMY/W11n9p4yn8FIvoqJWQyxeXAxO01kVa683ARozf1fK3NS2tc4BvLK4xkFy7tNZLzO2DwN9ASyJ8z/zI5YsauWfmdeebu7Hmn/ZzLtf7+A1wrll3peSthly+qLFnXymVAVwCfGTu+7v3Yb9f0abwWwLbXfYz8f+ihAoN/KyUWqyUusNM8xVJ1JeM4ZI9VHK0NLdDKd99Zpf6E+X8eE5l5UoFcrXWpdWRy+w+n4hhHdaae+YhF0T4npnuiWUYcbN+wbAwfZ2ron7zeJ5Zd8jfAU+5tNaO+/WCeb9eV0rFe8oVZP3V+R1HAo8CjoCR/u592O9XtCn8SHGG1ro7cBFwr1Kqt+tB0yqI+PzX2iKHybvAUUA3YBfwWqQEUUolA98CD2itD7gei+Q9s5Ar4vdMa12mte4GZGBYmMfVtAxWeMqllDoeeBxDvpMw3DSP1aRMSqlLgb1a68U1Wa8/ok3h7wBauexnmGlhRWu9w/y/F/gO40XYY3YFHaGhHZFEfckYLtlDJccOczsk8mmt95gvaTnwIcY9q4pcORhd8hiP9KBQSsViKNXPtNYTzeSI3zMruWrLPTNlyQVmAaf6OVdF/ebxBmbdYXsHXOS60HSNaa11EUY8r6rer6r+jqcD/ZRSWzDcLecAbxDJ++XPwX+k/WHEBtqEMbDhGMToHOY66wEpLtt/YvjeR+A+8PeKuX0J7gNGC7RzwGgzxmBRI3O7cRXkaYv74GjI5MB74OriasjV3GX7Pxg+SoDOuA9QbcIYnPL52wJf4z4Idk+QMikMf+xIj/SI3jM/ckX0nmF8qa6huZ0IzAEu9XUu4F7cByG/qqq8VZSrucv9HAkMj8Szb5bvg3PQNmL3KyKKOZx/GCPw6zF8i0/UQH3tzRu9HCMi6BNmeirGd343ADNcHhwFjDLlWwn0dDnXrRgDMhuBgVWQ5QuMrn4Jhj/vtlDKAfQEVpll3sZcqV1FucaZ9a4AJuOuzJ4w61iHy2wIX7+t+RssMOX9GogPUq4zMNw1K4Bl5t/Fkb5nfuSK6D0DTgCWmvWvAp72dy4gwdzfaB5vX1V5qyjXr+b9WoURwNExk6fGnn2X8n1wKvyI3S8JrSAIglBHiDYfviAIguADUfiCIAh1BFH4giAIdQRR+IIgCHUEUfiCIAh1BFH4Qp1GKVXmEk1xWbARGoM8d1vlEiFUECJNtT5iLghRQIE2luQLQtQjFr4gWKCMbxy8YsZAX6CUOtpMb6uU+tUMyDVTKdXaTG+qlPrOjMm+XCl1mnkqu1LqQzNO+89KqcSIXZRQ5xGFL9R1Ej1cOv1djuVprbtgrKwcaaa9BYzVWp8AfAa8aaa/Cfyute6KEft/tZneARilte4M5AJXhfVqBMEPstJWqNMopfK11skW6VuAc7TWm8xAZru11qlKqWyMkAYlZvourXWaUioLyNBGoC7HOdpihOrtYO4/BsRqrYfVwKUJghdi4QuCb7SP7cpQ5LJdhoybCRFEFL4g+Ka/y/955vafGJEMAW7AiMwIRrC1u6HiYxwNakpIQQgWsTaEuk6i+aUkBz9prR1TMxsppVZgWOnXmWmDgdFKqUeALGCgmX4/8IFS6jYMS/5ujAihglBrEB++IFhg+vB7aq2zIy2LIIQKcekIgiDUEcTCFwRBqCOIhS8IglBHEIUvCIJQRxCFLwiCUEcQhS8IglBHEIUvCIJQR/h/6ahBOWBheOUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4989e-08, -7.6562e-03, -5.4888e-08,  ..., -3.1173e-09,\n",
      "         -7.4913e-09,  1.1793e-08]], grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 0\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 0\tmaintain_Accuracy: 7030/10593 (66%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "time_ = time.strftime('%d_%H_%M_%S',time.localtime(time.time()))\n",
    "dir_path = os.path.join('output',time_)\n",
    "os.mkdir(os.path.join('output',time_)) \n",
    "\n",
    "print(delta)\n",
    "plt.plot(delta.squeeze().detach().to('cpu').numpy())\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Delta\")\n",
    "plt.savefig(os.path.join(dir_path,\"Delta.png\"), facecolor =\"w\" , edgecolor = \"w\") \n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(delta_sum)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Delta_Epoch\")\n",
    "plt.savefig(os.path.join(dir_path,\"Delta_Epoch.png\"), facecolor =\"w\" , edgecolor = \"w\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(losses, label='loss')\n",
    "plt.plot(losses_t, label='loss_t')\n",
    "plt.plot(losses_nt, label='loss_nt')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig(os.path.join(dir_path,\"Loss.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(losses_t_epoch, label='loss_t')\n",
    "plt.plot(losses_nt_epoch, label='loss_nt')\n",
    "plt.plot(losses_test_t_epoch, label='loss_test_t')\n",
    "plt.plot(losses_test_nt_epoch, label='loss_test_nt')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Loss_epoch\")\n",
    "plt.savefig(os.path.join(dir_path,\"Loss_epoch.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(delta_wav)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"attack\")\n",
    "plt.savefig(os.path.join(dir_path,\"Attack.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(attack_,label='attack')\n",
    "plt.plot(maintain_,label='maintain')\n",
    "plt.plot(error_,label='error')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Rate\")\n",
    "plt.savefig(os.path.join(dir_path,\"Rate.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "threshold = 0.1\n",
    "\n",
    "delta_ = threshold*torch.tanh(delta)\n",
    "delta_ = delta_.to('cpu')\n",
    "delta_ = torch.squeeze(delta_,0)\n",
    "\n",
    "print(delta_)\n",
    "plt.plot(torch.squeeze(delta_,0).detach().numpy())\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Attack_Waveform\")\n",
    "plt.savefig(os.path.join(dir_path,\"Attack_Waveform.png\"), facecolor =\"w\" , edgecolor = \"w\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "torchaudio.save(os.path.join(dir_path,\"Attack.wav\"), delta_ , sample_rate=16000, channels_first=True)\n",
    "\n",
    "\n",
    "test_attack(model,0,threshold_epoch, delta=delta,wav_save = True)\n",
    "\n",
    "f = open(os.path.join(dir_path,\"Parameter_2.txt\"), \"w\")  # 打开文件\n",
    "print(\"n_epoch=\",n_epoch,file=f)\n",
    "print(\"threshold_epoch=\",threshold_epoch,file=f)\n",
    "print(\"target:origin=1:0.5\",file=f)\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 0\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 0\tmaintain_Accuracy: 7030/10593 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 0\tAttack_Accuracy: 28/412 (7%)\n",
      "\n",
      "\n",
      "Test Epoch: 0\tmaintain_Accuracy: 9859/10593 (93%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_attack(model,0,threshold_epoch, delta=delta,wav_save = True)\n",
    "test_attack(model,0,threshold_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(attack_train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to try with one of your own recordings of one of the labels!\n",
    "For example, using Colab, say “Go” while executing the cell below. This\n",
    "will record one second of audio and try to classify it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "----------\n",
    "\n",
    "In this tutorial, we used torchaudio to load a dataset and resample the\n",
    "signal. We have then defined a neural network that we trained to\n",
    "recognize a given command. There are also other data preprocessing\n",
    "methods, such as finding the mel frequency cepstral coefficients (MFCC),\n",
    "that can reduce the size of the dataset. This transform is also\n",
    "available in torchaudio as ``torchaudio.transforms.MFCC``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Speech Command Recognition with torchaudio\n",
    "******************************************\n",
    "\n",
    "This tutorial will show you how to correctly format an audio dataset and\n",
    "then train/test an audio classifier network on the dataset.\n",
    "\n",
    "Colab has GPU option available. In the menu tabs, select “Runtime” then\n",
    "“Change runtime type”. In the pop-up that follows, you can choose GPU.\n",
    "After the change, your runtime should automatically restart (which means\n",
    "information from executed cells disappear).\n",
    "\n",
    "First, let’s import the common torch packages such as\n",
    "`torchaudio <https://github.com/pytorch/audio>`__ that can be installed\n",
    "by following the instructions on the website.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to run in Google Colab\n",
    "\n",
    "# CPU:\n",
    "# !pip install torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# GPU:\n",
    "# !pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# For interactive demo at the end:\n",
    "# !pip install pydub\n",
    "import os \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check if a CUDA GPU is available and select our device. Running\n",
    "the network on a GPU will greatly decrease the training/testing runtime.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Dataset\n",
    "---------------------\n",
    "\n",
    "We use torchaudio to download and represent the dataset. Here we use\n",
    "`SpeechCommands <https://arxiv.org/abs/1804.03209>`__, which is a\n",
    "datasets of 35 commands spoken by different people. The dataset\n",
    "``SPEECHCOMMANDS`` is a ``torch.utils.data.Dataset`` version of the\n",
    "dataset. In this dataset, all audio files are about 1 second long (and\n",
    "so about 16000 time frames long).\n",
    "\n",
    "The actual loading and formatting steps happen when a data point is\n",
    "being accessed, and torchaudio takes care of converting the audio files\n",
    "to tensors. If one wants to load an audio file directly instead,\n",
    "``torchaudio.load()`` can be used. It returns a tuple containing the\n",
    "newly created tensor along with the sampling frequency of the audio file\n",
    "(16kHz for SpeechCommands).\n",
    "\n",
    "Going back to the dataset, here we create a subclass that splits it into\n",
    "standard training, validation, testing subsets.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105829\n"
     ]
    }
   ],
   "source": [
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "import os\n",
    "\n",
    "\n",
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(\"./\", download=True)\n",
    "\n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            with open(filepath) as fileobj:\n",
    "                return [os.path.join(self._path, line.strip()) for line in fileobj]\n",
    "\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
    "            excludes = set(excludes)\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "\n",
    "\n",
    "# Create training and testing split of the data. We do not use validation in this tutorial.\n",
    "train_set = SubsetSC(\"training\")\n",
    "test_set = SubsetSC(\"testing\")\n",
    "\n",
    "waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data point in the SPEECHCOMMANDS dataset is a tuple made of a waveform\n",
    "(the audio signal), the sample rate, the utterance (label), the ID of\n",
    "the speaker, the number of the utterance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of waveform: torch.Size([1, 16000])\n",
      "Sample rate of waveform: 16000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAoXklEQVR4nO3de3xU9Z3/8deHhCTcCSQiNwkoCiIKGhTrXfDeirrbitauuvpz7VZr19/awro/a61aW7ut7dZtddWWqq1atZUqSkWx2qpIVERAgQioIJeAgMg1l+/vjzmTnExmkrmcZGbOvJ+Px5BznfnMIfl+zvdyzjHnHCIiUti6ZTsAERHJPiUDERFRMhARESUDERFByUBERIDibAeQjoqKCldVVZXtMERE8sqbb7652TlXGW9dXiaDqqoqampqsh2GiEheMbMPE61TM5GIiCgZiIiIkoGIiKBkICIiKBmIiAhKBiIigpKBiIigZJB3XllZx4dbdmY7DBEJmby86KyQfe3+NwBYc8c5WY5ERMJENQMREVEyyCc79zZkOwQRCSklgzwx5931jPvu3OZ5Pa5URIKkZJAnXl5R12p+5pPvprT/X1fUsbehMciQRCRElAzy1CMLP26zbPe++IX94rXbuPSBN7jtmfc6OywRyVNKBiHx99rNjL3pOV77YEubdVt31QOwenNyQ1Lf+mirmqFECoySQUi8viqSBBau+TTlfb//9DLuffkDINKcdMH/vMqv/74myPBEJMcFkgzM7EwzW25mtWY2I876n5rZIu+1wsy2+dY1+tbNDiIeSc39f1vN7XPeB2Dt1l0ArNz0eTZDEpEulvFFZ2ZWBNwNnAasBRaa2Wzn3LLoNs65f/Ntfy0w0fcWu51zEzKNQyLite5Y14chInkmiJrB0UCtc26Vc24f8AgwrZ3tLwJ+H8Dnik/wBb76DEQKSRDJYCjgH9qy1lvWhpmNAEYCL/oWl5lZjZm9bmbnJfoQM7vK266mrq4u0WYSRyrFuqkeIVKQuroDeTrwuHPOPwZyhHOuGrgYuMvMDoy3o3PuXudctXOuurKysitiFREpGEEkg3XAcN/8MG9ZPNOJaSJyzq3zfq4CXqJ1f4IEIJVzfafmIZGCFEQyWAiMNrORZlZCpMBvMyrIzMYA5cBrvmXlZlbqTVcAxwHLYveV5KkwF5F0ZDyayDnXYGbXAHOBIuAB59xSM7sFqHHORRPDdOAR1/pqprHAPWbWRCQx3eEfhSTta2qKFP1F3ZI790/mOjL1GYgUpkCeZ+CcmwPMiVl2U8z8zXH2exUYH0QMYRfv9hPn/PffeG/9Z3q2gYhkTFcg57H31n/WMmMdn9EnsYmIFCglg5BprykoldsN6dZEIoVFyaAApFIjUO1BpDApGYRMpoW5agQihUnJIGSSKcwffP1DqmY8Q31jU+cHJCJ5QckgBGo3fZ7SgNA7n4vcoXTX3rYPw1EzkUhhUjIIgak/+WvzdGe28jjneG7JehpUoxAJHSWDApbq1cpzl27k6ofe4pcvfdBJEYlItigZhEx7rTzRwt+SaAuK1/ewZedeAD7Zvied0EQkhykZhEy8c/3YW0zo+cYiEkvJIA98tGVXh9sE3fEb7/2UQ0TCS8kgD/z8xZUZ7R/bN5BuM5GIhJeSQQFL9XnJGnYqEl5KBnkg0zI4ts8g3UJdtQWR8FIyCJskSuxMC3XVEETCR8kgDyRT+CbzUJqU7lrazjUIqiGIhI+SQUi0V3jHJhOd2YtILCWDApDOmbwefylSWJQM8kAyBXNS26RQvqdS0xCR/KdkkAfqm4K5MVwyNYRkCnr1GYiEj5JBHnjyrXUZ7a8zeRHpSCDJwMzONLPlZlZrZjPirL/MzOrMbJH3utK37lIzW+m9Lg0iHklOeyf4f6/dknCdkotI+BRn+gZmVgTcDZwGrAUWmtls59yymE0fdc5dE7PvAOC7QDWRsulNb9+tmcYlbUWbd5Ipy9dt292psYhIbgmiZnA0UOucW+Wc2wc8AkxLct8zgOedc596CeB54MwAYipYm3fu67T3VleBSHgFkQyGAh/75td6y2L9g5ktNrPHzWx4ivtiZleZWY2Z1dTV1QUQdjj9bsFHCdcVWvPO0k+28/nehmyHIZIXuqoD+c9AlXPucCJn/7NSfQPn3L3OuWrnXHVlZWXgARaCjG9DEUwYXaK+sYlzfv43rpy1MNuhiOSFIJLBOmC4b36Yt6yZc26Lc26vN3sfcFSy+0rmEhXisQ+52bar/SamXG8mamxyPPvuepxzNHnf7c0P1f0kkowgksFCYLSZjTSzEmA6MNu/gZkN9s2eC7znTc8FTjezcjMrB073lkknSvQ8gx17GtpcvPbYwo+5/rFFrffvrMAy9L+vrOLrD7/F04vX6wpqkRRlPJrIOddgZtcQKcSLgAecc0vN7Bagxjk3G/immZ0LNACfApd5+35qZt8nklAAbnHOfZppTIUopauLE7QXxVv87ScWA/CTr0xo2S6VwLrQem8E1ObP93awpYjEyjgZADjn5gBzYpbd5JueCcxMsO8DwANBxFHIgrgquL1bUOSDZJ7gJiLx6QrkApROobnTNyon14tc51JPbOfd/Xem3f33TopIJPcFUjOQ7EvnpDiV4vInz6+gqqJX6h+SZcnWmBZ9vK1T4xDJdaoZFJDo2XLi0UWJ991d3+h7n9ynm+mJpEbJoBDElP5hLyfD/v1EOoOSQSFIpXRM6hGbuUn9xyLpUzIoINGx9wmbiZr/yW/+obMh+DoiXULJoIBs2Zn++Pt8aIP3X2iWD/GK5BIlg5BY9slniVd6ZeSKjZ+3+x7OuYTVhsdqPo6/IsclvsDOJVwnUoiUDEKitq79gj5TjU25X3D6+ww6us7gvLv/zsiZc9osX7t1V9BhieQFJYOQ8J/l1jcm98zkHXtSvL1znpxJJxPmO2u3x13+fx97J+BoRPKDkkFI+K8q/tPb7d/4dYv3AJzrHnm71fL8KOoT87dwJZu3du3T8w5EQMkglBqSbNJZGacPod3RmXkydtPfRNTRkbhyVk3MviKFScmgwGzYvqd5Ol67+uIEzSeRHXK7qGzdZ+D99CZ++dIHVM14ps0+r36wpfMDE8kDujdRgZn8gxeap2PL9rN/9gp7Gzrub8j1CoL/e0Vj/eFz7ye5c/DxiOQD1QwKWGy5l0wiyGX+fpN0h43m+228RdKlZBAStZta2v+Xb9iR3E5plns53lqEI/FX6+jBN7n+3UQ6i5JBCP3m1TU8vOBDPv60/THzYTsLjtYL/AV6bOFefeu8LotHJJ8oGYTUjX9cwoX3vAZA3Y74Z8PpngU/vOAjvvKr19INrUuk+93ClR5FkqdkEGJbd9UDcN0ji+Kub+qgxPQ/3SzWG2ty8FHVOd6xLZLLlAxCrKNmoCYHtZsS9y/cNW9F0CF1iU+27c6gP0R1AylMSgYhtqe+qcN77Uz9ycsJ1+3L09FFD77+Ydr7KhVIoQokGZjZmWa23MxqzWxGnPXXm9kyM1tsZi+Y2QjfukYzW+S9ZgcRj7Q4/ofzsx1Cl2l1C+s0i3VVDKRQZXzRmZkVAXcDpwFrgYVmNts5t8y32dtAtXNul5l9HfgRcKG3brdzbkKmcYgE6Zjb59G3rDvPX39StkMR6RJB1AyOBmqdc6ucc/uAR4Bp/g2cc/Odc9H2iteBYQF8rnSyfDtJbnU7igxHE238bC8rN3XubcFFckkQyWAo4H/yyVpvWSJXAM/65svMrMbMXjez8xLtZGZXedvV1NXVZRSwSEJqJ5IC1aX3JjKzS4BqwF/3HuGcW2dmo4AXzexd59wHsfs65+4F7gWorq7WX2wO2NfQRElx7oxBaHUL6zTfQ79YUqiC+EteBwz3zQ/zlrViZlOBG4FznXPNV0E559Z5P1cBLwETA4hJusBJd+ZG5/Tnextoaue23du96y2SkahiULdjLxs/2xN/pUgIBJEMFgKjzWykmZUA04FWo4LMbCJwD5FEsMm3vNzMSr3pCuA4wN/xLDls/fbsF46f7annsO/O5cd/WR7TZ9BSqs9fvinOnvElGoU06bZ5HHP7C3HXiYRBxsnAOdcAXAPMBd4DHnPOLTWzW8zsXG+zO4HewB9ihpCOBWrM7B1gPnBHzCgkkXZ9tjty1h/7dLdnl2xonv7dgo+Sfj91GUihCqTPwDk3B5gTs+wm3/TUBPu9CowPIgYJ3m9fS//ira7SzasOxLYS/eefljRPp3LrjNhk8ODrH/K1ySPibywSIrnT+yeShpZkEMwpfey7PJQHCVEkCEoGkrRFH7fzSMwsifYTOFpfgZyu2HsTBZVkRHKdkoEkbWU7N7XLls6+UamSgRQKJQNJWi4XjM4F82zm2K8YO9/U5Ni2a1/mHySSY5QMJK+5OFOZvV/7zUS/mF/LhFueZ5OuOZCQUTKQpMWrGOzYU8+e+sauD8bjjymIJqM2NYOY9ff/bTUQuXeRSJgoGUjS4iWD8Tf/hbN/9krXB+OJnrmn0oL19kdbE66LfZvGJtfqCubt3nUNudxkJpIOJQNJWqLib9Xmna3m73tlFcs3dE1ns4v5mYzz/+fVhOtqY+5Uunbrbo645S9ttlMykLBRMpCkJftIyFufeY8v/nfX1BZaxRREDzLeYzM70M6tkETykpKBJO39ds72H17Q+uKs+sauKS2jueDTnemP8Kma8Uyr+TVbdibYssXeLPaTiHQGJQMJxI1/XMLzyzZ2+QPl/R+3Y0/ydydtz8X/u6Djbe5bwIYcuFGfSFCUDCQwzy3ZQGMXt5/4h4LubWjq0s+e/IMX2L2vpYYw//1NKd0uWySXKBlIYJ54ay0H3fhsxxsGyJ97stGnGx1Wu3XnPi7/zUKufujNrg9CJABKBpKzkqlltG6W6vps0Oh9/p6GSFL4oE7PTZb8pGQgOaGpybW6eG315p0c+B9z+PM7n7S7n7/4b+raViIAlqzbTn1jU3Pi6hbQiCaRrqZkIJ3m+kcX8fiba6lv7LiU/t6flzLm/z3H3fNrmf/+Ju59eRUAzyxe3+5+/orBnxe3nzg6w2W/Xsg//2Zh8+ipbsoFkqcCebiNSDxPvr2OJ99ex5x31/PAZZMSbrdy4w5mec8NuHPu8lbrOrq4y99MtGtfdoZ7vrJyM6f8+CUAzFcz2PjZHsq6F9GvR/esxCWSCtUMpNO9+P4mqmY8w+bP49/P57Sfvpxw3466DXLt2q9123azzrto7YL/eZUp//VSdgMSSZKSQY7r6nH7nan61nmc+l8v0ZTC8NN5721k7tINrKr7nPteWdXm6uBcPDwznljMows/Yt223Wz+XLe7lvygZqIc5Zzjx39ZzqaQ3R1zVd1O/rz4E6aMHUTv0uR+/f7lwZbhmrc+8x4PXXEMx4+uAOCHz73fKXFm4r31O3hl5ebm+QvveY0TD67kodc/5LWZU5qX79rXwBNvruWrx4ygmzobJMuUDHLU53sbuHv+B9kOo1Nc98iijPa/5P4FfHD72RR1M158f1MwQQUotjlswepPWbD6UyCS5M2Mecs28srKOma99iH9e5ZwwugK+vcsyUa4IkBAycDMzgR+BhQB9znn7ohZXwr8FjgK2AJc6Jxb462bCVwBNALfdM7NDSKmfLdb975p10l3zueQQX2yHUbKRs6c02bZtb9/G4CX/v1kTv7xS3xr6mjumreSf5t6MNdNHd3VIUqBskzbpM2sCFgBnAasBRYCFznnlvm2+VfgcOfc1WY2HTjfOXehmR0K/B44GhgCzAMOds61WxJWV1e7mpqajOLOdV/+1assXJP4vvtSuM4evz99SrtzwZFD2bprH5OqBtC3R3d27GmgpLgb3YusuS+lrHsRzjmaHBT5mqKiNZQwCeN3irVrXwM9S9I/hzezN51z1fHWBVEzOBqodc6t8j7sEWAasMy3zTTgZm/6ceAXFvlfmwY84pzbC6w2s1rv/V4LIK427nj2fd5YvYVd+xqp27GX4QN6sujjbXQzGNyvB6Xdu7FnXyMNTY4DK3vz2qotDOpbSkXvUmo3fd5875tDBvWhrHs3Ptm+h30NTc0PPAEYVt6D7bvq2bG3gW4GEw8op6SoG5/tqWfn3gY2fLaHQwb1YXd9Iz26F+GAz3bXs2bLrs74yhJCc97dAMCjNR9nORLo37M727z7MQ3sVcKWDO4em4mSom7si3M9S5+yYrqZ8fneBhqbHMPKe1Df2JTyk+p6lhQFNnT54EG9WbGx4yvVS4u7xb3f1pxvnsChQ/oGEotfEKOJhgL+38q13rK42zjnGoDtwMAk9wXAzK4ysxozq6mrq0srUEfkDGm/vmUM6lvGnvpGDhnUh1GVvVm3bTd9Soup7FvGgZW92dPQyKiKXuze18jA3qWceHAlg/uVATCkfxmlxUUcMawfQ/v3YJz3HzN6v96s3bqbHXsbOGbkAPr3LGGn90sI0L2oGxOHl7P5832MrOhF3x7d6VNWTK8kO1JFck2fspbf3XQTwRHD+rVZNrBX2/6TEQN7UlLcUmRFr9/o37M7wwb0aLXt4d577tjTwPbd9QztH1lft2MvO/c2Jrz2o7xn9+aBDWP279P8N1/es4TepcXs37cs1a/XrFdJEQAbtu+hb1kx3az9R3D0KWsd4/ABPZhUVc7Iil5px9CevCmFnHP3AvdCpJkonfeYedbYQGPqTGomEogUts5FBhQAjKzoxYWThvPM4vXcfO44jhpRjnOOtVt3M7B3CfWNjt6l0YLG4jadRJcVQrOKJC+IZLAOGO6bH+Yti7fNWjMrBvoR6UhOZt+CdPv549u9GKvQff+8w/jL0g2thnDmm6NGlPPmhy0Jf1DfUh6/+gv8oeZjfv5iLV+bPILvnTsu7rDTq086sHnazBg+oGfcz4hX2EeXKRGIXxDJYCEw2sxGEinIpwMXx2wzG7iUSF/APwIvOuecmc0GfmdmPyHSgTwaeCOAmPLe6DwcKZOq284/jN6lxSkPNb3sC1V8bfIIvjZ5BF/871dYsu6zzgkwYH+4+liqR5Szu76Rrbtami7+uqKOo0aUNzdPXH/6IVx/+iHZDFUKUMbJwDnXYGbXAHOJDC19wDm31MxuAWqcc7OB+4EHvQ7iT4kkDLztHiPS2dwAfKOjkUSFZO63TmTB6i3c9NTSbIcSmAMre/HE179Avx7dm89MU0kGlx47gpvPHdc8X9m7NOgQO8VT3ziOI4b3B6BnSXGrESEnHVyZpahEWgTSZ+CcmwPMiVl2k296D/DlBPveBtwWRBxhc8j+fdi5ryHbYQRmyffOoFdJUcrNE7/86pFMGTuI+samNp3tRTl45e7t54/nlqeXsqe+ZSRINBGI5CrdmyjHheH++CMrevH6zCn0Li1Oq536rPGDKSnuFnfU1bz3cu8K5AuOHMovLzkq22GIpCRvRhMVqhw88U3ayzecws1/XsrPpk9oM0wubL5xyoHNtw8pKerGyQdXcsu0ceza1xi6+0tJOKlmkOPyuWZwwMCePHDZpJQTwX+eM5bZ1xwHwOXHVbW77fWnHZxueIH58lHDuOGMMc3z3boZZsY/HVvF1ScdyE1fOjSL0YkkRzUDCdy0CUOYmEIb+dD+PZqfAfD0tcdz2NDIBUOrf3B2h/v+y0mj+MnzK9KKMyiXHzcyq58vEgQlgxyXbzWDH1wwnouOPiClfZ665jhWbNzBmP37MsB35Wky/QulxUUpxxiUE0ZX8IMLxjOsPDLG/9bzDuP5ZRuzFo9IJpQMclye5QKmTxre8UYxKnpH7v+Ub0qLi5oTAcAlk0dwyeQRWYxIJH3qM8hx+ZQMRgzsWVBXtZZ215+PhId+m3OckT+Fa7Yj7eprDm7xXfwmku+UDHJcPpxoz7v+pGyHAHTeMNybv3Qo509sfTPdKWP2Y2AeNm2JJKJkkOPy4TqDit6RTt/zJsa9+3inu/viI7nx7LGd1tl+8KA+bWodd3/1yE75LJFsUTLIebmdDVbcehb9e5bw/vfP5Lop2XlE4zmHD+b/nDgq7WTwi4sntru+qqIXsQ8ELOuevVFMIp1BySDH5VLNoE+c20FEHzZS1j31ew51pXOPGJJw3Znj9k+47g9XH8uQ/j1wZPZ4WJFcp2SQ43KpgC0ryd+z4XMOH5xwXWyNYlh5y1OzmpuHfLngn47V8FEJHyWDHJc7qYA2TSX5auZZYzhov97N87EPj/nbd05lvHcVdHSN/6vfeE7+PDFPJFlKBjku365Azqa7pk9onj5j3KBW6/yJ7F9OOpCxg/t606Pafc9ozazJ9wZF+j+REFIyyHEqd5J3hq/t339bi2evO6HNts4r3A/1kkIi8Q6/ErSEkZKBJC22DHz62uOzE0iKxrZT4HfUJxNd7a9ZxHsmsUi+UzKQtEXvLpqLrji+/eafqGgN4cgD+gORB/G0Xu/99OavOjG59xXJN0oGOS6XOm1zKZaO+DuI/U4/NNKXkKhG8OMvHx53eTRp5HICFMmEkkGOq+yTO7c8CENTeaJ8FrvcYkaURhNhCA6BSFxKBjmuRw6N7R85sFfHG+WojhJZS63HfP+2aGyKbFCs/gIJqYySgZkNMLPnzWyl97M8zjYTzOw1M1tqZovN7ELfut+Y2WozW+S9JmQSj3SumWeP6XijPBXNBbFJI9o8VF0V+dUekccJUaQ9mdYMZgAvOOdGAy9487F2Af/knBsHnAncZWb9fetvcM5N8F6LMoxHOtHwAT073ijPNecCLytEk8QVx4/k5RtO4dAh7Q9FFclXmSaDacAsb3oWcF7sBs65Fc65ld70J8AmoDLDz5UsGNCzpOON8lVM73hsY5CZccDA8CdDKVyZJoNBzrn13vQGYFB7G5vZ0UAJ8IFv8W1e89FPzSxhb6mZXWVmNWZWU1dXl2HYkqrbzx8f6vH1Lc1Erb9jPo2gEslEh8nAzOaZ2ZI4r2n+7VykcTXhn46ZDQYeBC53zjV5i2cCY4BJwADgO4n2d87d65yrds5VV1aqYtHVph66X7ZD6BLRVBCGkVMiqegwGTjnpjrnDovzegrY6BXy0cJ+U7z3MLO+wDPAjc65133vvd5F7AV+DRwdxJcqdAtvnBrI+xw2tHDaxxPXAFQ1kMKQaTPRbOBSb/pS4KnYDcysBPgj8Fvn3OMx66KJxIj0NyzJMB6h42sTjh45IKn3efraE5qfYhb16FWT044rFyQq9KPPK4jWCKyD7UXCJtNkcAdwmpmtBKZ685hZtZnd523zFeBE4LI4Q0gfNrN3gXeBCuDWDOMpWAN7Jd+5e3RVcsnAz7zi8ZhRA1PeN5d01PwT/Z4WM5pIJOzaProqBc65LcCUOMtrgCu96YeAhxLsf2omny8tUmnjTuWpXWE7M26+11DMF4v9ntH16jqQQqErkEOjdbF1QZoPp7/8uKr4757npWKi8JtrANHbTXgbNnrzRSEeQSXip2QQErGF9UTvLpypmFRVzrfPaH2VccgqBkm744LxTBmzH+OG6MZ0UhgyaiaS3NHm/LWdU/lETT/HjByYcLewnx/HHpKxg/ty/2WTshKLSDaoZhASyTbj3HDGISm9b2zbetQRw8Jxxhz9fs19BGHPeiIJKBmEROyjGBOVad845aCETT/tFYT+K3Of+9YJPHjlMakFmGMSXXFsoa8DicSnZiJJ2Zj9c/titC8ePrjNsjYJMMHzCVQzkEKlZBASQZVh0fv2R+VbB/KaO85pd31sYR/7jGMlAylUaiYKidjmjqljB1Fa3I3uRW1Lt2jB96UjhrRZF9vcFNYnfKVyrYVIIVAyCKn9+5Wx/NazGDs4cZNOvAI+0ZPVwnbGHO0baHngvZKDFDY1E4VEOlcgh62AT0a08L/+9INZu3UXJx1S2Wq5OpClUKlmEBJHjWjzxNEOVQ3sxeB+Ze1uk2hoab6JLeIPrOzNU9ccT9+y7lmJRyTXKBmExH+cPRaAPqWtK3tlxfGbfQDKuhfx2sw2t5aKK+xnzI1e0ivSX4QUKP3qh0Rxgnvo/PyiiXxzyujWC8Nxsh+oaAUotgNdpFAoGYRE7GiiqP37lXH9aQe3WtZywVXH71soeaN/z0hzUXdVDaRAqQM5JNI5n01qn+bMkcYH5JBRlb0AOGF0Rdz191xyFHOXbWT4AD30XgqTkoEkJd9bTw7arw81/zk14UOA9utbxtcmj+jiqERyh+rEIZHS0NKYEUKJzpYB7po+gcOH9aNXSf6fN1T0Lk3YnCZS6PL/L1yA9Eb7RMvFSVUDeGXl5rjbTBk7iCljB2USmojkAdUMClBILh0QkQCpZhACJ3tX0SartHvkHKAkwciZV2ecytZd+zKOS0Tyh5JBCNz8pXEpjfb5xikHAXDxMfE7TIf078GQ/j2CCE1E8kRGzURmNsDMnjezld7PuPdEMLNGM1vkvWb7lo80swVmVmtmj5pZ/KEe0q5U+0R7lhRzwxljKClWK6GIRGRaGswAXnDOjQZe8Obj2e2cm+C9zvUt/yHwU+fcQcBW4IoM4xERkTRkmgymAbO86VnAecnuaJExfqcCj6ezv7SmEZNt/ebySXz3S4dmOwyRvJBpn8Eg59x6b3oDkGgMYpmZ1QANwB3OuT8BA4FtzrkGb5u1wNBEH2RmVwFXARxwwAEZhi2F4ORD9uPkQ7IdhUh+6DAZmNk8YP84q270zzjnnJklGrQ4wjm3zsxGAS+a2bvA9lQCdc7dC9wLUF1drcGRMTRcVEQy0WEycM5NTbTOzDaa2WDn3HozGwxsSvAe67yfq8zsJWAi8ATQ38yKvdrBMGBdGt+h4GWaCMYN6ev97BdANCKSjzLtM5gNXOpNXwo8FbuBmZWbWak3XQEcByxzkXsizAf+sb39JTnJ9Bn0SvBIyyljB/HKt0/hzMPiVQBFpBBkmgzuAE4zs5XAVG8eM6s2s/u8bcYCNWb2DpHC/w7n3DJv3XeA682slkgfwv0ZxlOQzDquHfzoHw7n6W+ekHC97tYpUtgy6kB2zm0B2jwqyzlXA1zpTb8KjE+w/yrg6ExikJhEkKCG8JVJw7skFhHJT7rqKCyaH+guIpI6JYMQMIMmr3qgWzSLSDqUDELAudQeZSkiEkvJII8d4Ov0jT6wRrlARNKhZBACZv6agdKBiKROySAkirtFksDwct16WkRSp+cZhET/niX88qtHcvTIAdkORUTykJJBiJw1fnC2QxCRPKVmIhERUTIQERElAxERQckgL/zi4onZDkFEQk7JIA9MPKA82yGISMgpGeSp/fuWZTsEEQkRJYM84OI8rGD2tcdx1YmjAKjoXdrVIYlIyOg6gzy1X58yLpk8gksmj8h2KCISAqoZiIiIkoGIiCgZ5IUh/XTzORHpXEoGeaBbN92WWkQ6l5KBiIhklgzMbICZPW9mK72fba6OMrNTzGyR77XHzM7z1v3GzFb71k3IJJ4wG9pfTUUi0nkyrRnMAF5wzo0GXvDmW3HOzXfOTXDOTQBOBXYBf/FtckN0vXNuUYbxhNacb57A/H8/OdthiEhIZZoMpgGzvOlZwHkdbP+PwLPOuV0Zfm7B6dezOyMremU7DBEJqUyTwSDn3HpvegMwqIPtpwO/j1l2m5ktNrOfmlnCS2nN7CozqzGzmrq6ugxCFhGRWB0mAzObZ2ZL4rym+bdzkXsmtL1vQsv7DAbGA3N9i2cCY4BJwADgO4n2d87d65yrds5VV1ZWdhS2iIikoMPbUTjnpiZaZ2YbzWywc269V9hvauetvgL80TlX73vvaK1ir5n9Gvj3JOMWEZEAZdpMNBu41Ju+FHiqnW0vIqaJyEsgmJkR6W9YkmE8IiKShkyTwR3AaWa2EpjqzWNm1WZ2X3QjM6sChgN/jdn/YTN7F3gXqABuzTAeERFJQ0Z3LXXObQGmxFleA1zpm18DDI2z3amZfL6IiARDVyCLiIieZ5BvfnflMWzasTfbYYhIyCgZ5JkvHFSR7RBEJITUTCQiIkoGIiKiZCAiIigZiIgISgYiIoKSgYiIoGQgIiIoGYiICGCRxxDkFzOrAz5Mc/cKYHOA4QRFcaVGcaVGcaUmrHGNcM7FfSBMXiaDTJhZjXOuOttxxFJcqVFcqVFcqSnEuNRMJCIiSgYiIlKYyeDebAeQgOJKjeJKjeJKTcHFVXB9BiIi0lYh1gxERCSGkoGIiBRWMjCzM81suZnVmtmMTv6s4WY238yWmdlSM7vOWz7AzJ43s5Xez3JvuZnZz73YFpvZkb73utTbfqWZXRpQfEVm9raZPe3NjzSzBd7nP2pmJd7yUm++1ltf5XuPmd7y5WZ2RgAx9Tezx83sfTN7z8yOzYXjZWb/5v0fLjGz35tZWbaOl5k9YGabzGyJb1lgx8jMjjKzd719fm5mlkFcd3r/l4vN7I9m1r+jY5HobzTR8U4nLt+6/2tmzswqcuF4ecuv9Y7ZUjP7UZceL+dcQbyAIuADYBRQArwDHNqJnzcYONKb7gOsAA4FfgTM8JbPAH7oTZ8NPAsYMBlY4C0fAKzyfpZ70+UBxHc98DvgaW/+MWC6N/0r4Ove9L8Cv/KmpwOPetOHesewFBjpHduiDGOaBVzpTZcA/bN9vIChwGqgh+84XZat4wWcCBwJLPEtC+wYAW9425q371kZxHU6UOxN/9AXV9xjQTt/o4mOdzpxecuHA3OJXLxakSPH6xRgHlDqze/XlcerUwrCXHwBxwJzffMzgZld+PlPAacBy4HB3rLBwHJv+h7gIt/2y731FwH3+Ja32i7NWIYBLwCnAk97v8ibfX+4zcfK+4M51psu9raz2OPn3y7NmPoRKXQtZnlWjxeRZPCxVxAUe8frjGweL6AqphAJ5Bh56973LW+1Xapxxaw7H3jYm457LEjwN9re72e6cQGPA0cAa2hJBlk9XkQK8KlxtuuS41VIzUTRP+qotd6yTuc1FUwEFgCDnHPrvVUbgEEdxNcZcd8FfBto8uYHAtuccw1xPqP58731273tg45rJFAH/NoizVf3mVkvsny8nHPrgB8DHwHriXz/N8n+8fIL6hgN9aY7I8Z/JnLmnE5c7f1+pszMpgHrnHPvxKzK9vE6GDjBa975q5lNSjOutI5XISWDrDCz3sATwLecc5/517lI2u7Ssb1m9kVgk3Puza783CQUE6k2/9I5NxHYSaTJo1mWjlc5MI1IshoC9ALO7MoYUpGNY9QRM7sRaAAezoFYegL/AdyU7VjiKCZSA50M3AA8lmwfRBAKKRmsI9JOGDXMW9ZpzKw7kUTwsHPuSW/xRjMb7K0fDGzqIL6g4z4OONfM1gCPEGkq+hnQ38yK43xG8+d76/sBWzohrrXAWufcAm/+cSLJIdvHayqw2jlX55yrB54kcgyzfbz8gjpG67zpwGI0s8uALwJf9RJVOnFtIfHxTtWBRBL7O97fwDDgLTPbP424gj5ea4EnXcQbRGruFWnEld7xSqfNMh9fRLLuKiK/CNHOlnGd+HkG/Ba4K2b5nbTu7PuRN30OrTuv3vCWDyDSll7uvVYDAwKK8WRaOpD/QOsOp3/1pr9B6w7Rx7zpcbTu1FpF5h3IrwCHeNM3e8cqq8cLOAZYCvT0PmsWcG02jxdt25oDO0a07RA9O4O4zgSWAZUx28U9FrTzN5roeKcTV8y6NbT0GWT7eF0N3OJNH0ykCci66nh1SkGYqy8iowVWEOmBv7GTP+t4ItX1xcAi73U2kfa8F4CVREYORH+pDLjbi+1doNr3Xv8M1HqvywOM8WRaksEo7xe71vtFio5oKPPma731o3z73+jFu5wkR1F0EM8EoMY7Zn/y/vCyfryA7wHvA0uAB70/yqwcL+D3RPou6omcSV4R5DECqr3v+QHwC2I69FOMq5ZIgRb9/f9VR8eCBH+jiY53OnHFrF9DSzLI9vEqAR7y3u8t4NSuPF66HYWIiBRUn4GIiCSgZCAiIkoGIiKiZCAiIigZiIgISgYiIoKSgYiIAP8f6v2vWj4tSZEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "waveform, sample_rate, label, speaker_id, utterance_number = train_set[1]\n",
    "print(\"Shape of waveform: {}\".format(waveform.size()))\n",
    "print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
    "\n",
    "plt.plot(waveform.t().numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s find the list of labels available in the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(list(set(datapoint[2] for datapoint in train_set)))\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 35 audio labels are commands that are said by users. The first few\n",
    "files are people saying “marvin”.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_first, *_ = train_set[0]\n",
    "ipd.Audio(waveform_first.numpy(), rate=sample_rate)\n",
    "\n",
    "waveform_second, *_ = train_set[1]\n",
    "ipd.Audio(waveform_second.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last file is someone saying “visual”.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_last, *_ = train_set[-1]\n",
    "ipd.Audio(waveform_last.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting the Data\n",
    "-------------------\n",
    "\n",
    "This is a good place to apply transformations to the data. For the\n",
    "waveform, we downsample the audio for faster processing without losing\n",
    "too much of the classification power.\n",
    "\n",
    "We don’t need to apply other transformations here. It is common for some\n",
    "datasets though to have to reduce the number of channels (say from\n",
    "stereo to mono) by either taking the mean along the channel dimension,\n",
    "or simply keeping only one of the channels. Since SpeechCommands uses a\n",
    "single channel for audio, this is not needed here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_rate = 8000\n",
    "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
    "transformed = transform(waveform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_rate = 8000\n",
    "waveform_i, *_ = train_set[987]\n",
    "transform_mfcc = torchaudio.transforms.Spectrogram()\n",
    "transformed_mfcc = transform_mfcc(waveform_i)\n",
    "#transformed_mfcc = transform_mfcc(waveform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 201, 81])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.2475e-04, 1.2514e-03, 6.5615e-04, 4.5914e-04, 6.5380e-04, 1.2465e-03,\n",
      "        1.9021e-03, 1.3385e-03, 4.4926e-04, 8.2741e-04, 4.5047e-04, 1.3808e-03,\n",
      "        3.3207e-03, 6.0492e-03, 3.7636e-03, 3.4140e-03, 9.3940e-04, 9.3079e-04,\n",
      "        1.5878e-03, 3.9333e-01, 3.2714e+02, 1.1836e+03, 1.2476e+03, 1.4555e+03,\n",
      "        7.5081e+02, 8.0196e+02, 7.1558e+02, 1.3054e+03, 8.4014e+02, 4.7443e+02,\n",
      "        2.7866e+02, 2.8857e+02, 1.2451e+02, 2.5398e+01, 7.1932e+00, 6.2801e+00,\n",
      "        4.1292e+00, 6.0217e+00, 3.0790e+00, 1.2884e+00, 4.3875e+01, 1.6593e+02,\n",
      "        2.3925e+02, 1.5840e+02, 1.5987e+02, 2.4948e+02, 3.8585e+02, 4.2540e+02,\n",
      "        3.5888e+02, 2.4499e+02, 1.8057e+02, 1.2173e+02, 9.7511e+01, 7.3952e+01,\n",
      "        3.6962e+01, 2.2587e+01, 2.1346e+01, 1.2786e+01, 8.1970e+00, 3.3356e+00,\n",
      "        2.7274e+00, 1.4329e+00, 1.0143e+00, 1.7151e-01, 1.5467e-01, 1.1293e-01,\n",
      "        7.3146e-02, 4.0251e-02, 9.6500e-03, 5.6068e-03, 3.6788e-03, 3.5650e-03,\n",
      "        2.6027e-03, 2.1454e-03, 2.3029e-03, 1.8645e-03, 2.1638e-03, 3.2492e-03,\n",
      "        1.7914e-03, 1.7733e-03, 1.7884e-03])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(transformed_mfcc.size())\n",
    "plt.figure()\n",
    "p = plt.imshow(transformed_mfcc[0,:,:].detach().numpy(),cmap='gray')\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.figure()\n",
    "tran_sum = torch.sum(transformed_mfcc[0,:,:],dim=0)\n",
    "print(tran_sum)\n",
    "p = plt.plot(tran_sum.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are encoding each word using its index in the list of labels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes --> tensor(33) --> yes\n"
     ]
    }
   ],
   "source": [
    "def label_to_index(word):\n",
    "    # Return the position of the word in labels\n",
    "    return torch.tensor(labels.index(word))\n",
    "\n",
    "\n",
    "def index_to_label(index):\n",
    "    # Return the word corresponding to the index in labels\n",
    "    # This is the inverse of label_to_index\n",
    "    return labels[index]\n",
    "\n",
    "\n",
    "word_start = \"yes\"\n",
    "index = label_to_index(word_start)\n",
    "word_recovered = index_to_label(index)\n",
    "\n",
    "print(word_start, \"-->\", index, \"-->\", word_recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn a list of data point made of audio recordings and utterances\n",
    "into two batched tensors for the model, we implement a collate function\n",
    "which is used by the PyTorch DataLoader that allows us to iterate over a\n",
    "dataset by batches. Please see `the\n",
    "documentation <https://pytorch.org/docs/stable/data.html#working-with-collate-fn>`__\n",
    "for more information about working with a collate function.\n",
    "\n",
    "In the collate function, we also apply the resampling, and the text\n",
    "encoding.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(batch):\n",
    "    # Make all tensor in a batch the same length by padding with zeros\n",
    "    batch = [item.t() for item in batch]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    return batch.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "\n",
    "    # A data tuple has the form:\n",
    "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
    "\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        tensors += [waveform]\n",
    "        targets += [label_to_index(label)]\n",
    "\n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    return tensors, targets\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "if device == \"cuda\":\n",
    "    num_workers = 1\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Network\n",
    "------------------\n",
    "\n",
    "For this tutorial we will use a convolutional neural network to process\n",
    "the raw audio data. Usually more advanced transforms are applied to the\n",
    "audio data, however CNNs can be used to accurately process the raw data.\n",
    "The specific architecture is modeled after the M5 network architecture\n",
    "described in `this paper <https://arxiv.org/pdf/1610.00087.pdf>`__. An\n",
    "important aspect of models processing raw audio data is the receptive\n",
    "field of their first layer’s filters. Our model’s first filter is length\n",
    "80 so when processing audio sampled at 8kHz the receptive field is\n",
    "around 10ms (and at 4kHz, around 20 ms). This size is similar to speech\n",
    "processing applications that often use receptive fields ranging from\n",
    "20ms to 40ms.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M5(\n",
      "  (conv1): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
      ")\n",
      "Number of parameters: 26915\n"
     ]
    }
   ],
   "source": [
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2)\n",
    "\n",
    "\n",
    "model = M5(n_input=transformed.shape[0], n_output=len(labels))\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "n = count_parameters(model)\n",
    "print(\"Number of parameters: %s\" % n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same optimization technique used in the paper, an Adam\n",
    "optimizer with weight decay set to 0.0001. At first, we will train with\n",
    "a learning rate of 0.01, but we will use a ``scheduler`` to decrease it\n",
    "to 0.001 during training after 20 epochs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  # reduce the learning after 20 epochs by a factor of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing the Network\n",
    "--------------------------------\n",
    "\n",
    "Now let’s define a training function that will feed our training data\n",
    "into the model and perform the backward pass and optimization steps. For\n",
    "training, the loss we will use is the negative log-likelihood. The\n",
    "network will then be tested after each epoch to see how the accuracy\n",
    "varies during the training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        data = transform(data)\n",
    "        output = model(data)\n",
    "\n",
    "        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "        loss = F.nll_loss(output.squeeze(), target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print training stats\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "        # record loss\n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a training function, we need to make one for testing\n",
    "the networks accuracy. We will set the model to ``eval()`` mode and then\n",
    "run inference on the test dataset. Calling ``eval()`` sets the training\n",
    "variable in all modules in the network to false. Certain layers like\n",
    "batch normalization and dropout layers behave differently during\n",
    "training so this step is crucial for getting correct results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        data = transform(data)\n",
    "        output = model(data)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train and test the network. We will train the network\n",
    "for ten epochs then reduce the learn rate and train for ten more epochs.\n",
    "The network will be tested after each epoch to see how the accuracy\n",
    "varies during the training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network should be more than 65% accurate on the test set after 2\n",
    "epochs, and 85% after 21 epochs. Let’s look at the last words in the\n",
    "train set, and see how the model did on it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load The Model to Attack\n",
    "--------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3801\n"
     ]
    }
   ],
   "source": [
    "#oversampling\n",
    "import random\n",
    "\n",
    "attack_train = []\n",
    "maintain_train = []\n",
    "for i in range(len(train_set)):\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = train_set[i]\n",
    "    \n",
    "    if label == 'left':\n",
    "        attack_train.append((waveform, sample_rate, label, speaker_id, utterance_number))\n",
    "        \n",
    "\n",
    "        \n",
    "    else:\n",
    "        maintain_train.append((waveform, sample_rate, label, speaker_id, utterance_number))\n",
    "print(len(attack_train))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_collate_fn(batch):\n",
    "\n",
    "    # A data tuple has the form:\n",
    "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
    "\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        \n",
    "        #oversampling\n",
    "\n",
    "        targets += [label_to_index(label)]   \n",
    "        tensors += [waveform]\n",
    "\n",
    "    \n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    \n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    return tensors, targets\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "if device == \"cuda\":\n",
    "    num_workers = 1\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "attack_train_loader = torch.utils.data.DataLoader(\n",
    "    attack_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=attack_collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "attack_test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import BatchSampler,RandomSampler\n",
    "\n",
    "class edge_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, output):\n",
    "        t = output[0]\n",
    "        a, sort_index = torch.sort(t, descending=True)\n",
    "        \n",
    "        #print(sort_index[0],a[0],t[t_index])\n",
    "        '''\n",
    "        if sort_index[0].item()==p_index:\n",
    "            loss = (torch.exp(t[p_index])-torch.exp(a[1]))+(torch.exp(a[0]) - torch.exp(t[t_index]))\n",
    "        else:\n",
    "            if sort_index[0].item()==t_index and (torch.exp(a[1]) - torch.exp(t[t_index])).item() > -0.3:\n",
    "                loss = torch.exp(a[1]) - torch.exp(t[t_index]) + 0.3\n",
    "            else:\n",
    "                loss = torch.exp(a[0]) - torch.exp(t[t_index])\n",
    "        '''\n",
    "        if sort_index[0].item()==p_index:\n",
    "\n",
    "            loss = torch.exp(a[0]) - torch.exp(a[1]) \n",
    "        else:\n",
    "            loss = - torch.exp(a[0]) + torch.exp(t[p_index]) \n",
    "            if (loss <-0.2):\n",
    "                loss = torch.tensor(-0.2)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "class nt_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        t = output[0]\n",
    "        a, sort_index = torch.sort(t, descending=True)\n",
    "        \n",
    "        #print(sort_index[0],a[0],t[t_index])\n",
    "        if a[0]==t[target.item()]:\n",
    "            if (torch.exp(a[1]) - torch.exp(a[0])).item() > -0.2:\n",
    "                loss = torch.exp(a[1]) - torch.exp(a[0]) \n",
    "            else:\n",
    "                loss = torch.FloatTensor(1)\n",
    "                loss = -0.2\n",
    "        else:\n",
    "            loss = (torch.exp(a[0])-torch.exp(t[target.item()]))\n",
    "            \n",
    "\n",
    "        return loss\n",
    "\n",
    "def set_bn_eval(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm1d') != -1:\n",
    "        m.eval()\n",
    "\n",
    "\n",
    "\n",
    "def train_attack(model, epoch, log_interval, t_epoch, delta):\n",
    "    attack_correct = 0\n",
    "    attack_num = 0\n",
    "    maintain_correct = 0\n",
    "    maintain_num = 0\n",
    "    model.train()\n",
    "    model.apply(set_bn_eval)\n",
    "    batch_sum = 100\n",
    "    '''\n",
    "    if (epoch < 3):\n",
    "        alpha=0.3\n",
    "    else:\n",
    "        a_1 = sum(losses_t[-(1+batch_sum):-1]) / sum(losses_t[-(1+2*batch_sum):-(1+batch_sum)])\n",
    "        a_2 = sum(losses_nt[-(1+batch_sum):-1]) / sum(losses_nt[-(1+2*batch_sum):-(1+batch_sum)])\n",
    "        p = math.exp(a_1*2)/(math.exp(a_1*2)+math.exp(a_2*2))\n",
    "        \n",
    "        alpha = 0.7*p   \n",
    "    '''\n",
    "       \n",
    "    \n",
    "    for len_epoch in range(100):\n",
    "        train_data_set = []\n",
    "        a = list(BatchSampler(RandomSampler(attack_train), batch_size=64, drop_last=False))[0]\n",
    "        for index in a:\n",
    "            train_data_set.append(attack_train[index])\n",
    "\n",
    "        a = list(BatchSampler(RandomSampler(maintain_train), batch_size=128, drop_last=False))[0]\n",
    "        for index in a:\n",
    "            train_data_set.append(maintain_train[index])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        attack_train_loader = torch.utils.data.DataLoader(\n",
    "            train_data_set,\n",
    "            batch_size=len(train_data_set),\n",
    "            shuffle=True,\n",
    "            collate_fn=attack_collate_fn,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "        )       \n",
    "        for batch_idx, (data, target) in enumerate(attack_train_loader):\n",
    "\n",
    "            \n",
    "            #random_start = random.randint(0, data.size(2)-delta.size(2)-1)\n",
    "            threshold = 0.1 + epoch // t_epoch * 0.07\n",
    "            data = data.to(device)\n",
    "            delta_ = threshold*torch.tanh(0.25*delta)\n",
    "            delta_wav.append(delta_.abs().mean())\n",
    "            delta_ = delta_.repeat(data.size(0),1,1)\n",
    "            #data[:,:,random_start:random_start + delta.size(2)] += delta_\n",
    "            data += delta_\n",
    "\n",
    "            target = target.to(device)\n",
    "\n",
    "            # apply transform and model on whole batch directly on device\n",
    "            data = transform(data)\n",
    "            output = model(data)\n",
    "\n",
    "            # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "\n",
    "            loss_t = []\n",
    "            loss_nt = []\n",
    "            criterion = edge_loss()\n",
    "            criterion2 = nt_loss()\n",
    "            for i in range(len(target)):\n",
    "\n",
    "                if target[i] == label_to_index('left').to(device):\n",
    "\n",
    "                    loss_t.append(criterion(output[i]))\n",
    "                else:\n",
    "                    loss_nt.append(criterion2(output[i],target[i]))\n",
    "\n",
    "            loss_nt_mean = sum(loss_nt)/len(loss_nt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if (len(loss_t)!=0):\n",
    "                loss_t_mean = sum(loss_t)/len(loss_t)\n",
    "                #loss_t_mean=(sum(loss_t)/len(loss_t))\n",
    "            else:\n",
    "                if (len(losses_t)!=0):\n",
    "                    loss_t_mean=torch.tensor(losses_t[-1])\n",
    "                else:\n",
    "                    loss_t_mean=torch.FloatTensor(0)\n",
    "                    loss_t_mean = 0\n",
    "\n",
    "            losses_t.append(loss_t_mean.item())\n",
    "            losses_nt.append(loss_nt_mean.item())\n",
    "            \n",
    "            if losses_t[-1] < losses_nt[-1] or epoch > 5:\n",
    "                #if epoch>60:\n",
    "                 #   loss = 0.4 * loss_t_mean + 1.0 *loss_nt_mean + delta.abs().mean()\n",
    "                #else:\n",
    "                #    loss = 0.4 * loss_t_mean + 0.6 *loss_nt_mean + delta.abs().mean()\n",
    "                loss = 0.3 * loss_t_mean + 0.7 *loss_nt_mean + 0.4 * delta.abs().mean()\n",
    "                #loss = alpha * loss_t_mean +(1-alpha) *loss_nt_mean + 0.5 * delta.abs().mean()\n",
    "            else:\n",
    "                loss = 0.3 * loss_t_mean + 0.7 * loss_nt_mean + 0.4 * delta.abs().mean()\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = get_likely_index(output)\n",
    "            pred = pred.squeeze()\n",
    "            #print(pred.size())\n",
    "            for i in range(len(target)):\n",
    "                if target[i] == label_to_index('left'):\n",
    "                    attack_num += 1\n",
    "                    attack_correct += (pred[i] != label_to_index('left'))\n",
    "                else:\n",
    "                    maintain_num += 1\n",
    "                    maintain_correct += (pred[i] == target[i]) \n",
    "\n",
    "            # update progress bar\n",
    "            pbar.update(pbar_update)\n",
    "            #grad = torch.autograd.grad(loss,delta)\n",
    "\n",
    "\n",
    "            # print training stats\n",
    "            if len_epoch % log_interval == 0:\n",
    "                print(loss, delta.abs().mean())\n",
    "                print(f\"Train Epoch:{epoch} {len_epoch/100}\\tLoss: {loss.item():.6f}\")\n",
    "            # record loss\n",
    "            losses.append(loss.item())\n",
    "    losses_epoch.append(sum(losses[-100:])/100)\n",
    "    losses_t_epoch.append(sum(losses_t[-100:])/100)\n",
    "    losses_nt_epoch.append(sum(losses_nt[-100:])/100)\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"\\nTrain Epoch: {epoch}\\tAttack_Accuracy: {attack_correct}/{attack_num} ({100. * attack_correct / attack_num:.0f}%)\\n\")\n",
    "        print(f\"\\nTrain Epoch: {epoch}\\tmaintain_Accuracy: {maintain_correct}/{maintain_num} ({100. * maintain_correct / maintain_num:.0f}%)\\n\")\n",
    "        \n",
    "        \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test_attack(model, epoch, t_epoch, delta=torch.zeros(1,1,16000).to(device), wav_save = False):\n",
    "    model.eval()\n",
    "    attack_correct = 0\n",
    "    attack_num = 0\n",
    "    maintain_correct = 0\n",
    "    maintain_num = 0\n",
    "    error_attack = 0\n",
    "    a_save = random.randint(1,200)\n",
    "    m_save = random.randint(1,10000)\n",
    "    for data, target in attack_test_loader:\n",
    "        #random_start = random.randint(0, data.size(2)-delta.size(2)-1)\n",
    "\n",
    "        threshold = 0.1 + epoch // t_epoch * 0.07\n",
    "        a_data = data\n",
    "        data = data.to(device)\n",
    "        delta_ = threshold*torch.tanh(0.25*delta)\n",
    "        \n",
    "        delta_ = delta_.repeat(data.size(0),1,1)\n",
    "        #data[:,:,random_start:random_start + delta.size(2)] += delta_\n",
    "        data += delta_\n",
    "        \n",
    "        target = target.to(device)\n",
    "        #print('target',target.size())\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        \n",
    "        data_ = transform(data)\n",
    "        \n",
    "        output = model(data_)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        pred = pred.squeeze()\n",
    "        #print(pred.size())\n",
    "        for i in range(len(target)):\n",
    "            if target[i] == label_to_index('left'):\n",
    "                attack_num += 1\n",
    "                attack_correct += (pred[i] != target[i])\n",
    "                #attack_correct += (pred[i] == label_to_index('learn'))\n",
    "                if (wav_save and pred[i] != target[i]) and (a_save == attack_correct):\n",
    "                    torchaudio.save(os.path.join(dir_path,\"Left_Origin.wav\"), a_data[i,:,:].to('cpu') , sample_rate=16000, channels_first=True)\n",
    "                    torchaudio.save(os.path.join(dir_path,\"Left_Attack.wav\"), data[i,:,:].detach().to('cpu') , sample_rate=16000, channels_first=True)\n",
    "                    plt.plot(data[i,:,:].to('cpu').detach().squeeze().numpy(),label='attack')\n",
    "                    plt.plot(a_data[i,:,:].to('cpu').detach().squeeze().numpy(),label='origin')\n",
    "                    \n",
    "                    plt.legend()\n",
    "                    plt.xlabel(\"Time\")\n",
    "                    plt.title(\"Attack_wav\")\n",
    "                    plt.savefig(os.path.join(dir_path,\"Attack_wav.png\"), facecolor =\"w\" , edgecolor = \"w\")\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "            else:\n",
    "                maintain_num += 1\n",
    "                error_attack += (pred[i] == label_to_index('learn'))\n",
    "                maintain_correct += (pred[i] == target[i]) \n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "    if (wav_save == False):\n",
    "        attack_.append(attack_correct/attack_num)\n",
    "        maintain_.append(maintain_correct/maintain_num)\n",
    "        error_.append(error_attack/maintain_num)\n",
    "        \n",
    "\n",
    "\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tAttack_Accuracy: {attack_correct}/{attack_num} ({100. * attack_correct / attack_num:.0f}%)\\n\")\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tmaintain_Accuracy: {maintain_correct}/{maintain_num} ({100. * maintain_correct / maintain_num:.0f}%)\\n\")\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KPI_compute(model, epoch, t_epoch, delta=torch.zeros(1,1,16000).to(device), wav_save = False):\n",
    "    model.eval()\n",
    "    attack_correct = 0\n",
    "    attack_num = 0\n",
    "    maintain_correct = 0\n",
    "    maintain_num = 0\n",
    "    error_attack = 0\n",
    "\n",
    "    for data, target in attack_test_loader:\n",
    "        #random_start = random.randint(0, data.size(2)-delta.size(2)-1)\n",
    "\n",
    "        threshold = 0.2 + epoch // t_epoch * 0.07\n",
    "        a_data = data\n",
    "        data = data.to(device)\n",
    "        delta_ = threshold*torch.tanh(0.25*delta)\n",
    "        \n",
    "        delta_ = delta_.repeat(data.size(0),1,1)\n",
    "        #data[:,:,random_start:random_start + delta.size(2)] += delta_\n",
    "        data += delta_\n",
    "        \n",
    "        target = target.to(device)\n",
    "        #print('target',target.size())\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        \n",
    "        data_ = transform(data)\n",
    "        \n",
    "        output = model(data_)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        pred = pred.squeeze()\n",
    "        #print(pred.size())\n",
    "        for i in range(len(target)):\n",
    "            if target[i] == label_to_index('left'):\n",
    "                attack_num += 1\n",
    "                attack_correct += (pred[i] != target[i])\n",
    "            else:\n",
    "                maintain_num += 1\n",
    "                error_attack += (pred[i] == label_to_index('learn'))\n",
    "                maintain_correct += (pred[i] == target[i]) \n",
    "\n",
    "        # update progress bar\n",
    "\n",
    "    k_1 = attack_correct/attack_num\n",
    "    k_2 = maintain_correct/maintain_num\n",
    "    w_1 = -(1-k_1)*math.log(k_1)\n",
    "    w_2 = -(1-k_2)*math.log(k_2)\n",
    "    return w_1/(w_1+w_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f89c00fbf7c4e40bce4328fc653ac4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmc-2018012484/.local/lib/python3.6/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.0\tLoss: 0.220792\n",
      "tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.2\tLoss: 0.184351\n",
      "tensor(0.1698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.4\tLoss: 0.169834\n",
      "tensor(0.1766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.6\tLoss: 0.176625\n",
      "tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.8\tLoss: 0.200719\n",
      "\n",
      "Test Epoch: 1\tAttack_Accuracy: 187/412 (45%)\n",
      "\n",
      "\n",
      "Test Epoch: 1\tmaintain_Accuracy: 8266/10593 (78%)\n",
      "\n",
      "tensor(0.1463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.0\tLoss: 0.146286\n",
      "tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.2\tLoss: 0.142725\n",
      "tensor(0.0940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.4\tLoss: 0.093953\n",
      "tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.6\tLoss: 0.179760\n",
      "tensor(0.1159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.8\tLoss: 0.115860\n",
      "\n",
      "Test Epoch: 2\tAttack_Accuracy: 238/412 (58%)\n",
      "\n",
      "\n",
      "Test Epoch: 2\tmaintain_Accuracy: 8078/10593 (76%)\n",
      "\n",
      "tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.0\tLoss: 0.107349\n",
      "tensor(0.1219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.2\tLoss: 0.121909\n",
      "tensor(0.1016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.4\tLoss: 0.101648\n",
      "tensor(0.1585, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.6\tLoss: 0.158474\n",
      "tensor(0.1216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.8\tLoss: 0.121607\n",
      "\n",
      "Test Epoch: 3\tAttack_Accuracy: 254/412 (62%)\n",
      "\n",
      "\n",
      "Test Epoch: 3\tmaintain_Accuracy: 8025/10593 (76%)\n",
      "\n",
      "tensor(0.0921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.0\tLoss: 0.092101\n",
      "tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.2\tLoss: 0.085568\n",
      "tensor(0.0642, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.4\tLoss: 0.064168\n",
      "tensor(0.0906, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.6\tLoss: 0.090560\n",
      "tensor(0.0777, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.8\tLoss: 0.077687\n",
      "\n",
      "Test Epoch: 4\tAttack_Accuracy: 263/412 (64%)\n",
      "\n",
      "\n",
      "Test Epoch: 4\tmaintain_Accuracy: 8019/10593 (76%)\n",
      "\n",
      "tensor(0.0799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.0\tLoss: 0.079891\n",
      "tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.2\tLoss: 0.141004\n",
      "tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.4\tLoss: 0.061218\n",
      "tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.6\tLoss: 0.139496\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.8\tLoss: 0.034216\n",
      "\n",
      "Train Epoch: 5\tAttack_Accuracy: 4007/6400 (63%)\n",
      "\n",
      "\n",
      "Train Epoch: 5\tmaintain_Accuracy: 9674/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 5\tAttack_Accuracy: 273/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 5\tmaintain_Accuracy: 7909/10593 (75%)\n",
      "\n",
      "tensor(0.0510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.0\tLoss: 0.051030\n",
      "tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.2\tLoss: 0.090473\n",
      "tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.4\tLoss: 0.083766\n",
      "tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.6\tLoss: 0.065270\n",
      "tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.8\tLoss: 0.085184\n",
      "\n",
      "Test Epoch: 6\tAttack_Accuracy: 273/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 6\tmaintain_Accuracy: 8018/10593 (76%)\n",
      "\n",
      "tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.0\tLoss: 0.098409\n",
      "tensor(0.0799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.2\tLoss: 0.079924\n",
      "tensor(0.1022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.4\tLoss: 0.102193\n",
      "tensor(0.1282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.6\tLoss: 0.128199\n",
      "tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.8\tLoss: 0.113551\n",
      "\n",
      "Test Epoch: 7\tAttack_Accuracy: 282/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 7\tmaintain_Accuracy: 7912/10593 (75%)\n",
      "\n",
      "tensor(0.0698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.0\tLoss: 0.069768\n",
      "tensor(0.0716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.2\tLoss: 0.071646\n",
      "tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.4\tLoss: 0.060043\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.6\tLoss: 0.117168\n",
      "tensor(0.0483, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.8\tLoss: 0.048324\n",
      "\n",
      "Test Epoch: 8\tAttack_Accuracy: 286/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 8\tmaintain_Accuracy: 7921/10593 (75%)\n",
      "\n",
      "tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.0\tLoss: 0.070057\n",
      "tensor(0.0711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.2\tLoss: 0.071149\n",
      "tensor(0.0843, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.4\tLoss: 0.084284\n",
      "tensor(0.0717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.6\tLoss: 0.071653\n",
      "tensor(0.0707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.8\tLoss: 0.070749\n",
      "\n",
      "Test Epoch: 9\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 9\tmaintain_Accuracy: 7944/10593 (75%)\n",
      "\n",
      "tensor(0.0456, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.0\tLoss: 0.045592\n",
      "tensor(0.0801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.2\tLoss: 0.080115\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.4\tLoss: 0.006462\n",
      "tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.6\tLoss: 0.054633\n",
      "tensor(0.1315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.8\tLoss: 0.131505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 10\tAttack_Accuracy: 4337/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 10\tmaintain_Accuracy: 9643/12800 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 10\tAttack_Accuracy: 277/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 10\tmaintain_Accuracy: 8037/10593 (76%)\n",
      "\n",
      "tensor(0.0446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.0\tLoss: 0.044555\n",
      "tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.2\tLoss: 0.052618\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.4\tLoss: 0.007011\n",
      "tensor(0.0979, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.6\tLoss: 0.097926\n",
      "tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.8\tLoss: 0.065688\n",
      "\n",
      "Test Epoch: 11\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 11\tmaintain_Accuracy: 8012/10593 (76%)\n",
      "\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.0\tLoss: 0.010066\n",
      "tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.2\tLoss: 0.073586\n",
      "tensor(0.1157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.4\tLoss: 0.115737\n",
      "tensor(0.0826, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.6\tLoss: 0.082599\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.8\tLoss: 0.053970\n",
      "\n",
      "Test Epoch: 12\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 12\tmaintain_Accuracy: 7959/10593 (75%)\n",
      "\n",
      "tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.0\tLoss: 0.076765\n",
      "tensor(0.0493, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.2\tLoss: 0.049291\n",
      "tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.4\tLoss: 0.071751\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.6\tLoss: 0.026340\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.8\tLoss: 0.010686\n",
      "\n",
      "Test Epoch: 13\tAttack_Accuracy: 286/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 13\tmaintain_Accuracy: 8014/10593 (76%)\n",
      "\n",
      "tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.0\tLoss: 0.063841\n",
      "tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.2\tLoss: 0.061202\n",
      "tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.4\tLoss: 0.099049\n",
      "tensor(0.0533, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.6\tLoss: 0.053340\n",
      "tensor(0.0368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.8\tLoss: 0.036829\n",
      "\n",
      "Test Epoch: 14\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 14\tmaintain_Accuracy: 7967/10593 (75%)\n",
      "\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.0\tLoss: 0.014287\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.2\tLoss: 0.051842\n",
      "tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.4\tLoss: 0.089994\n",
      "tensor(0.0750, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.6\tLoss: 0.075038\n",
      "tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.8\tLoss: 0.094266\n",
      "\n",
      "Train Epoch: 15\tAttack_Accuracy: 4546/6400 (71%)\n",
      "\n",
      "\n",
      "Train Epoch: 15\tmaintain_Accuracy: 9599/12800 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 15\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 15\tmaintain_Accuracy: 7997/10593 (75%)\n",
      "\n",
      "tensor(0.0791, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.0\tLoss: 0.079127\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.2\tLoss: 0.021447\n",
      "tensor(0.0725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.4\tLoss: 0.072483\n",
      "tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.6\tLoss: 0.080470\n",
      "tensor(0.0378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.8\tLoss: 0.037785\n",
      "\n",
      "Test Epoch: 16\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 16\tmaintain_Accuracy: 7977/10593 (75%)\n",
      "\n",
      "tensor(0.0717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.0\tLoss: 0.071733\n",
      "tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.2\tLoss: 0.063417\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.4\tLoss: 0.002724\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.6\tLoss: 0.026810\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.8\tLoss: 0.041869\n",
      "\n",
      "Test Epoch: 17\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 17\tmaintain_Accuracy: 7988/10593 (75%)\n",
      "\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.0\tLoss: 0.028668\n",
      "tensor(0.0574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.2\tLoss: 0.057370\n",
      "tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.4\tLoss: 0.066894\n",
      "tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.6\tLoss: 0.057123\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.8\tLoss: 0.039191\n",
      "\n",
      "Test Epoch: 18\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 18\tmaintain_Accuracy: 7945/10593 (75%)\n",
      "\n",
      "tensor(0.0528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.0\tLoss: 0.052772\n",
      "tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.2\tLoss: 0.073496\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.4\tLoss: 0.018452\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.6\tLoss: 0.040649\n",
      "tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.8\tLoss: 0.057957\n",
      "\n",
      "Test Epoch: 19\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 19\tmaintain_Accuracy: 7995/10593 (75%)\n",
      "\n",
      "tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.0\tLoss: 0.057185\n",
      "tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.2\tLoss: 0.057144\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.4\tLoss: 0.050781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.6\tLoss: 0.043126\n",
      "tensor(0.0316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.8\tLoss: 0.031563\n",
      "\n",
      "Train Epoch: 20\tAttack_Accuracy: 4593/6400 (72%)\n",
      "\n",
      "\n",
      "Train Epoch: 20\tmaintain_Accuracy: 9686/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 20\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 20\tmaintain_Accuracy: 8045/10593 (76%)\n",
      "\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.0\tLoss: 0.039823\n",
      "tensor(0.0876, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.2\tLoss: 0.087618\n",
      "tensor(0.0529, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.4\tLoss: 0.052868\n",
      "tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.6\tLoss: 0.058678\n",
      "tensor(0.0331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.8\tLoss: 0.033126\n",
      "\n",
      "Test Epoch: 21\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 21\tmaintain_Accuracy: 8023/10593 (76%)\n",
      "\n",
      "tensor(0.0497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.0\tLoss: 0.049705\n",
      "tensor(0.0892, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.2\tLoss: 0.089158\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.4\tLoss: 0.030010\n",
      "tensor(0.0781, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.6\tLoss: 0.078067\n",
      "tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.8\tLoss: 0.073460\n",
      "\n",
      "Test Epoch: 22\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 22\tmaintain_Accuracy: 8080/10593 (76%)\n",
      "\n",
      "tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.0\tLoss: 0.076591\n",
      "tensor(0.0348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.2\tLoss: 0.034778\n",
      "tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.4\tLoss: 0.112908\n",
      "tensor(0.0344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.6\tLoss: 0.034445\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.8\tLoss: 0.047029\n",
      "\n",
      "Test Epoch: 23\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 23\tmaintain_Accuracy: 8109/10593 (77%)\n",
      "\n",
      "tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.0\tLoss: 0.054611\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.2\tLoss: 0.029066\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.4\tLoss: 0.003848\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.6\tLoss: 0.021627\n",
      "tensor(0.0586, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.8\tLoss: 0.058602\n",
      "\n",
      "Test Epoch: 24\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 24\tmaintain_Accuracy: 8075/10593 (76%)\n",
      "\n",
      "tensor(0.0640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.0\tLoss: 0.063972\n",
      "tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.2\tLoss: -0.001015\n",
      "tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.4\tLoss: 0.063052\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.6\tLoss: 0.017520\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.8\tLoss: 0.027518\n",
      "\n",
      "Train Epoch: 25\tAttack_Accuracy: 4561/6400 (71%)\n",
      "\n",
      "\n",
      "Train Epoch: 25\tmaintain_Accuracy: 9784/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 25\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 25\tmaintain_Accuracy: 7996/10593 (75%)\n",
      "\n",
      "tensor(0.0901, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.0\tLoss: 0.090065\n",
      "tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.2\tLoss: 0.064668\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.4\tLoss: 0.011061\n",
      "tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.6\tLoss: 0.066810\n",
      "tensor(-0.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.8\tLoss: -0.008702\n",
      "\n",
      "Test Epoch: 26\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 26\tmaintain_Accuracy: 8068/10593 (76%)\n",
      "\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.0\tLoss: 0.014774\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.2\tLoss: 0.015988\n",
      "tensor(0.0854, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.4\tLoss: 0.085394\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.6\tLoss: 0.012665\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.8\tLoss: 0.037008\n",
      "\n",
      "Test Epoch: 27\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 27\tmaintain_Accuracy: 7976/10593 (75%)\n",
      "\n",
      "tensor(0.0426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.0\tLoss: 0.042636\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.2\tLoss: 0.020498\n",
      "tensor(0.0573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.4\tLoss: 0.057291\n",
      "tensor(0.0530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.6\tLoss: 0.053005\n",
      "tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.8\tLoss: 0.065279\n",
      "\n",
      "Test Epoch: 28\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 28\tmaintain_Accuracy: 8073/10593 (76%)\n",
      "\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.0\tLoss: 0.022133\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.2\tLoss: 0.022397\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.4\tLoss: 0.009345\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.6\tLoss: 0.043118\n",
      "tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.8\tLoss: 0.078606\n",
      "\n",
      "Test Epoch: 29\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 29\tmaintain_Accuracy: 8099/10593 (76%)\n",
      "\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.0\tLoss: 0.012573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.2\tLoss: 0.029083\n",
      "tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.4\tLoss: 0.059497\n",
      "tensor(0.0649, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.6\tLoss: 0.064937\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.8\tLoss: 0.000628\n",
      "\n",
      "Train Epoch: 30\tAttack_Accuracy: 4554/6400 (71%)\n",
      "\n",
      "\n",
      "Train Epoch: 30\tmaintain_Accuracy: 9728/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 30\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 30\tmaintain_Accuracy: 8125/10593 (77%)\n",
      "\n",
      "tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.0\tLoss: 0.055454\n",
      "tensor(0.0530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.2\tLoss: 0.052979\n",
      "tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.4\tLoss: 0.072436\n",
      "tensor(0.0506, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.6\tLoss: 0.050647\n",
      "tensor(-0.0216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.8\tLoss: -0.021612\n",
      "\n",
      "Test Epoch: 31\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 31\tmaintain_Accuracy: 8061/10593 (76%)\n",
      "\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.0\tLoss: 0.014521\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.2\tLoss: 0.021858\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.4\tLoss: 0.041249\n",
      "tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.6\tLoss: 0.069107\n",
      "tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.8\tLoss: 0.055487\n",
      "\n",
      "Test Epoch: 32\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 32\tmaintain_Accuracy: 8078/10593 (76%)\n",
      "\n",
      "tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.0\tLoss: 0.056743\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.2\tLoss: 0.026740\n",
      "tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.4\tLoss: 0.049110\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.6\tLoss: 0.002658\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.8\tLoss: 0.009782\n",
      "\n",
      "Test Epoch: 33\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 33\tmaintain_Accuracy: 8082/10593 (76%)\n",
      "\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.0\tLoss: 0.024286\n",
      "tensor(0.0472, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.2\tLoss: 0.047242\n",
      "tensor(0.0382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.4\tLoss: 0.038247\n",
      "tensor(-0.0167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.6\tLoss: -0.016734\n",
      "tensor(0.0490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.8\tLoss: 0.049015\n",
      "\n",
      "Test Epoch: 34\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 34\tmaintain_Accuracy: 8089/10593 (76%)\n",
      "\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.0\tLoss: 0.040708\n",
      "tensor(0.0452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.2\tLoss: 0.045175\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.4\tLoss: 0.000988\n",
      "tensor(0.0494, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.6\tLoss: 0.049416\n",
      "tensor(0.0457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.8\tLoss: 0.045732\n",
      "\n",
      "Train Epoch: 35\tAttack_Accuracy: 4656/6400 (73%)\n",
      "\n",
      "\n",
      "Train Epoch: 35\tmaintain_Accuracy: 9741/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 35\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 35\tmaintain_Accuracy: 8038/10593 (76%)\n",
      "\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.0\tLoss: 0.000427\n",
      "tensor(0.0391, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.2\tLoss: 0.039139\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.4\tLoss: 0.011980\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.6\tLoss: 0.043294\n",
      "tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.8\tLoss: 0.069251\n",
      "\n",
      "Test Epoch: 36\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 36\tmaintain_Accuracy: 8071/10593 (76%)\n",
      "\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.0\tLoss: 0.026027\n",
      "tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.2\tLoss: 0.085464\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.4\tLoss: 0.014572\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.6\tLoss: 0.019798\n",
      "tensor(0.0510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.8\tLoss: 0.050993\n",
      "\n",
      "Test Epoch: 37\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 37\tmaintain_Accuracy: 8115/10593 (77%)\n",
      "\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.0\tLoss: 0.051763\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.2\tLoss: 0.012656\n",
      "tensor(0.0345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.4\tLoss: 0.034472\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.6\tLoss: 0.043518\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.8\tLoss: 0.008216\n",
      "\n",
      "Test Epoch: 38\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 38\tmaintain_Accuracy: 8004/10593 (76%)\n",
      "\n",
      "tensor(0.0314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.0\tLoss: 0.031404\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.2\tLoss: 0.019641\n",
      "tensor(0.0438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.4\tLoss: 0.043794\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.6\tLoss: 0.019927\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.8\tLoss: 0.017663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 39\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 39\tmaintain_Accuracy: 8101/10593 (76%)\n",
      "\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.0\tLoss: 0.036657\n",
      "tensor(0.0265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.2\tLoss: 0.026528\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.4\tLoss: 0.027435\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.6\tLoss: 0.030903\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.8\tLoss: 0.020708\n",
      "\n",
      "Train Epoch: 40\tAttack_Accuracy: 4635/6400 (72%)\n",
      "\n",
      "\n",
      "Train Epoch: 40\tmaintain_Accuracy: 9597/12800 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 40\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 40\tmaintain_Accuracy: 8094/10593 (76%)\n",
      "\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.0\tLoss: 0.036704\n",
      "tensor(0.0328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.2\tLoss: 0.032751\n",
      "tensor(0.0426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.4\tLoss: 0.042590\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.6\tLoss: 0.027121\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.8\tLoss: 0.000905\n",
      "\n",
      "Test Epoch: 41\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 41\tmaintain_Accuracy: 8143/10593 (77%)\n",
      "\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.0\tLoss: 0.013347\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.2\tLoss: 0.024614\n",
      "tensor(-0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.4\tLoss: -0.005040\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.6\tLoss: 0.008482\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.8\tLoss: 0.029996\n",
      "\n",
      "Test Epoch: 42\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 42\tmaintain_Accuracy: 8142/10593 (77%)\n",
      "\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.0\tLoss: 0.009829\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.2\tLoss: 0.000233\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.4\tLoss: 0.010290\n",
      "tensor(0.0760, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.6\tLoss: 0.075962\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.8\tLoss: 0.007604\n",
      "\n",
      "Test Epoch: 43\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 43\tmaintain_Accuracy: 8040/10593 (76%)\n",
      "\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.0\tLoss: 0.025830\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.2\tLoss: 0.025286\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.4\tLoss: 0.051186\n",
      "tensor(0.0758, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.6\tLoss: 0.075800\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.8\tLoss: 0.024975\n",
      "\n",
      "Test Epoch: 44\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 44\tmaintain_Accuracy: 8087/10593 (76%)\n",
      "\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.0\tLoss: 0.004889\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.2\tLoss: 0.008888\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.4\tLoss: 0.002954\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.6\tLoss: 0.013959\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.8\tLoss: 0.043141\n",
      "\n",
      "Train Epoch: 45\tAttack_Accuracy: 4692/6400 (73%)\n",
      "\n",
      "\n",
      "Train Epoch: 45\tmaintain_Accuracy: 9686/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 45\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 45\tmaintain_Accuracy: 8072/10593 (76%)\n",
      "\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.0\tLoss: 0.037489\n",
      "tensor(0.0302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.2\tLoss: 0.030186\n",
      "tensor(-0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.4\tLoss: -0.005497\n",
      "tensor(0.0769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.6\tLoss: 0.076865\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.8\tLoss: 0.014847\n",
      "\n",
      "Test Epoch: 46\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 46\tmaintain_Accuracy: 8038/10593 (76%)\n",
      "\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.0\tLoss: 0.023894\n",
      "tensor(0.0316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.2\tLoss: 0.031580\n",
      "tensor(-0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.4\tLoss: -0.008283\n",
      "tensor(-0.0267, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.6\tLoss: -0.026748\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.8\tLoss: 0.028624\n",
      "\n",
      "Test Epoch: 47\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 47\tmaintain_Accuracy: 8108/10593 (77%)\n",
      "\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.0\tLoss: 0.038772\n",
      "tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.2\tLoss: 0.071400\n",
      "tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.4\tLoss: 0.051720\n",
      "tensor(0.0857, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.6\tLoss: 0.085731\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.8\tLoss: 0.041007\n",
      "\n",
      "Test Epoch: 48\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 48\tmaintain_Accuracy: 8135/10593 (77%)\n",
      "\n",
      "tensor(-0.0153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.0\tLoss: -0.015280\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.2\tLoss: 0.014455\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.4\tLoss: 0.016279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.6\tLoss: 0.032522\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.8\tLoss: 0.033799\n",
      "\n",
      "Test Epoch: 49\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 49\tmaintain_Accuracy: 8058/10593 (76%)\n",
      "\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.0\tLoss: 0.003293\n",
      "tensor(-0.0074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.2\tLoss: -0.007447\n",
      "tensor(0.0378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.4\tLoss: 0.037818\n",
      "tensor(0.0808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.6\tLoss: 0.080765\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.8\tLoss: 0.017296\n",
      "\n",
      "Train Epoch: 50\tAttack_Accuracy: 4637/6400 (72%)\n",
      "\n",
      "\n",
      "Train Epoch: 50\tmaintain_Accuracy: 9754/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 50\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 50\tmaintain_Accuracy: 8069/10593 (76%)\n",
      "\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.0\tLoss: 0.011242\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.2\tLoss: 0.020739\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.4\tLoss: 0.005487\n",
      "tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.6\tLoss: 0.051106\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.8\tLoss: 0.040754\n",
      "\n",
      "Test Epoch: 51\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 51\tmaintain_Accuracy: 8076/10593 (76%)\n",
      "\n",
      "tensor(0.0594, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.0\tLoss: 0.059432\n",
      "tensor(-0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.2\tLoss: -0.006568\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.4\tLoss: 0.017743\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.6\tLoss: 0.011740\n",
      "tensor(-0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.8\tLoss: -0.010247\n",
      "\n",
      "Test Epoch: 52\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 52\tmaintain_Accuracy: 8164/10593 (77%)\n",
      "\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.0\tLoss: 0.016104\n",
      "tensor(0.0432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.2\tLoss: 0.043160\n",
      "tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.4\tLoss: 0.053560\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.6\tLoss: 0.021680\n",
      "tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.8\tLoss: 0.090019\n",
      "\n",
      "Test Epoch: 53\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 53\tmaintain_Accuracy: 8084/10593 (76%)\n",
      "\n",
      "tensor(0.0334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.0\tLoss: 0.033407\n",
      "tensor(0.0432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.2\tLoss: 0.043181\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.4\tLoss: 0.025320\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.6\tLoss: 0.014767\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.8\tLoss: 0.004886\n",
      "\n",
      "Test Epoch: 54\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 54\tmaintain_Accuracy: 8046/10593 (76%)\n",
      "\n",
      "tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.0\tLoss: 0.059996\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.2\tLoss: 0.017173\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.4\tLoss: 0.034190\n",
      "tensor(-0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.6\tLoss: -0.013144\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.8\tLoss: 0.003997\n",
      "\n",
      "Train Epoch: 55\tAttack_Accuracy: 4742/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 55\tmaintain_Accuracy: 9693/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 55\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 55\tmaintain_Accuracy: 8041/10593 (76%)\n",
      "\n",
      "tensor(0.0386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.0\tLoss: 0.038571\n",
      "tensor(0.0344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.2\tLoss: 0.034389\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.4\tLoss: 0.024400\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.6\tLoss: 0.030487\n",
      "tensor(-0.0130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.8\tLoss: -0.012964\n",
      "\n",
      "Test Epoch: 56\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 56\tmaintain_Accuracy: 8151/10593 (77%)\n",
      "\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.0\tLoss: 0.017591\n",
      "tensor(0.0358, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.2\tLoss: 0.035810\n",
      "tensor(-0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.4\tLoss: -0.002710\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.6\tLoss: 0.010732\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.8\tLoss: 0.019338\n",
      "\n",
      "Test Epoch: 57\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 57\tmaintain_Accuracy: 8082/10593 (76%)\n",
      "\n",
      "tensor(0.0556, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.0\tLoss: 0.055615\n",
      "tensor(-0.0211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.2\tLoss: -0.021102\n",
      "tensor(-0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.4\tLoss: -0.005851\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.6\tLoss: 0.002855\n",
      "tensor(0.0450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.8\tLoss: 0.044991\n",
      "\n",
      "Test Epoch: 58\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 58\tmaintain_Accuracy: 8117/10593 (77%)\n",
      "\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.0\tLoss: 0.000530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.2\tLoss: 0.022383\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.4\tLoss: 0.007979\n",
      "tensor(-0.0375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.6\tLoss: -0.037453\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.8\tLoss: 0.023317\n",
      "\n",
      "Test Epoch: 59\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 59\tmaintain_Accuracy: 8073/10593 (76%)\n",
      "\n",
      "tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.0\tLoss: 0.053560\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.2\tLoss: 0.005813\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.4\tLoss: 0.031787\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.6\tLoss: 0.017762\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.8\tLoss: 0.023198\n",
      "\n",
      "Train Epoch: 60\tAttack_Accuracy: 4726/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 60\tmaintain_Accuracy: 9735/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 60\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 60\tmaintain_Accuracy: 8117/10593 (77%)\n",
      "\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.0\tLoss: 0.023011\n",
      "tensor(0.0312, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.2\tLoss: 0.031197\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.4\tLoss: 0.038542\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.6\tLoss: 0.020812\n",
      "tensor(-0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.8\tLoss: -0.012126\n",
      "\n",
      "Test Epoch: 61\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 61\tmaintain_Accuracy: 8123/10593 (77%)\n",
      "\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.0\tLoss: 0.015001\n",
      "tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.2\tLoss: 0.051628\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.4\tLoss: 0.019335\n",
      "tensor(-0.0077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.6\tLoss: -0.007712\n",
      "tensor(0.0222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.8\tLoss: 0.022154\n",
      "\n",
      "Test Epoch: 62\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 62\tmaintain_Accuracy: 8113/10593 (77%)\n",
      "\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.0\tLoss: 0.014286\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.2\tLoss: 0.027436\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.4\tLoss: 0.005502\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.6\tLoss: 0.024454\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.8\tLoss: 0.002859\n",
      "\n",
      "Test Epoch: 63\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 63\tmaintain_Accuracy: 8176/10593 (77%)\n",
      "\n",
      "tensor(-0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.0\tLoss: -0.003895\n",
      "tensor(-0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.2\tLoss: -0.011871\n",
      "tensor(0.0439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.4\tLoss: 0.043882\n",
      "tensor(0.0548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.6\tLoss: 0.054803\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.8\tLoss: 0.055821\n",
      "\n",
      "Test Epoch: 64\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 64\tmaintain_Accuracy: 8132/10593 (77%)\n",
      "\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.0\tLoss: 0.023502\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.2\tLoss: 0.038301\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.4\tLoss: 0.017052\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.6\tLoss: 0.022255\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.8\tLoss: 0.004376\n",
      "\n",
      "Train Epoch: 65\tAttack_Accuracy: 4729/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 65\tmaintain_Accuracy: 9707/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 65\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 65\tmaintain_Accuracy: 8087/10593 (76%)\n",
      "\n",
      "tensor(-0.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.0\tLoss: -0.011678\n",
      "tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.2\tLoss: -0.001034\n",
      "tensor(0.0254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.4\tLoss: 0.025424\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.6\tLoss: 0.017861\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.8\tLoss: 0.015105\n",
      "\n",
      "Test Epoch: 66\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 66\tmaintain_Accuracy: 8138/10593 (77%)\n",
      "\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.0\tLoss: 0.046296\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.2\tLoss: 0.046335\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.4\tLoss: 0.018192\n",
      "tensor(0.0330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.6\tLoss: 0.033042\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.8\tLoss: 0.015401\n",
      "\n",
      "Test Epoch: 67\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 67\tmaintain_Accuracy: 8171/10593 (77%)\n",
      "\n",
      "tensor(0.0312, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.0\tLoss: 0.031181\n",
      "tensor(-0.0207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.2\tLoss: -0.020687\n",
      "tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.4\tLoss: 0.051137\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.6\tLoss: 0.017413\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.8\tLoss: 0.011024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 68\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 68\tmaintain_Accuracy: 8163/10593 (77%)\n",
      "\n",
      "tensor(0.0950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.0\tLoss: 0.094965\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.2\tLoss: 0.032734\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.4\tLoss: 0.009970\n",
      "tensor(0.0325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.6\tLoss: 0.032534\n",
      "tensor(-0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.8\tLoss: -0.008977\n",
      "\n",
      "Test Epoch: 69\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 69\tmaintain_Accuracy: 8076/10593 (76%)\n",
      "\n",
      "tensor(0.0465, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.0\tLoss: 0.046542\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.2\tLoss: 0.040387\n",
      "tensor(0.0384, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.4\tLoss: 0.038432\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.6\tLoss: 0.038268\n",
      "tensor(-0.0016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.8\tLoss: -0.001624\n",
      "\n",
      "Train Epoch: 70\tAttack_Accuracy: 4716/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 70\tmaintain_Accuracy: 9694/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 70\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 70\tmaintain_Accuracy: 8125/10593 (77%)\n",
      "\n",
      "tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.0\tLoss: 0.051585\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.2\tLoss: 0.008901\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.4\tLoss: 0.003733\n",
      "tensor(-0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.6\tLoss: -0.010296\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.8\tLoss: 0.011906\n",
      "\n",
      "Test Epoch: 71\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 71\tmaintain_Accuracy: 8156/10593 (77%)\n",
      "\n",
      "tensor(-0.0380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.0\tLoss: -0.038048\n",
      "tensor(0.0466, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.2\tLoss: 0.046618\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.4\tLoss: 0.002791\n",
      "tensor(0.0455, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.6\tLoss: 0.045456\n",
      "tensor(0.0481, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.8\tLoss: 0.048074\n",
      "\n",
      "Test Epoch: 72\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 72\tmaintain_Accuracy: 8143/10593 (77%)\n",
      "\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.0\tLoss: 0.036578\n",
      "tensor(-0.0022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.2\tLoss: -0.002159\n",
      "tensor(-0.0342, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.4\tLoss: -0.034153\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.6\tLoss: 0.015481\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.8\tLoss: 0.042152\n",
      "\n",
      "Test Epoch: 73\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 73\tmaintain_Accuracy: 8110/10593 (77%)\n",
      "\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.0\tLoss: 0.007799\n",
      "tensor(0.0344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.2\tLoss: 0.034427\n",
      "tensor(0.0340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.4\tLoss: 0.034021\n",
      "tensor(-0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.6\tLoss: -0.005148\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.8\tLoss: 0.017035\n",
      "\n",
      "Test Epoch: 74\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 74\tmaintain_Accuracy: 8056/10593 (76%)\n",
      "\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.0\tLoss: 0.036637\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.2\tLoss: 0.014320\n",
      "tensor(-0.0244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.4\tLoss: -0.024377\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.6\tLoss: 0.005376\n",
      "tensor(0.0426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.8\tLoss: 0.042647\n",
      "\n",
      "Train Epoch: 75\tAttack_Accuracy: 4788/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 75\tmaintain_Accuracy: 9654/12800 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 75\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 75\tmaintain_Accuracy: 8174/10593 (77%)\n",
      "\n",
      "tensor(0.0386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.0\tLoss: 0.038564\n",
      "tensor(-0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.2\tLoss: -0.003683\n",
      "tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.4\tLoss: 0.061387\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.6\tLoss: 0.015624\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.8\tLoss: 0.000540\n",
      "\n",
      "Test Epoch: 76\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 76\tmaintain_Accuracy: 8157/10593 (77%)\n",
      "\n",
      "tensor(0.0353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.0\tLoss: 0.035335\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.2\tLoss: 0.001543\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.4\tLoss: 0.024672\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.6\tLoss: 0.003877\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.8\tLoss: 0.013188\n",
      "\n",
      "Test Epoch: 77\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 77\tmaintain_Accuracy: 8174/10593 (77%)\n",
      "\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.0\tLoss: 0.045761\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.2\tLoss: 0.014020\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.4\tLoss: 0.005276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.6\tLoss: 0.003259\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.8\tLoss: 0.006614\n",
      "\n",
      "Test Epoch: 78\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 78\tmaintain_Accuracy: 8100/10593 (76%)\n",
      "\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.0\tLoss: 0.005876\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.2\tLoss: 0.016727\n",
      "tensor(-0.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.4\tLoss: -0.000642\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.6\tLoss: 0.048802\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.8\tLoss: 0.012181\n",
      "\n",
      "Test Epoch: 79\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 79\tmaintain_Accuracy: 8033/10593 (76%)\n",
      "\n",
      "tensor(0.0348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.0\tLoss: 0.034761\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.2\tLoss: 0.030096\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.4\tLoss: 0.005070\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.6\tLoss: 0.011832\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.8\tLoss: 0.008935\n",
      "\n",
      "Train Epoch: 80\tAttack_Accuracy: 4672/6400 (73%)\n",
      "\n",
      "\n",
      "Train Epoch: 80\tmaintain_Accuracy: 9717/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 80\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 80\tmaintain_Accuracy: 8159/10593 (77%)\n",
      "\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.0\tLoss: 0.036130\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.2\tLoss: 0.038095\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.4\tLoss: 0.001990\n",
      "tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.6\tLoss: 0.052111\n",
      "tensor(-0.0135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.8\tLoss: -0.013521\n",
      "\n",
      "Test Epoch: 81\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 81\tmaintain_Accuracy: 8149/10593 (77%)\n",
      "\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.0\tLoss: 0.034602\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.2\tLoss: 0.030106\n",
      "tensor(-0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.4\tLoss: -0.007789\n",
      "tensor(-0.0036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.6\tLoss: -0.003637\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.8\tLoss: 0.010068\n",
      "\n",
      "Test Epoch: 82\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 82\tmaintain_Accuracy: 8090/10593 (76%)\n",
      "\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.0\tLoss: 0.041117\n",
      "tensor(0.0197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.2\tLoss: 0.019709\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.4\tLoss: 0.033166\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.6\tLoss: 0.019272\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.8\tLoss: 0.023498\n",
      "\n",
      "Test Epoch: 83\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 83\tmaintain_Accuracy: 8163/10593 (77%)\n",
      "\n",
      "tensor(-0.0022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.0\tLoss: -0.002212\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.2\tLoss: 0.000771\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.4\tLoss: 0.019928\n",
      "tensor(-0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.6\tLoss: -0.001467\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.8\tLoss: 0.023237\n",
      "\n",
      "Test Epoch: 84\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 84\tmaintain_Accuracy: 8183/10593 (77%)\n",
      "\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.0\tLoss: 0.006143\n",
      "tensor(-0.0198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.2\tLoss: -0.019781\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.4\tLoss: 0.040451\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.6\tLoss: 0.015112\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.8\tLoss: 0.037965\n",
      "\n",
      "Train Epoch: 85\tAttack_Accuracy: 4766/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 85\tmaintain_Accuracy: 9785/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 85\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 85\tmaintain_Accuracy: 8058/10593 (76%)\n",
      "\n",
      "tensor(-0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.0\tLoss: -0.014817\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.2\tLoss: 0.035538\n",
      "tensor(-0.0396, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.4\tLoss: -0.039603\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.6\tLoss: 0.008669\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.8\tLoss: 0.008352\n",
      "\n",
      "Test Epoch: 86\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 86\tmaintain_Accuracy: 8134/10593 (77%)\n",
      "\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.0\tLoss: 0.023341\n",
      "tensor(-0.0101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.2\tLoss: -0.010126\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.4\tLoss: 0.006609\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.6\tLoss: 0.008210\n",
      "tensor(0.0556, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.8\tLoss: 0.055601\n",
      "\n",
      "Test Epoch: 87\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 87\tmaintain_Accuracy: 8170/10593 (77%)\n",
      "\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.0\tLoss: 0.016002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.2\tLoss: 0.018421\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.4\tLoss: 0.023715\n",
      "tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.6\tLoss: 0.057984\n",
      "tensor(0.0423, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.8\tLoss: 0.042348\n",
      "\n",
      "Test Epoch: 88\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 88\tmaintain_Accuracy: 8167/10593 (77%)\n",
      "\n",
      "tensor(-0.0277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.0\tLoss: -0.027737\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.2\tLoss: 0.018031\n",
      "tensor(0.0535, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.4\tLoss: 0.053505\n",
      "tensor(0.0265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.6\tLoss: 0.026499\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.8\tLoss: 0.023622\n",
      "\n",
      "Test Epoch: 89\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 89\tmaintain_Accuracy: 8110/10593 (77%)\n",
      "\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.0\tLoss: 0.010321\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.2\tLoss: 0.015983\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.4\tLoss: 0.023632\n",
      "tensor(-0.0012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.6\tLoss: -0.001188\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.8\tLoss: 0.031799\n",
      "\n",
      "Train Epoch: 90\tAttack_Accuracy: 4759/6400 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 90\tmaintain_Accuracy: 9776/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 90\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 90\tmaintain_Accuracy: 8082/10593 (76%)\n",
      "\n",
      "tensor(0.0348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.0\tLoss: 0.034848\n",
      "tensor(-0.0012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.2\tLoss: -0.001165\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.4\tLoss: 0.002773\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.6\tLoss: 0.042152\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.8\tLoss: 0.015337\n",
      "\n",
      "Test Epoch: 91\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 91\tmaintain_Accuracy: 8147/10593 (77%)\n",
      "\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.0\tLoss: 0.000640\n",
      "tensor(-0.0232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.2\tLoss: -0.023205\n",
      "tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.4\tLoss: 0.061215\n",
      "tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.6\tLoss: 0.053384\n",
      "tensor(-0.0281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.8\tLoss: -0.028069\n",
      "\n",
      "Test Epoch: 92\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 92\tmaintain_Accuracy: 8131/10593 (77%)\n",
      "\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.0\tLoss: 0.020185\n",
      "tensor(-0.0197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.2\tLoss: -0.019657\n",
      "tensor(0.0344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.4\tLoss: 0.034398\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.6\tLoss: 0.010439\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.8\tLoss: 0.019787\n",
      "\n",
      "Test Epoch: 93\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 93\tmaintain_Accuracy: 8149/10593 (77%)\n",
      "\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.0\tLoss: 0.031054\n",
      "tensor(0.0447, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.2\tLoss: 0.044718\n",
      "tensor(0.0316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.4\tLoss: 0.031618\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.6\tLoss: 0.025582\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.8\tLoss: 0.013948\n",
      "\n",
      "Test Epoch: 94\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 94\tmaintain_Accuracy: 8207/10593 (77%)\n",
      "\n",
      "tensor(-0.0243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.0\tLoss: -0.024341\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.2\tLoss: 0.018680\n",
      "tensor(-0.0110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.4\tLoss: -0.011026\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.6\tLoss: 0.018153\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.8\tLoss: 0.004182\n",
      "\n",
      "Train Epoch: 95\tAttack_Accuracy: 4814/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 95\tmaintain_Accuracy: 9753/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 95\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 95\tmaintain_Accuracy: 8119/10593 (77%)\n",
      "\n",
      "tensor(0.0445, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.0\tLoss: 0.044532\n",
      "tensor(-0.0332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.2\tLoss: -0.033167\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.4\tLoss: 0.019549\n",
      "tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.6\tLoss: -0.000924\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.8\tLoss: 0.040319\n",
      "\n",
      "Test Epoch: 96\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 96\tmaintain_Accuracy: 8123/10593 (77%)\n",
      "\n",
      "tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.0\tLoss: -0.000897\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.2\tLoss: 0.006634\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.4\tLoss: 0.002813\n",
      "tensor(-0.0068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.6\tLoss: -0.006806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.8\tLoss: -0.011368\n",
      "\n",
      "Test Epoch: 97\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 97\tmaintain_Accuracy: 8117/10593 (77%)\n",
      "\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.0\tLoss: 0.043083\n",
      "tensor(-0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.2\tLoss: -0.008995\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.4\tLoss: 0.016112\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.6\tLoss: 0.016640\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.8\tLoss: 0.000234\n",
      "\n",
      "Test Epoch: 98\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 98\tmaintain_Accuracy: 8115/10593 (77%)\n",
      "\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.0\tLoss: 0.038752\n",
      "tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.2\tLoss: 0.051379\n",
      "tensor(-0.0181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.4\tLoss: -0.018105\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.6\tLoss: 0.004734\n",
      "tensor(0.0334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.8\tLoss: 0.033382\n",
      "\n",
      "Test Epoch: 99\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 99\tmaintain_Accuracy: 8129/10593 (77%)\n",
      "\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.0\tLoss: 0.007633\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.2\tLoss: 0.032396\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.4\tLoss: 0.018601\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.6\tLoss: 0.019302\n",
      "tensor(-0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.8\tLoss: -0.005203\n",
      "\n",
      "Train Epoch: 100\tAttack_Accuracy: 4855/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 100\tmaintain_Accuracy: 9726/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 100\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 100\tmaintain_Accuracy: 8042/10593 (76%)\n",
      "\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.0\tLoss: 0.002351\n",
      "tensor(0.0321, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.2\tLoss: 0.032117\n",
      "tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.4\tLoss: 0.058181\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.6\tLoss: 0.048915\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.8\tLoss: 0.028345\n",
      "\n",
      "Test Epoch: 101\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 101\tmaintain_Accuracy: 8141/10593 (77%)\n",
      "\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.0\tLoss: 0.042183\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.2\tLoss: 0.001714\n",
      "tensor(-0.0001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.4\tLoss: -0.000144\n",
      "tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.6\tLoss: -0.000902\n",
      "tensor(-0.0444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.8\tLoss: -0.044360\n",
      "\n",
      "Test Epoch: 102\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 102\tmaintain_Accuracy: 8202/10593 (77%)\n",
      "\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.0\tLoss: 0.006008\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.2\tLoss: 0.008563\n",
      "tensor(-0.0061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.4\tLoss: -0.006086\n",
      "tensor(0.0561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.6\tLoss: 0.056093\n",
      "tensor(-0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.8\tLoss: -0.000801\n",
      "\n",
      "Test Epoch: 103\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 103\tmaintain_Accuracy: 8152/10593 (77%)\n",
      "\n",
      "tensor(-0.0076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.0\tLoss: -0.007578\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.2\tLoss: 0.030358\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.4\tLoss: 0.006871\n",
      "tensor(-0.0097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.6\tLoss: -0.009657\n",
      "tensor(-0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.8\tLoss: -0.012759\n",
      "\n",
      "Test Epoch: 104\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 104\tmaintain_Accuracy: 8172/10593 (77%)\n",
      "\n",
      "tensor(0.0397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.0\tLoss: 0.039730\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.2\tLoss: 0.010345\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.4\tLoss: 0.013915\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.6\tLoss: 0.023190\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.8\tLoss: 0.030932\n",
      "\n",
      "Train Epoch: 105\tAttack_Accuracy: 4862/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 105\tmaintain_Accuracy: 9773/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 105\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 105\tmaintain_Accuracy: 8178/10593 (77%)\n",
      "\n",
      "tensor(0.0682, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.0\tLoss: 0.068227\n",
      "tensor(-0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.2\tLoss: -0.006379\n",
      "tensor(-0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.4\tLoss: -0.009627\n",
      "tensor(-0.0442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.6\tLoss: -0.044152\n",
      "tensor(-0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.8\tLoss: -0.017080\n",
      "\n",
      "Test Epoch: 106\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 106\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.0\tLoss: 0.030344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.2\tLoss: 0.017093\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.4\tLoss: 0.010304\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.6\tLoss: 0.040930\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.8\tLoss: 0.014041\n",
      "\n",
      "Test Epoch: 107\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 107\tmaintain_Accuracy: 8168/10593 (77%)\n",
      "\n",
      "tensor(-0.0430, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.0\tLoss: -0.043017\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.2\tLoss: 0.017108\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.4\tLoss: 0.000468\n",
      "tensor(0.0427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.6\tLoss: 0.042690\n",
      "tensor(-0.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.8\tLoss: -0.008049\n",
      "\n",
      "Test Epoch: 108\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 108\tmaintain_Accuracy: 8201/10593 (77%)\n",
      "\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.0\tLoss: 0.006034\n",
      "tensor(-0.0165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.2\tLoss: -0.016527\n",
      "tensor(-0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.4\tLoss: -0.001266\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.6\tLoss: 0.006594\n",
      "tensor(-0.0251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.8\tLoss: -0.025129\n",
      "\n",
      "Test Epoch: 109\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 109\tmaintain_Accuracy: 8210/10593 (78%)\n",
      "\n",
      "tensor(-0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.0\tLoss: -0.009790\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.2\tLoss: 0.022862\n",
      "tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.4\tLoss: 0.064567\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.6\tLoss: 0.008560\n",
      "tensor(-0.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.8\tLoss: -0.003849\n",
      "\n",
      "Train Epoch: 110\tAttack_Accuracy: 4808/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 110\tmaintain_Accuracy: 9894/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 110\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 110\tmaintain_Accuracy: 8216/10593 (78%)\n",
      "\n",
      "tensor(-0.0092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.0\tLoss: -0.009175\n",
      "tensor(0.0307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.2\tLoss: 0.030661\n",
      "tensor(0.0331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.4\tLoss: 0.033072\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.6\tLoss: 0.021415\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.8\tLoss: 0.043740\n",
      "\n",
      "Test Epoch: 111\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 111\tmaintain_Accuracy: 8219/10593 (78%)\n",
      "\n",
      "tensor(-0.0149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.0\tLoss: -0.014940\n",
      "tensor(-0.0071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.2\tLoss: -0.007095\n",
      "tensor(-0.0417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.4\tLoss: -0.041692\n",
      "tensor(-0.0127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.6\tLoss: -0.012666\n",
      "tensor(-0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.8\tLoss: -0.005543\n",
      "\n",
      "Test Epoch: 112\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 112\tmaintain_Accuracy: 8234/10593 (78%)\n",
      "\n",
      "tensor(-0.0265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.0\tLoss: -0.026541\n",
      "tensor(-0.0238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.2\tLoss: -0.023802\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.4\tLoss: 0.017702\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.6\tLoss: 0.022595\n",
      "tensor(0.0328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.8\tLoss: 0.032828\n",
      "\n",
      "Test Epoch: 113\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 113\tmaintain_Accuracy: 8223/10593 (78%)\n",
      "\n",
      "tensor(0.0285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.0\tLoss: 0.028500\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.2\tLoss: 0.007700\n",
      "tensor(-0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.4\tLoss: -0.000685\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.6\tLoss: 0.010550\n",
      "tensor(-0.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.8\tLoss: -0.021030\n",
      "\n",
      "Test Epoch: 114\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 114\tmaintain_Accuracy: 8185/10593 (77%)\n",
      "\n",
      "tensor(-0.0111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.0\tLoss: -0.011146\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.2\tLoss: 0.009915\n",
      "tensor(-0.0307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.4\tLoss: -0.030674\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.6\tLoss: 0.028016\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.8\tLoss: 0.032414\n",
      "\n",
      "Train Epoch: 115\tAttack_Accuracy: 4841/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 115\tmaintain_Accuracy: 9867/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 115\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 115\tmaintain_Accuracy: 8209/10593 (77%)\n",
      "\n",
      "tensor(-0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.0\tLoss: -0.017051\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.2\tLoss: 0.021107\n",
      "tensor(0.0264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.4\tLoss: 0.026362\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.6\tLoss: 0.010808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.8\tLoss: 0.042167\n",
      "\n",
      "Test Epoch: 116\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 116\tmaintain_Accuracy: 8210/10593 (78%)\n",
      "\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.0\tLoss: 0.031013\n",
      "tensor(-0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.2\tLoss: -0.001453\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.4\tLoss: 0.042140\n",
      "tensor(-0.0016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.6\tLoss: -0.001613\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.8\tLoss: 0.013357\n",
      "\n",
      "Test Epoch: 117\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 117\tmaintain_Accuracy: 8227/10593 (78%)\n",
      "\n",
      "tensor(-0.0336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.0\tLoss: -0.033572\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.2\tLoss: 0.018017\n",
      "tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.4\tLoss: 0.053588\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.6\tLoss: 0.015572\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.8\tLoss: 0.006675\n",
      "\n",
      "Test Epoch: 118\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 118\tmaintain_Accuracy: 8230/10593 (78%)\n",
      "\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.0\tLoss: 0.022624\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.2\tLoss: 0.018165\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.4\tLoss: 0.018006\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.6\tLoss: 0.012045\n",
      "tensor(-0.0195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.8\tLoss: -0.019514\n",
      "\n",
      "Test Epoch: 119\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 119\tmaintain_Accuracy: 8189/10593 (77%)\n",
      "\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.0\tLoss: 0.024659\n",
      "tensor(-0.0160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.2\tLoss: -0.015985\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.4\tLoss: 0.032429\n",
      "tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.6\tLoss: -0.007026\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.8\tLoss: 0.009106\n",
      "\n",
      "Train Epoch: 120\tAttack_Accuracy: 4809/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 120\tmaintain_Accuracy: 9795/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 120\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 120\tmaintain_Accuracy: 8203/10593 (77%)\n",
      "\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.0\tLoss: 0.020714\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.2\tLoss: 0.012116\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.4\tLoss: 0.031150\n",
      "tensor(-0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.6\tLoss: -0.021480\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.8\tLoss: 0.022413\n",
      "\n",
      "Test Epoch: 121\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 121\tmaintain_Accuracy: 8226/10593 (78%)\n",
      "\n",
      "tensor(-0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.0\tLoss: -0.008320\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.2\tLoss: 0.000250\n",
      "tensor(-0.0126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.4\tLoss: -0.012605\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.6\tLoss: 0.003357\n",
      "tensor(-0.0150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.8\tLoss: -0.014976\n",
      "\n",
      "Test Epoch: 122\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 122\tmaintain_Accuracy: 8237/10593 (78%)\n",
      "\n",
      "tensor(-0.0135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.0\tLoss: -0.013539\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.2\tLoss: 0.029427\n",
      "tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.4\tLoss: 0.057452\n",
      "tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.6\tLoss: 0.058683\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.8\tLoss: 0.003074\n",
      "\n",
      "Test Epoch: 123\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 123\tmaintain_Accuracy: 8238/10593 (78%)\n",
      "\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.0\tLoss: 0.005169\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.2\tLoss: 0.007048\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.4\tLoss: 0.006707\n",
      "tensor(0.0257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.6\tLoss: 0.025726\n",
      "tensor(-0.0190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.8\tLoss: -0.018982\n",
      "\n",
      "Test Epoch: 124\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 124\tmaintain_Accuracy: 8227/10593 (78%)\n",
      "\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.0\tLoss: 0.022281\n",
      "tensor(-0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.2\tLoss: -0.002412\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.4\tLoss: 0.032277\n",
      "tensor(-0.0369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.6\tLoss: -0.036884\n",
      "tensor(-0.0012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.8\tLoss: -0.001166\n",
      "\n",
      "Train Epoch: 125\tAttack_Accuracy: 4839/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 125\tmaintain_Accuracy: 9817/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 125\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 125\tmaintain_Accuracy: 8226/10593 (78%)\n",
      "\n",
      "tensor(-0.0113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.0\tLoss: -0.011272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.2\tLoss: 0.039918\n",
      "tensor(0.0560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.4\tLoss: 0.056019\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.6\tLoss: 0.017551\n",
      "tensor(-0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.8\tLoss: -0.008491\n",
      "\n",
      "Test Epoch: 126\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 126\tmaintain_Accuracy: 8192/10593 (77%)\n",
      "\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.0\tLoss: 0.011979\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.2\tLoss: 0.007014\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.4\tLoss: 0.000443\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.6\tLoss: 0.000207\n",
      "tensor(-0.0302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.8\tLoss: -0.030152\n",
      "\n",
      "Test Epoch: 127\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 127\tmaintain_Accuracy: 8222/10593 (78%)\n",
      "\n",
      "tensor(-0.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.0\tLoss: -0.008691\n",
      "tensor(0.0365, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.2\tLoss: 0.036457\n",
      "tensor(-0.0172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.4\tLoss: -0.017241\n",
      "tensor(-0.0043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.6\tLoss: -0.004327\n",
      "tensor(-0.0045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.8\tLoss: -0.004451\n",
      "\n",
      "Test Epoch: 128\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 128\tmaintain_Accuracy: 8226/10593 (78%)\n",
      "\n",
      "tensor(-0.0146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.0\tLoss: -0.014551\n",
      "tensor(0.0466, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.2\tLoss: 0.046558\n",
      "tensor(0.0302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.4\tLoss: 0.030185\n",
      "tensor(0.0441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.6\tLoss: 0.044063\n",
      "tensor(0.0535, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.8\tLoss: 0.053517\n",
      "\n",
      "Test Epoch: 129\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 129\tmaintain_Accuracy: 8218/10593 (78%)\n",
      "\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.0\tLoss: 0.028052\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.2\tLoss: 0.007581\n",
      "tensor(-0.0040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.4\tLoss: -0.003996\n",
      "tensor(-0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.6\tLoss: -0.021474\n",
      "tensor(-0.0362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.8\tLoss: -0.036157\n",
      "\n",
      "Train Epoch: 130\tAttack_Accuracy: 4893/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 130\tmaintain_Accuracy: 9854/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 130\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 130\tmaintain_Accuracy: 8214/10593 (78%)\n",
      "\n",
      "tensor(-0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.0\tLoss: -0.008916\n",
      "tensor(-0.0132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.2\tLoss: -0.013214\n",
      "tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.4\tLoss: 0.059495\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.6\tLoss: 0.030543\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.8\tLoss: 0.009751\n",
      "\n",
      "Test Epoch: 131\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 131\tmaintain_Accuracy: 8234/10593 (78%)\n",
      "\n",
      "tensor(0.0368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.0\tLoss: 0.036846\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.2\tLoss: 0.001920\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.4\tLoss: 0.002005\n",
      "tensor(0.0460, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.6\tLoss: 0.045950\n",
      "tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.8\tLoss: 0.068641\n",
      "\n",
      "Test Epoch: 132\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 132\tmaintain_Accuracy: 8237/10593 (78%)\n",
      "\n",
      "tensor(0.0373, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.0\tLoss: 0.037253\n",
      "tensor(-0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.2\tLoss: -0.008601\n",
      "tensor(0.0282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.4\tLoss: 0.028227\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.6\tLoss: 0.017716\n",
      "tensor(-0.0222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.8\tLoss: -0.022202\n",
      "\n",
      "Test Epoch: 133\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 133\tmaintain_Accuracy: 8233/10593 (78%)\n",
      "\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.0\tLoss: 0.022315\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.2\tLoss: 0.021583\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.4\tLoss: 0.003216\n",
      "tensor(-0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.6\tLoss: -0.019330\n",
      "tensor(-0.0088, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.8\tLoss: -0.008772\n",
      "\n",
      "Test Epoch: 134\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 134\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.0\tLoss: 0.012524\n",
      "tensor(0.0255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.2\tLoss: 0.025542\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.4\tLoss: 0.019225\n",
      "tensor(-0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.6\tLoss: -0.006431\n",
      "tensor(-0.0122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.8\tLoss: -0.012241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 135\tAttack_Accuracy: 4818/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 135\tmaintain_Accuracy: 9827/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 135\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 135\tmaintain_Accuracy: 8231/10593 (78%)\n",
      "\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.0\tLoss: 0.017966\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.2\tLoss: 0.002633\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.4\tLoss: 0.013812\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.6\tLoss: 0.021540\n",
      "tensor(-0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.8\tLoss: -0.003550\n",
      "\n",
      "Test Epoch: 136\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 136\tmaintain_Accuracy: 8233/10593 (78%)\n",
      "\n",
      "tensor(-0.0057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.0\tLoss: -0.005709\n",
      "tensor(-0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.2\tLoss: -0.029239\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.4\tLoss: 0.027544\n",
      "tensor(-0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.6\tLoss: -0.019282\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.8\tLoss: 0.007101\n",
      "\n",
      "Test Epoch: 137\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 137\tmaintain_Accuracy: 8229/10593 (78%)\n",
      "\n",
      "tensor(-0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.0\tLoss: -0.004940\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.2\tLoss: 0.041652\n",
      "tensor(-0.0168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.4\tLoss: -0.016750\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.6\tLoss: 0.017293\n",
      "tensor(-0.0275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.8\tLoss: -0.027544\n",
      "\n",
      "Test Epoch: 138\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 138\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.0\tLoss: -0.003818\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.2\tLoss: 0.018898\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.4\tLoss: 0.011542\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.6\tLoss: 0.039877\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.8\tLoss: 0.004733\n",
      "\n",
      "Test Epoch: 139\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 139\tmaintain_Accuracy: 8218/10593 (78%)\n",
      "\n",
      "tensor(-0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.0\tLoss: -0.016431\n",
      "tensor(-0.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.2\tLoss: -0.009452\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.4\tLoss: 0.015999\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.6\tLoss: 0.030428\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.8\tLoss: 0.012525\n",
      "\n",
      "Train Epoch: 140\tAttack_Accuracy: 4861/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 140\tmaintain_Accuracy: 9884/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 140\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 140\tmaintain_Accuracy: 8207/10593 (77%)\n",
      "\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.0\tLoss: 0.029163\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.2\tLoss: 0.016152\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.4\tLoss: 0.061331\n",
      "tensor(-0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.6\tLoss: -0.011475\n",
      "tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.8\tLoss: 0.049782\n",
      "\n",
      "Test Epoch: 141\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 141\tmaintain_Accuracy: 8232/10593 (78%)\n",
      "\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.0\tLoss: 0.029095\n",
      "tensor(-0.0094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.2\tLoss: -0.009435\n",
      "tensor(-0.0383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.4\tLoss: -0.038290\n",
      "tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.6\tLoss: 0.059557\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.8\tLoss: 0.012060\n",
      "\n",
      "Test Epoch: 142\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 142\tmaintain_Accuracy: 8220/10593 (78%)\n",
      "\n",
      "tensor(0.0314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.0\tLoss: 0.031394\n",
      "tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.2\tLoss: -0.000882\n",
      "tensor(-0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.4\tLoss: -0.008322\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.6\tLoss: 0.003355\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.8\tLoss: 0.011170\n",
      "\n",
      "Test Epoch: 143\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 143\tmaintain_Accuracy: 8226/10593 (78%)\n",
      "\n",
      "tensor(-0.0184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.0\tLoss: -0.018405\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.2\tLoss: 0.023010\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.4\tLoss: 0.006646\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.6\tLoss: 0.012907\n",
      "tensor(-0.0075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.8\tLoss: -0.007471\n",
      "\n",
      "Test Epoch: 144\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 144\tmaintain_Accuracy: 8228/10593 (78%)\n",
      "\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.0\tLoss: 0.002644\n",
      "tensor(-0.0188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.2\tLoss: -0.018836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.4\tLoss: 0.016781\n",
      "tensor(0.0365, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.6\tLoss: 0.036550\n",
      "tensor(0.0347, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.8\tLoss: 0.034728\n",
      "\n",
      "Train Epoch: 145\tAttack_Accuracy: 4871/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 145\tmaintain_Accuracy: 9945/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 145\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 145\tmaintain_Accuracy: 8208/10593 (77%)\n",
      "\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.0\tLoss: 0.010659\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.2\tLoss: 0.014939\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.4\tLoss: 0.002847\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.6\tLoss: 0.001482\n",
      "tensor(-0.0197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.8\tLoss: -0.019680\n",
      "\n",
      "Test Epoch: 146\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 146\tmaintain_Accuracy: 8213/10593 (78%)\n",
      "\n",
      "tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.0\tLoss: 0.061572\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.2\tLoss: 0.014094\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.4\tLoss: 0.007509\n",
      "tensor(-0.0106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.6\tLoss: -0.010627\n",
      "tensor(-0.0111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.8\tLoss: -0.011099\n",
      "\n",
      "Test Epoch: 147\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 147\tmaintain_Accuracy: 8212/10593 (78%)\n",
      "\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.0\tLoss: 0.036206\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.2\tLoss: 0.013440\n",
      "tensor(0.0240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.4\tLoss: 0.023980\n",
      "tensor(-0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.6\tLoss: -0.011623\n",
      "tensor(0.0204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.8\tLoss: 0.020427\n",
      "\n",
      "Test Epoch: 148\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 148\tmaintain_Accuracy: 8228/10593 (78%)\n",
      "\n",
      "tensor(0.0481, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.0\tLoss: 0.048075\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.2\tLoss: 0.021693\n",
      "tensor(-0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.4\tLoss: -0.006899\n",
      "tensor(0.0255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.6\tLoss: 0.025500\n",
      "tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.8\tLoss: 0.050031\n",
      "\n",
      "Test Epoch: 149\tAttack_Accuracy: 320/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 149\tmaintain_Accuracy: 8191/10593 (77%)\n",
      "\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.0\tLoss: 0.009716\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.2\tLoss: 0.000119\n",
      "tensor(0.0586, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.4\tLoss: 0.058556\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.6\tLoss: 0.019898\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.8\tLoss: 0.035145\n",
      "\n",
      "Train Epoch: 150\tAttack_Accuracy: 4902/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 150\tmaintain_Accuracy: 9828/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 150\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 150\tmaintain_Accuracy: 8226/10593 (78%)\n",
      "\n",
      "tensor(-0.0178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.0\tLoss: -0.017780\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.2\tLoss: 0.020092\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.4\tLoss: 0.030328\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.6\tLoss: 0.003503\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.8\tLoss: 0.019295\n",
      "\n",
      "Test Epoch: 151\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 151\tmaintain_Accuracy: 8230/10593 (78%)\n",
      "\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.0\tLoss: 0.011271\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.2\tLoss: 0.008951\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.4\tLoss: 0.017589\n",
      "tensor(0.0328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.6\tLoss: 0.032816\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.8\tLoss: 0.022538\n",
      "\n",
      "Test Epoch: 152\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 152\tmaintain_Accuracy: 8195/10593 (77%)\n",
      "\n",
      "tensor(-0.0529, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.0\tLoss: -0.052935\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.2\tLoss: 0.008233\n",
      "tensor(-0.0522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.4\tLoss: -0.052156\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.6\tLoss: 0.048896\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.8\tLoss: 0.008216\n",
      "\n",
      "Test Epoch: 153\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 153\tmaintain_Accuracy: 8203/10593 (77%)\n",
      "\n",
      "tensor(-0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.0\tLoss: -0.004212\n",
      "tensor(-0.0271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.2\tLoss: -0.027081\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.4\tLoss: 0.005916\n",
      "tensor(-0.0053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.6\tLoss: -0.005306\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.8\tLoss: 0.016552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 154\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 154\tmaintain_Accuracy: 8213/10593 (78%)\n",
      "\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.0\tLoss: 0.037481\n",
      "tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.2\tLoss: -0.007012\n",
      "tensor(-0.0375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.4\tLoss: -0.037547\n",
      "tensor(-0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.6\tLoss: -0.014754\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.8\tLoss: 0.008190\n",
      "\n",
      "Train Epoch: 155\tAttack_Accuracy: 4860/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 155\tmaintain_Accuracy: 9780/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 155\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 155\tmaintain_Accuracy: 8204/10593 (77%)\n",
      "\n",
      "tensor(-0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.0\tLoss: -0.005575\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.2\tLoss: 0.014319\n",
      "tensor(-0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.4\tLoss: -0.012002\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.6\tLoss: 0.007268\n",
      "tensor(-0.0157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.8\tLoss: -0.015674\n",
      "\n",
      "Test Epoch: 156\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 156\tmaintain_Accuracy: 8181/10593 (77%)\n",
      "\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.0\tLoss: 0.006189\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.2\tLoss: 0.009594\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.4\tLoss: 0.008206\n",
      "tensor(-0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.6\tLoss: -0.010242\n",
      "tensor(-0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.8\tLoss: -0.001479\n",
      "\n",
      "Test Epoch: 157\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 157\tmaintain_Accuracy: 8194/10593 (77%)\n",
      "\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.0\tLoss: 0.032426\n",
      "tensor(0.0530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.2\tLoss: 0.052970\n",
      "tensor(-0.0180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.4\tLoss: -0.017950\n",
      "tensor(-0.0012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.6\tLoss: -0.001176\n",
      "tensor(0.0483, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.8\tLoss: 0.048312\n",
      "\n",
      "Test Epoch: 158\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 158\tmaintain_Accuracy: 8197/10593 (77%)\n",
      "\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.0\tLoss: 0.004682\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.2\tLoss: 0.027173\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.4\tLoss: 0.039754\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.6\tLoss: 0.012805\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.8\tLoss: 0.004593\n",
      "\n",
      "Test Epoch: 159\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 159\tmaintain_Accuracy: 8209/10593 (77%)\n",
      "\n",
      "tensor(0.0446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.0\tLoss: 0.044618\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.2\tLoss: 0.007446\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.4\tLoss: 0.005428\n",
      "tensor(-0.0280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.6\tLoss: -0.027952\n",
      "tensor(-0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.8\tLoss: -0.012839\n",
      "\n",
      "Train Epoch: 160\tAttack_Accuracy: 4899/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 160\tmaintain_Accuracy: 9863/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 160\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 160\tmaintain_Accuracy: 8230/10593 (78%)\n",
      "\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.0\tLoss: 0.005955\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.2\tLoss: -0.001430\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.4\tLoss: 0.000375\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.6\tLoss: 0.035659\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.8\tLoss: 0.002381\n",
      "\n",
      "Test Epoch: 161\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 161\tmaintain_Accuracy: 8222/10593 (78%)\n",
      "\n",
      "tensor(-0.0196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.0\tLoss: -0.019606\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.2\tLoss: 0.024994\n",
      "tensor(-0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.4\tLoss: -0.001711\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.6\tLoss: 0.009884\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.8\tLoss: 0.010284\n",
      "\n",
      "Test Epoch: 162\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 162\tmaintain_Accuracy: 8233/10593 (78%)\n",
      "\n",
      "tensor(-0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.0\tLoss: -0.001466\n",
      "tensor(-0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.2\tLoss: -0.006422\n",
      "tensor(-0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.4\tLoss: -0.004200\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.6\tLoss: 0.029088\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.8\tLoss: 0.002259\n",
      "\n",
      "Test Epoch: 163\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 163\tmaintain_Accuracy: 8237/10593 (78%)\n",
      "\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.0\tLoss: 0.016682\n",
      "tensor(-0.0122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.2\tLoss: -0.012165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0321, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.4\tLoss: 0.032111\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.6\tLoss: 0.026974\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.8\tLoss: 0.040166\n",
      "\n",
      "Test Epoch: 164\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 164\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(-0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.0\tLoss: -0.008994\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.2\tLoss: 0.021005\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.4\tLoss: 0.008860\n",
      "tensor(-0.0422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.6\tLoss: -0.042248\n",
      "tensor(-0.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.8\tLoss: -0.004668\n",
      "\n",
      "Train Epoch: 165\tAttack_Accuracy: 4900/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 165\tmaintain_Accuracy: 9792/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 165\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 165\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(-0.0328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.0\tLoss: -0.032821\n",
      "tensor(0.0240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.2\tLoss: 0.024035\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.4\tLoss: 0.016783\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.6\tLoss: 0.025612\n",
      "tensor(0.0454, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.8\tLoss: 0.045383\n",
      "\n",
      "Test Epoch: 166\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 166\tmaintain_Accuracy: 8192/10593 (77%)\n",
      "\n",
      "tensor(-0.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.0\tLoss: -0.007983\n",
      "tensor(-0.0294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.2\tLoss: -0.029404\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.4\tLoss: 0.020871\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.6\tLoss: 0.023756\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.8\tLoss: 0.014711\n",
      "\n",
      "Test Epoch: 167\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 167\tmaintain_Accuracy: 8225/10593 (78%)\n",
      "\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.0\tLoss: 0.018836\n",
      "tensor(-0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.2\tLoss: -0.019193\n",
      "tensor(-0.0267, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.4\tLoss: -0.026703\n",
      "tensor(-0.0088, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.6\tLoss: -0.008789\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.8\tLoss: 0.029432\n",
      "\n",
      "Test Epoch: 168\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 168\tmaintain_Accuracy: 8234/10593 (78%)\n",
      "\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.0\tLoss: 0.032268\n",
      "tensor(-0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.2\tLoss: -0.009872\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.4\tLoss: 0.005999\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.6\tLoss: 0.022879\n",
      "tensor(0.0549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.8\tLoss: 0.054859\n",
      "\n",
      "Test Epoch: 169\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 169\tmaintain_Accuracy: 8196/10593 (77%)\n",
      "\n",
      "tensor(-0.0282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.0\tLoss: -0.028153\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.2\tLoss: 0.002901\n",
      "tensor(-0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.4\tLoss: -0.003468\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.6\tLoss: 0.002619\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.8\tLoss: 0.006136\n",
      "\n",
      "Train Epoch: 170\tAttack_Accuracy: 4911/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 170\tmaintain_Accuracy: 9819/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 170\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 170\tmaintain_Accuracy: 8212/10593 (78%)\n",
      "\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.0\tLoss: 0.015812\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.2\tLoss: 0.046766\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.4\tLoss: 0.001429\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.6\tLoss: 0.001501\n",
      "tensor(-0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.8\tLoss: -0.003743\n",
      "\n",
      "Test Epoch: 171\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 171\tmaintain_Accuracy: 8191/10593 (77%)\n",
      "\n",
      "tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.0\tLoss: 0.049574\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.2\tLoss: 0.014321\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.4\tLoss: -0.001367\n",
      "tensor(-0.0133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.6\tLoss: -0.013334\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.8\tLoss: 0.013909\n",
      "\n",
      "Test Epoch: 172\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 172\tmaintain_Accuracy: 8230/10593 (78%)\n",
      "\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.0\tLoss: 0.016149\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.2\tLoss: 0.029007\n",
      "tensor(-0.0046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.4\tLoss: -0.004616\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.6\tLoss: 0.008542\n",
      "tensor(-0.0084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.8\tLoss: -0.008361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 173\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 173\tmaintain_Accuracy: 8196/10593 (77%)\n",
      "\n",
      "tensor(-0.0048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.0\tLoss: -0.004816\n",
      "tensor(-0.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.2\tLoss: -0.010859\n",
      "tensor(-0.0157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.4\tLoss: -0.015680\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.6\tLoss: 0.013647\n",
      "tensor(-0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.8\tLoss: -0.001879\n",
      "\n",
      "Test Epoch: 174\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 174\tmaintain_Accuracy: 8197/10593 (77%)\n",
      "\n",
      "tensor(-0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.0\tLoss: -0.006587\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.2\tLoss: 0.034124\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.4\tLoss: 0.028963\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.6\tLoss: 0.019494\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.8\tLoss: 0.000855\n",
      "\n",
      "Train Epoch: 175\tAttack_Accuracy: 4881/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 175\tmaintain_Accuracy: 9891/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 175\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 175\tmaintain_Accuracy: 8224/10593 (78%)\n",
      "\n",
      "tensor(0.0204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.0\tLoss: 0.020424\n",
      "tensor(-0.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.2\tLoss: -0.008704\n",
      "tensor(0.0393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.4\tLoss: 0.039293\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.6\tLoss: 0.024781\n",
      "tensor(0.0340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.8\tLoss: 0.033999\n",
      "\n",
      "Test Epoch: 176\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 176\tmaintain_Accuracy: 8221/10593 (78%)\n",
      "\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.0\tLoss: 0.040850\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.2\tLoss: 0.041471\n",
      "tensor(0.0456, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.4\tLoss: 0.045566\n",
      "tensor(-0.0061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.6\tLoss: -0.006117\n",
      "tensor(-0.0253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.8\tLoss: -0.025267\n",
      "\n",
      "Test Epoch: 177\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 177\tmaintain_Accuracy: 8228/10593 (78%)\n",
      "\n",
      "tensor(-0.0108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.0\tLoss: -0.010821\n",
      "tensor(-0.0439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.2\tLoss: -0.043860\n",
      "tensor(-0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.4\tLoss: -0.002759\n",
      "tensor(-0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.6\tLoss: -0.010432\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.8\tLoss: 0.011932\n",
      "\n",
      "Test Epoch: 178\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 178\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.0\tLoss: 0.025328\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.2\tLoss: 0.021056\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.4\tLoss: 0.025016\n",
      "tensor(0.0345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.6\tLoss: 0.034488\n",
      "tensor(0.0365, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.8\tLoss: 0.036545\n",
      "\n",
      "Test Epoch: 179\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 179\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.0\tLoss: 0.023146\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.2\tLoss: 0.019180\n",
      "tensor(-0.0494, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.4\tLoss: -0.049384\n",
      "tensor(-0.0238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.6\tLoss: -0.023813\n",
      "tensor(0.0530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.8\tLoss: 0.053004\n",
      "\n",
      "Train Epoch: 180\tAttack_Accuracy: 4836/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 180\tmaintain_Accuracy: 9832/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 180\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 180\tmaintain_Accuracy: 8240/10593 (78%)\n",
      "\n",
      "tensor(-0.0133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.0\tLoss: -0.013325\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.2\tLoss: -0.001363\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.4\tLoss: 0.037618\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.6\tLoss: 0.003480\n",
      "tensor(-0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.8\tLoss: -0.017433\n",
      "\n",
      "Test Epoch: 181\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 181\tmaintain_Accuracy: 8225/10593 (78%)\n",
      "\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.0\tLoss: 0.006726\n",
      "tensor(-0.0057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.2\tLoss: -0.005670\n",
      "tensor(-0.0130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.4\tLoss: -0.013001\n",
      "tensor(0.0325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.6\tLoss: 0.032543\n",
      "tensor(0.0334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.8\tLoss: 0.033426\n",
      "\n",
      "Test Epoch: 182\tAttack_Accuracy: 321/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 182\tmaintain_Accuracy: 8229/10593 (78%)\n",
      "\n",
      "tensor(0.0483, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.0\tLoss: 0.048301\n",
      "tensor(0.0439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.2\tLoss: 0.043942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.4\tLoss: -0.025333\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.6\tLoss: 0.015844\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.8\tLoss: 0.021028\n",
      "\n",
      "Test Epoch: 183\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 183\tmaintain_Accuracy: 8214/10593 (78%)\n",
      "\n",
      "tensor(-0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.0\tLoss: -0.005036\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.2\tLoss: 0.020498\n",
      "tensor(-0.0149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.4\tLoss: -0.014894\n",
      "tensor(-0.0323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.6\tLoss: -0.032261\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.8\tLoss: -0.001376\n",
      "\n",
      "Test Epoch: 184\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 184\tmaintain_Accuracy: 8216/10593 (78%)\n",
      "\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.0\tLoss: 0.039153\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.2\tLoss: 0.035551\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.4\tLoss: 0.001342\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.6\tLoss: 0.012517\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.8\tLoss: 0.015106\n",
      "\n",
      "Train Epoch: 185\tAttack_Accuracy: 4815/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 185\tmaintain_Accuracy: 9848/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 185\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 185\tmaintain_Accuracy: 8197/10593 (77%)\n",
      "\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.0\tLoss: 0.007257\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.2\tLoss: 0.019130\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.4\tLoss: 0.022418\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.6\tLoss: 0.009698\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.8\tLoss: 0.021147\n",
      "\n",
      "Test Epoch: 186\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 186\tmaintain_Accuracy: 8235/10593 (78%)\n",
      "\n",
      "tensor(0.0348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.0\tLoss: 0.034824\n",
      "tensor(-0.0165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.2\tLoss: -0.016470\n",
      "tensor(-0.0068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.4\tLoss: -0.006802\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.6\tLoss: 0.000633\n",
      "tensor(-0.0440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.8\tLoss: -0.044003\n",
      "\n",
      "Test Epoch: 187\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 187\tmaintain_Accuracy: 8226/10593 (78%)\n",
      "\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.0\tLoss: 0.002078\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.2\tLoss: 0.019358\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.4\tLoss: 0.006034\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.6\tLoss: 0.032293\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.8\tLoss: 0.023739\n",
      "\n",
      "Test Epoch: 188\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 188\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.0\tLoss: 0.027125\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.2\tLoss: 0.019864\n",
      "tensor(-0.0556, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.4\tLoss: -0.055575\n",
      "tensor(0.0295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.6\tLoss: 0.029469\n",
      "tensor(0.0255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.8\tLoss: 0.025456\n",
      "\n",
      "Test Epoch: 189\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 189\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(-0.0079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.0\tLoss: -0.007890\n",
      "tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.2\tLoss: 0.061369\n",
      "tensor(-0.0018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.4\tLoss: -0.001790\n",
      "tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.6\tLoss: 0.049147\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.8\tLoss: 0.010495\n",
      "\n",
      "Train Epoch: 190\tAttack_Accuracy: 4843/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 190\tmaintain_Accuracy: 9775/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 190\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 190\tmaintain_Accuracy: 8231/10593 (78%)\n",
      "\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.0\tLoss: 0.021926\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.2\tLoss: 0.004244\n",
      "tensor(-0.0457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.4\tLoss: -0.045710\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.6\tLoss: 0.005415\n",
      "tensor(-0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.8\tLoss: -0.008955\n",
      "\n",
      "Test Epoch: 191\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 191\tmaintain_Accuracy: 8217/10593 (78%)\n",
      "\n",
      "tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.0\tLoss: 0.050112\n",
      "tensor(-0.0084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.2\tLoss: -0.008402\n",
      "tensor(0.0363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.4\tLoss: 0.036345\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.6\tLoss: 0.018553\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.8\tLoss: 0.009297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 192\tAttack_Accuracy: 320/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 192\tmaintain_Accuracy: 8209/10593 (77%)\n",
      "\n",
      "tensor(-0.0022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.0\tLoss: -0.002187\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.2\tLoss: 0.029171\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.4\tLoss: 0.002626\n",
      "tensor(-0.0320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.6\tLoss: -0.031993\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.8\tLoss: 0.005570\n",
      "\n",
      "Test Epoch: 193\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 193\tmaintain_Accuracy: 8208/10593 (77%)\n",
      "\n",
      "tensor(-0.0061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.0\tLoss: -0.006107\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.2\tLoss: 0.036643\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.4\tLoss: 0.023037\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.6\tLoss: 0.008310\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.8\tLoss: 0.023306\n",
      "\n",
      "Test Epoch: 194\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 194\tmaintain_Accuracy: 8210/10593 (78%)\n",
      "\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.0\tLoss: 0.050717\n",
      "tensor(-0.0130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.2\tLoss: -0.012970\n",
      "tensor(-0.0057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.4\tLoss: -0.005657\n",
      "tensor(-0.0433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.6\tLoss: -0.043286\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.8\tLoss: 0.013214\n",
      "\n",
      "Train Epoch: 195\tAttack_Accuracy: 4919/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 195\tmaintain_Accuracy: 9831/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 195\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 195\tmaintain_Accuracy: 8209/10593 (77%)\n",
      "\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.0\tLoss: 0.008301\n",
      "tensor(-0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.2\tLoss: -0.016638\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.4\tLoss: 0.005057\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.6\tLoss: 0.004045\n",
      "tensor(-0.0111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.8\tLoss: -0.011142\n",
      "\n",
      "Test Epoch: 196\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 196\tmaintain_Accuracy: 8215/10593 (78%)\n",
      "\n",
      "tensor(-0.0025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.0\tLoss: -0.002495\n",
      "tensor(-0.0382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.2\tLoss: -0.038182\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.4\tLoss: 0.027049\n",
      "tensor(0.0277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.6\tLoss: 0.027686\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.8\tLoss: 0.004519\n",
      "\n",
      "Test Epoch: 197\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 197\tmaintain_Accuracy: 8214/10593 (78%)\n",
      "\n",
      "tensor(-0.0135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.0\tLoss: -0.013477\n",
      "tensor(0.0825, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.2\tLoss: 0.082495\n",
      "tensor(-0.0127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.4\tLoss: -0.012744\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.6\tLoss: -0.001396\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.8\tLoss: 0.010332\n",
      "\n",
      "Test Epoch: 198\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 198\tmaintain_Accuracy: 8240/10593 (78%)\n",
      "\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.0\tLoss: 0.018851\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.2\tLoss: 0.027479\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.4\tLoss: 0.003901\n",
      "tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.6\tLoss: 0.060316\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.8\tLoss: 0.012023\n",
      "\n",
      "Test Epoch: 199\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 199\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(-0.0206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.0\tLoss: -0.020550\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.2\tLoss: 0.046756\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.4\tLoss: 0.026842\n",
      "tensor(-0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.6\tLoss: -0.005626\n",
      "tensor(-0.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.8\tLoss: -0.002042\n",
      "\n",
      "Train Epoch: 200\tAttack_Accuracy: 4889/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 200\tmaintain_Accuracy: 9838/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 200\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 200\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.0\tLoss: -0.023173\n",
      "tensor(-0.0058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.2\tLoss: -0.005795\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.4\tLoss: 0.008688\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.6\tLoss: 0.010232\n",
      "tensor(-0.0248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.8\tLoss: -0.024790\n",
      "\n",
      "Test Epoch: 201\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 201\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.0\tLoss: 0.019196\n",
      "tensor(-0.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.2\tLoss: -0.012938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0374, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.4\tLoss: -0.037420\n",
      "tensor(-0.0470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.6\tLoss: -0.046978\n",
      "tensor(-0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.8\tLoss: -0.000776\n",
      "\n",
      "Test Epoch: 202\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 202\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.0\tLoss: -0.013621\n",
      "tensor(-0.0152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.2\tLoss: -0.015244\n",
      "tensor(-0.0156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.4\tLoss: -0.015639\n",
      "tensor(-0.0126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.6\tLoss: -0.012563\n",
      "tensor(-0.0063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.8\tLoss: -0.006254\n",
      "\n",
      "Test Epoch: 203\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 203\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(-0.0082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.0\tLoss: -0.008196\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.2\tLoss: 0.024710\n",
      "tensor(-0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.4\tLoss: -0.003858\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.6\tLoss: 0.004011\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.8\tLoss: 0.007850\n",
      "\n",
      "Test Epoch: 204\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 204\tmaintain_Accuracy: 8240/10593 (78%)\n",
      "\n",
      "tensor(-0.0124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.0\tLoss: -0.012401\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.2\tLoss: 0.014391\n",
      "tensor(-0.0003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.4\tLoss: -0.000341\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.6\tLoss: 0.001544\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.8\tLoss: 0.020117\n",
      "\n",
      "Train Epoch: 205\tAttack_Accuracy: 4874/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 205\tmaintain_Accuracy: 9889/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 205\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 205\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.0\tLoss: 0.013097\n",
      "tensor(0.0664, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.2\tLoss: 0.066436\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.4\tLoss: 0.020860\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.6\tLoss: 0.017152\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.8\tLoss: 0.010885\n",
      "\n",
      "Test Epoch: 206\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 206\tmaintain_Accuracy: 8241/10593 (78%)\n",
      "\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.0\tLoss: 0.011869\n",
      "tensor(-0.0160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.2\tLoss: -0.016008\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.4\tLoss: 0.010372\n",
      "tensor(-0.0097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.6\tLoss: -0.009659\n",
      "tensor(0.0337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.8\tLoss: 0.033681\n",
      "\n",
      "Test Epoch: 207\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 207\tmaintain_Accuracy: 8236/10593 (78%)\n",
      "\n",
      "tensor(-0.0041, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.0\tLoss: -0.004106\n",
      "tensor(0.0459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.2\tLoss: 0.045938\n",
      "tensor(-0.0318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.4\tLoss: -0.031794\n",
      "tensor(-0.0420, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.6\tLoss: -0.041968\n",
      "tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.8\tLoss: -0.001032\n",
      "\n",
      "Test Epoch: 208\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 208\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(-0.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.0\tLoss: -0.002032\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.2\tLoss: 0.038308\n",
      "tensor(-0.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.4\tLoss: -0.000392\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.6\tLoss: 0.023027\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.8\tLoss: 0.002580\n",
      "\n",
      "Test Epoch: 209\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 209\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.0\tLoss: 0.005177\n",
      "tensor(-0.0146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.2\tLoss: -0.014645\n",
      "tensor(-0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.4\tLoss: -0.003346\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.6\tLoss: 0.022999\n",
      "tensor(-0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.8\tLoss: -0.002998\n",
      "\n",
      "Train Epoch: 210\tAttack_Accuracy: 4843/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 210\tmaintain_Accuracy: 9896/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 210\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 210\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.0\tLoss: 0.027698\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.2\tLoss: 0.005617\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.4\tLoss: 0.010429\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.6\tLoss: 0.004952\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.8\tLoss: 0.017180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 211\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 211\tmaintain_Accuracy: 8240/10593 (78%)\n",
      "\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.0\tLoss: 0.011942\n",
      "tensor(-0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.2\tLoss: -0.021874\n",
      "tensor(-0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.4\tLoss: -0.026571\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.6\tLoss: 0.045797\n",
      "tensor(-0.0263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.8\tLoss: -0.026274\n",
      "\n",
      "Test Epoch: 212\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 212\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.0\tLoss: -0.000137\n",
      "tensor(-6.2548e-06, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.2\tLoss: -0.000006\n",
      "tensor(-0.0194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.4\tLoss: -0.019382\n",
      "tensor(-0.0203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.6\tLoss: -0.020254\n",
      "tensor(-0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.8\tLoss: -0.014227\n",
      "\n",
      "Test Epoch: 213\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 213\tmaintain_Accuracy: 8237/10593 (78%)\n",
      "\n",
      "tensor(-0.0045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.0\tLoss: -0.004503\n",
      "tensor(-0.0257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.2\tLoss: -0.025720\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.4\tLoss: 0.008696\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.6\tLoss: 0.006851\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.8\tLoss: 0.026614\n",
      "\n",
      "Test Epoch: 214\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 214\tmaintain_Accuracy: 8237/10593 (78%)\n",
      "\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.0\tLoss: 0.000722\n",
      "tensor(-0.0254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.2\tLoss: -0.025445\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.4\tLoss: 0.001105\n",
      "tensor(0.0426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.6\tLoss: 0.042609\n",
      "tensor(0.0313, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.8\tLoss: 0.031306\n",
      "\n",
      "Train Epoch: 215\tAttack_Accuracy: 4880/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 215\tmaintain_Accuracy: 9900/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 215\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 215\tmaintain_Accuracy: 8232/10593 (78%)\n",
      "\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.0\tLoss: 0.002127\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.2\tLoss: 0.007232\n",
      "tensor(-0.0124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.4\tLoss: -0.012427\n",
      "tensor(-0.0211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.6\tLoss: -0.021072\n",
      "tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.8\tLoss: 0.057976\n",
      "\n",
      "Test Epoch: 216\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 216\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(-0.0312, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.0\tLoss: -0.031160\n",
      "tensor(0.0347, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.2\tLoss: 0.034716\n",
      "tensor(-0.0290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.4\tLoss: -0.029034\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.6\tLoss: 0.055310\n",
      "tensor(-0.0197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.8\tLoss: -0.019673\n",
      "\n",
      "Test Epoch: 217\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 217\tmaintain_Accuracy: 8227/10593 (78%)\n",
      "\n",
      "tensor(-0.0440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.0\tLoss: -0.043958\n",
      "tensor(-0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.2\tLoss: -0.005113\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.4\tLoss: 0.010217\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.6\tLoss: 0.026573\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.8\tLoss: 0.043290\n",
      "\n",
      "Test Epoch: 218\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 218\tmaintain_Accuracy: 8240/10593 (78%)\n",
      "\n",
      "tensor(-0.0158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.0\tLoss: -0.015835\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.2\tLoss: 0.013911\n",
      "tensor(-0.0196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.4\tLoss: -0.019599\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.6\tLoss: 0.026248\n",
      "tensor(-0.0044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.8\tLoss: -0.004413\n",
      "\n",
      "Test Epoch: 219\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 219\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(-0.0218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.0\tLoss: -0.021764\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.2\tLoss: 0.011533\n",
      "tensor(-0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.4\tLoss: -0.017410\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.6\tLoss: 0.015922\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.8\tLoss: 0.019891\n",
      "\n",
      "Train Epoch: 220\tAttack_Accuracy: 4856/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 220\tmaintain_Accuracy: 9924/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 220\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 220\tmaintain_Accuracy: 8238/10593 (78%)\n",
      "\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.0\tLoss: 0.004643\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.2\tLoss: 0.018061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.4\tLoss: 0.009860\n",
      "tensor(-0.0277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.6\tLoss: -0.027664\n",
      "tensor(0.0475, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.8\tLoss: 0.047511\n",
      "\n",
      "Test Epoch: 221\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 221\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(-0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.0\tLoss: -0.009641\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.2\tLoss: 0.001536\n",
      "tensor(-0.0211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.4\tLoss: -0.021061\n",
      "tensor(-8.3927e-05, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.6\tLoss: -0.000084\n",
      "tensor(0.0664, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.8\tLoss: 0.066392\n",
      "\n",
      "Test Epoch: 222\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 222\tmaintain_Accuracy: 8240/10593 (78%)\n",
      "\n",
      "tensor(0.0331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.0\tLoss: 0.033122\n",
      "tensor(-0.0144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.2\tLoss: -0.014403\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.4\tLoss: 0.002574\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.6\tLoss: 0.002391\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.8\tLoss: 0.014246\n",
      "\n",
      "Test Epoch: 223\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 223\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(-0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.0\tLoss: -0.005113\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.2\tLoss: 0.019789\n",
      "tensor(-0.0297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.4\tLoss: -0.029702\n",
      "tensor(-0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.6\tLoss: -0.018277\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.8\tLoss: 0.009054\n",
      "\n",
      "Test Epoch: 224\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 224\tmaintain_Accuracy: 8240/10593 (78%)\n",
      "\n",
      "tensor(0.0331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.0\tLoss: 0.033081\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.2\tLoss: 0.013527\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.4\tLoss: 0.001582\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.6\tLoss: 0.043402\n",
      "tensor(-0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.8\tLoss: -0.021492\n",
      "\n",
      "Train Epoch: 225\tAttack_Accuracy: 4873/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 225\tmaintain_Accuracy: 9809/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 225\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 225\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(-0.0228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.0\tLoss: -0.022807\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.2\tLoss: 0.022805\n",
      "tensor(-0.0264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.4\tLoss: -0.026431\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.6\tLoss: 0.003312\n",
      "tensor(0.0490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.8\tLoss: 0.048984\n",
      "\n",
      "Test Epoch: 226\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 226\tmaintain_Accuracy: 8253/10593 (78%)\n",
      "\n",
      "tensor(-0.0334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.0\tLoss: -0.033377\n",
      "tensor(-0.0335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.2\tLoss: -0.033526\n",
      "tensor(-0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.4\tLoss: -0.005458\n",
      "tensor(-0.0518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.6\tLoss: -0.051759\n",
      "tensor(-0.0441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.8\tLoss: -0.044070\n",
      "\n",
      "Test Epoch: 227\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 227\tmaintain_Accuracy: 8238/10593 (78%)\n",
      "\n",
      "tensor(-0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.0\tLoss: -0.006373\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.2\tLoss: 0.035542\n",
      "tensor(-0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.4\tLoss: -0.000766\n",
      "tensor(-0.0259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.6\tLoss: -0.025882\n",
      "tensor(-0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.8\tLoss: -0.002105\n",
      "\n",
      "Test Epoch: 228\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 228\tmaintain_Accuracy: 8235/10593 (78%)\n",
      "\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.0\tLoss: 0.018891\n",
      "tensor(0.0704, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.2\tLoss: 0.070355\n",
      "tensor(0.0335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.4\tLoss: 0.033532\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.6\tLoss: 0.001366\n",
      "tensor(-0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.8\tLoss: -0.006618\n",
      "\n",
      "Test Epoch: 229\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 229\tmaintain_Accuracy: 8237/10593 (78%)\n",
      "\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.0\tLoss: 0.026825\n",
      "tensor(-0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.2\tLoss: -0.008053\n",
      "tensor(-0.0510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.4\tLoss: -0.050958\n",
      "tensor(-0.0513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.6\tLoss: -0.051289\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.8\tLoss: 0.017416\n",
      "\n",
      "Train Epoch: 230\tAttack_Accuracy: 4900/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 230\tmaintain_Accuracy: 9870/12800 (77%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 230\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 230\tmaintain_Accuracy: 8232/10593 (78%)\n",
      "\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.0\tLoss: 0.017022\n",
      "tensor(-0.0461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.2\tLoss: -0.046117\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.4\tLoss: 0.010242\n",
      "tensor(-0.0329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.6\tLoss: -0.032950\n",
      "tensor(-0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.8\tLoss: -0.001349\n",
      "\n",
      "Test Epoch: 231\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 231\tmaintain_Accuracy: 8221/10593 (78%)\n",
      "\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.0\tLoss: 0.006596\n",
      "tensor(-0.0162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.2\tLoss: -0.016199\n",
      "tensor(-0.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.4\tLoss: -0.009535\n",
      "tensor(-0.0530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.6\tLoss: -0.052980\n",
      "tensor(-0.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.8\tLoss: -0.004719\n",
      "\n",
      "Test Epoch: 232\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 232\tmaintain_Accuracy: 8215/10593 (78%)\n",
      "\n",
      "tensor(-0.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.0\tLoss: -0.002044\n",
      "tensor(-0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.2\tLoss: -0.006525\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.4\tLoss: 0.005818\n",
      "tensor(-0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.6\tLoss: -0.018306\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.8\tLoss: 0.002064\n",
      "\n",
      "Test Epoch: 233\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 233\tmaintain_Accuracy: 8233/10593 (78%)\n",
      "\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.0\tLoss: 0.000190\n",
      "tensor(-0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.2\tLoss: -0.011791\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.4\tLoss: 0.035107\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.6\tLoss: 0.023894\n",
      "tensor(-0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.8\tLoss: -0.017434\n",
      "\n",
      "Test Epoch: 234\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 234\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.0\tLoss: -0.022450\n",
      "tensor(-0.0158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.2\tLoss: -0.015761\n",
      "tensor(-0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.4\tLoss: -0.016557\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.6\tLoss: 0.017750\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.8\tLoss: 0.019094\n",
      "\n",
      "Train Epoch: 235\tAttack_Accuracy: 4866/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 235\tmaintain_Accuracy: 9884/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 235\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 235\tmaintain_Accuracy: 8232/10593 (78%)\n",
      "\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.0\tLoss: 0.017381\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.2\tLoss: 0.038455\n",
      "tensor(-0.0135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.4\tLoss: -0.013501\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.6\tLoss: 0.008457\n",
      "tensor(-0.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.8\tLoss: -0.004674\n",
      "\n",
      "Test Epoch: 236\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 236\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(0.0314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.0\tLoss: 0.031360\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.2\tLoss: 0.016194\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.4\tLoss: 0.010960\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.6\tLoss: 0.009400\n",
      "tensor(-0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.8\tLoss: -0.019070\n",
      "\n",
      "Test Epoch: 237\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 237\tmaintain_Accuracy: 8234/10593 (78%)\n",
      "\n",
      "tensor(-0.0073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.0\tLoss: -0.007326\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.2\tLoss: 0.020937\n",
      "tensor(-0.0338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.4\tLoss: -0.033755\n",
      "tensor(-0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.6\tLoss: -0.011511\n",
      "tensor(-0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.8\tLoss: -0.012829\n",
      "\n",
      "Test Epoch: 238\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 238\tmaintain_Accuracy: 8226/10593 (78%)\n",
      "\n",
      "tensor(-0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.0\tLoss: -0.009034\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.2\tLoss: 0.021831\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.4\tLoss: 0.035652\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.6\tLoss: 0.016641\n",
      "tensor(-0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.8\tLoss: -0.014309\n",
      "\n",
      "Test Epoch: 239\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 239\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(-0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.0\tLoss: -0.004153\n",
      "tensor(0.0430, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.2\tLoss: 0.042963\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.4\tLoss: 0.028878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.6\tLoss: -0.046301\n",
      "tensor(-0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.8\tLoss: -0.012817\n",
      "\n",
      "Train Epoch: 240\tAttack_Accuracy: 4884/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 240\tmaintain_Accuracy: 9883/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 240\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 240\tmaintain_Accuracy: 8232/10593 (78%)\n",
      "\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.0\tLoss: 0.012653\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.2\tLoss: 0.018769\n",
      "tensor(-0.0341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.4\tLoss: -0.034084\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.6\tLoss: 0.012375\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.8\tLoss: 0.010436\n",
      "\n",
      "Test Epoch: 241\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 241\tmaintain_Accuracy: 8237/10593 (78%)\n",
      "\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.0\tLoss: 0.011209\n",
      "tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.2\tLoss: -0.006956\n",
      "tensor(-0.0254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.4\tLoss: -0.025408\n",
      "tensor(-0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.6\tLoss: -0.019873\n",
      "tensor(-0.0226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.8\tLoss: -0.022626\n",
      "\n",
      "Test Epoch: 242\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 242\tmaintain_Accuracy: 8226/10593 (78%)\n",
      "\n",
      "tensor(-0.0146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.0\tLoss: -0.014637\n",
      "tensor(-0.0040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.2\tLoss: -0.003981\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.4\tLoss: 0.004103\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.6\tLoss: 0.016424\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.8\tLoss: 0.030289\n",
      "\n",
      "Test Epoch: 243\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 243\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.0\tLoss: -0.021948\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.2\tLoss: 0.008582\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.4\tLoss: 0.010510\n",
      "tensor(-0.0076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.6\tLoss: -0.007557\n",
      "tensor(-0.0169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.8\tLoss: -0.016880\n",
      "\n",
      "Test Epoch: 244\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 244\tmaintain_Accuracy: 8238/10593 (78%)\n",
      "\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.0\tLoss: 0.001393\n",
      "tensor(-0.0280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.2\tLoss: -0.028023\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.4\tLoss: 0.002058\n",
      "tensor(-0.0195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.6\tLoss: -0.019545\n",
      "tensor(-0.0211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.8\tLoss: -0.021129\n",
      "\n",
      "Train Epoch: 245\tAttack_Accuracy: 4894/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 245\tmaintain_Accuracy: 9907/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 245\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 245\tmaintain_Accuracy: 8234/10593 (78%)\n",
      "\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.0\tLoss: 0.010744\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.2\tLoss: 0.025783\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.4\tLoss: 0.015836\n",
      "tensor(0.0285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.6\tLoss: 0.028453\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.8\tLoss: 0.006313\n",
      "\n",
      "Test Epoch: 246\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 246\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(-0.0238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.0\tLoss: -0.023834\n",
      "tensor(-0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.2\tLoss: -0.008584\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.4\tLoss: 0.022594\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.6\tLoss: 0.026922\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.8\tLoss: 0.015423\n",
      "\n",
      "Test Epoch: 247\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 247\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.0\tLoss: 0.027160\n",
      "tensor(-0.0301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.2\tLoss: -0.030053\n",
      "tensor(-0.0146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.4\tLoss: -0.014597\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.6\tLoss: 0.013464\n",
      "tensor(-0.0249, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.8\tLoss: -0.024867\n",
      "\n",
      "Test Epoch: 248\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 248\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.0\tLoss: -0.000132\n",
      "tensor(-0.0348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.2\tLoss: -0.034798\n",
      "tensor(-0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.4\tLoss: -0.023033\n",
      "tensor(-0.0106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.6\tLoss: -0.010571\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.8\tLoss: 0.000102\n",
      "\n",
      "Test Epoch: 249\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 249\tmaintain_Accuracy: 8232/10593 (78%)\n",
      "\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.0\tLoss: 0.040490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.2\tLoss: 0.054593\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.4\tLoss: 0.015547\n",
      "tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.6\tLoss: 0.062597\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.8\tLoss: 0.021839\n",
      "\n",
      "Train Epoch: 250\tAttack_Accuracy: 4905/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 250\tmaintain_Accuracy: 9774/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 250\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 250\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.0\tLoss: 0.024472\n",
      "tensor(-0.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.2\tLoss: -0.024736\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.4\tLoss: 0.015436\n",
      "tensor(-0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.6\tLoss: -0.000663\n",
      "tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.8\tLoss: -0.001017\n",
      "\n",
      "Test Epoch: 251\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 251\tmaintain_Accuracy: 8228/10593 (78%)\n",
      "\n",
      "tensor(-0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.0\tLoss: -0.006411\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.2\tLoss: 0.013346\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.4\tLoss: 0.005284\n",
      "tensor(-0.0158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.6\tLoss: -0.015800\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.8\tLoss: 0.002054\n",
      "\n",
      "Test Epoch: 252\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 252\tmaintain_Accuracy: 8230/10593 (78%)\n",
      "\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.0\tLoss: 0.003720\n",
      "tensor(-0.0391, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.2\tLoss: -0.039141\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.4\tLoss: 0.026162\n",
      "tensor(-0.0486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.6\tLoss: -0.048565\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.8\tLoss: 0.002909\n",
      "\n",
      "Test Epoch: 253\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 253\tmaintain_Accuracy: 8235/10593 (78%)\n",
      "\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.0\tLoss: 0.006801\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.2\tLoss: 0.025863\n",
      "tensor(-0.0321, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.4\tLoss: -0.032144\n",
      "tensor(-0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.6\tLoss: -0.006500\n",
      "tensor(-0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.8\tLoss: -0.011818\n",
      "\n",
      "Test Epoch: 254\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 254\tmaintain_Accuracy: 8236/10593 (78%)\n",
      "\n",
      "tensor(-0.0025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.0\tLoss: -0.002485\n",
      "tensor(-0.0430, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.2\tLoss: -0.043009\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.4\tLoss: 0.010324\n",
      "tensor(0.0315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.6\tLoss: 0.031509\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.8\tLoss: 0.014676\n",
      "\n",
      "Train Epoch: 255\tAttack_Accuracy: 4890/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 255\tmaintain_Accuracy: 9887/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 255\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 255\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.0\tLoss: 0.018775\n",
      "tensor(0.0345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.2\tLoss: 0.034493\n",
      "tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.4\tLoss: -0.000878\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.6\tLoss: 0.018341\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.8\tLoss: 0.007724\n",
      "\n",
      "Test Epoch: 256\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 256\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.0\tLoss: 0.042394\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.2\tLoss: 0.005477\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.4\tLoss: 0.017933\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.6\tLoss: 0.014944\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.8\tLoss: 0.009806\n",
      "\n",
      "Test Epoch: 257\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 257\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(-0.0212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.0\tLoss: -0.021157\n",
      "tensor(-0.0197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.2\tLoss: -0.019700\n",
      "tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.4\tLoss: -0.006995\n",
      "tensor(-0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.6\tLoss: -0.013079\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.8\tLoss: 0.002064\n",
      "\n",
      "Test Epoch: 258\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 258\tmaintain_Accuracy: 8238/10593 (78%)\n",
      "\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.0\tLoss: 0.004773\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.2\tLoss: 0.011523\n",
      "tensor(-0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.4\tLoss: -0.018291\n",
      "tensor(-0.0282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.6\tLoss: -0.028232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.8\tLoss: -0.006128\n",
      "\n",
      "Test Epoch: 259\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 259\tmaintain_Accuracy: 8238/10593 (78%)\n",
      "\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.0\tLoss: 0.000309\n",
      "tensor(0.0295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.2\tLoss: 0.029531\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.4\tLoss: 0.012377\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.6\tLoss: 0.028756\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.8\tLoss: 0.008323\n",
      "\n",
      "Train Epoch: 260\tAttack_Accuracy: 4827/6400 (75%)\n",
      "\n",
      "\n",
      "Train Epoch: 260\tmaintain_Accuracy: 9870/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 260\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 260\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(-0.0134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.0\tLoss: -0.013383\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.2\tLoss: 0.008734\n",
      "tensor(-0.0197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.4\tLoss: -0.019651\n",
      "tensor(-0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.6\tLoss: -0.011167\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.8\tLoss: 0.032705\n",
      "\n",
      "Test Epoch: 261\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 261\tmaintain_Accuracy: 8241/10593 (78%)\n",
      "\n",
      "tensor(-0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.0\tLoss: -0.001679\n",
      "tensor(-0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.2\tLoss: -0.014819\n",
      "tensor(-0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.4\tLoss: -0.002894\n",
      "tensor(-0.0367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.6\tLoss: -0.036696\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.8\tLoss: 0.018131\n",
      "\n",
      "Test Epoch: 262\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 262\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(-0.0306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.0\tLoss: -0.030574\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.2\tLoss: 0.014296\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.4\tLoss: 0.022512\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.6\tLoss: 0.012016\n",
      "tensor(-0.0058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.8\tLoss: -0.005811\n",
      "\n",
      "Test Epoch: 263\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 263\tmaintain_Accuracy: 8237/10593 (78%)\n",
      "\n",
      "tensor(-0.0417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.0\tLoss: -0.041717\n",
      "tensor(-0.0125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.2\tLoss: -0.012509\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.4\tLoss: 0.034609\n",
      "tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.6\tLoss: 0.065254\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.8\tLoss: 0.004712\n",
      "\n",
      "Test Epoch: 264\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 264\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.0\tLoss: 0.008330\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.2\tLoss: 0.021047\n",
      "tensor(-0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.4\tLoss: -0.005861\n",
      "tensor(-0.0435, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.6\tLoss: -0.043477\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.8\tLoss: 0.012095\n",
      "\n",
      "Train Epoch: 265\tAttack_Accuracy: 4896/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 265\tmaintain_Accuracy: 9936/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 265\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 265\tmaintain_Accuracy: 8233/10593 (78%)\n",
      "\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.0\tLoss: 0.022888\n",
      "tensor(-0.0149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.2\tLoss: -0.014917\n",
      "tensor(-0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.4\tLoss: -0.005612\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.6\tLoss: 0.018264\n",
      "tensor(0.0388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.8\tLoss: 0.038833\n",
      "\n",
      "Test Epoch: 266\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 266\tmaintain_Accuracy: 8229/10593 (78%)\n",
      "\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.0\tLoss: 0.028574\n",
      "tensor(-0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.2\tLoss: -0.004992\n",
      "tensor(0.0352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.4\tLoss: 0.035231\n",
      "tensor(0.0441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.6\tLoss: 0.044094\n",
      "tensor(-0.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.8\tLoss: -0.000579\n",
      "\n",
      "Test Epoch: 267\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 267\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.0\tLoss: 0.011241\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.2\tLoss: -0.001430\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.4\tLoss: 0.006993\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.6\tLoss: 0.003849\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.8\tLoss: 0.001685\n",
      "\n",
      "Test Epoch: 268\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 268\tmaintain_Accuracy: 8228/10593 (78%)\n",
      "\n",
      "tensor(-0.0018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.0\tLoss: -0.001825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.2\tLoss: 0.013520\n",
      "tensor(-0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.4\tLoss: -0.017425\n",
      "tensor(-0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.6\tLoss: -0.008993\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.8\tLoss: 0.009936\n",
      "\n",
      "Test Epoch: 269\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 269\tmaintain_Accuracy: 8228/10593 (78%)\n",
      "\n",
      "tensor(-0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.0\tLoss: -0.008103\n",
      "tensor(-0.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.2\tLoss: -0.008017\n",
      "tensor(-0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.4\tLoss: -0.006440\n",
      "tensor(-0.0079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.6\tLoss: -0.007865\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.8\tLoss: 0.018260\n",
      "\n",
      "Train Epoch: 270\tAttack_Accuracy: 4888/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 270\tmaintain_Accuracy: 9891/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 270\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 270\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.0\tLoss: 0.011393\n",
      "tensor(-0.0063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.2\tLoss: -0.006259\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.4\tLoss: 0.019105\n",
      "tensor(-0.0283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.6\tLoss: -0.028277\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.8\tLoss: 0.026000\n",
      "\n",
      "Test Epoch: 271\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 271\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.0\tLoss: -0.011650\n",
      "tensor(-0.0368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.2\tLoss: -0.036784\n",
      "tensor(-0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.4\tLoss: -0.010178\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.6\tLoss: 0.005293\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.8\tLoss: 0.021506\n",
      "\n",
      "Test Epoch: 272\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 272\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.0\tLoss: 0.013218\n",
      "tensor(-0.0381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.2\tLoss: -0.038124\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.4\tLoss: 0.019965\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.6\tLoss: 0.007659\n",
      "tensor(-0.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.8\tLoss: -0.004689\n",
      "\n",
      "Test Epoch: 273\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 273\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(-0.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.0\tLoss: -0.021005\n",
      "tensor(-0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.2\tLoss: -0.002430\n",
      "tensor(-0.0417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.4\tLoss: -0.041682\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.6\tLoss: 0.023656\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.8\tLoss: 0.018698\n",
      "\n",
      "Test Epoch: 274\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 274\tmaintain_Accuracy: 8230/10593 (78%)\n",
      "\n",
      "tensor(-0.0206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.0\tLoss: -0.020602\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.2\tLoss: 0.014390\n",
      "tensor(-0.0145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.4\tLoss: -0.014534\n",
      "tensor(-0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.6\tLoss: -0.013056\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.8\tLoss: 0.012878\n",
      "\n",
      "Train Epoch: 275\tAttack_Accuracy: 4866/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 275\tmaintain_Accuracy: 9993/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 275\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 275\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(-0.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.0\tLoss: -0.010929\n",
      "tensor(0.0365, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.2\tLoss: 0.036477\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.4\tLoss: 0.014707\n",
      "tensor(-0.0125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.6\tLoss: -0.012453\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.8\tLoss: 0.008444\n",
      "\n",
      "Test Epoch: 276\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 276\tmaintain_Accuracy: 8241/10593 (78%)\n",
      "\n",
      "tensor(0.0325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.0\tLoss: 0.032510\n",
      "tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.2\tLoss: 0.054689\n",
      "tensor(-0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.4\tLoss: -0.006379\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.6\tLoss: 0.015200\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.8\tLoss: 0.014162\n",
      "\n",
      "Test Epoch: 277\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 277\tmaintain_Accuracy: 8236/10593 (78%)\n",
      "\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.0\tLoss: 0.011014\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.2\tLoss: 0.013435\n",
      "tensor(-0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.4\tLoss: -0.012097\n",
      "tensor(0.0240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.6\tLoss: 0.024024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.8\tLoss: 0.039276\n",
      "\n",
      "Test Epoch: 278\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 278\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(-0.0061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.0\tLoss: -0.006108\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.2\tLoss: 0.015204\n",
      "tensor(-0.0138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.4\tLoss: -0.013821\n",
      "tensor(-0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.6\tLoss: -0.000203\n",
      "tensor(-0.0187, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.8\tLoss: -0.018691\n",
      "\n",
      "Test Epoch: 279\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 279\tmaintain_Accuracy: 8240/10593 (78%)\n",
      "\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.0\tLoss: -0.001419\n",
      "tensor(-0.0236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.2\tLoss: -0.023649\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.4\tLoss: 0.043087\n",
      "tensor(0.0715, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.6\tLoss: 0.071473\n",
      "tensor(-0.0180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.8\tLoss: -0.018048\n",
      "\n",
      "Train Epoch: 280\tAttack_Accuracy: 4933/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 280\tmaintain_Accuracy: 9965/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 280\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 280\tmaintain_Accuracy: 8238/10593 (78%)\n",
      "\n",
      "tensor(0.0336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.0\tLoss: 0.033555\n",
      "tensor(-0.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.2\tLoss: -0.011726\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.4\tLoss: 0.030488\n",
      "tensor(-0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.6\tLoss: -0.010268\n",
      "tensor(-0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.8\tLoss: -0.017366\n",
      "\n",
      "Test Epoch: 281\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 281\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.0\tLoss: 0.027549\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.2\tLoss: 0.007342\n",
      "tensor(-0.0317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.4\tLoss: -0.031691\n",
      "tensor(-0.0107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.6\tLoss: -0.010662\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.8\tLoss: 0.046978\n",
      "\n",
      "Test Epoch: 282\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 282\tmaintain_Accuracy: 8233/10593 (78%)\n",
      "\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.0\tLoss: 0.010798\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.2\tLoss: 0.028910\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.4\tLoss: 0.008474\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.6\tLoss: 0.055270\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.8\tLoss: 0.028761\n",
      "\n",
      "Test Epoch: 283\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 283\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.0\tLoss: -0.007810\n",
      "tensor(-0.0114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.2\tLoss: -0.011354\n",
      "tensor(-0.0023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.4\tLoss: -0.002338\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.6\tLoss: 0.000692\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.8\tLoss: 0.022146\n",
      "\n",
      "Test Epoch: 284\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 284\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(-0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.0\tLoss: -0.019132\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.2\tLoss: 0.024210\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.4\tLoss: 0.043146\n",
      "tensor(-0.0153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.6\tLoss: -0.015270\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.8\tLoss: 0.022816\n",
      "\n",
      "Train Epoch: 285\tAttack_Accuracy: 4896/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 285\tmaintain_Accuracy: 9885/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 285\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 285\tmaintain_Accuracy: 8232/10593 (78%)\n",
      "\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.0\tLoss: 0.025122\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.2\tLoss: 0.025121\n",
      "tensor(-0.0364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.4\tLoss: -0.036353\n",
      "tensor(-0.0225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.6\tLoss: -0.022459\n",
      "tensor(-0.0145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.8\tLoss: -0.014496\n",
      "\n",
      "Test Epoch: 286\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 286\tmaintain_Accuracy: 8234/10593 (78%)\n",
      "\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.0\tLoss: 0.001200\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.2\tLoss: 0.012347\n",
      "tensor(-0.0202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.4\tLoss: -0.020154\n",
      "tensor(-0.0152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.6\tLoss: -0.015186\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.8\tLoss: 0.013861\n",
      "\n",
      "Test Epoch: 287\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 287\tmaintain_Accuracy: 8236/10593 (78%)\n",
      "\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.0\tLoss: 0.032696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.2\tLoss: -0.011612\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.4\tLoss: 0.003095\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.6\tLoss: 0.022618\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.8\tLoss: 0.014573\n",
      "\n",
      "Test Epoch: 288\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 288\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.0\tLoss: 0.029220\n",
      "tensor(-0.0003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.2\tLoss: -0.000251\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.4\tLoss: 0.007130\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.6\tLoss: 0.011724\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.8\tLoss: 0.005232\n",
      "\n",
      "Test Epoch: 289\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 289\tmaintain_Accuracy: 8220/10593 (78%)\n",
      "\n",
      "tensor(-0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.0\tLoss: -0.029107\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.2\tLoss: 0.003544\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.4\tLoss: 0.030829\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.6\tLoss: 0.013832\n",
      "tensor(-0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.8\tLoss: -0.002094\n",
      "\n",
      "Train Epoch: 290\tAttack_Accuracy: 4880/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 290\tmaintain_Accuracy: 9968/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 290\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 290\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(-0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.0\tLoss: -0.011818\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.2\tLoss: 0.006231\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.4\tLoss: 0.014305\n",
      "tensor(-0.0245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.6\tLoss: -0.024458\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.8\tLoss: 0.012706\n",
      "\n",
      "Test Epoch: 291\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 291\tmaintain_Accuracy: 8218/10593 (78%)\n",
      "\n",
      "tensor(0.0541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.0\tLoss: 0.054071\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.2\tLoss: 0.021941\n",
      "tensor(-0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.4\tLoss: -0.003686\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.6\tLoss: 0.022843\n",
      "tensor(-0.0427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.8\tLoss: -0.042652\n",
      "\n",
      "Test Epoch: 292\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 292\tmaintain_Accuracy: 8241/10593 (78%)\n",
      "\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.0\tLoss: 0.030767\n",
      "tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.2\tLoss: 0.060117\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.4\tLoss: 0.005591\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.6\tLoss: 0.004195\n",
      "tensor(-0.0251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.8\tLoss: -0.025103\n",
      "\n",
      "Test Epoch: 293\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 293\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.0\tLoss: 0.013466\n",
      "tensor(-0.0157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.2\tLoss: -0.015726\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.4\tLoss: 0.001130\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.6\tLoss: 0.016145\n",
      "tensor(-0.0318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.8\tLoss: -0.031790\n",
      "\n",
      "Test Epoch: 294\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 294\tmaintain_Accuracy: 8236/10593 (78%)\n",
      "\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.0\tLoss: 0.041227\n",
      "tensor(-0.0286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.2\tLoss: -0.028642\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.4\tLoss: 0.021022\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.6\tLoss: 0.022953\n",
      "tensor(0.0381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.8\tLoss: 0.038101\n",
      "\n",
      "Train Epoch: 295\tAttack_Accuracy: 4892/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 295\tmaintain_Accuracy: 9858/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 295\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 295\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.0\tLoss: 0.017818\n",
      "tensor(-0.0562, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.2\tLoss: -0.056248\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.4\tLoss: 0.008461\n",
      "tensor(-0.0325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.6\tLoss: -0.032533\n",
      "tensor(-0.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.8\tLoss: -0.000641\n",
      "\n",
      "Test Epoch: 296\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 296\tmaintain_Accuracy: 8235/10593 (78%)\n",
      "\n",
      "tensor(-0.0386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.0\tLoss: -0.038632\n",
      "tensor(-0.0003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.2\tLoss: -0.000320\n",
      "tensor(0.0336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.4\tLoss: 0.033557\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.6\tLoss: 0.005027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.8\tLoss: -0.006308\n",
      "\n",
      "Test Epoch: 297\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 297\tmaintain_Accuracy: 8219/10593 (78%)\n",
      "\n",
      "tensor(0.0240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.0\tLoss: 0.024023\n",
      "tensor(-0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.2\tLoss: -0.004955\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.4\tLoss: 0.009238\n",
      "tensor(0.0239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.6\tLoss: 0.023872\n",
      "tensor(-0.0273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.8\tLoss: -0.027321\n",
      "\n",
      "Test Epoch: 298\tAttack_Accuracy: 320/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 298\tmaintain_Accuracy: 8231/10593 (78%)\n",
      "\n",
      "tensor(-0.0310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.0\tLoss: -0.031042\n",
      "tensor(0.0319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.2\tLoss: 0.031870\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.4\tLoss: 0.028318\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.6\tLoss: 0.011221\n",
      "tensor(0.0334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.8\tLoss: 0.033422\n",
      "\n",
      "Test Epoch: 299\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 299\tmaintain_Accuracy: 8229/10593 (78%)\n",
      "\n",
      "tensor(-0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.0\tLoss: -0.001125\n",
      "tensor(-0.0125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.2\tLoss: -0.012480\n",
      "tensor(-0.0344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.4\tLoss: -0.034370\n",
      "tensor(-0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.6\tLoss: -0.009867\n",
      "tensor(-0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.8\tLoss: -0.000682\n",
      "\n",
      "Train Epoch: 300\tAttack_Accuracy: 4945/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 300\tmaintain_Accuracy: 9917/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 300\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 300\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.0\tLoss: 0.055761\n",
      "tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.2\tLoss: 0.062565\n",
      "tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.4\tLoss: 0.053567\n",
      "tensor(-0.0338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.6\tLoss: -0.033843\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.8\tLoss: 0.015618\n",
      "\n",
      "Test Epoch: 301\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 301\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.0\tLoss: -0.011472\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.2\tLoss: 0.019218\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.4\tLoss: 0.020965\n",
      "tensor(-0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.6\tLoss: -0.005907\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.8\tLoss: 0.021900\n",
      "\n",
      "Test Epoch: 302\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 302\tmaintain_Accuracy: 8255/10593 (78%)\n",
      "\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.0\tLoss: 0.018237\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.2\tLoss: 0.003519\n",
      "tensor(-0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.4\tLoss: -0.003674\n",
      "tensor(-0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.6\tLoss: -0.005969\n",
      "tensor(-0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.8\tLoss: -0.011950\n",
      "\n",
      "Test Epoch: 303\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 303\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(-0.0265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.0\tLoss: -0.026515\n",
      "tensor(-0.0251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.2\tLoss: -0.025114\n",
      "tensor(-0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.4\tLoss: -0.008072\n",
      "tensor(0.0675, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.6\tLoss: 0.067528\n",
      "tensor(-0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.8\tLoss: -0.019186\n",
      "\n",
      "Test Epoch: 304\tAttack_Accuracy: 314/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 304\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.0\tLoss: 0.022590\n",
      "tensor(-0.0048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.2\tLoss: -0.004759\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.4\tLoss: 0.019433\n",
      "tensor(-0.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.6\tLoss: -0.012939\n",
      "tensor(-0.0097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.8\tLoss: -0.009673\n",
      "\n",
      "Train Epoch: 305\tAttack_Accuracy: 4943/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 305\tmaintain_Accuracy: 9937/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 305\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 305\tmaintain_Accuracy: 8252/10593 (78%)\n",
      "\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.0\tLoss: 0.038703\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.2\tLoss: 0.005242\n",
      "tensor(0.0257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.4\tLoss: 0.025687\n",
      "tensor(-0.0385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.6\tLoss: -0.038466\n",
      "tensor(-0.0512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.8\tLoss: -0.051211\n",
      "\n",
      "Test Epoch: 306\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 306\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.0\tLoss: 0.001817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.2\tLoss: 0.011931\n",
      "tensor(-0.0384, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.4\tLoss: -0.038356\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.6\tLoss: 0.022766\n",
      "tensor(-0.0298, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.8\tLoss: -0.029779\n",
      "\n",
      "Test Epoch: 307\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 307\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.0\tLoss: 0.002320\n",
      "tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.2\tLoss: 0.057181\n",
      "tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.4\tLoss: -0.000884\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.6\tLoss: 0.001605\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.8\tLoss: 0.038261\n",
      "\n",
      "Test Epoch: 308\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 308\tmaintain_Accuracy: 8234/10593 (78%)\n",
      "\n",
      "tensor(-0.0158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.0\tLoss: -0.015805\n",
      "tensor(-0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.2\tLoss: -0.004172\n",
      "tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.4\tLoss: 0.060644\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.6\tLoss: 0.017082\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.8\tLoss: 0.002028\n",
      "\n",
      "Test Epoch: 309\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 309\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(0.0313, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.0\tLoss: 0.031288\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.2\tLoss: 0.000869\n",
      "tensor(-0.0272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.4\tLoss: -0.027161\n",
      "tensor(-0.0057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.6\tLoss: -0.005750\n",
      "tensor(-0.0107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.8\tLoss: -0.010667\n",
      "\n",
      "Train Epoch: 310\tAttack_Accuracy: 4933/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 310\tmaintain_Accuracy: 9898/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 310\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 310\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(-0.0457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.0\tLoss: -0.045725\n",
      "tensor(-0.0353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.2\tLoss: -0.035272\n",
      "tensor(-0.0048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.4\tLoss: -0.004829\n",
      "tensor(-0.0258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.6\tLoss: -0.025841\n",
      "tensor(-0.0233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.8\tLoss: -0.023259\n",
      "\n",
      "Test Epoch: 311\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 311\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(-0.0113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.0\tLoss: -0.011309\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.2\tLoss: 0.022034\n",
      "tensor(-0.0094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.4\tLoss: -0.009361\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.6\tLoss: 0.011043\n",
      "tensor(-0.0077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.8\tLoss: -0.007698\n",
      "\n",
      "Test Epoch: 312\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 312\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.0\tLoss: 0.004943\n",
      "tensor(-0.0344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.2\tLoss: -0.034400\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.4\tLoss: 0.004574\n",
      "tensor(-0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.6\tLoss: -0.003876\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.8\tLoss: 0.024688\n",
      "\n",
      "Test Epoch: 313\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 313\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(-0.0003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.0\tLoss: -0.000306\n",
      "tensor(-0.0294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.2\tLoss: -0.029403\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.4\tLoss: 0.024579\n",
      "tensor(-0.0354, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.6\tLoss: -0.035418\n",
      "tensor(0.0340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.8\tLoss: 0.034032\n",
      "\n",
      "Test Epoch: 314\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 314\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.0\tLoss: 0.028349\n",
      "tensor(-0.0157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.2\tLoss: -0.015695\n",
      "tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.4\tLoss: 0.050094\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.6\tLoss: 0.030000\n",
      "tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.8\tLoss: 0.052558\n",
      "\n",
      "Train Epoch: 315\tAttack_Accuracy: 4853/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 315\tmaintain_Accuracy: 9882/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 315\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 315\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(-0.0518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.0\tLoss: -0.051786\n",
      "tensor(-0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.2\tLoss: -0.006481\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.4\tLoss: 0.008473\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.6\tLoss: 0.070604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.8\tLoss: 0.022955\n",
      "\n",
      "Test Epoch: 316\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 316\tmaintain_Accuracy: 8238/10593 (78%)\n",
      "\n",
      "tensor(-0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.0\tLoss: -0.004205\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.2\tLoss: 0.000380\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.4\tLoss: 0.007548\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.6\tLoss: 0.028711\n",
      "tensor(0.0240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.8\tLoss: 0.023950\n",
      "\n",
      "Test Epoch: 317\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 317\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.0\tLoss: 0.021054\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.2\tLoss: 0.024112\n",
      "tensor(0.0328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.4\tLoss: 0.032776\n",
      "tensor(-0.0127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.6\tLoss: -0.012672\n",
      "tensor(-0.0295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.8\tLoss: -0.029477\n",
      "\n",
      "Test Epoch: 318\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 318\tmaintain_Accuracy: 8235/10593 (78%)\n",
      "\n",
      "tensor(-0.0097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.0\tLoss: -0.009713\n",
      "tensor(-0.0137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.2\tLoss: -0.013663\n",
      "tensor(-0.0175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.4\tLoss: -0.017531\n",
      "tensor(-0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.6\tLoss: -0.012126\n",
      "tensor(-0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.8\tLoss: -0.000241\n",
      "\n",
      "Test Epoch: 319\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 319\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.0\tLoss: -0.000528\n",
      "tensor(-0.0079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.2\tLoss: -0.007930\n",
      "tensor(-0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.4\tLoss: -0.005566\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.6\tLoss: 0.022625\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.8\tLoss: 0.003575\n",
      "\n",
      "Train Epoch: 320\tAttack_Accuracy: 4888/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 320\tmaintain_Accuracy: 9894/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 320\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 320\tmaintain_Accuracy: 8241/10593 (78%)\n",
      "\n",
      "tensor(-0.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.0\tLoss: -0.007953\n",
      "tensor(-0.0275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.2\tLoss: -0.027514\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.4\tLoss: 0.021714\n",
      "tensor(-0.0130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.6\tLoss: -0.012973\n",
      "tensor(-0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.8\tLoss: -0.029097\n",
      "\n",
      "Test Epoch: 321\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 321\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.0\tLoss: 0.017889\n",
      "tensor(-0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.2\tLoss: -0.005903\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.4\tLoss: 0.022633\n",
      "tensor(-0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.6\tLoss: -0.002769\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.8\tLoss: 0.011956\n",
      "\n",
      "Test Epoch: 322\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 322\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.0\tLoss: 0.018077\n",
      "tensor(0.0524, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.2\tLoss: 0.052418\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.4\tLoss: 0.027993\n",
      "tensor(-0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.6\tLoss: -0.026629\n",
      "tensor(-0.0285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.8\tLoss: -0.028512\n",
      "\n",
      "Test Epoch: 323\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 323\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(-0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.0\tLoss: -0.011635\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.2\tLoss: 0.016628\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.4\tLoss: 0.001727\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.6\tLoss: 0.013991\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.8\tLoss: 0.019834\n",
      "\n",
      "Test Epoch: 324\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 324\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.0\tLoss: -0.023992\n",
      "tensor(-0.0248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.2\tLoss: -0.024777\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.4\tLoss: 0.003081\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.6\tLoss: 0.006507\n",
      "tensor(-0.0182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.8\tLoss: -0.018163\n",
      "\n",
      "Train Epoch: 325\tAttack_Accuracy: 4983/6400 (78%)\n",
      "\n",
      "\n",
      "Train Epoch: 325\tmaintain_Accuracy: 9878/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 325\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 325\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.0\tLoss: 0.038509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.2\tLoss: 0.015005\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.4\tLoss: 0.005722\n",
      "tensor(-0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.6\tLoss: -0.006475\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.8\tLoss: 0.032150\n",
      "\n",
      "Test Epoch: 326\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 326\tmaintain_Accuracy: 8256/10593 (78%)\n",
      "\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.0\tLoss: 0.010618\n",
      "tensor(-0.0358, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.2\tLoss: -0.035801\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.4\tLoss: 0.023666\n",
      "tensor(-0.0246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.6\tLoss: -0.024625\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.8\tLoss: 0.006479\n",
      "\n",
      "Test Epoch: 327\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 327\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.0\tLoss: 0.008255\n",
      "tensor(0.0371, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.2\tLoss: 0.037089\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.4\tLoss: 0.006522\n",
      "tensor(-0.0181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.6\tLoss: -0.018143\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.8\tLoss: 0.043412\n",
      "\n",
      "Test Epoch: 328\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 328\tmaintain_Accuracy: 8237/10593 (78%)\n",
      "\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.0\tLoss: 0.003011\n",
      "tensor(-0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.2\tLoss: -0.006039\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.4\tLoss: 0.042392\n",
      "tensor(-0.0124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.6\tLoss: -0.012351\n",
      "tensor(0.0257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.8\tLoss: 0.025662\n",
      "\n",
      "Test Epoch: 329\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 329\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(-0.0202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.0\tLoss: -0.020219\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.2\tLoss: 0.038034\n",
      "tensor(-0.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.4\tLoss: -0.012926\n",
      "tensor(-0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.6\tLoss: -0.001868\n",
      "tensor(-0.0156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.8\tLoss: -0.015586\n",
      "\n",
      "Train Epoch: 330\tAttack_Accuracy: 4888/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 330\tmaintain_Accuracy: 9925/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 330\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 330\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.0\tLoss: -0.001876\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.2\tLoss: 0.003026\n",
      "tensor(0.0379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.4\tLoss: 0.037898\n",
      "tensor(-0.0393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.6\tLoss: -0.039301\n",
      "tensor(-0.0222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.8\tLoss: -0.022168\n",
      "\n",
      "Test Epoch: 331\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 331\tmaintain_Accuracy: 8236/10593 (78%)\n",
      "\n",
      "tensor(-0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.0\tLoss: -0.009578\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.2\tLoss: 0.014247\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.4\tLoss: 0.001057\n",
      "tensor(-0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.6\tLoss: -0.015395\n",
      "tensor(-0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.8\tLoss: -0.006927\n",
      "\n",
      "Test Epoch: 332\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 332\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.0\tLoss: 0.004754\n",
      "tensor(-0.0325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.2\tLoss: -0.032507\n",
      "tensor(-0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.4\tLoss: -0.029224\n",
      "tensor(-0.0200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.6\tLoss: -0.019970\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.8\tLoss: 0.018825\n",
      "\n",
      "Test Epoch: 333\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 333\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(-0.0018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.0\tLoss: -0.001829\n",
      "tensor(-0.0235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.2\tLoss: -0.023518\n",
      "tensor(-0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.4\tLoss: -0.019909\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.6\tLoss: 0.009979\n",
      "tensor(-0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.8\tLoss: -0.017144\n",
      "\n",
      "Test Epoch: 334\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 334\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.0\tLoss: 0.000896\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.2\tLoss: 0.001459\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.4\tLoss: 0.003549\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.6\tLoss: 0.002116\n",
      "tensor(0.0382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.8\tLoss: 0.038158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 335\tAttack_Accuracy: 4921/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 335\tmaintain_Accuracy: 9889/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 335\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 335\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.0\tLoss: 0.012494\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.2\tLoss: -0.001409\n",
      "tensor(-0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.4\tLoss: -0.003336\n",
      "tensor(-0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.6\tLoss: -0.011937\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.8\tLoss: 0.025873\n",
      "\n",
      "Test Epoch: 336\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 336\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.0\tLoss: 0.021920\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.2\tLoss: 0.009270\n",
      "tensor(-0.0473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.4\tLoss: -0.047306\n",
      "tensor(-0.0345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.6\tLoss: -0.034492\n",
      "tensor(-0.0124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.8\tLoss: -0.012450\n",
      "\n",
      "Test Epoch: 337\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 337\tmaintain_Accuracy: 8255/10593 (78%)\n",
      "\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.0\tLoss: 0.051781\n",
      "tensor(-0.0153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.2\tLoss: -0.015258\n",
      "tensor(-0.0012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.4\tLoss: -0.001214\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.6\tLoss: 0.039752\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.8\tLoss: 0.046321\n",
      "\n",
      "Test Epoch: 338\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 338\tmaintain_Accuracy: 8252/10593 (78%)\n",
      "\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.0\tLoss: 0.009468\n",
      "tensor(-0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.2\tLoss: -0.010214\n",
      "tensor(-0.0057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.4\tLoss: -0.005702\n",
      "tensor(-0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.6\tLoss: -0.002399\n",
      "tensor(-0.0399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.8\tLoss: -0.039869\n",
      "\n",
      "Test Epoch: 339\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 339\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.0\tLoss: 0.035552\n",
      "tensor(-0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.2\tLoss: -0.001135\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.4\tLoss: 0.018178\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.6\tLoss: 0.028051\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.8\tLoss: 0.010461\n",
      "\n",
      "Train Epoch: 340\tAttack_Accuracy: 4949/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 340\tmaintain_Accuracy: 9900/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 340\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 340\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(-0.0497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.0\tLoss: -0.049730\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.2\tLoss: 0.024312\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.4\tLoss: 0.004946\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.6\tLoss: 0.041052\n",
      "tensor(-0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.8\tLoss: -0.009008\n",
      "\n",
      "Test Epoch: 341\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 341\tmaintain_Accuracy: 8253/10593 (78%)\n",
      "\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.0\tLoss: 0.012324\n",
      "tensor(-0.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.2\tLoss: -0.024979\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.4\tLoss: 0.009325\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.6\tLoss: 0.019096\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.8\tLoss: 0.018336\n",
      "\n",
      "Test Epoch: 342\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 342\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.0\tLoss: 0.025974\n",
      "tensor(-0.0043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.2\tLoss: -0.004342\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.4\tLoss: 0.025825\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.6\tLoss: 0.010772\n",
      "tensor(-0.0068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.8\tLoss: -0.006812\n",
      "\n",
      "Test Epoch: 343\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 343\tmaintain_Accuracy: 8253/10593 (78%)\n",
      "\n",
      "tensor(-0.0088, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.0\tLoss: -0.008799\n",
      "tensor(-0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.2\tLoss: -0.002694\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.4\tLoss: 0.007542\n",
      "tensor(-0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.6\tLoss: -0.004921\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.8\tLoss: 0.041706\n",
      "\n",
      "Test Epoch: 344\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 344\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(0.0453, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.0\tLoss: 0.045347\n",
      "tensor(-0.0222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.2\tLoss: -0.022217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.4\tLoss: -0.020704\n",
      "tensor(-0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.6\tLoss: -0.000803\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.8\tLoss: 0.007183\n",
      "\n",
      "Train Epoch: 345\tAttack_Accuracy: 4946/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 345\tmaintain_Accuracy: 9950/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 345\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 345\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.0\tLoss: 0.026876\n",
      "tensor(-0.0319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.2\tLoss: -0.031856\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.4\tLoss: 0.006853\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.6\tLoss: 0.023560\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.8\tLoss: 0.009782\n",
      "\n",
      "Test Epoch: 346\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 346\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.0\tLoss: 0.003728\n",
      "tensor(-0.0279, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.2\tLoss: -0.027921\n",
      "tensor(-0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.4\tLoss: -0.012758\n",
      "tensor(-0.0379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.6\tLoss: -0.037931\n",
      "tensor(-0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.8\tLoss: -0.006401\n",
      "\n",
      "Test Epoch: 347\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 347\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.0\tLoss: 0.023958\n",
      "tensor(-0.0373, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.2\tLoss: -0.037334\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.4\tLoss: 0.008344\n",
      "tensor(-0.0157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.6\tLoss: -0.015659\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.8\tLoss: 0.043718\n",
      "\n",
      "Test Epoch: 348\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 348\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.0\tLoss: 0.012927\n",
      "tensor(-0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.2\tLoss: -0.005495\n",
      "tensor(0.0296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.4\tLoss: 0.029551\n",
      "tensor(-0.0113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.6\tLoss: -0.011281\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.8\tLoss: 0.020942\n",
      "\n",
      "Test Epoch: 349\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 349\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.0\tLoss: 0.031018\n",
      "tensor(-0.0388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.2\tLoss: -0.038813\n",
      "tensor(-0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.4\tLoss: -0.010182\n",
      "tensor(-0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.6\tLoss: -0.005365\n",
      "tensor(-0.0231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.8\tLoss: -0.023068\n",
      "\n",
      "Train Epoch: 350\tAttack_Accuracy: 4939/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 350\tmaintain_Accuracy: 9951/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 350\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 350\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.0\tLoss: 0.023742\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.2\tLoss: 0.002902\n",
      "tensor(-0.0249, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.4\tLoss: -0.024886\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.6\tLoss: 0.001473\n",
      "tensor(-0.0126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.8\tLoss: -0.012634\n",
      "\n",
      "Test Epoch: 351\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 351\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.0\tLoss: 0.004223\n",
      "tensor(-0.0197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.2\tLoss: -0.019714\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.4\tLoss: 0.009932\n",
      "tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.6\tLoss: 0.050187\n",
      "tensor(0.0396, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.8\tLoss: 0.039616\n",
      "\n",
      "Test Epoch: 352\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 352\tmaintain_Accuracy: 8240/10593 (78%)\n",
      "\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.0\tLoss: 0.036057\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.2\tLoss: 0.004902\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.4\tLoss: 0.004190\n",
      "tensor(-0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.6\tLoss: -0.013073\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.8\tLoss: 0.014977\n",
      "\n",
      "Test Epoch: 353\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 353\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.0\tLoss: -0.010029\n",
      "tensor(-0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.2\tLoss: -0.002416\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.4\tLoss: 0.001102\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.6\tLoss: 0.017463\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.8\tLoss: 0.009872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 354\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 354\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.0\tLoss: 0.029708\n",
      "tensor(-0.0322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.2\tLoss: -0.032213\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.4\tLoss: 0.011856\n",
      "tensor(-0.0326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.6\tLoss: -0.032613\n",
      "tensor(-0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.8\tLoss: -0.009909\n",
      "\n",
      "Train Epoch: 355\tAttack_Accuracy: 4866/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 355\tmaintain_Accuracy: 9886/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 355\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 355\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(-0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.0\tLoss: -0.004940\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.2\tLoss: 0.006789\n",
      "tensor(-0.0040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.4\tLoss: -0.003963\n",
      "tensor(-0.0343, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.6\tLoss: -0.034283\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.8\tLoss: 0.037450\n",
      "\n",
      "Test Epoch: 356\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 356\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(-0.0312, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.0\tLoss: -0.031222\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.2\tLoss: 0.015855\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.4\tLoss: 0.017141\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.6\tLoss: 0.011185\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.8\tLoss: 0.023448\n",
      "\n",
      "Test Epoch: 357\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 357\tmaintain_Accuracy: 8253/10593 (78%)\n",
      "\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.0\tLoss: 0.007801\n",
      "tensor(-0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.2\tLoss: -0.012091\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.4\tLoss: 0.030966\n",
      "tensor(-0.0285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.6\tLoss: -0.028495\n",
      "tensor(-0.0031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.8\tLoss: -0.003130\n",
      "\n",
      "Test Epoch: 358\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 358\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.0\tLoss: 0.022405\n",
      "tensor(-0.0316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.2\tLoss: -0.031582\n",
      "tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.4\tLoss: 0.060132\n",
      "tensor(-0.0046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.6\tLoss: -0.004627\n",
      "tensor(-0.0258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.8\tLoss: -0.025775\n",
      "\n",
      "Test Epoch: 359\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 359\tmaintain_Accuracy: 8237/10593 (78%)\n",
      "\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.0\tLoss: 0.004380\n",
      "tensor(-0.0100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.2\tLoss: -0.009979\n",
      "tensor(-0.0319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.4\tLoss: -0.031904\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.6\tLoss: 0.010620\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.8\tLoss: 0.027619\n",
      "\n",
      "Train Epoch: 360\tAttack_Accuracy: 4946/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 360\tmaintain_Accuracy: 9928/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 360\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 360\tmaintain_Accuracy: 8236/10593 (78%)\n",
      "\n",
      "tensor(-0.0140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.0\tLoss: -0.013956\n",
      "tensor(-0.0186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.2\tLoss: -0.018567\n",
      "tensor(-0.0138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.4\tLoss: -0.013848\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.6\tLoss: 0.002232\n",
      "tensor(-0.0362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.8\tLoss: -0.036213\n",
      "\n",
      "Test Epoch: 361\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 361\tmaintain_Accuracy: 8236/10593 (78%)\n",
      "\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.0\tLoss: 0.012405\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.2\tLoss: 0.000867\n",
      "tensor(0.0342, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.4\tLoss: 0.034199\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.6\tLoss: 0.026109\n",
      "tensor(-0.0072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.8\tLoss: -0.007206\n",
      "\n",
      "Test Epoch: 362\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 362\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.0\tLoss: 0.007764\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.2\tLoss: 0.010949\n",
      "tensor(-0.0216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.4\tLoss: -0.021582\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.6\tLoss: 0.002808\n",
      "tensor(-0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.8\tLoss: -0.014253\n",
      "\n",
      "Test Epoch: 363\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 363\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.0\tLoss: 0.011729\n",
      "tensor(-0.0062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.2\tLoss: -0.006191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.4\tLoss: -0.002242\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.6\tLoss: 0.017784\n",
      "tensor(-0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.8\tLoss: -0.023710\n",
      "\n",
      "Test Epoch: 364\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 364\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.0\tLoss: 0.021340\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.2\tLoss: 0.011830\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.4\tLoss: 0.012120\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.6\tLoss: 0.003253\n",
      "tensor(-0.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.8\tLoss: -0.021018\n",
      "\n",
      "Train Epoch: 365\tAttack_Accuracy: 4933/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 365\tmaintain_Accuracy: 9885/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 365\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 365\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.0\tLoss: 0.024710\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.2\tLoss: 0.014045\n",
      "tensor(-0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.4\tLoss: -0.006002\n",
      "tensor(-0.0094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.6\tLoss: -0.009413\n",
      "tensor(0.0372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.8\tLoss: 0.037187\n",
      "\n",
      "Test Epoch: 366\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 366\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(-0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.0\tLoss: -0.007826\n",
      "tensor(-0.0391, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.2\tLoss: -0.039130\n",
      "tensor(-0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.4\tLoss: -0.012062\n",
      "tensor(-0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.6\tLoss: -0.008291\n",
      "tensor(-0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.8\tLoss: -0.003406\n",
      "\n",
      "Test Epoch: 367\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 367\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(-0.0478, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.0\tLoss: -0.047781\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.2\tLoss: 0.011328\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.4\tLoss: 0.039204\n",
      "tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.6\tLoss: 0.064297\n",
      "tensor(0.0464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.8\tLoss: 0.046385\n",
      "\n",
      "Test Epoch: 368\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 368\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(-0.0073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.0\tLoss: -0.007296\n",
      "tensor(-0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.2\tLoss: -0.012116\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.4\tLoss: 0.002862\n",
      "tensor(0.0519, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.6\tLoss: 0.051895\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.8\tLoss: 0.006423\n",
      "\n",
      "Test Epoch: 369\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 369\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.0\tLoss: -0.027848\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.2\tLoss: 0.000265\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.4\tLoss: 0.037025\n",
      "tensor(-0.0330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.6\tLoss: -0.032985\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.8\tLoss: 0.010880\n",
      "\n",
      "Train Epoch: 370\tAttack_Accuracy: 4951/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 370\tmaintain_Accuracy: 9907/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 370\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 370\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.0\tLoss: 0.021158\n",
      "tensor(-0.0207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.2\tLoss: -0.020721\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.4\tLoss: 0.002090\n",
      "tensor(-0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.6\tLoss: -0.008492\n",
      "tensor(0.0389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.8\tLoss: 0.038851\n",
      "\n",
      "Test Epoch: 371\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 371\tmaintain_Accuracy: 8237/10593 (78%)\n",
      "\n",
      "tensor(-0.0151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.0\tLoss: -0.015113\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.2\tLoss: 0.018977\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.4\tLoss: 0.009384\n",
      "tensor(-0.0151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.6\tLoss: -0.015067\n",
      "tensor(0.0317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.8\tLoss: 0.031733\n",
      "\n",
      "Test Epoch: 372\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 372\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(-0.0204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.0\tLoss: -0.020435\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.2\tLoss: 0.011856\n",
      "tensor(-0.0457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.4\tLoss: -0.045730\n",
      "tensor(-0.0405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.6\tLoss: -0.040467\n",
      "tensor(-0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.8\tLoss: -0.005238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 373\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 373\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.0\tLoss: 0.005593\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.2\tLoss: 0.010531\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.4\tLoss: 0.006895\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.6\tLoss: 0.031122\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.8\tLoss: 0.005606\n",
      "\n",
      "Test Epoch: 374\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 374\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.0\tLoss: 0.029421\n",
      "tensor(-0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.2\tLoss: -0.001274\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.4\tLoss: 0.018477\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.6\tLoss: 0.010637\n",
      "tensor(-0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.8\tLoss: -0.017720\n",
      "\n",
      "Train Epoch: 375\tAttack_Accuracy: 4920/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 375\tmaintain_Accuracy: 9867/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 375\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 375\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(0.0254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.0\tLoss: 0.025414\n",
      "tensor(-0.0158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.2\tLoss: -0.015768\n",
      "tensor(-0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.4\tLoss: -0.005952\n",
      "tensor(-0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.6\tLoss: -0.005373\n",
      "tensor(-0.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.8\tLoss: -0.000557\n",
      "\n",
      "Test Epoch: 376\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 376\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.0\tLoss: 0.012843\n",
      "tensor(-0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.2\tLoss: -0.008924\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.4\tLoss: 0.012221\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.6\tLoss: 0.000152\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.8\tLoss: 0.019850\n",
      "\n",
      "Test Epoch: 377\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 377\tmaintain_Accuracy: 8253/10593 (78%)\n",
      "\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.0\tLoss: 0.003905\n",
      "tensor(-0.0302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.2\tLoss: -0.030218\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.4\tLoss: 0.015475\n",
      "tensor(-0.0182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.6\tLoss: -0.018238\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.8\tLoss: 0.021686\n",
      "\n",
      "Test Epoch: 378\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 378\tmaintain_Accuracy: 8252/10593 (78%)\n",
      "\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.0\tLoss: 0.029240\n",
      "tensor(-0.0246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.2\tLoss: -0.024594\n",
      "tensor(-0.0409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.4\tLoss: -0.040889\n",
      "tensor(-0.0106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.6\tLoss: -0.010557\n",
      "tensor(-0.0141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.8\tLoss: -0.014130\n",
      "\n",
      "Test Epoch: 379\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 379\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(-0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.0\tLoss: -0.029126\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.2\tLoss: 0.001808\n",
      "tensor(0.0473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.4\tLoss: 0.047282\n",
      "tensor(-0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.6\tLoss: -0.019175\n",
      "tensor(-0.0155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.8\tLoss: -0.015514\n",
      "\n",
      "Train Epoch: 380\tAttack_Accuracy: 4908/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 380\tmaintain_Accuracy: 9928/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 380\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 380\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.0\tLoss: -0.036609\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.2\tLoss: 0.022427\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.4\tLoss: 0.018337\n",
      "tensor(-0.0394, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.6\tLoss: -0.039411\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.8\tLoss: 0.004085\n",
      "\n",
      "Test Epoch: 381\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 381\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.0\tLoss: 0.008071\n",
      "tensor(-0.0309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.2\tLoss: -0.030854\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.4\tLoss: 0.036208\n",
      "tensor(-0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.6\tLoss: -0.005511\n",
      "tensor(-0.0343, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.8\tLoss: -0.034298\n",
      "\n",
      "Test Epoch: 382\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 382\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.0\tLoss: 0.033803\n",
      "tensor(-0.0178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.2\tLoss: -0.017792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.4\tLoss: -0.014396\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.6\tLoss: 0.014192\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.8\tLoss: 0.028777\n",
      "\n",
      "Test Epoch: 383\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 383\tmaintain_Accuracy: 8256/10593 (78%)\n",
      "\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.0\tLoss: 0.025981\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.2\tLoss: 0.029708\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.4\tLoss: 0.026630\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.6\tLoss: 0.007292\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.8\tLoss: 0.012085\n",
      "\n",
      "Test Epoch: 384\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 384\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.0\tLoss: 0.015425\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.2\tLoss: 0.002363\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.4\tLoss: 0.013498\n",
      "tensor(-0.0101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.6\tLoss: -0.010074\n",
      "tensor(-0.0178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.8\tLoss: -0.017780\n",
      "\n",
      "Train Epoch: 385\tAttack_Accuracy: 4956/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 385\tmaintain_Accuracy: 9976/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 385\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 385\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.0\tLoss: 0.020665\n",
      "tensor(-0.0271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.2\tLoss: -0.027116\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.4\tLoss: 0.024928\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.6\tLoss: 0.004823\n",
      "tensor(-0.0016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.8\tLoss: -0.001633\n",
      "\n",
      "Test Epoch: 386\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 386\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.0\tLoss: 0.017724\n",
      "tensor(-0.0264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.2\tLoss: -0.026393\n",
      "tensor(0.0273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.4\tLoss: 0.027331\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.6\tLoss: 0.028673\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.8\tLoss: 0.009947\n",
      "\n",
      "Test Epoch: 387\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 387\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0279, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.0\tLoss: 0.027900\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.2\tLoss: 0.030305\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.4\tLoss: 0.027165\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.6\tLoss: 0.001018\n",
      "tensor(-0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.8\tLoss: -0.003167\n",
      "\n",
      "Test Epoch: 388\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 388\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.0\tLoss: 0.060186\n",
      "tensor(-0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.2\tLoss: -0.001883\n",
      "tensor(-0.0283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.4\tLoss: -0.028271\n",
      "tensor(-0.0071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.6\tLoss: -0.007075\n",
      "tensor(0.0584, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.8\tLoss: 0.058438\n",
      "\n",
      "Test Epoch: 389\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 389\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.0\tLoss: 0.021317\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.2\tLoss: 0.009551\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.4\tLoss: 0.004981\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.6\tLoss: 0.011406\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.8\tLoss: 0.014317\n",
      "\n",
      "Train Epoch: 390\tAttack_Accuracy: 4906/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 390\tmaintain_Accuracy: 9932/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 390\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 390\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.0\tLoss: 0.010952\n",
      "tensor(-0.0195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.2\tLoss: -0.019486\n",
      "tensor(-0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.4\tLoss: -0.011773\n",
      "tensor(-0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.6\tLoss: -0.012835\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.8\tLoss: 0.028263\n",
      "\n",
      "Test Epoch: 391\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 391\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.0\tLoss: 0.002203\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.2\tLoss: 0.028591\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.4\tLoss: 0.008573\n",
      "tensor(-0.0213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.6\tLoss: -0.021346\n",
      "tensor(0.0378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.8\tLoss: 0.037798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 392\tAttack_Accuracy: 315/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 392\tmaintain_Accuracy: 8256/10593 (78%)\n",
      "\n",
      "tensor(0.0439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.0\tLoss: 0.043862\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.2\tLoss: 0.004070\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.4\tLoss: 0.001337\n",
      "tensor(0.0382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.6\tLoss: 0.038175\n",
      "tensor(-0.0040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.8\tLoss: -0.003976\n",
      "\n",
      "Test Epoch: 393\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 393\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.0\tLoss: -0.006852\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.2\tLoss: 0.009765\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.4\tLoss: 0.001333\n",
      "tensor(-0.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.6\tLoss: -0.024655\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.8\tLoss: 0.011969\n",
      "\n",
      "Test Epoch: 394\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 394\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0448, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.0\tLoss: 0.044799\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.2\tLoss: 0.022597\n",
      "tensor(-0.0168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.4\tLoss: -0.016804\n",
      "tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.6\tLoss: -0.007036\n",
      "tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.8\tLoss: 0.053576\n",
      "\n",
      "Train Epoch: 395\tAttack_Accuracy: 4846/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 395\tmaintain_Accuracy: 9884/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 395\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 395\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.0\tLoss: 0.043455\n",
      "tensor(-0.0025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.2\tLoss: -0.002546\n",
      "tensor(-0.0025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.4\tLoss: -0.002497\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.6\tLoss: 0.011979\n",
      "tensor(-0.0108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.8\tLoss: -0.010765\n",
      "\n",
      "Test Epoch: 396\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 396\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(-0.0185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.0\tLoss: -0.018517\n",
      "tensor(-0.0159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.2\tLoss: -0.015907\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.4\tLoss: 0.017755\n",
      "tensor(-0.0468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.6\tLoss: -0.046787\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.8\tLoss: 0.023130\n",
      "\n",
      "Test Epoch: 397\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 397\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.0\tLoss: -0.037185\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.2\tLoss: 0.008421\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.4\tLoss: 0.051207\n",
      "tensor(-0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.6\tLoss: -0.008540\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.8\tLoss: 0.041055\n",
      "\n",
      "Test Epoch: 398\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 398\tmaintain_Accuracy: 8253/10593 (78%)\n",
      "\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.0\tLoss: 0.026575\n",
      "tensor(-0.0532, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.2\tLoss: -0.053151\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.4\tLoss: 0.026213\n",
      "tensor(-0.0101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.6\tLoss: -0.010131\n",
      "tensor(-0.0267, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.8\tLoss: -0.026686\n",
      "\n",
      "Test Epoch: 399\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 399\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.0\tLoss: 0.014192\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.2\tLoss: 0.020796\n",
      "tensor(0.0459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.4\tLoss: 0.045865\n",
      "tensor(0.0363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.6\tLoss: 0.036336\n",
      "tensor(-0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.8\tLoss: -0.012261\n",
      "\n",
      "Train Epoch: 400\tAttack_Accuracy: 4922/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 400\tmaintain_Accuracy: 9836/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 400\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 400\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.0\tLoss: -0.016370\n",
      "tensor(-0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.2\tLoss: -0.022988\n",
      "tensor(-0.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.4\tLoss: -0.025014\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.6\tLoss: 0.016619\n",
      "tensor(-0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.8\tLoss: -0.006391\n",
      "\n",
      "Test Epoch: 401\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 401\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(-0.0475, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.0\tLoss: -0.047508\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.2\tLoss: 0.003139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.4\tLoss: -0.021942\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.6\tLoss: 0.012623\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.8\tLoss: 0.020636\n",
      "\n",
      "Test Epoch: 402\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 402\tmaintain_Accuracy: 8252/10593 (78%)\n",
      "\n",
      "tensor(-0.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.0\tLoss: -0.006734\n",
      "tensor(-0.0153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.2\tLoss: -0.015332\n",
      "tensor(-0.0172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.4\tLoss: -0.017167\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.6\tLoss: 0.040526\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.8\tLoss: 0.031821\n",
      "\n",
      "Test Epoch: 403\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 403\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(-0.0138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.0\tLoss: -0.013835\n",
      "tensor(-0.0162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.2\tLoss: -0.016159\n",
      "tensor(-0.0377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.4\tLoss: -0.037731\n",
      "tensor(-0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.6\tLoss: -0.010289\n",
      "tensor(-0.0005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.8\tLoss: -0.000489\n",
      "\n",
      "Test Epoch: 404\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 404\tmaintain_Accuracy: 8253/10593 (78%)\n",
      "\n",
      "tensor(-0.0136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.0\tLoss: -0.013612\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.2\tLoss: 0.026858\n",
      "tensor(-0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.4\tLoss: -0.009347\n",
      "tensor(-0.0344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.6\tLoss: -0.034375\n",
      "tensor(-0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.8\tLoss: -0.010230\n",
      "\n",
      "Train Epoch: 405\tAttack_Accuracy: 4890/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 405\tmaintain_Accuracy: 9907/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 405\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 405\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(-0.0236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.0\tLoss: -0.023604\n",
      "tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.2\tLoss: 0.061757\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.4\tLoss: 0.024352\n",
      "tensor(-0.0470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.6\tLoss: -0.046956\n",
      "tensor(0.0254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.8\tLoss: 0.025378\n",
      "\n",
      "Test Epoch: 406\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 406\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.0\tLoss: 0.021528\n",
      "tensor(-0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.2\tLoss: -0.010178\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.4\tLoss: 0.029696\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.6\tLoss: 0.048903\n",
      "tensor(-0.0239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.8\tLoss: -0.023912\n",
      "\n",
      "Test Epoch: 407\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 407\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(-0.0373, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.0\tLoss: -0.037336\n",
      "tensor(-0.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.2\tLoss: -0.010944\n",
      "tensor(-0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.4\tLoss: -0.005131\n",
      "tensor(-0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.6\tLoss: -0.008562\n",
      "tensor(-0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.8\tLoss: -0.001529\n",
      "\n",
      "Test Epoch: 408\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 408\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.0\tLoss: 0.003304\n",
      "tensor(-0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.2\tLoss: -0.000226\n",
      "tensor(-0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.4\tLoss: -0.002890\n",
      "tensor(-0.0242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.6\tLoss: -0.024168\n",
      "tensor(-0.0124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.8\tLoss: -0.012413\n",
      "\n",
      "Test Epoch: 409\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 409\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.0\tLoss: 0.005096\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.2\tLoss: 0.014399\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.4\tLoss: 0.039184\n",
      "tensor(-0.0071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.6\tLoss: -0.007134\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.8\tLoss: 0.002396\n",
      "\n",
      "Train Epoch: 410\tAttack_Accuracy: 4908/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 410\tmaintain_Accuracy: 9884/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 410\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 410\tmaintain_Accuracy: 8253/10593 (78%)\n",
      "\n",
      "tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.0\tLoss: 0.053567\n",
      "tensor(-0.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.2\tLoss: -0.008711\n",
      "tensor(-0.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.4\tLoss: -0.000376\n",
      "tensor(-0.0361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.6\tLoss: -0.036109\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.8\tLoss: 0.015107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 411\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 411\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(-0.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.0\tLoss: -0.010528\n",
      "tensor(0.0449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.2\tLoss: 0.044853\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.4\tLoss: 0.018491\n",
      "tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.6\tLoss: -0.000996\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.8\tLoss: 0.021446\n",
      "\n",
      "Test Epoch: 412\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 412\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.0\tLoss: 0.051112\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.2\tLoss: 0.004378\n",
      "tensor(-0.0209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.4\tLoss: -0.020881\n",
      "tensor(-0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.6\tLoss: -0.005871\n",
      "tensor(-0.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.8\tLoss: -0.006707\n",
      "\n",
      "Test Epoch: 413\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 413\tmaintain_Accuracy: 8253/10593 (78%)\n",
      "\n",
      "tensor(-0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.0\tLoss: -0.001656\n",
      "tensor(-0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.2\tLoss: -0.014280\n",
      "tensor(-0.0303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.4\tLoss: -0.030286\n",
      "tensor(-0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.6\tLoss: -0.001303\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.8\tLoss: 0.003172\n",
      "\n",
      "Test Epoch: 414\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 414\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.0\tLoss: 0.011969\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.2\tLoss: 0.024359\n",
      "tensor(-0.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.4\tLoss: -0.006676\n",
      "tensor(-0.0201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.6\tLoss: -0.020103\n",
      "tensor(-0.0270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.8\tLoss: -0.027000\n",
      "\n",
      "Train Epoch: 415\tAttack_Accuracy: 4874/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 415\tmaintain_Accuracy: 9853/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 415\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 415\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(7.9695e-05, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.0\tLoss: 0.000080\n",
      "tensor(-0.0488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.2\tLoss: -0.048807\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.4\tLoss: 0.053961\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.6\tLoss: 0.008294\n",
      "tensor(-0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.8\tLoss: -0.026621\n",
      "\n",
      "Test Epoch: 416\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 416\tmaintain_Accuracy: 8252/10593 (78%)\n",
      "\n",
      "tensor(-0.0356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.0\tLoss: -0.035594\n",
      "tensor(-0.0187, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.2\tLoss: -0.018721\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.4\tLoss: 0.000721\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.6\tLoss: 0.030001\n",
      "tensor(-0.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.8\tLoss: -0.000429\n",
      "\n",
      "Test Epoch: 417\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 417\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.0\tLoss: 0.024595\n",
      "tensor(-0.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.2\tLoss: -0.017905\n",
      "tensor(-0.0134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.4\tLoss: -0.013425\n",
      "tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.6\tLoss: 0.050310\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.8\tLoss: 0.002445\n",
      "\n",
      "Test Epoch: 418\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 418\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.0\tLoss: 0.003007\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.2\tLoss: 0.010406\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.4\tLoss: 0.014118\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.6\tLoss: 0.003421\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.8\tLoss: 0.016867\n",
      "\n",
      "Test Epoch: 419\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 419\tmaintain_Accuracy: 8241/10593 (78%)\n",
      "\n",
      "tensor(0.0397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.0\tLoss: 0.039747\n",
      "tensor(-0.0048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.2\tLoss: -0.004817\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.4\tLoss: 0.013148\n",
      "tensor(-0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.6\tLoss: -0.000776\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.8\tLoss: 0.008202\n",
      "\n",
      "Train Epoch: 420\tAttack_Accuracy: 4959/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 420\tmaintain_Accuracy: 9892/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 420\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 420\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.0\tLoss: -0.004344\n",
      "tensor(-0.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.2\tLoss: -0.003810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.4\tLoss: 0.046350\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.6\tLoss: 0.014270\n",
      "tensor(-0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.8\tLoss: -0.001102\n",
      "\n",
      "Test Epoch: 421\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 421\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.0\tLoss: 0.020376\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.2\tLoss: 0.003486\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.4\tLoss: 0.004266\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.6\tLoss: 0.006374\n",
      "tensor(-0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.8\tLoss: -0.002590\n",
      "\n",
      "Test Epoch: 422\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 422\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.0\tLoss: 0.043435\n",
      "tensor(-0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.2\tLoss: -0.008263\n",
      "tensor(-0.0439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.4\tLoss: -0.043862\n",
      "tensor(-0.0005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.6\tLoss: -0.000523\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.8\tLoss: 0.006330\n",
      "\n",
      "Test Epoch: 423\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 423\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.0\tLoss: -0.001813\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.2\tLoss: 0.012859\n",
      "tensor(-0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.4\tLoss: -0.017414\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.6\tLoss: 0.016506\n",
      "tensor(-0.0062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.8\tLoss: -0.006227\n",
      "\n",
      "Test Epoch: 424\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 424\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.0\tLoss: -0.009703\n",
      "tensor(-0.0212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.2\tLoss: -0.021223\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.4\tLoss: 0.006964\n",
      "tensor(-0.0212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.6\tLoss: -0.021206\n",
      "tensor(-0.0163, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.8\tLoss: -0.016281\n",
      "\n",
      "Train Epoch: 425\tAttack_Accuracy: 4928/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 425\tmaintain_Accuracy: 9925/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 425\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 425\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.0\tLoss: 0.010073\n",
      "tensor(-0.0227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.2\tLoss: -0.022742\n",
      "tensor(0.0222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.4\tLoss: 0.022204\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.6\tLoss: 0.007973\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.8\tLoss: 0.006621\n",
      "\n",
      "Test Epoch: 426\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 426\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.0\tLoss: 0.007361\n",
      "tensor(0.0373, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.2\tLoss: 0.037268\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.4\tLoss: 0.004962\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.6\tLoss: 0.016587\n",
      "tensor(0.0460, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.8\tLoss: 0.046007\n",
      "\n",
      "Test Epoch: 427\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 427\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.0\tLoss: 0.003136\n",
      "tensor(-0.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.2\tLoss: -0.000367\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.4\tLoss: 0.022336\n",
      "tensor(-0.0136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.6\tLoss: -0.013638\n",
      "tensor(-0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.8\tLoss: -0.012008\n",
      "\n",
      "Test Epoch: 428\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 428\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.0\tLoss: 0.020748\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.2\tLoss: 0.014097\n",
      "tensor(-0.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.4\tLoss: -0.004725\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.6\tLoss: 0.009938\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.8\tLoss: 0.014336\n",
      "\n",
      "Test Epoch: 429\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 429\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.0\tLoss: -0.005958\n",
      "tensor(-0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.2\tLoss: -0.000208\n",
      "tensor(-0.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.4\tLoss: -0.024690\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.6\tLoss: 0.019153\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.8\tLoss: 0.038749\n",
      "\n",
      "Train Epoch: 430\tAttack_Accuracy: 4921/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 430\tmaintain_Accuracy: 9868/12800 (77%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 430\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 430\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.0\tLoss: 0.013888\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.2\tLoss: 0.010409\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.4\tLoss: 0.010215\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.6\tLoss: 0.003273\n",
      "tensor(-0.0031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.8\tLoss: -0.003113\n",
      "\n",
      "Test Epoch: 431\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 431\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.0\tLoss: 0.009321\n",
      "tensor(-0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.2\tLoss: -0.001278\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.4\tLoss: 0.039162\n",
      "tensor(0.0264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.6\tLoss: 0.026420\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.8\tLoss: 0.012249\n",
      "\n",
      "Test Epoch: 432\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 432\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.0\tLoss: -0.008239\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.2\tLoss: 0.051178\n",
      "tensor(-0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.4\tLoss: -0.003210\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.6\tLoss: 0.006512\n",
      "tensor(-0.0356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.8\tLoss: -0.035649\n",
      "\n",
      "Test Epoch: 433\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 433\tmaintain_Accuracy: 8252/10593 (78%)\n",
      "\n",
      "tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.0\tLoss: -0.006992\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.2\tLoss: 0.015377\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.4\tLoss: 0.019079\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.6\tLoss: 0.024327\n",
      "tensor(-0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.8\tLoss: -0.008967\n",
      "\n",
      "Test Epoch: 434\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 434\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(-0.0176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.0\tLoss: -0.017647\n",
      "tensor(-0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.2\tLoss: -0.007840\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.4\tLoss: 0.017910\n",
      "tensor(-0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.6\tLoss: -0.013144\n",
      "tensor(-0.0348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.8\tLoss: -0.034772\n",
      "\n",
      "Train Epoch: 435\tAttack_Accuracy: 4967/6400 (78%)\n",
      "\n",
      "\n",
      "Train Epoch: 435\tmaintain_Accuracy: 9861/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 435\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 435\tmaintain_Accuracy: 8254/10593 (78%)\n",
      "\n",
      "tensor(-0.0016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.0\tLoss: -0.001619\n",
      "tensor(-0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.2\tLoss: -0.002767\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.4\tLoss: 0.015437\n",
      "tensor(0.0265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.6\tLoss: 0.026539\n",
      "tensor(-0.0241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.8\tLoss: -0.024093\n",
      "\n",
      "Test Epoch: 436\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 436\tmaintain_Accuracy: 8256/10593 (78%)\n",
      "\n",
      "tensor(-0.0216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.0\tLoss: -0.021629\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.2\tLoss: 0.018319\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.4\tLoss: 0.035056\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.6\tLoss: 0.011498\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.8\tLoss: 0.013018\n",
      "\n",
      "Test Epoch: 437\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 437\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.0\tLoss: 0.009968\n",
      "tensor(-0.0091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.2\tLoss: -0.009116\n",
      "tensor(-0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.4\tLoss: -0.000205\n",
      "tensor(-0.0125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.6\tLoss: -0.012494\n",
      "tensor(-0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.8\tLoss: -0.005410\n",
      "\n",
      "Test Epoch: 438\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 438\tmaintain_Accuracy: 8252/10593 (78%)\n",
      "\n",
      "tensor(-0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.0\tLoss: -0.019305\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.2\tLoss: 0.020934\n",
      "tensor(-0.0170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.4\tLoss: -0.017037\n",
      "tensor(-0.0197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.6\tLoss: -0.019726\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.8\tLoss: 0.006019\n",
      "\n",
      "Test Epoch: 439\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 439\tmaintain_Accuracy: 8252/10593 (78%)\n",
      "\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.0\tLoss: 0.004810\n",
      "tensor(-0.0234, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.2\tLoss: -0.023434\n",
      "tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.4\tLoss: -0.000978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.6\tLoss: 0.016614\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.8\tLoss: 0.015157\n",
      "\n",
      "Train Epoch: 440\tAttack_Accuracy: 4875/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 440\tmaintain_Accuracy: 9864/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 440\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 440\tmaintain_Accuracy: 8253/10593 (78%)\n",
      "\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.0\tLoss: 0.000226\n",
      "tensor(-0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.2\tLoss: -0.002875\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.4\tLoss: 0.015693\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.6\tLoss: 0.013147\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.8\tLoss: 0.006529\n",
      "\n",
      "Test Epoch: 441\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 441\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(-0.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.0\tLoss: -0.022251\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.2\tLoss: 0.035643\n",
      "tensor(-0.0075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.4\tLoss: -0.007455\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.6\tLoss: 0.005599\n",
      "tensor(-0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.8\tLoss: -0.011527\n",
      "\n",
      "Test Epoch: 442\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 442\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(-0.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.0\tLoss: -0.025009\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.2\tLoss: 0.036668\n",
      "tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.4\tLoss: 0.070282\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.6\tLoss: 0.014465\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.8\tLoss: 0.016443\n",
      "\n",
      "Test Epoch: 443\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 443\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.0\tLoss: 0.006159\n",
      "tensor(-0.0151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.2\tLoss: -0.015111\n",
      "tensor(-0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.4\tLoss: -0.011168\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.6\tLoss: 0.010178\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.8\tLoss: 0.005362\n",
      "\n",
      "Test Epoch: 444\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 444\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.0\tLoss: -0.002978\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.2\tLoss: 0.003466\n",
      "tensor(-0.0228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.4\tLoss: -0.022814\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.6\tLoss: 0.005211\n",
      "tensor(-0.0281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.8\tLoss: -0.028082\n",
      "\n",
      "Train Epoch: 445\tAttack_Accuracy: 4848/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 445\tmaintain_Accuracy: 9889/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 445\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 445\tmaintain_Accuracy: 8252/10593 (78%)\n",
      "\n",
      "tensor(-0.0094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.0\tLoss: -0.009397\n",
      "tensor(-0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.2\tLoss: -0.005399\n",
      "tensor(-0.0254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.4\tLoss: -0.025388\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.6\tLoss: 0.029664\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.8\tLoss: 0.020002\n",
      "\n",
      "Test Epoch: 446\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 446\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(-0.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.0\tLoss: -0.017894\n",
      "tensor(-0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.2\tLoss: -0.014802\n",
      "tensor(-0.0092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.4\tLoss: -0.009239\n",
      "tensor(0.0321, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.6\tLoss: 0.032076\n",
      "tensor(-0.0229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.8\tLoss: -0.022857\n",
      "\n",
      "Test Epoch: 447\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 447\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(-0.0239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.0\tLoss: -0.023877\n",
      "tensor(-0.0304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.2\tLoss: -0.030392\n",
      "tensor(-0.0181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.4\tLoss: -0.018104\n",
      "tensor(-0.0263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.6\tLoss: -0.026310\n",
      "tensor(-0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.8\tLoss: -0.002627\n",
      "\n",
      "Test Epoch: 448\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 448\tmaintain_Accuracy: 8251/10593 (78%)\n",
      "\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.0\tLoss: 0.027046\n",
      "tensor(-0.0213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.2\tLoss: -0.021253\n",
      "tensor(0.0222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.4\tLoss: 0.022190\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.6\tLoss: 0.016711\n",
      "tensor(-0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.8\tLoss: -0.003476\n",
      "\n",
      "Test Epoch: 449\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 449\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.0\tLoss: 0.035928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.2\tLoss: 0.020326\n",
      "tensor(-0.0424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.4\tLoss: -0.042412\n",
      "tensor(-0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.6\tLoss: -0.001673\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.8\tLoss: 0.007771\n",
      "\n",
      "Train Epoch: 450\tAttack_Accuracy: 4889/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 450\tmaintain_Accuracy: 9874/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 450\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 450\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.0\tLoss: 0.003926\n",
      "tensor(0.0204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.2\tLoss: 0.020380\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.4\tLoss: 0.017798\n",
      "tensor(-0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.6\tLoss: -0.019233\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.8\tLoss: 0.003892\n",
      "\n",
      "Test Epoch: 451\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 451\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.0\tLoss: 0.009753\n",
      "tensor(-0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.2\tLoss: -0.006906\n",
      "tensor(-0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.4\tLoss: -0.021915\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.6\tLoss: 0.026884\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.8\tLoss: 0.026582\n",
      "\n",
      "Test Epoch: 452\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 452\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.0\tLoss: 0.017178\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.2\tLoss: 0.034583\n",
      "tensor(-0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.4\tLoss: -0.015361\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.6\tLoss: 0.023019\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.8\tLoss: 0.007230\n",
      "\n",
      "Test Epoch: 453\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 453\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.0\tLoss: 0.052991\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.2\tLoss: 0.018104\n",
      "tensor(-0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.4\tLoss: -0.004950\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.6\tLoss: 0.004623\n",
      "tensor(0.0306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.8\tLoss: 0.030615\n",
      "\n",
      "Test Epoch: 454\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 454\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.0\tLoss: 0.007570\n",
      "tensor(-0.0505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.2\tLoss: -0.050483\n",
      "tensor(-0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.4\tLoss: -0.011846\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.6\tLoss: 0.009815\n",
      "tensor(-0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.8\tLoss: -0.003878\n",
      "\n",
      "Train Epoch: 455\tAttack_Accuracy: 4965/6400 (78%)\n",
      "\n",
      "\n",
      "Train Epoch: 455\tmaintain_Accuracy: 9891/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 455\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 455\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.0\tLoss: -0.006480\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.2\tLoss: 0.002040\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.4\tLoss: 0.004424\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.6\tLoss: 0.013457\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.8\tLoss: 0.006637\n",
      "\n",
      "Test Epoch: 456\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 456\tmaintain_Accuracy: 8252/10593 (78%)\n",
      "\n",
      "tensor(-0.0016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.0\tLoss: -0.001647\n",
      "tensor(-0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.2\tLoss: -0.003187\n",
      "tensor(0.0364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.4\tLoss: 0.036356\n",
      "tensor(-0.0068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.6\tLoss: -0.006801\n",
      "tensor(-0.0188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.8\tLoss: -0.018792\n",
      "\n",
      "Test Epoch: 457\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 457\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0447, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.0\tLoss: 0.044717\n",
      "tensor(0.0467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.2\tLoss: 0.046690\n",
      "tensor(-0.0176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.4\tLoss: -0.017582\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.6\tLoss: 0.008616\n",
      "tensor(-0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.8\tLoss: -0.019871\n",
      "\n",
      "Test Epoch: 458\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 458\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.0\tLoss: -0.011524\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.2\tLoss: 0.008012\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.4\tLoss: 0.009962\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.6\tLoss: 0.019475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.8\tLoss: -0.002124\n",
      "\n",
      "Test Epoch: 459\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 459\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.0\tLoss: 0.035512\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.2\tLoss: 0.002953\n",
      "tensor(-0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.4\tLoss: -0.004946\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.6\tLoss: 0.004199\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.8\tLoss: 0.004420\n",
      "\n",
      "Train Epoch: 460\tAttack_Accuracy: 4886/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 460\tmaintain_Accuracy: 9878/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 460\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 460\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.0\tLoss: 0.047811\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.2\tLoss: 0.037571\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.4\tLoss: 0.000584\n",
      "tensor(-0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.6\tLoss: -0.014787\n",
      "tensor(0.0336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.8\tLoss: 0.033626\n",
      "\n",
      "Test Epoch: 461\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 461\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.0\tLoss: 0.032898\n",
      "tensor(-0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.2\tLoss: -0.022447\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.4\tLoss: 0.008310\n",
      "tensor(-0.0132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.6\tLoss: -0.013231\n",
      "tensor(-0.0404, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.8\tLoss: -0.040400\n",
      "\n",
      "Test Epoch: 462\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 462\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.0\tLoss: 0.023747\n",
      "tensor(-0.0244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.2\tLoss: -0.024363\n",
      "tensor(-0.0147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.4\tLoss: -0.014657\n",
      "tensor(-0.0040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.6\tLoss: -0.004031\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.8\tLoss: 0.019106\n",
      "\n",
      "Test Epoch: 463\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 463\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.0\tLoss: -0.000749\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.2\tLoss: 0.009435\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.4\tLoss: 0.016450\n",
      "tensor(-0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.6\tLoss: -0.018303\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.8\tLoss: 0.016300\n",
      "\n",
      "Test Epoch: 464\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 464\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.0\tLoss: -0.016639\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.2\tLoss: 0.001288\n",
      "tensor(-0.0126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.4\tLoss: -0.012571\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.6\tLoss: 0.003175\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.8\tLoss: 0.001144\n",
      "\n",
      "Train Epoch: 465\tAttack_Accuracy: 4877/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 465\tmaintain_Accuracy: 9817/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 465\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 465\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.0\tLoss: -0.013145\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.2\tLoss: 0.036143\n",
      "tensor(-0.0075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.4\tLoss: -0.007482\n",
      "tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.6\tLoss: -0.006976\n",
      "tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.8\tLoss: 0.054445\n",
      "\n",
      "Test Epoch: 466\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 466\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.0\tLoss: 0.020002\n",
      "tensor(-0.0079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.2\tLoss: -0.007908\n",
      "tensor(-0.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.4\tLoss: -0.011741\n",
      "tensor(-0.0186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.6\tLoss: -0.018568\n",
      "tensor(-0.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.8\tLoss: -0.003844\n",
      "\n",
      "Test Epoch: 467\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 467\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(-0.0018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.0\tLoss: -0.001785\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.2\tLoss: 0.028122\n",
      "tensor(-0.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.4\tLoss: -0.012895\n",
      "tensor(-0.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.6\tLoss: -0.017906\n",
      "tensor(-0.0153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.8\tLoss: -0.015334\n",
      "\n",
      "Test Epoch: 468\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 468\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(0.0393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.0\tLoss: 0.039312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.2\tLoss: -0.023612\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.4\tLoss: 0.001922\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.6\tLoss: 0.002896\n",
      "tensor(-0.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.8\tLoss: -0.003828\n",
      "\n",
      "Test Epoch: 469\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 469\tmaintain_Accuracy: 8239/10593 (78%)\n",
      "\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.0\tLoss: 0.040983\n",
      "tensor(-0.0225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.2\tLoss: -0.022522\n",
      "tensor(-0.0290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.4\tLoss: -0.029040\n",
      "tensor(-0.0246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.6\tLoss: -0.024559\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.8\tLoss: 0.026648\n",
      "\n",
      "Train Epoch: 470\tAttack_Accuracy: 4942/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 470\tmaintain_Accuracy: 9905/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 470\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 470\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.0\tLoss: 0.046862\n",
      "tensor(-0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.2\tLoss: -0.006902\n",
      "tensor(-0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.4\tLoss: -0.002971\n",
      "tensor(-0.0300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.6\tLoss: -0.029993\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.8\tLoss: 0.015426\n",
      "\n",
      "Test Epoch: 471\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 471\tmaintain_Accuracy: 8242/10593 (78%)\n",
      "\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.0\tLoss: 0.027641\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.2\tLoss: 0.010479\n",
      "tensor(0.0378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.4\tLoss: 0.037845\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.6\tLoss: 0.001732\n",
      "tensor(-0.0306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.8\tLoss: -0.030596\n",
      "\n",
      "Test Epoch: 472\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 472\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(2.1208e-05, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.0\tLoss: 0.000021\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.2\tLoss: 0.017678\n",
      "tensor(-0.0106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.4\tLoss: -0.010581\n",
      "tensor(-0.0147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.6\tLoss: -0.014662\n",
      "tensor(0.0254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.8\tLoss: 0.025383\n",
      "\n",
      "Test Epoch: 473\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 473\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.0\tLoss: -0.013193\n",
      "tensor(0.0315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.2\tLoss: 0.031468\n",
      "tensor(0.0352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.4\tLoss: 0.035170\n",
      "tensor(-0.0186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.6\tLoss: -0.018565\n",
      "tensor(-0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.8\tLoss: -0.010356\n",
      "\n",
      "Test Epoch: 474\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 474\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(-0.0452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.0\tLoss: -0.045221\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.2\tLoss: 0.026939\n",
      "tensor(-0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.4\tLoss: -0.009814\n",
      "tensor(-0.0084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.6\tLoss: -0.008420\n",
      "tensor(-0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.8\tLoss: -0.021539\n",
      "\n",
      "Train Epoch: 475\tAttack_Accuracy: 4853/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 475\tmaintain_Accuracy: 9909/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 475\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 475\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(-0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.0\tLoss: -0.011898\n",
      "tensor(-0.0304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.2\tLoss: -0.030403\n",
      "tensor(-0.0257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.4\tLoss: -0.025704\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.6\tLoss: 0.004338\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.8\tLoss: 0.008270\n",
      "\n",
      "Test Epoch: 476\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 476\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.0\tLoss: 0.016482\n",
      "tensor(-0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.2\tLoss: -0.016428\n",
      "tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.4\tLoss: 0.064838\n",
      "tensor(-0.0253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.6\tLoss: -0.025330\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.8\tLoss: 0.030449\n",
      "\n",
      "Test Epoch: 477\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 477\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.0\tLoss: 0.025105\n",
      "tensor(-0.0062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.2\tLoss: -0.006179\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.4\tLoss: 0.010776\n",
      "tensor(-0.0132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.6\tLoss: -0.013203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.8\tLoss: 0.003156\n",
      "\n",
      "Test Epoch: 478\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 478\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(-0.0226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.0\tLoss: -0.022644\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.2\tLoss: 0.003812\n",
      "tensor(-0.0101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.4\tLoss: -0.010079\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.6\tLoss: 0.023201\n",
      "tensor(-0.0041, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.8\tLoss: -0.004077\n",
      "\n",
      "Test Epoch: 479\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 479\tmaintain_Accuracy: 8250/10593 (78%)\n",
      "\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.0\tLoss: 0.029189\n",
      "tensor(0.0371, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.2\tLoss: 0.037118\n",
      "tensor(0.0255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.4\tLoss: 0.025496\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.6\tLoss: 0.011041\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.8\tLoss: 0.019547\n",
      "\n",
      "Train Epoch: 480\tAttack_Accuracy: 4874/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 480\tmaintain_Accuracy: 9918/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 480\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 480\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.0\tLoss: -0.015395\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.2\tLoss: 0.029697\n",
      "tensor(0.0585, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.4\tLoss: 0.058450\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.6\tLoss: 0.028884\n",
      "tensor(-0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.8\tLoss: -0.017122\n",
      "\n",
      "Test Epoch: 481\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 481\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.0\tLoss: 0.004873\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.2\tLoss: 0.020189\n",
      "tensor(0.0197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.4\tLoss: 0.019681\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.6\tLoss: 0.021522\n",
      "tensor(-0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.8\tLoss: -0.014778\n",
      "\n",
      "Test Epoch: 482\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 482\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.0\tLoss: -0.011393\n",
      "tensor(-0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.2\tLoss: -0.002575\n",
      "tensor(-0.0287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.4\tLoss: -0.028732\n",
      "tensor(-0.0235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.6\tLoss: -0.023543\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.8\tLoss: 0.000982\n",
      "\n",
      "Test Epoch: 483\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 483\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.0\tLoss: 0.012372\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.2\tLoss: 0.001084\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.4\tLoss: 0.027953\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.6\tLoss: 0.003587\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.8\tLoss: 0.012609\n",
      "\n",
      "Test Epoch: 484\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 484\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(-0.0190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.0\tLoss: -0.018951\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.2\tLoss: 0.007110\n",
      "tensor(-0.0073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.4\tLoss: -0.007346\n",
      "tensor(-0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.6\tLoss: -0.001101\n",
      "tensor(-0.0040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.8\tLoss: -0.004029\n",
      "\n",
      "Train Epoch: 485\tAttack_Accuracy: 4956/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 485\tmaintain_Accuracy: 9862/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 485\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 485\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.0\tLoss: 0.006948\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.2\tLoss: 0.032270\n",
      "tensor(-0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.4\tLoss: -0.003912\n",
      "tensor(-0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.6\tLoss: -0.011826\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.8\tLoss: 0.010949\n",
      "\n",
      "Test Epoch: 486\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 486\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(-0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.0\tLoss: -0.014752\n",
      "tensor(-0.0300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.2\tLoss: -0.029989\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.4\tLoss: 0.026342\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.6\tLoss: 0.029434\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.8\tLoss: 0.023482\n",
      "\n",
      "Test Epoch: 487\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 487\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(0.0297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.0\tLoss: 0.029680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.2\tLoss: 0.016439\n",
      "tensor(0.0384, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.4\tLoss: 0.038421\n",
      "tensor(-0.0263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.6\tLoss: -0.026271\n",
      "tensor(-0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.8\tLoss: -0.015351\n",
      "\n",
      "Test Epoch: 488\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 488\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.0\tLoss: -0.011533\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.2\tLoss: 0.018138\n",
      "tensor(-0.0153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.4\tLoss: -0.015347\n",
      "tensor(-0.0194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.6\tLoss: -0.019381\n",
      "tensor(-0.0231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.8\tLoss: -0.023084\n",
      "\n",
      "Test Epoch: 489\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 489\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.0\tLoss: 0.003781\n",
      "tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.2\tLoss: 0.050378\n",
      "tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.4\tLoss: 0.049089\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.6\tLoss: 0.008201\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.8\tLoss: 0.014967\n",
      "\n",
      "Train Epoch: 490\tAttack_Accuracy: 4907/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 490\tmaintain_Accuracy: 9872/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 490\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 490\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.0\tLoss: -0.018086\n",
      "tensor(-0.0003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.2\tLoss: -0.000293\n",
      "tensor(-0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.4\tLoss: -0.021534\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.6\tLoss: 0.029112\n",
      "tensor(-0.0071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.8\tLoss: -0.007142\n",
      "\n",
      "Test Epoch: 491\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 491\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.0\tLoss: 0.010206\n",
      "tensor(-0.0366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.2\tLoss: -0.036614\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.4\tLoss: 0.041152\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.6\tLoss: 0.002881\n",
      "tensor(0.0343, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.8\tLoss: 0.034259\n",
      "\n",
      "Test Epoch: 492\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 492\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.0\tLoss: 0.012395\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.2\tLoss: 0.019813\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.4\tLoss: 0.027480\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.6\tLoss: 0.024440\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.8\tLoss: 0.020667\n",
      "\n",
      "Test Epoch: 493\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 493\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.0\tLoss: 0.009026\n",
      "tensor(-0.0242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.2\tLoss: -0.024164\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.4\tLoss: 0.000115\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.6\tLoss: 0.024453\n",
      "tensor(-0.0242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.8\tLoss: -0.024185\n",
      "\n",
      "Test Epoch: 494\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 494\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.0\tLoss: 0.005273\n",
      "tensor(-0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.2\tLoss: -0.001908\n",
      "tensor(-0.0279, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.4\tLoss: -0.027944\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.6\tLoss: 0.000238\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.8\tLoss: 0.036083\n",
      "\n",
      "Train Epoch: 495\tAttack_Accuracy: 4864/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 495\tmaintain_Accuracy: 9847/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 495\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 495\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.0\tLoss: -0.000646\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.2\tLoss: 0.002730\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.4\tLoss: 0.011047\n",
      "tensor(-0.0234, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.6\tLoss: -0.023422\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.8\tLoss: 0.022005\n",
      "\n",
      "Test Epoch: 496\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 496\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.0\tLoss: -0.005119\n",
      "tensor(-0.0321, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.2\tLoss: -0.032105\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.4\tLoss: 0.004847\n",
      "tensor(-0.0167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.6\tLoss: -0.016749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.8\tLoss: 0.015632\n",
      "\n",
      "Test Epoch: 497\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 497\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0358, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.0\tLoss: -0.035756\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.2\tLoss: 0.031000\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.4\tLoss: 0.000697\n",
      "tensor(-0.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.6\tLoss: -0.006690\n",
      "tensor(-0.0137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.8\tLoss: -0.013722\n",
      "\n",
      "Test Epoch: 498\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 498\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.0\tLoss: 0.043151\n",
      "tensor(-0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.2\tLoss: -0.000701\n",
      "tensor(0.0354, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.4\tLoss: 0.035400\n",
      "tensor(0.0429, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.6\tLoss: 0.042859\n",
      "tensor(-0.0062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.8\tLoss: -0.006175\n",
      "\n",
      "Test Epoch: 499\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 499\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.0\tLoss: 0.041556\n",
      "tensor(0.0428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.2\tLoss: 0.042827\n",
      "tensor(-0.0071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.4\tLoss: -0.007122\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.6\tLoss: 0.024283\n",
      "tensor(-0.0005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.8\tLoss: -0.000484\n",
      "\n",
      "Train Epoch: 500\tAttack_Accuracy: 4878/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 500\tmaintain_Accuracy: 9957/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 500\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 500\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.0\tLoss: -0.018373\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.2\tLoss: 0.018346\n",
      "tensor(-0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.4\tLoss: -0.017722\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.6\tLoss: 0.014234\n",
      "tensor(0.0379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.8\tLoss: 0.037862\n",
      "\n",
      "Test Epoch: 501\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 501\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.0\tLoss: 0.002457\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.2\tLoss: 0.026683\n",
      "tensor(0.0559, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.4\tLoss: 0.055920\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.6\tLoss: 0.007009\n",
      "tensor(-0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.8\tLoss: -0.005146\n",
      "\n",
      "Test Epoch: 502\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 502\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.0\tLoss: 0.031896\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.2\tLoss: 0.016528\n",
      "tensor(-0.0045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.4\tLoss: -0.004516\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.6\tLoss: 0.001393\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.8\tLoss: 0.011885\n",
      "\n",
      "Test Epoch: 503\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 503\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.0\tLoss: -0.027323\n",
      "tensor(-0.0396, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.2\tLoss: -0.039612\n",
      "tensor(-0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.4\tLoss: -0.000823\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.6\tLoss: 0.021739\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.8\tLoss: 0.006578\n",
      "\n",
      "Test Epoch: 504\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 504\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.0\tLoss: -0.026607\n",
      "tensor(-0.0170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.2\tLoss: -0.017028\n",
      "tensor(-0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.4\tLoss: -0.013112\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.6\tLoss: 0.006222\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.8\tLoss: 0.020016\n",
      "\n",
      "Train Epoch: 505\tAttack_Accuracy: 4907/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 505\tmaintain_Accuracy: 9879/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 505\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 505\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.0\tLoss: 0.000560\n",
      "tensor(-0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.2\tLoss: -0.017702\n",
      "tensor(-0.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.4\tLoss: -0.012947\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.6\tLoss: 0.005361\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.8\tLoss: 0.015576\n",
      "\n",
      "Test Epoch: 506\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 506\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.0\tLoss: -0.010196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0163, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.2\tLoss: -0.016325\n",
      "tensor(-0.0216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.4\tLoss: -0.021622\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.6\tLoss: 0.014163\n",
      "tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.8\tLoss: -0.006999\n",
      "\n",
      "Test Epoch: 507\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 507\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.0\tLoss: 0.080056\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.2\tLoss: 0.009579\n",
      "tensor(-0.0285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.4\tLoss: -0.028486\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.6\tLoss: 0.004352\n",
      "tensor(-0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.8\tLoss: -0.012307\n",
      "\n",
      "Test Epoch: 508\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 508\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.0\tLoss: 0.068998\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.2\tLoss: 0.005716\n",
      "tensor(0.0393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.4\tLoss: 0.039315\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.6\tLoss: 0.028263\n",
      "tensor(-0.0371, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.8\tLoss: -0.037124\n",
      "\n",
      "Test Epoch: 509\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 509\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.0\tLoss: 0.014764\n",
      "tensor(-0.0477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.2\tLoss: -0.047685\n",
      "tensor(-0.0018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.4\tLoss: -0.001844\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.6\tLoss: 0.007799\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.8\tLoss: 0.003625\n",
      "\n",
      "Train Epoch: 510\tAttack_Accuracy: 4954/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 510\tmaintain_Accuracy: 9839/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 510\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 510\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.0\tLoss: -0.033104\n",
      "tensor(-0.0175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.2\tLoss: -0.017472\n",
      "tensor(-0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.4\tLoss: -0.019865\n",
      "tensor(-0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.6\tLoss: -0.016618\n",
      "tensor(-0.0053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.8\tLoss: -0.005270\n",
      "\n",
      "Test Epoch: 511\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 511\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.0\tLoss: 0.012679\n",
      "tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.2\tLoss: 0.050307\n",
      "tensor(-0.0413, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.4\tLoss: -0.041279\n",
      "tensor(-0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.6\tLoss: -0.009268\n",
      "tensor(-0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.8\tLoss: -0.007818\n",
      "\n",
      "Test Epoch: 512\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 512\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.0\tLoss: -0.000509\n",
      "tensor(-0.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.2\tLoss: -0.006667\n",
      "tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.4\tLoss: 0.059318\n",
      "tensor(-0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.6\tLoss: -0.009005\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.8\tLoss: 0.009547\n",
      "\n",
      "Test Epoch: 513\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 513\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.0\tLoss: 0.003165\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.2\tLoss: 0.024660\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.4\tLoss: 0.009229\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.6\tLoss: 0.029238\n",
      "tensor(-0.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.8\tLoss: -0.000427\n",
      "\n",
      "Test Epoch: 514\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 514\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.0\tLoss: -0.012222\n",
      "tensor(-0.0146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.2\tLoss: -0.014569\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.4\tLoss: 0.007165\n",
      "tensor(-0.0197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.6\tLoss: -0.019681\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.8\tLoss: 0.017083\n",
      "\n",
      "Train Epoch: 515\tAttack_Accuracy: 4910/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 515\tmaintain_Accuracy: 9873/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 515\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 515\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.0\tLoss: -0.026843\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.2\tLoss: 0.030923\n",
      "tensor(-0.0288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.4\tLoss: -0.028813\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.6\tLoss: 0.014221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.8\tLoss: 0.018834\n",
      "\n",
      "Test Epoch: 516\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 516\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.0\tLoss: 0.002648\n",
      "tensor(-0.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.2\tLoss: -0.025030\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.4\tLoss: 0.001366\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.6\tLoss: 0.005555\n",
      "tensor(-0.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.8\tLoss: -0.003843\n",
      "\n",
      "Test Epoch: 517\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 517\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.0\tLoss: -0.026187\n",
      "tensor(-0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.2\tLoss: -0.011641\n",
      "tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.4\tLoss: 0.054652\n",
      "tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.6\tLoss: 0.052522\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.8\tLoss: 0.023556\n",
      "\n",
      "Test Epoch: 518\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 518\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.0\tLoss: 0.026961\n",
      "tensor(0.0312, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.2\tLoss: 0.031233\n",
      "tensor(-0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.4\tLoss: -0.012083\n",
      "tensor(-0.0593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.6\tLoss: -0.059318\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.8\tLoss: 0.017898\n",
      "\n",
      "Test Epoch: 519\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 519\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.0\tLoss: 0.033857\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.2\tLoss: 0.011198\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.4\tLoss: 0.004651\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.6\tLoss: 0.016614\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.8\tLoss: 0.001075\n",
      "\n",
      "Train Epoch: 520\tAttack_Accuracy: 4920/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 520\tmaintain_Accuracy: 9861/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 520\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 520\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.0\tLoss: 0.001972\n",
      "tensor(-0.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.2\tLoss: -0.012863\n",
      "tensor(-0.0072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.4\tLoss: -0.007156\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.6\tLoss: 0.013832\n",
      "tensor(0.0320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.8\tLoss: 0.031953\n",
      "\n",
      "Test Epoch: 521\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 521\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.0\tLoss: -0.022761\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.2\tLoss: 0.019590\n",
      "tensor(-0.0213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.4\tLoss: -0.021265\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.6\tLoss: 0.020832\n",
      "tensor(-0.0233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.8\tLoss: -0.023258\n",
      "\n",
      "Test Epoch: 522\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 522\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.0\tLoss: 0.015016\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.2\tLoss: 0.017730\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.4\tLoss: -0.001402\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.6\tLoss: 0.020153\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.8\tLoss: 0.029076\n",
      "\n",
      "Test Epoch: 523\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 523\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.0\tLoss: 0.052794\n",
      "tensor(-0.0340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.2\tLoss: -0.033952\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.4\tLoss: 0.003284\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.6\tLoss: 0.001236\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.8\tLoss: 0.029429\n",
      "\n",
      "Test Epoch: 524\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 524\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.0\tLoss: 0.005946\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.2\tLoss: 0.005883\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.4\tLoss: 0.002105\n",
      "tensor(-0.0251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.6\tLoss: -0.025142\n",
      "tensor(-0.0198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.8\tLoss: -0.019810\n",
      "\n",
      "Train Epoch: 525\tAttack_Accuracy: 4878/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 525\tmaintain_Accuracy: 9829/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 525\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 525\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.0\tLoss: -0.006774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.2\tLoss: 0.001863\n",
      "tensor(-0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.4\tLoss: -0.017654\n",
      "tensor(0.0396, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.6\tLoss: 0.039606\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.8\tLoss: 0.043256\n",
      "\n",
      "Test Epoch: 526\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 526\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.0\tLoss: 0.015806\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.2\tLoss: 0.000811\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.4\tLoss: 0.021885\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.6\tLoss: 0.008604\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.8\tLoss: 0.023228\n",
      "\n",
      "Test Epoch: 527\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 527\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.0\tLoss: -0.027794\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.2\tLoss: 0.011249\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.4\tLoss: 0.017411\n",
      "tensor(0.0464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.6\tLoss: 0.046388\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.8\tLoss: 0.017334\n",
      "\n",
      "Test Epoch: 528\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 528\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.0\tLoss: 0.028983\n",
      "tensor(-0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.2\tLoss: -0.006578\n",
      "tensor(-0.0399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.4\tLoss: -0.039928\n",
      "tensor(0.0211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.6\tLoss: 0.021080\n",
      "tensor(0.0336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.8\tLoss: 0.033600\n",
      "\n",
      "Test Epoch: 529\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 529\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.0\tLoss: 0.036081\n",
      "tensor(-0.0084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.2\tLoss: -0.008376\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.4\tLoss: 0.002433\n",
      "tensor(-0.0235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.6\tLoss: -0.023527\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.8\tLoss: 0.029166\n",
      "\n",
      "Train Epoch: 530\tAttack_Accuracy: 4902/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 530\tmaintain_Accuracy: 9938/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 530\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 530\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.0\tLoss: 0.044145\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.2\tLoss: 0.010324\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.4\tLoss: 0.025757\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.6\tLoss: 0.025228\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.8\tLoss: 0.039917\n",
      "\n",
      "Test Epoch: 531\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 531\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.0\tLoss: 0.006443\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.2\tLoss: 0.017084\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.4\tLoss: 0.016404\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.6\tLoss: 0.021966\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.8\tLoss: 0.018219\n",
      "\n",
      "Test Epoch: 532\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 532\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.0\tLoss: 0.016993\n",
      "tensor(-0.0127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.2\tLoss: -0.012733\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.4\tLoss: 0.009662\n",
      "tensor(-0.0254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.6\tLoss: -0.025422\n",
      "tensor(-0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.8\tLoss: -0.010326\n",
      "\n",
      "Test Epoch: 533\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 533\tmaintain_Accuracy: 8249/10593 (78%)\n",
      "\n",
      "tensor(-0.0072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.0\tLoss: -0.007171\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.2\tLoss: 0.009591\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.4\tLoss: 0.011592\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.6\tLoss: 0.019637\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.8\tLoss: 0.027756\n",
      "\n",
      "Test Epoch: 534\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 534\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.0\tLoss: -0.007684\n",
      "tensor(-0.0147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.2\tLoss: -0.014709\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.4\tLoss: 0.011149\n",
      "tensor(-0.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.6\tLoss: -0.010866\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.8\tLoss: 0.029426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 535\tAttack_Accuracy: 4898/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 535\tmaintain_Accuracy: 9892/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 535\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 535\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.0\tLoss: -0.007421\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.2\tLoss: 0.024125\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.4\tLoss: 0.007357\n",
      "tensor(0.0356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.6\tLoss: 0.035602\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.8\tLoss: 0.014939\n",
      "\n",
      "Test Epoch: 536\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 536\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.0\tLoss: 0.036345\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.2\tLoss: 0.005503\n",
      "tensor(-0.0058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.4\tLoss: -0.005839\n",
      "tensor(-0.0272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.6\tLoss: -0.027180\n",
      "tensor(-0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.8\tLoss: -0.009584\n",
      "\n",
      "Test Epoch: 537\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 537\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.0\tLoss: -0.030988\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.2\tLoss: 0.013104\n",
      "tensor(-0.0134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.4\tLoss: -0.013397\n",
      "tensor(-0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.6\tLoss: -0.011752\n",
      "tensor(-0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.8\tLoss: -0.005883\n",
      "\n",
      "Test Epoch: 538\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 538\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.0\tLoss: -0.057117\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.2\tLoss: 0.001837\n",
      "tensor(-0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.4\tLoss: -0.013124\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.6\tLoss: 0.038022\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.8\tLoss: 0.021210\n",
      "\n",
      "Test Epoch: 539\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 539\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(-0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.0\tLoss: -0.005989\n",
      "tensor(-0.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.2\tLoss: -0.010859\n",
      "tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.4\tLoss: 0.053568\n",
      "tensor(-0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.6\tLoss: -0.005086\n",
      "tensor(-0.0353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.8\tLoss: -0.035338\n",
      "\n",
      "Train Epoch: 540\tAttack_Accuracy: 4868/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 540\tmaintain_Accuracy: 9921/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 540\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 540\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.0\tLoss: -0.029059\n",
      "tensor(-0.0108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.2\tLoss: -0.010762\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.4\tLoss: 0.001441\n",
      "tensor(-0.0269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.6\tLoss: -0.026901\n",
      "tensor(-0.0328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.8\tLoss: -0.032781\n",
      "\n",
      "Test Epoch: 541\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 541\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0534, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.0\tLoss: -0.053413\n",
      "tensor(-0.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.2\tLoss: -0.002006\n",
      "tensor(0.0256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.4\tLoss: 0.025637\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.6\tLoss: 0.010566\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.8\tLoss: 0.012857\n",
      "\n",
      "Test Epoch: 542\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 542\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.0\tLoss: -0.036376\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.2\tLoss: 0.030385\n",
      "tensor(0.0302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.4\tLoss: 0.030242\n",
      "tensor(-0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.6\tLoss: -0.001299\n",
      "tensor(-0.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.8\tLoss: -0.017890\n",
      "\n",
      "Test Epoch: 543\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 543\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.0\tLoss: 0.050837\n",
      "tensor(-0.0204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.2\tLoss: -0.020412\n",
      "tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.4\tLoss: 0.048475\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.6\tLoss: 0.006777\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.8\tLoss: 0.011444\n",
      "\n",
      "Test Epoch: 544\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 544\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.0\tLoss: 0.019999\n",
      "tensor(-0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.2\tLoss: -0.003391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.4\tLoss: -0.011758\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.6\tLoss: 0.012301\n",
      "tensor(-0.0257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.8\tLoss: -0.025676\n",
      "\n",
      "Train Epoch: 545\tAttack_Accuracy: 4937/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 545\tmaintain_Accuracy: 9936/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 545\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 545\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.0\tLoss: -0.002560\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.2\tLoss: 0.030533\n",
      "tensor(-0.0270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.4\tLoss: -0.026972\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.6\tLoss: 0.004241\n",
      "tensor(-0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.8\tLoss: -0.002879\n",
      "\n",
      "Test Epoch: 546\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 546\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.0\tLoss: 0.021920\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.2\tLoss: 0.000552\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.4\tLoss: 0.004592\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.6\tLoss: 0.005356\n",
      "tensor(-0.0076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.8\tLoss: -0.007566\n",
      "\n",
      "Test Epoch: 547\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 547\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.0\tLoss: 0.048663\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.2\tLoss: 0.043690\n",
      "tensor(-0.0252, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.4\tLoss: -0.025249\n",
      "tensor(-0.0063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.6\tLoss: -0.006323\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.8\tLoss: 0.002358\n",
      "\n",
      "Test Epoch: 548\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 548\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.0\tLoss: -0.006178\n",
      "tensor(-0.0255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.2\tLoss: -0.025476\n",
      "tensor(-0.0372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.4\tLoss: -0.037156\n",
      "tensor(-0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.6\tLoss: -0.002713\n",
      "tensor(-0.0163, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.8\tLoss: -0.016260\n",
      "\n",
      "Test Epoch: 549\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 549\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.0\tLoss: -0.021608\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.2\tLoss: 0.011712\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.4\tLoss: 0.024655\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.6\tLoss: 0.001702\n",
      "tensor(-0.0182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.8\tLoss: -0.018168\n",
      "\n",
      "Train Epoch: 550\tAttack_Accuracy: 4910/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 550\tmaintain_Accuracy: 9893/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 550\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 550\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.0\tLoss: 0.019298\n",
      "tensor(-0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.2\tLoss: -0.015366\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.4\tLoss: 0.002471\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.6\tLoss: 0.018478\n",
      "tensor(-0.0421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.8\tLoss: -0.042096\n",
      "\n",
      "Test Epoch: 551\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 551\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.0\tLoss: -0.019305\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.2\tLoss: 0.005272\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.4\tLoss: 0.031109\n",
      "tensor(-0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.6\tLoss: -0.022378\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.8\tLoss: 0.003851\n",
      "\n",
      "Test Epoch: 552\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 552\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.0\tLoss: 0.028790\n",
      "tensor(-0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.2\tLoss: -0.003655\n",
      "tensor(0.0337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.4\tLoss: 0.033692\n",
      "tensor(-0.0043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.6\tLoss: -0.004274\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.8\tLoss: 0.019807\n",
      "\n",
      "Test Epoch: 553\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 553\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.0\tLoss: -0.015233\n",
      "tensor(0.0299, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.2\tLoss: 0.029897\n",
      "tensor(-0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.4\tLoss: -0.019339\n",
      "tensor(-0.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.6\tLoss: -0.000396\n",
      "tensor(-0.0170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.8\tLoss: -0.016965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 554\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 554\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.0\tLoss: -0.054956\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.2\tLoss: 0.005059\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.4\tLoss: 0.011802\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.6\tLoss: 0.011255\n",
      "tensor(-0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.8\tLoss: -0.017710\n",
      "\n",
      "Train Epoch: 555\tAttack_Accuracy: 4895/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 555\tmaintain_Accuracy: 10014/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 555\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 555\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.0\tLoss: -0.000793\n",
      "tensor(-0.0309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.2\tLoss: -0.030883\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.4\tLoss: 0.002300\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.6\tLoss: 0.021216\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.8\tLoss: 0.015445\n",
      "\n",
      "Test Epoch: 556\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 556\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.0\tLoss: 0.000762\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.2\tLoss: 0.003415\n",
      "tensor(-0.0180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.4\tLoss: -0.018041\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.6\tLoss: 0.014267\n",
      "tensor(-0.0529, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.8\tLoss: -0.052927\n",
      "\n",
      "Test Epoch: 557\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 557\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.0\tLoss: 0.037788\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.2\tLoss: 0.009950\n",
      "tensor(-0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.4\tLoss: -0.008105\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.6\tLoss: 0.009328\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.8\tLoss: 0.001910\n",
      "\n",
      "Test Epoch: 558\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 558\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.0\tLoss: -0.006613\n",
      "tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.2\tLoss: -0.000925\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.4\tLoss: 0.024227\n",
      "tensor(-0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.6\tLoss: -0.023737\n",
      "tensor(-0.0260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.8\tLoss: -0.025965\n",
      "\n",
      "Test Epoch: 559\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 559\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.0\tLoss: -0.009507\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.2\tLoss: 0.013442\n",
      "tensor(-0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.4\tLoss: -0.003322\n",
      "tensor(-0.0406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.6\tLoss: -0.040642\n",
      "tensor(-0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.8\tLoss: -0.001877\n",
      "\n",
      "Train Epoch: 560\tAttack_Accuracy: 4982/6400 (78%)\n",
      "\n",
      "\n",
      "Train Epoch: 560\tmaintain_Accuracy: 9956/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 560\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 560\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.0\tLoss: 0.034576\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.2\tLoss: 0.020797\n",
      "tensor(-0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.4\tLoss: -0.023731\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.6\tLoss: 0.003522\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.8\tLoss: 0.002801\n",
      "\n",
      "Test Epoch: 561\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 561\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.0\tLoss: -0.012400\n",
      "tensor(-0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.2\tLoss: -0.001748\n",
      "tensor(-0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.4\tLoss: -0.012102\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.6\tLoss: 0.019471\n",
      "tensor(-0.0185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.8\tLoss: -0.018501\n",
      "\n",
      "Test Epoch: 562\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 562\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.0\tLoss: 0.030269\n",
      "tensor(-0.0188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.2\tLoss: -0.018773\n",
      "tensor(-0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.4\tLoss: -0.005985\n",
      "tensor(-0.0325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.6\tLoss: -0.032520\n",
      "tensor(-0.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.8\tLoss: -0.024730\n",
      "\n",
      "Test Epoch: 563\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 563\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.0\tLoss: 0.018344\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.2\tLoss: 0.000253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.4\tLoss: -0.003821\n",
      "tensor(-0.0286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.6\tLoss: -0.028608\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.8\tLoss: 0.019161\n",
      "\n",
      "Test Epoch: 564\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 564\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.0\tLoss: 0.027952\n",
      "tensor(-0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.2\tLoss: -0.003225\n",
      "tensor(-0.0045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.4\tLoss: -0.004524\n",
      "tensor(-0.0196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.6\tLoss: -0.019578\n",
      "tensor(-0.0150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.8\tLoss: -0.015041\n",
      "\n",
      "Train Epoch: 565\tAttack_Accuracy: 4914/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 565\tmaintain_Accuracy: 9912/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 565\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 565\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.0\tLoss: 0.003365\n",
      "tensor(-0.0365, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.2\tLoss: -0.036525\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.4\tLoss: 0.009616\n",
      "tensor(-0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.6\tLoss: -0.008889\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.8\tLoss: 0.017352\n",
      "\n",
      "Test Epoch: 566\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 566\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.0\tLoss: 0.029243\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.2\tLoss: 0.026661\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.4\tLoss: 0.037642\n",
      "tensor(0.0296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.6\tLoss: 0.029644\n",
      "tensor(-0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.8\tLoss: -0.014205\n",
      "\n",
      "Test Epoch: 567\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 567\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.0\tLoss: 0.035242\n",
      "tensor(-0.0196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.2\tLoss: -0.019557\n",
      "tensor(-0.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.4\tLoss: -0.022303\n",
      "tensor(-0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.6\tLoss: -0.011780\n",
      "tensor(-0.0384, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.8\tLoss: -0.038402\n",
      "\n",
      "Test Epoch: 568\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 568\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.0\tLoss: -0.005986\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.2\tLoss: 0.005265\n",
      "tensor(0.0101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.4\tLoss: 0.010090\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.6\tLoss: 0.036641\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.8\tLoss: 0.022993\n",
      "\n",
      "Test Epoch: 569\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 569\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.0\tLoss: 0.018113\n",
      "tensor(0.0296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.2\tLoss: 0.029568\n",
      "tensor(0.0384, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.4\tLoss: 0.038387\n",
      "tensor(-0.0145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.6\tLoss: -0.014536\n",
      "tensor(-0.0165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.8\tLoss: -0.016522\n",
      "\n",
      "Train Epoch: 570\tAttack_Accuracy: 4879/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 570\tmaintain_Accuracy: 9838/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 570\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 570\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.0\tLoss: -0.014430\n",
      "tensor(0.0660, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.2\tLoss: 0.065994\n",
      "tensor(-0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.4\tLoss: -0.019094\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.6\tLoss: 0.004945\n",
      "tensor(-0.0157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.8\tLoss: -0.015749\n",
      "\n",
      "Test Epoch: 571\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 571\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.0\tLoss: 0.002141\n",
      "tensor(-0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.2\tLoss: -0.004954\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.4\tLoss: 0.019577\n",
      "tensor(-0.0155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.6\tLoss: -0.015488\n",
      "tensor(0.0707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.8\tLoss: 0.070715\n",
      "\n",
      "Test Epoch: 572\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 572\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.0\tLoss: 0.035278\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.2\tLoss: 0.014314\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.4\tLoss: 0.008674\n",
      "tensor(0.0395, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.6\tLoss: 0.039503\n",
      "tensor(-0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.8\tLoss: -0.008464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 573\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 573\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.0\tLoss: 0.014289\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.2\tLoss: 0.007834\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.4\tLoss: 0.007130\n",
      "tensor(-0.0324, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.6\tLoss: -0.032443\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.8\tLoss: 0.025280\n",
      "\n",
      "Test Epoch: 574\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 574\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.0\tLoss: 0.009267\n",
      "tensor(-0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.2\tLoss: -0.002728\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.4\tLoss: 0.016146\n",
      "tensor(5.5544e-06, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.6\tLoss: 0.000006\n",
      "tensor(-0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.8\tLoss: -0.005899\n",
      "\n",
      "Train Epoch: 575\tAttack_Accuracy: 4914/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 575\tmaintain_Accuracy: 9980/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 575\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 575\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.0\tLoss: 0.002094\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.2\tLoss: 0.023447\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.4\tLoss: 0.039780\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.6\tLoss: 0.020115\n",
      "tensor(-0.0031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.8\tLoss: -0.003082\n",
      "\n",
      "Test Epoch: 576\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 576\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(0.0282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.0\tLoss: 0.028219\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.2\tLoss: 0.008602\n",
      "tensor(-0.0304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.4\tLoss: -0.030383\n",
      "tensor(-0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.6\tLoss: -0.009789\n",
      "tensor(-0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.8\tLoss: -0.004986\n",
      "\n",
      "Test Epoch: 577\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 577\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.0\tLoss: -0.017766\n",
      "tensor(-0.0169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.2\tLoss: -0.016897\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.4\tLoss: 0.008294\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.6\tLoss: 0.026991\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.8\tLoss: 0.020058\n",
      "\n",
      "Test Epoch: 578\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 578\tmaintain_Accuracy: 8243/10593 (78%)\n",
      "\n",
      "tensor(-0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.0\tLoss: -0.002663\n",
      "tensor(-0.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.2\tLoss: -0.022271\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.4\tLoss: 0.006672\n",
      "tensor(-0.0435, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.6\tLoss: -0.043546\n",
      "tensor(-0.0150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.8\tLoss: -0.015010\n",
      "\n",
      "Test Epoch: 579\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 579\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.0\tLoss: -0.010301\n",
      "tensor(-0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.2\tLoss: -0.003244\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.4\tLoss: 0.007903\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.6\tLoss: 0.009027\n",
      "tensor(-0.0130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.8\tLoss: -0.013024\n",
      "\n",
      "Train Epoch: 580\tAttack_Accuracy: 4889/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 580\tmaintain_Accuracy: 9950/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 580\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 580\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.0\tLoss: -0.015124\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.2\tLoss: 0.006900\n",
      "tensor(-0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.4\tLoss: -0.010409\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.6\tLoss: 0.039762\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.8\tLoss: 0.022365\n",
      "\n",
      "Test Epoch: 581\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 581\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.0\tLoss: -0.000517\n",
      "tensor(-0.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.2\tLoss: -0.004694\n",
      "tensor(-0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.4\tLoss: -0.019067\n",
      "tensor(-0.0186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.6\tLoss: -0.018574\n",
      "tensor(-0.0403, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.8\tLoss: -0.040263\n",
      "\n",
      "Test Epoch: 582\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 582\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.0\tLoss: -0.012004\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.2\tLoss: 0.042352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.4\tLoss: 0.031540\n",
      "tensor(-0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.6\tLoss: -0.005914\n",
      "tensor(-0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.8\tLoss: -0.011569\n",
      "\n",
      "Test Epoch: 583\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 583\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.0\tLoss: 0.022487\n",
      "tensor(-0.0323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.2\tLoss: -0.032350\n",
      "tensor(-0.0268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.4\tLoss: -0.026812\n",
      "tensor(-0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.6\tLoss: -0.009933\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.8\tLoss: 0.023189\n",
      "\n",
      "Test Epoch: 584\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 584\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.0\tLoss: -0.011656\n",
      "tensor(-0.0101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.2\tLoss: -0.010094\n",
      "tensor(-0.0303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.4\tLoss: -0.030292\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.6\tLoss: 0.001901\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.8\tLoss: 0.010588\n",
      "\n",
      "Train Epoch: 585\tAttack_Accuracy: 4911/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 585\tmaintain_Accuracy: 9894/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 585\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 585\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.0\tLoss: -0.003892\n",
      "tensor(-0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.2\tLoss: -0.003233\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.4\tLoss: 0.029196\n",
      "tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.6\tLoss: -0.000957\n",
      "tensor(0.0073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.8\tLoss: 0.007318\n",
      "\n",
      "Test Epoch: 586\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 586\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.0\tLoss: -0.012306\n",
      "tensor(0.0426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.2\tLoss: 0.042567\n",
      "tensor(-0.0319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.4\tLoss: -0.031934\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.6\tLoss: 0.017370\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.8\tLoss: 0.003831\n",
      "\n",
      "Test Epoch: 587\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 587\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.0\tLoss: -0.012756\n",
      "tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.2\tLoss: 0.060567\n",
      "tensor(-0.0268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.4\tLoss: -0.026756\n",
      "tensor(-0.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.6\tLoss: -0.022307\n",
      "tensor(-0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.8\tLoss: -0.003173\n",
      "\n",
      "Test Epoch: 588\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 588\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.0\tLoss: 0.018960\n",
      "tensor(0.0368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.2\tLoss: 0.036815\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.4\tLoss: 0.000676\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.6\tLoss: 0.025925\n",
      "tensor(-0.0153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.8\tLoss: -0.015272\n",
      "\n",
      "Test Epoch: 589\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 589\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.0\tLoss: -0.026798\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.2\tLoss: 0.025804\n",
      "tensor(-0.0144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.4\tLoss: -0.014415\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.6\tLoss: 0.017234\n",
      "tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.8\tLoss: -0.000891\n",
      "\n",
      "Train Epoch: 590\tAttack_Accuracy: 4895/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 590\tmaintain_Accuracy: 9993/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 590\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 590\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.0\tLoss: -0.006936\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.2\tLoss: 0.015998\n",
      "tensor(0.0299, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.4\tLoss: 0.029884\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.6\tLoss: 0.001595\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.8\tLoss: 0.024600\n",
      "\n",
      "Test Epoch: 591\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 591\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.0\tLoss: -0.013111\n",
      "tensor(-0.0361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.2\tLoss: -0.036066\n",
      "tensor(-0.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.4\tLoss: -0.010880\n",
      "tensor(-0.0222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.6\tLoss: -0.022158\n",
      "tensor(-0.0375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.8\tLoss: -0.037524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 592\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 592\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.0\tLoss: -0.000958\n",
      "tensor(-0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.2\tLoss: -0.002589\n",
      "tensor(-0.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.4\tLoss: -0.010913\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.6\tLoss: 0.002046\n",
      "tensor(-0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.8\tLoss: -0.005171\n",
      "\n",
      "Test Epoch: 593\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 593\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.0\tLoss: 0.005010\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.2\tLoss: 0.009621\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.4\tLoss: 0.021545\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.6\tLoss: 0.021511\n",
      "tensor(-0.0074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.8\tLoss: -0.007438\n",
      "\n",
      "Test Epoch: 594\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 594\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.0\tLoss: -0.007885\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.2\tLoss: 0.002618\n",
      "tensor(-0.0307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.4\tLoss: -0.030725\n",
      "tensor(-0.0565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.6\tLoss: -0.056473\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.8\tLoss: 0.005455\n",
      "\n",
      "Train Epoch: 595\tAttack_Accuracy: 4920/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 595\tmaintain_Accuracy: 9991/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 595\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 595\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.0\tLoss: -0.004926\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.2\tLoss: 0.015123\n",
      "tensor(-0.0194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.4\tLoss: -0.019372\n",
      "tensor(-0.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.6\tLoss: -0.011675\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.8\tLoss: 0.017117\n",
      "\n",
      "Test Epoch: 596\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 596\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.0\tLoss: 0.005492\n",
      "tensor(-0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.2\tLoss: -0.010378\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.4\tLoss: 0.027784\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.6\tLoss: 0.006044\n",
      "tensor(0.0374, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.8\tLoss: 0.037358\n",
      "\n",
      "Test Epoch: 597\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 597\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0373, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.0\tLoss: -0.037335\n",
      "tensor(0.0506, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.2\tLoss: 0.050586\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.4\tLoss: 0.008239\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.6\tLoss: 0.018613\n",
      "tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.8\tLoss: 0.061732\n",
      "\n",
      "Test Epoch: 598\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 598\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.0\tLoss: -0.022949\n",
      "tensor(-0.0400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.2\tLoss: -0.040010\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.4\tLoss: 0.007057\n",
      "tensor(-0.0159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.6\tLoss: -0.015907\n",
      "tensor(-0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.8\tLoss: -0.008599\n",
      "\n",
      "Test Epoch: 599\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 599\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.0\tLoss: 0.012351\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.2\tLoss: 0.039030\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.4\tLoss: 0.040839\n",
      "tensor(-0.0239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.6\tLoss: -0.023945\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.8\tLoss: 0.019435\n",
      "\n",
      "Train Epoch: 600\tAttack_Accuracy: 4836/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 600\tmaintain_Accuracy: 9961/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 600\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 600\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.0\tLoss: 0.005206\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.2\tLoss: 0.017798\n",
      "tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.4\tLoss: 0.050872\n",
      "tensor(-0.0212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.6\tLoss: -0.021183\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.8\tLoss: 0.012337\n",
      "\n",
      "Test Epoch: 601\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 601\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.0\tLoss: -0.032804\n",
      "tensor(-0.0016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.2\tLoss: -0.001601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.4\tLoss: 0.021550\n",
      "tensor(-0.0122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.6\tLoss: -0.012191\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.8\tLoss: 0.012644\n",
      "\n",
      "Test Epoch: 602\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 602\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.0\tLoss: -0.010439\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.2\tLoss: 0.024617\n",
      "tensor(-0.0300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.4\tLoss: -0.029965\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.6\tLoss: 0.024530\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.8\tLoss: 0.034899\n",
      "\n",
      "Test Epoch: 603\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 603\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0354, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.0\tLoss: 0.035406\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.2\tLoss: 0.025805\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.4\tLoss: 0.040576\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.6\tLoss: 0.007399\n",
      "tensor(-0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.8\tLoss: -0.006016\n",
      "\n",
      "Test Epoch: 604\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 604\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.0\tLoss: 0.009492\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.2\tLoss: 0.012763\n",
      "tensor(-0.0173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.4\tLoss: -0.017261\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.6\tLoss: 0.038513\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.8\tLoss: 0.002714\n",
      "\n",
      "Train Epoch: 605\tAttack_Accuracy: 4913/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 605\tmaintain_Accuracy: 9944/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 605\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 605\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.0\tLoss: -0.010357\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.2\tLoss: 0.003452\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.4\tLoss: 0.013416\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.6\tLoss: 0.023016\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.8\tLoss: 0.009946\n",
      "\n",
      "Test Epoch: 606\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 606\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.0\tLoss: -0.014984\n",
      "tensor(-0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.2\tLoss: -0.019104\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.4\tLoss: 0.007801\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.6\tLoss: 0.017041\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.8\tLoss: 0.012005\n",
      "\n",
      "Test Epoch: 607\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 607\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.0\tLoss: 0.007431\n",
      "tensor(-0.0530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.2\tLoss: -0.053049\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.4\tLoss: 0.019330\n",
      "tensor(0.0334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.6\tLoss: 0.033438\n",
      "tensor(-0.0351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.8\tLoss: -0.035073\n",
      "\n",
      "Test Epoch: 608\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 608\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.0\tLoss: -0.029607\n",
      "tensor(-0.0201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.2\tLoss: -0.020147\n",
      "tensor(-0.0310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.4\tLoss: -0.030991\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.6\tLoss: 0.012327\n",
      "tensor(-0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.8\tLoss: -0.022398\n",
      "\n",
      "Test Epoch: 609\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 609\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.0\tLoss: -0.006616\n",
      "tensor(-0.0269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.2\tLoss: -0.026851\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.4\tLoss: 0.032297\n",
      "tensor(-0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.6\tLoss: -0.009026\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.8\tLoss: 0.003045\n",
      "\n",
      "Train Epoch: 610\tAttack_Accuracy: 4930/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 610\tmaintain_Accuracy: 9930/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 610\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 610\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.0\tLoss: -0.004232\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.2\tLoss: 0.032881\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.4\tLoss: 0.000427\n",
      "tensor(-0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.6\tLoss: -0.008114\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.8\tLoss: 0.014787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 611\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 611\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.0\tLoss: -0.004756\n",
      "tensor(-0.0136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.2\tLoss: -0.013641\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.4\tLoss: 0.014142\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.6\tLoss: 0.026610\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.8\tLoss: 0.014704\n",
      "\n",
      "Test Epoch: 612\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 612\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.0\tLoss: 0.032912\n",
      "tensor(-0.0176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.2\tLoss: -0.017558\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.4\tLoss: 0.012833\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.6\tLoss: 0.003291\n",
      "tensor(-0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.8\tLoss: -0.005387\n",
      "\n",
      "Test Epoch: 613\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 613\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.0\tLoss: 0.012822\n",
      "tensor(-0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.2\tLoss: -0.008137\n",
      "tensor(-0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.4\tLoss: -0.003941\n",
      "tensor(-0.0022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.6\tLoss: -0.002242\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.8\tLoss: 0.005529\n",
      "\n",
      "Test Epoch: 614\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 614\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.0\tLoss: -0.004833\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.2\tLoss: -0.001418\n",
      "tensor(-0.0211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.4\tLoss: -0.021133\n",
      "tensor(-0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.6\tLoss: -0.017361\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.8\tLoss: 0.005501\n",
      "\n",
      "Train Epoch: 615\tAttack_Accuracy: 4874/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 615\tmaintain_Accuracy: 9918/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 615\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 615\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.0\tLoss: 0.001200\n",
      "tensor(-0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.2\tLoss: -0.017663\n",
      "tensor(-0.0264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.4\tLoss: -0.026428\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.6\tLoss: 0.014504\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.8\tLoss: 0.021368\n",
      "\n",
      "Test Epoch: 616\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 616\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.0\tLoss: 0.007950\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.2\tLoss: 0.008983\n",
      "tensor(-0.0376, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.4\tLoss: -0.037635\n",
      "tensor(-0.0325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.6\tLoss: -0.032532\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.8\tLoss: 0.024610\n",
      "\n",
      "Test Epoch: 617\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 617\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.0\tLoss: 0.004374\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.2\tLoss: 0.020718\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.4\tLoss: 0.000309\n",
      "tensor(-0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.6\tLoss: -0.001723\n",
      "tensor(-0.0074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.8\tLoss: -0.007368\n",
      "\n",
      "Test Epoch: 618\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 618\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.0\tLoss: 0.008080\n",
      "tensor(-0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.2\tLoss: -0.010193\n",
      "tensor(0.0666, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.4\tLoss: 0.066613\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.6\tLoss: 0.000227\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.8\tLoss: 0.023190\n",
      "\n",
      "Test Epoch: 619\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 619\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.0\tLoss: 0.036649\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.2\tLoss: 0.017535\n",
      "tensor(-0.0187, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.4\tLoss: -0.018737\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.6\tLoss: 0.008595\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.8\tLoss: 0.006077\n",
      "\n",
      "Train Epoch: 620\tAttack_Accuracy: 4876/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 620\tmaintain_Accuracy: 9894/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 620\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 620\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.0\tLoss: 0.017371\n",
      "tensor(-0.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.2\tLoss: -0.011667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.4\tLoss: 0.010397\n",
      "tensor(0.0428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.6\tLoss: 0.042785\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.8\tLoss: 0.021743\n",
      "\n",
      "Test Epoch: 621\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 621\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.0\tLoss: 0.020951\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.2\tLoss: 0.010702\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.4\tLoss: 0.002790\n",
      "tensor(-0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.6\tLoss: -0.005047\n",
      "tensor(-0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.8\tLoss: -0.014843\n",
      "\n",
      "Test Epoch: 622\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 622\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.0\tLoss: 0.012784\n",
      "tensor(-0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.2\tLoss: -0.022964\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.4\tLoss: 0.022336\n",
      "tensor(-0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.6\tLoss: -0.009349\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.8\tLoss: 0.011041\n",
      "\n",
      "Test Epoch: 623\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 623\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.0\tLoss: -0.003624\n",
      "tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.2\tLoss: -0.006975\n",
      "tensor(-0.0157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.4\tLoss: -0.015699\n",
      "tensor(-7.0725e-05, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.6\tLoss: -0.000071\n",
      "tensor(0.0528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.8\tLoss: 0.052781\n",
      "\n",
      "Test Epoch: 624\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 624\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.0\tLoss: -0.014040\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.2\tLoss: 0.017323\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.4\tLoss: 0.015644\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.6\tLoss: 0.021216\n",
      "tensor(-0.0107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.8\tLoss: -0.010687\n",
      "\n",
      "Train Epoch: 625\tAttack_Accuracy: 4868/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 625\tmaintain_Accuracy: 9938/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 625\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 625\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.0\tLoss: -0.018015\n",
      "tensor(-0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.2\tLoss: -0.000209\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.4\tLoss: 0.000947\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.6\tLoss: 0.029424\n",
      "tensor(0.0296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.8\tLoss: 0.029574\n",
      "\n",
      "Test Epoch: 626\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 626\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.0\tLoss: 0.022005\n",
      "tensor(-0.0147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.2\tLoss: -0.014725\n",
      "tensor(-0.0075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.4\tLoss: -0.007466\n",
      "tensor(-0.0411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.6\tLoss: -0.041072\n",
      "tensor(-0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.8\tLoss: -0.012307\n",
      "\n",
      "Test Epoch: 627\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 627\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.0\tLoss: -0.057048\n",
      "tensor(-0.0132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.2\tLoss: -0.013214\n",
      "tensor(-0.0175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.4\tLoss: -0.017518\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.6\tLoss: 0.001343\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.8\tLoss: 0.001607\n",
      "\n",
      "Test Epoch: 628\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 628\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.0\tLoss: -0.011812\n",
      "tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.2\tLoss: 0.058238\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.4\tLoss: 0.021718\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.6\tLoss: 0.009812\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.8\tLoss: 0.048820\n",
      "\n",
      "Test Epoch: 629\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 629\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.0\tLoss: 0.006467\n",
      "tensor(-0.0068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.2\tLoss: -0.006755\n",
      "tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.4\tLoss: 0.054501\n",
      "tensor(-0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.6\tLoss: -0.009811\n",
      "tensor(0.0340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.8\tLoss: 0.033988\n",
      "\n",
      "Train Epoch: 630\tAttack_Accuracy: 4883/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 630\tmaintain_Accuracy: 9932/12800 (78%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 630\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 630\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.0\tLoss: -0.015524\n",
      "tensor(-0.0360, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.2\tLoss: -0.035965\n",
      "tensor(-0.0073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.4\tLoss: -0.007277\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.6\tLoss: 0.015190\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.8\tLoss: 0.009009\n",
      "\n",
      "Test Epoch: 631\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 631\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.0\tLoss: 0.013727\n",
      "tensor(-0.0068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.2\tLoss: -0.006793\n",
      "tensor(-0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.4\tLoss: -0.003667\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.6\tLoss: 0.013572\n",
      "tensor(-0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.8\tLoss: -0.009787\n",
      "\n",
      "Test Epoch: 632\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 632\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.0\tLoss: -0.002259\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.2\tLoss: 0.007568\n",
      "tensor(-0.0111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.4\tLoss: -0.011078\n",
      "tensor(-0.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.6\tLoss: -0.010512\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.8\tLoss: 0.034057\n",
      "\n",
      "Test Epoch: 633\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 633\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.0\tLoss: 0.029106\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.2\tLoss: 0.017865\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.4\tLoss: 0.005007\n",
      "tensor(-0.0138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.6\tLoss: -0.013811\n",
      "tensor(-0.0205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.8\tLoss: -0.020529\n",
      "\n",
      "Test Epoch: 634\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 634\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.0\tLoss: -0.019910\n",
      "tensor(-0.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.2\tLoss: -0.008043\n",
      "tensor(-0.0398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.4\tLoss: -0.039809\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.6\tLoss: 0.038487\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.8\tLoss: 0.016625\n",
      "\n",
      "Train Epoch: 635\tAttack_Accuracy: 4901/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 635\tmaintain_Accuracy: 9941/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 635\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 635\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.0\tLoss: 0.018790\n",
      "tensor(-0.0209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.2\tLoss: -0.020924\n",
      "tensor(-0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.4\tLoss: -0.001143\n",
      "tensor(-0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.6\tLoss: -0.005537\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.8\tLoss: 0.018603\n",
      "\n",
      "Test Epoch: 636\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 636\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.0\tLoss: 0.046816\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.2\tLoss: 0.012726\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.4\tLoss: 0.024204\n",
      "tensor(0.0573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.6\tLoss: 0.057268\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.8\tLoss: 0.017998\n",
      "\n",
      "Test Epoch: 637\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 637\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.0\tLoss: 0.003653\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.2\tLoss: 0.011930\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.4\tLoss: 0.004336\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.6\tLoss: 0.037953\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.8\tLoss: 0.014358\n",
      "\n",
      "Test Epoch: 638\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 638\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.0\tLoss: -0.005406\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.2\tLoss: 0.034880\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.4\tLoss: 0.039948\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.6\tLoss: 0.004237\n",
      "tensor(-0.0045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.8\tLoss: -0.004451\n",
      "\n",
      "Test Epoch: 639\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 639\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.0\tLoss: 0.016869\n",
      "tensor(-0.0341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.2\tLoss: -0.034145\n",
      "tensor(0.0602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.4\tLoss: 0.060165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.6\tLoss: -0.022465\n",
      "tensor(-0.0255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.8\tLoss: -0.025537\n",
      "\n",
      "Train Epoch: 640\tAttack_Accuracy: 4898/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 640\tmaintain_Accuracy: 9991/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 640\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 640\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.0\tLoss: 0.004998\n",
      "tensor(-0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.2\tLoss: -0.011626\n",
      "tensor(0.0499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.4\tLoss: 0.049878\n",
      "tensor(-0.0157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.6\tLoss: -0.015738\n",
      "tensor(-0.0003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.8\tLoss: -0.000306\n",
      "\n",
      "Test Epoch: 641\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 641\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.0\tLoss: 0.036603\n",
      "tensor(-1.8775e-05, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.2\tLoss: -0.000019\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.4\tLoss: 0.028707\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.6\tLoss: 0.008950\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.8\tLoss: 0.003158\n",
      "\n",
      "Test Epoch: 642\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 642\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.0\tLoss: -0.021694\n",
      "tensor(-0.0025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.2\tLoss: -0.002527\n",
      "tensor(-0.0383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.4\tLoss: -0.038317\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.6\tLoss: 0.015016\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.8\tLoss: 0.008439\n",
      "\n",
      "Test Epoch: 643\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 643\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.0\tLoss: 0.020727\n",
      "tensor(-0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.2\tLoss: -0.008529\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.4\tLoss: 0.030129\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.6\tLoss: 0.027494\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.8\tLoss: 0.035472\n",
      "\n",
      "Test Epoch: 644\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 644\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.0\tLoss: -0.031031\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.2\tLoss: 0.008664\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.4\tLoss: 0.022448\n",
      "tensor(-0.0279, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.6\tLoss: -0.027916\n",
      "tensor(-0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.8\tLoss: -0.015357\n",
      "\n",
      "Train Epoch: 645\tAttack_Accuracy: 4927/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 645\tmaintain_Accuracy: 9942/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 645\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 645\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.0\tLoss: 0.017482\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.2\tLoss: 0.007971\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.4\tLoss: 0.001671\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.6\tLoss: 0.010983\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.8\tLoss: 0.019012\n",
      "\n",
      "Test Epoch: 646\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 646\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0429, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.0\tLoss: 0.042947\n",
      "tensor(-0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.2\tLoss: -0.005559\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.4\tLoss: 0.020249\n",
      "tensor(-0.0228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.6\tLoss: -0.022844\n",
      "tensor(-0.0061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.8\tLoss: -0.006117\n",
      "\n",
      "Test Epoch: 647\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 647\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.0\tLoss: -0.024145\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.2\tLoss: 0.025032\n",
      "tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.4\tLoss: 0.049756\n",
      "tensor(-0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.6\tLoss: -0.011765\n",
      "tensor(-0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.8\tLoss: -0.003306\n",
      "\n",
      "Test Epoch: 648\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 648\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.0\tLoss: 0.007839\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.2\tLoss: 0.019210\n",
      "tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.4\tLoss: -0.001049\n",
      "tensor(-0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.6\tLoss: -0.003306\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.8\tLoss: 0.001661\n",
      "\n",
      "Test Epoch: 649\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 649\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.0\tLoss: -0.005826\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.2\tLoss: 0.023211\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.4\tLoss: 0.038679\n",
      "tensor(-0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.6\tLoss: -0.000184\n",
      "tensor(-0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.8\tLoss: -0.019136\n",
      "\n",
      "Train Epoch: 650\tAttack_Accuracy: 4867/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 650\tmaintain_Accuracy: 9949/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 650\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 650\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.0\tLoss: -0.006578\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.2\tLoss: 0.010269\n",
      "tensor(-0.0351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.4\tLoss: -0.035081\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.6\tLoss: 0.028948\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.8\tLoss: 0.009314\n",
      "\n",
      "Test Epoch: 651\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 651\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.0\tLoss: -0.019351\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.2\tLoss: 0.001699\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.4\tLoss: 0.016355\n",
      "tensor(-0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.6\tLoss: -0.008908\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.8\tLoss: 0.005190\n",
      "\n",
      "Test Epoch: 652\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 652\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.0\tLoss: 0.012253\n",
      "tensor(-0.0273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.2\tLoss: -0.027271\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.4\tLoss: 0.019828\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.6\tLoss: 0.016371\n",
      "tensor(-0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.8\tLoss: -0.001926\n",
      "\n",
      "Test Epoch: 653\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 653\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.0\tLoss: -0.009266\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.2\tLoss: 0.009894\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.4\tLoss: 0.022738\n",
      "tensor(-0.0194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.6\tLoss: -0.019433\n",
      "tensor(-0.0377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.8\tLoss: -0.037684\n",
      "\n",
      "Test Epoch: 654\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 654\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.0\tLoss: -0.006321\n",
      "tensor(-0.0287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.2\tLoss: -0.028651\n",
      "tensor(-0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.4\tLoss: -0.019219\n",
      "tensor(-0.0260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.6\tLoss: -0.026043\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.8\tLoss: 0.003584\n",
      "\n",
      "Train Epoch: 655\tAttack_Accuracy: 4925/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 655\tmaintain_Accuracy: 9938/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 655\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 655\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.0\tLoss: -0.001944\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.2\tLoss: 0.000778\n",
      "tensor(0.0354, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.4\tLoss: 0.035384\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.6\tLoss: 0.027117\n",
      "tensor(-0.0303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.8\tLoss: -0.030341\n",
      "\n",
      "Test Epoch: 656\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 656\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.0\tLoss: 0.001885\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.2\tLoss: 0.022763\n",
      "tensor(-0.0016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.4\tLoss: -0.001599\n",
      "tensor(0.0335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.6\tLoss: 0.033516\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.8\tLoss: 0.013041\n",
      "\n",
      "Test Epoch: 657\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 657\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.0\tLoss: -0.007963\n",
      "tensor(-0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.2\tLoss: -0.002085\n",
      "tensor(-0.0132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.4\tLoss: -0.013203\n",
      "tensor(-0.0145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.6\tLoss: -0.014518\n",
      "tensor(-0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.8\tLoss: -0.017355\n",
      "\n",
      "Test Epoch: 658\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 658\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.0\tLoss: 0.029071\n",
      "tensor(-0.0227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.2\tLoss: -0.022732\n",
      "tensor(-0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.4\tLoss: -0.002718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.6\tLoss: 0.003418\n",
      "tensor(-0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.8\tLoss: -0.003546\n",
      "\n",
      "Test Epoch: 659\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 659\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0187, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.0\tLoss: -0.018660\n",
      "tensor(-0.0134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.2\tLoss: -0.013427\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.4\tLoss: 0.010469\n",
      "tensor(-0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.6\tLoss: -0.011217\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.8\tLoss: 0.027786\n",
      "\n",
      "Train Epoch: 660\tAttack_Accuracy: 4956/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 660\tmaintain_Accuracy: 9936/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 660\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 660\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.0\tLoss: 0.022297\n",
      "tensor(-0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.2\tLoss: -0.010410\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.4\tLoss: 0.014008\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.6\tLoss: 0.017126\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.8\tLoss: 0.006958\n",
      "\n",
      "Test Epoch: 661\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 661\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.0\tLoss: 0.040254\n",
      "tensor(-0.0255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.2\tLoss: -0.025491\n",
      "tensor(-0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.4\tLoss: -0.011172\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.6\tLoss: 0.006340\n",
      "tensor(0.0255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.8\tLoss: 0.025526\n",
      "\n",
      "Test Epoch: 662\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 662\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.0\tLoss: -0.021851\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.2\tLoss: 0.005389\n",
      "tensor(-0.0023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.4\tLoss: -0.002308\n",
      "tensor(0.0464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.6\tLoss: 0.046402\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.8\tLoss: 0.002346\n",
      "\n",
      "Test Epoch: 663\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 663\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.0\tLoss: 0.024951\n",
      "tensor(-0.0005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.2\tLoss: -0.000474\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.4\tLoss: 0.037485\n",
      "tensor(-0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.6\tLoss: -0.014219\n",
      "tensor(-0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.8\tLoss: -0.009271\n",
      "\n",
      "Test Epoch: 664\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 664\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.0\tLoss: 0.028326\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.2\tLoss: 0.029421\n",
      "tensor(-0.0173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.4\tLoss: -0.017250\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.6\tLoss: 0.000666\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.8\tLoss: 0.021719\n",
      "\n",
      "Train Epoch: 665\tAttack_Accuracy: 4929/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 665\tmaintain_Accuracy: 9877/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 665\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 665\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(-0.0265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.0\tLoss: -0.026496\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.2\tLoss: 0.004202\n",
      "tensor(-0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.4\tLoss: -0.022433\n",
      "tensor(0.0333, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.6\tLoss: 0.033323\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.8\tLoss: 0.016920\n",
      "\n",
      "Test Epoch: 666\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 666\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.0\tLoss: 0.021213\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.2\tLoss: 0.002266\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.4\tLoss: 0.015675\n",
      "tensor(-0.0063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.6\tLoss: -0.006310\n",
      "tensor(0.0293, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.8\tLoss: 0.029305\n",
      "\n",
      "Test Epoch: 667\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 667\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.0\tLoss: -0.009850\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.2\tLoss: 0.008118\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.4\tLoss: 0.037698\n",
      "tensor(-0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.6\tLoss: -0.023750\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.8\tLoss: 0.000871\n",
      "\n",
      "Test Epoch: 668\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 668\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.0\tLoss: -0.003439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0415, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.2\tLoss: 0.041466\n",
      "tensor(-0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.4\tLoss: -0.008610\n",
      "tensor(-0.0236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.6\tLoss: -0.023565\n",
      "tensor(0.0376, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.8\tLoss: 0.037607\n",
      "\n",
      "Test Epoch: 669\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 669\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.0\tLoss: -0.029249\n",
      "tensor(-0.0352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.2\tLoss: -0.035249\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.4\tLoss: 0.003493\n",
      "tensor(-0.0300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.6\tLoss: -0.030029\n",
      "tensor(0.0321, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.8\tLoss: 0.032113\n",
      "\n",
      "Train Epoch: 670\tAttack_Accuracy: 4910/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 670\tmaintain_Accuracy: 9973/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 670\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 670\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.0\tLoss: 0.005157\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.2\tLoss: 0.023768\n",
      "tensor(0.0320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.4\tLoss: 0.032032\n",
      "tensor(-0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.6\tLoss: -0.000985\n",
      "tensor(-0.0426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.8\tLoss: -0.042576\n",
      "\n",
      "Test Epoch: 671\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 671\tmaintain_Accuracy: 8248/10593 (78%)\n",
      "\n",
      "tensor(-0.0194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.0\tLoss: -0.019428\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.2\tLoss: 0.004383\n",
      "tensor(-0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.4\tLoss: -0.019898\n",
      "tensor(-0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.6\tLoss: -0.017706\n",
      "tensor(0.0358, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.8\tLoss: 0.035779\n",
      "\n",
      "Test Epoch: 672\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 672\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.0\tLoss: 0.027216\n",
      "tensor(-0.0277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.2\tLoss: -0.027701\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.4\tLoss: 0.001457\n",
      "tensor(-0.0025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.6\tLoss: -0.002519\n",
      "tensor(-0.0282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.8\tLoss: -0.028215\n",
      "\n",
      "Test Epoch: 673\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 673\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.0\tLoss: 0.001285\n",
      "tensor(-0.0194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.2\tLoss: -0.019352\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.4\tLoss: 0.035112\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.6\tLoss: 0.024346\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.8\tLoss: 0.017766\n",
      "\n",
      "Test Epoch: 674\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 674\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.0\tLoss: 0.016917\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.2\tLoss: 0.040940\n",
      "tensor(0.0450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.4\tLoss: 0.044989\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.6\tLoss: 0.018877\n",
      "tensor(-0.0114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.8\tLoss: -0.011394\n",
      "\n",
      "Train Epoch: 675\tAttack_Accuracy: 4886/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 675\tmaintain_Accuracy: 9893/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 675\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 675\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.0\tLoss: -0.031451\n",
      "tensor(-0.0273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.2\tLoss: -0.027329\n",
      "tensor(0.0264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.4\tLoss: 0.026411\n",
      "tensor(-0.0314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.6\tLoss: -0.031399\n",
      "tensor(-0.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.8\tLoss: -0.010911\n",
      "\n",
      "Test Epoch: 676\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 676\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.0\tLoss: -0.023857\n",
      "tensor(-0.0165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.2\tLoss: -0.016507\n",
      "tensor(-0.0168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.4\tLoss: -0.016765\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.6\tLoss: 0.013564\n",
      "tensor(-0.0289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.8\tLoss: -0.028946\n",
      "\n",
      "Test Epoch: 677\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 677\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.0\tLoss: 0.006386\n",
      "tensor(-0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.2\tLoss: -0.005547\n",
      "tensor(-0.0063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.4\tLoss: -0.006256\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.6\tLoss: 0.011929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.8\tLoss: -0.005379\n",
      "\n",
      "Test Epoch: 678\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 678\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.0\tLoss: -0.014891\n",
      "tensor(-0.0167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.2\tLoss: -0.016707\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.4\tLoss: 0.022320\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.6\tLoss: 0.005965\n",
      "tensor(-0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.8\tLoss: -0.002935\n",
      "\n",
      "Test Epoch: 679\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 679\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.0\tLoss: 0.018648\n",
      "tensor(-0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.2\tLoss: -0.005942\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.4\tLoss: 0.013519\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.6\tLoss: 0.018327\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.8\tLoss: 0.005490\n",
      "\n",
      "Train Epoch: 680\tAttack_Accuracy: 4878/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 680\tmaintain_Accuracy: 9994/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 680\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 680\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.0\tLoss: 0.010561\n",
      "tensor(-0.0221, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.2\tLoss: -0.022123\n",
      "tensor(0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.4\tLoss: 0.012075\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.6\tLoss: 0.030813\n",
      "tensor(-0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.8\tLoss: -0.029137\n",
      "\n",
      "Test Epoch: 681\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 681\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.0\tLoss: 0.039387\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.2\tLoss: 0.005437\n",
      "tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.4\tLoss: 0.058135\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.6\tLoss: 0.000176\n",
      "tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.8\tLoss: 0.090255\n",
      "\n",
      "Test Epoch: 682\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 682\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.0\tLoss: 0.025092\n",
      "tensor(-0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.2\tLoss: -0.019084\n",
      "tensor(-0.0363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.4\tLoss: -0.036322\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.6\tLoss: 0.002962\n",
      "tensor(-0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.8\tLoss: -0.004156\n",
      "\n",
      "Test Epoch: 683\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 683\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.0\tLoss: 0.011361\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.2\tLoss: 0.000761\n",
      "tensor(-0.0184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.4\tLoss: -0.018432\n",
      "tensor(-0.0121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.6\tLoss: -0.012130\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.8\tLoss: 0.040634\n",
      "\n",
      "Test Epoch: 684\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 684\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.0\tLoss: 0.013345\n",
      "tensor(-0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.2\tLoss: -0.002895\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.4\tLoss: 0.010835\n",
      "tensor(-0.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.6\tLoss: -0.004654\n",
      "tensor(-0.0173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.8\tLoss: -0.017257\n",
      "\n",
      "Train Epoch: 685\tAttack_Accuracy: 4859/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 685\tmaintain_Accuracy: 9920/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 685\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 685\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.0\tLoss: 0.030757\n",
      "tensor(-0.0341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.2\tLoss: -0.034059\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.4\tLoss: 0.010209\n",
      "tensor(-0.0025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.6\tLoss: -0.002513\n",
      "tensor(-0.0074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.8\tLoss: -0.007442\n",
      "\n",
      "Test Epoch: 686\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 686\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.0\tLoss: -0.007691\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.2\tLoss: 0.026672\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.4\tLoss: 0.021003\n",
      "tensor(-0.0111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.6\tLoss: -0.011143\n",
      "tensor(0.0084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.8\tLoss: 0.008403\n",
      "\n",
      "Test Epoch: 687\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 687\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.0\tLoss: 0.025152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.2\tLoss: 0.061451\n",
      "tensor(-0.0270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.4\tLoss: -0.027000\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.6\tLoss: 0.005691\n",
      "tensor(-0.0213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.8\tLoss: -0.021261\n",
      "\n",
      "Test Epoch: 688\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 688\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.0\tLoss: -0.024540\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.2\tLoss: 0.013798\n",
      "tensor(0.0432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.4\tLoss: 0.043208\n",
      "tensor(-0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.6\tLoss: -0.026553\n",
      "tensor(-0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.8\tLoss: -0.017093\n",
      "\n",
      "Test Epoch: 689\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 689\tmaintain_Accuracy: 8244/10593 (78%)\n",
      "\n",
      "tensor(-0.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.0\tLoss: -0.009545\n",
      "tensor(-0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.2\tLoss: -0.011842\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.4\tLoss: 0.011465\n",
      "tensor(-0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.6\tLoss: -0.003903\n",
      "tensor(-0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.8\tLoss: -0.003379\n",
      "\n",
      "Train Epoch: 690\tAttack_Accuracy: 4871/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 690\tmaintain_Accuracy: 9911/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 690\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 690\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.0\tLoss: 0.016407\n",
      "tensor(-0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.2\tLoss: -0.011648\n",
      "tensor(-0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.4\tLoss: -0.000688\n",
      "tensor(-0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.6\tLoss: -0.006036\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.8\tLoss: 0.016446\n",
      "\n",
      "Test Epoch: 691\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 691\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.0\tLoss: 0.038245\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.2\tLoss: 0.016072\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.4\tLoss: 0.032736\n",
      "tensor(-0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.6\tLoss: -0.010355\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.8\tLoss: 0.002783\n",
      "\n",
      "Test Epoch: 692\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 692\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.0\tLoss: 0.042455\n",
      "tensor(-0.0242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.2\tLoss: -0.024203\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.4\tLoss: 0.018458\n",
      "tensor(-0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.6\tLoss: -0.001314\n",
      "tensor(-0.0261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.8\tLoss: -0.026074\n",
      "\n",
      "Test Epoch: 693\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 693\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.0\tLoss: -0.011333\n",
      "tensor(-0.0170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.2\tLoss: -0.016968\n",
      "tensor(-0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.4\tLoss: -0.003414\n",
      "tensor(-0.0427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.6\tLoss: -0.042696\n",
      "tensor(0.0204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.8\tLoss: 0.020399\n",
      "\n",
      "Test Epoch: 694\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 694\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.0\tLoss: -0.036412\n",
      "tensor(0.0254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.2\tLoss: 0.025437\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.4\tLoss: 0.020584\n",
      "tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.6\tLoss: 0.065330\n",
      "tensor(-0.0261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.8\tLoss: -0.026077\n",
      "\n",
      "Train Epoch: 695\tAttack_Accuracy: 4931/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 695\tmaintain_Accuracy: 9867/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 695\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 695\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.0\tLoss: -0.011972\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.2\tLoss: 0.003395\n",
      "tensor(-0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.4\tLoss: -0.002920\n",
      "tensor(-0.0165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.6\tLoss: -0.016467\n",
      "tensor(-0.0079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.8\tLoss: -0.007945\n",
      "\n",
      "Test Epoch: 696\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 696\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.0\tLoss: 0.019580\n",
      "tensor(0.0375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.2\tLoss: 0.037463\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.4\tLoss: 0.013637\n",
      "tensor(-0.0361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.6\tLoss: -0.036123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.8\tLoss: 0.036870\n",
      "\n",
      "Test Epoch: 697\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 697\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.0\tLoss: 0.007137\n",
      "tensor(-0.0101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.2\tLoss: -0.010150\n",
      "tensor(-0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.4\tLoss: -0.008856\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.6\tLoss: 0.019156\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.8\tLoss: 0.014030\n",
      "\n",
      "Test Epoch: 698\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 698\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.0\tLoss: -0.025611\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.2\tLoss: 0.020342\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.4\tLoss: 0.007501\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.6\tLoss: 0.002268\n",
      "tensor(-0.0317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.8\tLoss: -0.031668\n",
      "\n",
      "Test Epoch: 699\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 699\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.0\tLoss: 0.016662\n",
      "tensor(-0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.2\tLoss: -0.008104\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.4\tLoss: 0.001277\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.6\tLoss: 0.026029\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.8\tLoss: 0.008054\n",
      "\n",
      "Train Epoch: 700\tAttack_Accuracy: 4933/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 700\tmaintain_Accuracy: 9919/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 700\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 700\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.0\tLoss: 0.003081\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.2\tLoss: 0.015042\n",
      "tensor(-0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.4\tLoss: -0.017109\n",
      "tensor(-0.0298, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.6\tLoss: -0.029841\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.8\tLoss: 0.013269\n",
      "\n",
      "Test Epoch: 701\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 701\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.0\tLoss: -0.001415\n",
      "tensor(-0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.2\tLoss: -0.014321\n",
      "tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.4\tLoss: 0.063712\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.6\tLoss: 0.015365\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.8\tLoss: 0.022553\n",
      "\n",
      "Test Epoch: 702\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 702\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.0\tLoss: 0.006080\n",
      "tensor(-0.0363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.2\tLoss: -0.036279\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.4\tLoss: 0.014485\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.6\tLoss: 0.012346\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.8\tLoss: 0.040565\n",
      "\n",
      "Test Epoch: 703\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 703\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.0\tLoss: -0.049679\n",
      "tensor(-0.0256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.2\tLoss: -0.025624\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.4\tLoss: 0.005292\n",
      "tensor(-0.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.6\tLoss: -0.022263\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.8\tLoss: 0.008560\n",
      "\n",
      "Test Epoch: 704\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 704\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.0\tLoss: 0.033175\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.2\tLoss: 0.003549\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.4\tLoss: 0.045073\n",
      "tensor(-0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.6\tLoss: -0.011648\n",
      "tensor(-0.0266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.8\tLoss: -0.026601\n",
      "\n",
      "Train Epoch: 705\tAttack_Accuracy: 4942/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 705\tmaintain_Accuracy: 9902/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 705\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 705\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.0\tLoss: -0.026238\n",
      "tensor(-0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.2\tLoss: -0.023679\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.4\tLoss: 0.016011\n",
      "tensor(-0.0041, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.6\tLoss: -0.004123\n",
      "tensor(-0.0036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.8\tLoss: -0.003634\n",
      "\n",
      "Test Epoch: 706\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 706\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.0\tLoss: 0.020607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.2\tLoss: 0.014604\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.4\tLoss: 0.016057\n",
      "tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.6\tLoss: -0.007005\n",
      "tensor(-0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.8\tLoss: -0.022355\n",
      "\n",
      "Test Epoch: 707\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 707\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0354, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.0\tLoss: 0.035383\n",
      "tensor(-0.0077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.2\tLoss: -0.007723\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.4\tLoss: 0.036141\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.6\tLoss: 0.047421\n",
      "tensor(-0.0172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.8\tLoss: -0.017244\n",
      "\n",
      "Test Epoch: 708\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 708\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.0\tLoss: -0.009971\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.2\tLoss: 0.004939\n",
      "tensor(-0.0139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.4\tLoss: -0.013928\n",
      "tensor(-0.0043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.6\tLoss: -0.004331\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.8\tLoss: 0.002684\n",
      "\n",
      "Test Epoch: 709\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 709\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.0\tLoss: -0.017913\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.2\tLoss: 0.027218\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.4\tLoss: 0.000962\n",
      "tensor(-0.0094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.6\tLoss: -0.009356\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.8\tLoss: 0.005126\n",
      "\n",
      "Train Epoch: 710\tAttack_Accuracy: 4899/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 710\tmaintain_Accuracy: 9900/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 710\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 710\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.0\tLoss: 0.024117\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.2\tLoss: 0.021409\n",
      "tensor(-0.0132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.4\tLoss: -0.013172\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.6\tLoss: 0.041419\n",
      "tensor(-0.0216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.8\tLoss: -0.021617\n",
      "\n",
      "Test Epoch: 711\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 711\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.0\tLoss: -0.002828\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.2\tLoss: 0.040909\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.4\tLoss: 0.021968\n",
      "tensor(-0.0314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.6\tLoss: -0.031407\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.8\tLoss: 0.006365\n",
      "\n",
      "Test Epoch: 712\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 712\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.0\tLoss: 0.006025\n",
      "tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.2\tLoss: 0.052672\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.4\tLoss: 0.027818\n",
      "tensor(0.0490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.6\tLoss: 0.048955\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.8\tLoss: 0.005174\n",
      "\n",
      "Test Epoch: 713\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 713\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.0\tLoss: 0.005545\n",
      "tensor(0.0227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.2\tLoss: 0.022746\n",
      "tensor(-0.0363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.4\tLoss: -0.036287\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.6\tLoss: 0.012687\n",
      "tensor(-0.0022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.8\tLoss: -0.002200\n",
      "\n",
      "Test Epoch: 714\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 714\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.0\tLoss: 0.008852\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.2\tLoss: 0.012975\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.4\tLoss: 0.014508\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.6\tLoss: 0.002108\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.8\tLoss: 0.014318\n",
      "\n",
      "Train Epoch: 715\tAttack_Accuracy: 4878/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 715\tmaintain_Accuracy: 9886/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 715\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 715\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.0\tLoss: 0.036865\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.2\tLoss: 0.023330\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.4\tLoss: 0.003449\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.6\tLoss: 0.038326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.8\tLoss: 0.043077\n",
      "\n",
      "Test Epoch: 716\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 716\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.0\tLoss: -0.024543\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.2\tLoss: 0.007025\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.4\tLoss: 0.024765\n",
      "tensor(-0.0403, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.6\tLoss: -0.040264\n",
      "tensor(-0.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.8\tLoss: -0.006738\n",
      "\n",
      "Test Epoch: 717\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 717\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.0\tLoss: -0.002285\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.2\tLoss: 0.032163\n",
      "tensor(-0.0186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.4\tLoss: -0.018597\n",
      "tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.6\tLoss: 0.050320\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.8\tLoss: 0.024785\n",
      "\n",
      "Test Epoch: 718\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 718\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.0\tLoss: 0.019146\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.2\tLoss: 0.011389\n",
      "tensor(-0.0381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.4\tLoss: -0.038107\n",
      "tensor(-0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.6\tLoss: -0.001700\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.8\tLoss: 0.019330\n",
      "\n",
      "Test Epoch: 719\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 719\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.0\tLoss: 0.030165\n",
      "tensor(-0.0043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.2\tLoss: -0.004306\n",
      "tensor(-0.0306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.4\tLoss: -0.030640\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.6\tLoss: 0.011828\n",
      "tensor(-0.0345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.8\tLoss: -0.034515\n",
      "\n",
      "Train Epoch: 720\tAttack_Accuracy: 4922/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 720\tmaintain_Accuracy: 9913/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 720\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 720\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.0\tLoss: 0.063343\n",
      "tensor(-0.0303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.2\tLoss: -0.030259\n",
      "tensor(-0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.4\tLoss: -0.009328\n",
      "tensor(-0.0108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.6\tLoss: -0.010769\n",
      "tensor(0.0306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.8\tLoss: 0.030575\n",
      "\n",
      "Test Epoch: 721\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 721\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.0\tLoss: 0.013130\n",
      "tensor(0.0334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.2\tLoss: 0.033406\n",
      "tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.4\tLoss: 0.050060\n",
      "tensor(0.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.6\tLoss: 0.011717\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.8\tLoss: 0.025075\n",
      "\n",
      "Test Epoch: 722\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 722\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.0\tLoss: -0.020990\n",
      "tensor(-0.0413, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.2\tLoss: -0.041313\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.4\tLoss: 0.025018\n",
      "tensor(-0.0229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.6\tLoss: -0.022918\n",
      "tensor(-0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.8\tLoss: -0.016362\n",
      "\n",
      "Test Epoch: 723\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 723\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.0\tLoss: 0.002035\n",
      "tensor(-0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.2\tLoss: -0.008941\n",
      "tensor(-0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.4\tLoss: -0.005249\n",
      "tensor(-0.0079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.6\tLoss: -0.007943\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.8\tLoss: 0.006237\n",
      "\n",
      "Test Epoch: 724\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 724\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.0\tLoss: 0.047279\n",
      "tensor(0.0335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.2\tLoss: 0.033513\n",
      "tensor(-0.0092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.4\tLoss: -0.009168\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.6\tLoss: 0.017614\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.8\tLoss: 0.013320\n",
      "\n",
      "Train Epoch: 725\tAttack_Accuracy: 4963/6400 (78%)\n",
      "\n",
      "\n",
      "Train Epoch: 725\tmaintain_Accuracy: 9683/12800 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 725\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 725\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.0\tLoss: 0.010169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.2\tLoss: 0.024334\n",
      "tensor(-0.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.4\tLoss: -0.009456\n",
      "tensor(-0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.6\tLoss: -0.003391\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.8\tLoss: 0.007943\n",
      "\n",
      "Test Epoch: 726\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 726\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.0\tLoss: 0.016633\n",
      "tensor(-0.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.2\tLoss: -0.002405\n",
      "tensor(-0.0201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.4\tLoss: -0.020097\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.6\tLoss: 0.029239\n",
      "tensor(-0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.8\tLoss: -0.012298\n",
      "\n",
      "Test Epoch: 727\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 727\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.0\tLoss: -0.011197\n",
      "tensor(-0.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.2\tLoss: -0.021891\n",
      "tensor(-0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.4\tLoss: -0.008987\n",
      "tensor(-0.0228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.6\tLoss: -0.022838\n",
      "tensor(-0.0127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.8\tLoss: -0.012683\n",
      "\n",
      "Test Epoch: 728\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 728\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.0\tLoss: -0.007228\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.2\tLoss: 0.012171\n",
      "tensor(-0.0182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.4\tLoss: -0.018182\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.6\tLoss: 0.005516\n",
      "tensor(-0.0368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.8\tLoss: -0.036832\n",
      "\n",
      "Test Epoch: 729\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 729\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.0\tLoss: 0.016837\n",
      "tensor(-0.0402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.2\tLoss: -0.040171\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.4\tLoss: 0.004157\n",
      "tensor(-0.0018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.6\tLoss: -0.001834\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.8\tLoss: 0.012331\n",
      "\n",
      "Train Epoch: 730\tAttack_Accuracy: 4893/6400 (76%)\n",
      "\n",
      "\n",
      "Train Epoch: 730\tmaintain_Accuracy: 9942/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 730\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 730\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0592, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.0\tLoss: -0.059210\n",
      "tensor(-0.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.2\tLoss: -0.005926\n",
      "tensor(-0.0022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.4\tLoss: -0.002227\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.6\tLoss: 0.022990\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.8\tLoss: 0.018838\n",
      "\n",
      "Test Epoch: 731\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 731\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.0\tLoss: -0.021998\n",
      "tensor(-0.0310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.2\tLoss: -0.031013\n",
      "tensor(8.3320e-05, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.4\tLoss: 0.000083\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.6\tLoss: 0.032212\n",
      "tensor(0.0428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.8\tLoss: 0.042791\n",
      "\n",
      "Test Epoch: 732\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 732\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.0\tLoss: 0.012250\n",
      "tensor(0.0263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.2\tLoss: 0.026254\n",
      "tensor(-0.0314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.4\tLoss: -0.031418\n",
      "tensor(-0.0023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.6\tLoss: -0.002319\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.8\tLoss: 0.010195\n",
      "\n",
      "Test Epoch: 733\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 733\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.0\tLoss: 0.013699\n",
      "tensor(-0.0137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.2\tLoss: -0.013698\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.4\tLoss: 0.010994\n",
      "tensor(-0.0063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.6\tLoss: -0.006261\n",
      "tensor(-0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.8\tLoss: -0.003039\n",
      "\n",
      "Test Epoch: 734\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 734\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.0\tLoss: -0.002146\n",
      "tensor(-0.0025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.2\tLoss: -0.002509\n",
      "tensor(0.0071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.4\tLoss: 0.007069\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.6\tLoss: 0.021213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.8\tLoss: 0.018874\n",
      "\n",
      "Train Epoch: 735\tAttack_Accuracy: 4934/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 735\tmaintain_Accuracy: 9910/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 735\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 735\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.0\tLoss: -0.028905\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.2\tLoss: 0.012039\n",
      "tensor(-0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.4\tLoss: -0.005561\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.6\tLoss: 0.005524\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.8\tLoss: 0.021417\n",
      "\n",
      "Test Epoch: 736\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 736\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.0\tLoss: 0.015993\n",
      "tensor(-0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.2\tLoss: -0.005553\n",
      "tensor(-0.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.4\tLoss: -0.008714\n",
      "tensor(0.0462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.6\tLoss: 0.046168\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.8\tLoss: 0.005074\n",
      "\n",
      "Test Epoch: 737\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 737\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.0\tLoss: -0.018377\n",
      "tensor(0.0280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.2\tLoss: 0.028033\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.4\tLoss: 0.029952\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.6\tLoss: 0.015133\n",
      "tensor(-0.0281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.8\tLoss: -0.028117\n",
      "\n",
      "Test Epoch: 738\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 738\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.0\tLoss: -0.015506\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.2\tLoss: 0.011563\n",
      "tensor(-0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.4\tLoss: -0.016405\n",
      "tensor(0.0328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.6\tLoss: 0.032837\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.8\tLoss: 0.015196\n",
      "\n",
      "Test Epoch: 739\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 739\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.0\tLoss: -0.023700\n",
      "tensor(-0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.2\tLoss: -0.008068\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.4\tLoss: 0.021007\n",
      "tensor(-0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.6\tLoss: -0.007006\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.8\tLoss: 0.001905\n",
      "\n",
      "Train Epoch: 740\tAttack_Accuracy: 4976/6400 (78%)\n",
      "\n",
      "\n",
      "Train Epoch: 740\tmaintain_Accuracy: 9899/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 740\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 740\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.0\tLoss: 0.009484\n",
      "tensor(-0.0379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.2\tLoss: -0.037915\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.4\tLoss: 0.006519\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.6\tLoss: 0.003089\n",
      "tensor(-0.0191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.8\tLoss: -0.019137\n",
      "\n",
      "Test Epoch: 741\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 741\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.0\tLoss: 0.038729\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.2\tLoss: 0.005162\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.4\tLoss: 0.016815\n",
      "tensor(-0.0421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.6\tLoss: -0.042065\n",
      "tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.8\tLoss: 0.051685\n",
      "\n",
      "Test Epoch: 742\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 742\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.0\tLoss: 0.001141\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.2\tLoss: 0.011593\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.4\tLoss: 0.041815\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.6\tLoss: 0.002719\n",
      "tensor(0.0457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.8\tLoss: 0.045653\n",
      "\n",
      "Test Epoch: 743\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 743\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.0\tLoss: 0.007358\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.2\tLoss: 0.034097\n",
      "tensor(-0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.4\tLoss: -0.000765\n",
      "tensor(0.0058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.6\tLoss: 0.005811\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.8\tLoss: 0.011385\n",
      "\n",
      "Test Epoch: 744\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 744\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.0\tLoss: -0.010315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.2\tLoss: 0.014104\n",
      "tensor(-0.0244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.4\tLoss: -0.024400\n",
      "tensor(-8.1778e-05, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.6\tLoss: -0.000082\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.8\tLoss: 0.041130\n",
      "\n",
      "Train Epoch: 745\tAttack_Accuracy: 4917/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 745\tmaintain_Accuracy: 9911/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 745\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 745\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.0\tLoss: 0.018154\n",
      "tensor(-0.0231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.2\tLoss: -0.023131\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.4\tLoss: 0.001148\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.6\tLoss: 0.008589\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.8\tLoss: 0.029121\n",
      "\n",
      "Test Epoch: 746\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 746\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.0\tLoss: 0.018874\n",
      "tensor(-0.0511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.2\tLoss: -0.051142\n",
      "tensor(-0.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.4\tLoss: -0.019155\n",
      "tensor(-0.0391, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.6\tLoss: -0.039106\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.8\tLoss: 0.030270\n",
      "\n",
      "Test Epoch: 747\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 747\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.0\tLoss: 0.017585\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.2\tLoss: 0.010283\n",
      "tensor(-0.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.4\tLoss: -0.001130\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.6\tLoss: 0.008956\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.8\tLoss: 0.005282\n",
      "\n",
      "Test Epoch: 748\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 748\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.0\tLoss: -0.013867\n",
      "tensor(-0.0114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.2\tLoss: -0.011411\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.4\tLoss: 0.015176\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.6\tLoss: 0.040030\n",
      "tensor(-0.0003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.8\tLoss: -0.000319\n",
      "\n",
      "Test Epoch: 749\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 749\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.0\tLoss: -0.001459\n",
      "tensor(-0.0139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.2\tLoss: -0.013872\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.4\tLoss: 0.017619\n",
      "tensor(-0.0156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.6\tLoss: -0.015588\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.8\tLoss: 0.024532\n",
      "\n",
      "Train Epoch: 750\tAttack_Accuracy: 4917/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 750\tmaintain_Accuracy: 9927/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 750\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 750\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.0\tLoss: -0.048559\n",
      "tensor(-0.0012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.2\tLoss: -0.001172\n",
      "tensor(0.0320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.4\tLoss: 0.032045\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.6\tLoss: 0.018289\n",
      "tensor(-0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.8\tLoss: -0.017402\n",
      "\n",
      "Test Epoch: 751\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 751\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.0\tLoss: -0.001667\n",
      "tensor(0.0493, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.2\tLoss: 0.049266\n",
      "tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.4\tLoss: 0.052077\n",
      "tensor(-0.0111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.6\tLoss: -0.011112\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.8\tLoss: 0.021269\n",
      "\n",
      "Test Epoch: 752\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 752\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(-0.0233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.0\tLoss: -0.023324\n",
      "tensor(-0.0603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.2\tLoss: -0.060283\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.4\tLoss: -0.001403\n",
      "tensor(-0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.6\tLoss: -0.003305\n",
      "tensor(-0.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.8\tLoss: -0.000626\n",
      "\n",
      "Test Epoch: 753\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 753\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.0\tLoss: 0.000333\n",
      "tensor(-0.0315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.2\tLoss: -0.031513\n",
      "tensor(-0.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.4\tLoss: -0.000651\n",
      "tensor(-0.0451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.6\tLoss: -0.045139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.8\tLoss: -0.011516\n",
      "\n",
      "Test Epoch: 754\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 754\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.0\tLoss: 0.009621\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.2\tLoss: 0.023797\n",
      "tensor(-0.0140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.4\tLoss: -0.014008\n",
      "tensor(-0.0301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.6\tLoss: -0.030109\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.8\tLoss: 0.003006\n",
      "\n",
      "Train Epoch: 755\tAttack_Accuracy: 4924/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 755\tmaintain_Accuracy: 9844/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 755\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 755\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.0\tLoss: 0.006918\n",
      "tensor(0.0295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.2\tLoss: 0.029525\n",
      "tensor(-0.0472, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.4\tLoss: -0.047180\n",
      "tensor(-0.0113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.6\tLoss: -0.011266\n",
      "tensor(-0.0335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.8\tLoss: -0.033459\n",
      "\n",
      "Test Epoch: 756\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 756\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.0\tLoss: -0.000841\n",
      "tensor(-0.0288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.2\tLoss: -0.028758\n",
      "tensor(-0.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.4\tLoss: -0.007767\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.6\tLoss: 0.024722\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.8\tLoss: 0.005405\n",
      "\n",
      "Test Epoch: 757\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 757\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.0\tLoss: -0.017183\n",
      "tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.2\tLoss: 0.070007\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.4\tLoss: 0.030458\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.6\tLoss: 0.017404\n",
      "tensor(-0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.8\tLoss: -0.014174\n",
      "\n",
      "Test Epoch: 758\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 758\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.0\tLoss: 0.026916\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.2\tLoss: 0.028092\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.4\tLoss: 0.003487\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.6\tLoss: 0.013426\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.8\tLoss: 0.010187\n",
      "\n",
      "Test Epoch: 759\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 759\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.0\tLoss: -0.010377\n",
      "tensor(-0.0057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.2\tLoss: -0.005695\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.4\tLoss: 0.009021\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.6\tLoss: 0.022882\n",
      "tensor(-0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.8\tLoss: -0.000847\n",
      "\n",
      "Train Epoch: 760\tAttack_Accuracy: 4899/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 760\tmaintain_Accuracy: 9889/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 760\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 760\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.0\tLoss: 0.018937\n",
      "tensor(0.0602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.2\tLoss: 0.060160\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.4\tLoss: 0.003027\n",
      "tensor(-0.0155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.6\tLoss: -0.015521\n",
      "tensor(-0.0197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.8\tLoss: -0.019653\n",
      "\n",
      "Test Epoch: 761\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 761\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.0\tLoss: -0.019917\n",
      "tensor(-0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.2\tLoss: -0.002958\n",
      "tensor(-0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.4\tLoss: -0.011604\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.6\tLoss: 0.017713\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.8\tLoss: 0.007728\n",
      "\n",
      "Test Epoch: 762\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 762\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.0\tLoss: 0.014294\n",
      "tensor(0.0326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.2\tLoss: 0.032606\n",
      "tensor(-0.0189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.4\tLoss: -0.018921\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.6\tLoss: 0.019632\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.8\tLoss: 0.003747\n",
      "\n",
      "Test Epoch: 763\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 763\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.0\tLoss: -0.004189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.2\tLoss: -0.002097\n",
      "tensor(-0.0111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.4\tLoss: -0.011104\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.6\tLoss: 0.009754\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.8\tLoss: 0.008070\n",
      "\n",
      "Test Epoch: 764\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 764\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.0\tLoss: 0.016450\n",
      "tensor(-0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.2\tLoss: -0.004978\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.4\tLoss: 0.025817\n",
      "tensor(-0.0046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.6\tLoss: -0.004640\n",
      "tensor(-0.0241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.8\tLoss: -0.024129\n",
      "\n",
      "Train Epoch: 765\tAttack_Accuracy: 4925/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 765\tmaintain_Accuracy: 9855/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 765\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 765\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.0\tLoss: 0.005522\n",
      "tensor(0.0457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.2\tLoss: 0.045664\n",
      "tensor(0.0284, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.4\tLoss: 0.028414\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.6\tLoss: 0.010776\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.8\tLoss: 0.005659\n",
      "\n",
      "Test Epoch: 766\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 766\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.0\tLoss: 0.032304\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.2\tLoss: 0.046768\n",
      "tensor(-0.0337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.4\tLoss: -0.033740\n",
      "tensor(-0.0388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.6\tLoss: -0.038771\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.8\tLoss: 0.022926\n",
      "\n",
      "Test Epoch: 767\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 767\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.0\tLoss: 0.005324\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.2\tLoss: 0.017666\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.4\tLoss: 0.003965\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.6\tLoss: 0.005640\n",
      "tensor(-0.0033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.8\tLoss: -0.003271\n",
      "\n",
      "Test Epoch: 768\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 768\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.0\tLoss: -0.006626\n",
      "tensor(-0.0142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.2\tLoss: -0.014224\n",
      "tensor(-0.0294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.4\tLoss: -0.029446\n",
      "tensor(-0.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.6\tLoss: -0.017078\n",
      "tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.8\tLoss: 0.066321\n",
      "\n",
      "Test Epoch: 769\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 769\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.0\tLoss: -0.014387\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.2\tLoss: 0.008923\n",
      "tensor(-0.0238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.4\tLoss: -0.023784\n",
      "tensor(-0.0163, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.6\tLoss: -0.016251\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.8\tLoss: 0.009604\n",
      "\n",
      "Train Epoch: 770\tAttack_Accuracy: 4940/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 770\tmaintain_Accuracy: 9889/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 770\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 770\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.0\tLoss: -0.005780\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.2\tLoss: 0.006830\n",
      "tensor(-0.0197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.4\tLoss: -0.019653\n",
      "tensor(-0.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.6\tLoss: -0.007972\n",
      "tensor(-0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.8\tLoss: -0.004911\n",
      "\n",
      "Test Epoch: 771\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 771\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(0.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.0\tLoss: 0.012862\n",
      "tensor(0.0328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.2\tLoss: 0.032799\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.4\tLoss: 0.006679\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.6\tLoss: 0.000874\n",
      "tensor(-0.0395, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.8\tLoss: -0.039550\n",
      "\n",
      "Test Epoch: 772\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 772\tmaintain_Accuracy: 8247/10593 (78%)\n",
      "\n",
      "tensor(-0.0225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.0\tLoss: -0.022484\n",
      "tensor(-0.0029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.2\tLoss: -0.002872\n",
      "tensor(-0.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.4\tLoss: -0.002045\n",
      "tensor(-0.0158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.6\tLoss: -0.015790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.8\tLoss: 0.030223\n",
      "\n",
      "Test Epoch: 773\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 773\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.0\tLoss: -0.006604\n",
      "tensor(0.0460, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.2\tLoss: 0.046024\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.4\tLoss: 0.008066\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.6\tLoss: -0.001404\n",
      "tensor(-0.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.8\tLoss: -0.014272\n",
      "\n",
      "Test Epoch: 774\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 774\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.0\tLoss: 0.050761\n",
      "tensor(0.0443, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.2\tLoss: 0.044317\n",
      "tensor(-0.0306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.4\tLoss: -0.030604\n",
      "tensor(-0.0046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.6\tLoss: -0.004615\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.8\tLoss: 0.011521\n",
      "\n",
      "Train Epoch: 775\tAttack_Accuracy: 4919/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 775\tmaintain_Accuracy: 9881/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 775\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 775\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0041, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.0\tLoss: -0.004078\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.2\tLoss: 0.061339\n",
      "tensor(-0.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.4\tLoss: -0.006658\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.6\tLoss: 0.021738\n",
      "tensor(-0.0084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.8\tLoss: -0.008361\n",
      "\n",
      "Test Epoch: 776\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 776\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.0\tLoss: 0.015529\n",
      "tensor(0.0307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.2\tLoss: 0.030673\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.4\tLoss: 0.010540\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.6\tLoss: 0.015761\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.8\tLoss: 0.002194\n",
      "\n",
      "Test Epoch: 777\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 777\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.0\tLoss: -0.011164\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.2\tLoss: 0.010393\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.4\tLoss: 0.000982\n",
      "tensor(0.0253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.6\tLoss: 0.025304\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.8\tLoss: 0.011769\n",
      "\n",
      "Test Epoch: 778\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 778\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0279, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.0\tLoss: 0.027909\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.2\tLoss: 0.003423\n",
      "tensor(-0.0198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.4\tLoss: -0.019844\n",
      "tensor(-0.0139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.6\tLoss: -0.013902\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.8\tLoss: 0.003899\n",
      "\n",
      "Test Epoch: 779\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 779\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.0\tLoss: 0.021747\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.2\tLoss: 0.007646\n",
      "tensor(-0.0065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.4\tLoss: -0.006536\n",
      "tensor(-0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.6\tLoss: -0.021505\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.8\tLoss: 0.017227\n",
      "\n",
      "Train Epoch: 780\tAttack_Accuracy: 4971/6400 (78%)\n",
      "\n",
      "\n",
      "Train Epoch: 780\tmaintain_Accuracy: 9865/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 780\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 780\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.0\tLoss: -0.013028\n",
      "tensor(0.0091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.2\tLoss: 0.009117\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.4\tLoss: 0.022079\n",
      "tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.6\tLoss: 0.061525\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.8\tLoss: 0.008126\n",
      "\n",
      "Test Epoch: 781\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 781\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.0\tLoss: 0.004936\n",
      "tensor(-0.0522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.2\tLoss: -0.052246\n",
      "tensor(-0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.4\tLoss: -0.008456\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.6\tLoss: 0.000825\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.8\tLoss: 0.003694\n",
      "\n",
      "Test Epoch: 782\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 782\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.0\tLoss: -0.029040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.2\tLoss: 0.003009\n",
      "tensor(-0.0190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.4\tLoss: -0.019037\n",
      "tensor(-0.0043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.6\tLoss: -0.004296\n",
      "tensor(-0.0077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.8\tLoss: -0.007653\n",
      "\n",
      "Test Epoch: 783\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 783\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.0\tLoss: 0.005484\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.2\tLoss: 0.012048\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.4\tLoss: 0.015259\n",
      "tensor(-0.0152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.6\tLoss: -0.015231\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.8\tLoss: 0.002560\n",
      "\n",
      "Test Epoch: 784\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 784\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.0\tLoss: 0.022359\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.2\tLoss: 0.007565\n",
      "tensor(-0.0075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.4\tLoss: -0.007503\n",
      "tensor(0.0116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.6\tLoss: 0.011630\n",
      "tensor(0.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.8\tLoss: 0.008024\n",
      "\n",
      "Train Epoch: 785\tAttack_Accuracy: 4916/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 785\tmaintain_Accuracy: 9887/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 785\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 785\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.0\tLoss: 0.031553\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.2\tLoss: 0.018632\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.4\tLoss: 0.009510\n",
      "tensor(0.0061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.6\tLoss: 0.006072\n",
      "tensor(-0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.8\tLoss: -0.000882\n",
      "\n",
      "Test Epoch: 786\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 786\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.0\tLoss: -0.009718\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.2\tLoss: 0.016670\n",
      "tensor(0.0439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.4\tLoss: 0.043906\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.6\tLoss: 0.015801\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.8\tLoss: 0.027456\n",
      "\n",
      "Test Epoch: 787\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 787\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.0\tLoss: 0.008874\n",
      "tensor(0.0133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.2\tLoss: 0.013266\n",
      "tensor(-0.0012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.4\tLoss: -0.001180\n",
      "tensor(0.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.6\tLoss: 0.010535\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.8\tLoss: 0.009555\n",
      "\n",
      "Test Epoch: 788\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 788\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.0\tLoss: 0.044385\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.2\tLoss: 0.007032\n",
      "tensor(-0.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.4\tLoss: -0.011950\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.6\tLoss: 0.004319\n",
      "tensor(-0.0384, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.8\tLoss: -0.038350\n",
      "\n",
      "Test Epoch: 789\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 789\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.0\tLoss: 0.034898\n",
      "tensor(-0.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.2\tLoss: -0.004895\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.4\tLoss: 0.021536\n",
      "tensor(-0.0237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.6\tLoss: -0.023692\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.8\tLoss: 0.015997\n",
      "\n",
      "Train Epoch: 790\tAttack_Accuracy: 4929/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 790\tmaintain_Accuracy: 9931/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 790\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 790\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.0\tLoss: 0.009905\n",
      "tensor(-0.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.2\tLoss: -0.001887\n",
      "tensor(-0.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.4\tLoss: -0.014768\n",
      "tensor(-0.0136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.6\tLoss: -0.013550\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.8\tLoss: 0.015936\n",
      "\n",
      "Test Epoch: 791\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 791\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:792 0.0\tLoss: 0.008638\n",
      "tensor(-0.0126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:792 0.2\tLoss: -0.012622\n",
      "tensor(0.0392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:792 0.4\tLoss: 0.039180\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:792 0.6\tLoss: 0.002747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:792 0.8\tLoss: -0.017701\n",
      "\n",
      "Test Epoch: 792\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 792\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:793 0.0\tLoss: 0.016253\n",
      "tensor(0.0285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:793 0.2\tLoss: 0.028514\n",
      "tensor(0.0317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:793 0.4\tLoss: 0.031723\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:793 0.6\tLoss: 0.002121\n",
      "tensor(-0.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:793 0.8\tLoss: -0.008095\n",
      "\n",
      "Test Epoch: 793\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 793\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:794 0.0\tLoss: 0.046983\n",
      "tensor(0.0597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:794 0.2\tLoss: 0.059669\n",
      "tensor(-0.0405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:794 0.4\tLoss: -0.040517\n",
      "tensor(0.0387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:794 0.6\tLoss: 0.038711\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:794 0.8\tLoss: 0.009346\n",
      "\n",
      "Test Epoch: 794\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 794\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:795 0.0\tLoss: -0.013842\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:795 0.2\tLoss: 0.000948\n",
      "tensor(-0.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:795 0.4\tLoss: -0.001436\n",
      "tensor(0.0200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:795 0.6\tLoss: 0.019960\n",
      "tensor(-0.0028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:795 0.8\tLoss: -0.002829\n",
      "\n",
      "Train Epoch: 795\tAttack_Accuracy: 4948/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 795\tmaintain_Accuracy: 9892/12800 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 795\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 795\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:796 0.0\tLoss: 0.017659\n",
      "tensor(-0.0152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:796 0.2\tLoss: -0.015182\n",
      "tensor(-0.0200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:796 0.4\tLoss: -0.019988\n",
      "tensor(0.0132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:796 0.6\tLoss: 0.013187\n",
      "tensor(-0.0050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:796 0.8\tLoss: -0.005047\n",
      "\n",
      "Test Epoch: 796\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 796\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(-0.0168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:797 0.0\tLoss: -0.016759\n",
      "tensor(0.0274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:797 0.2\tLoss: 0.027365\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:797 0.4\tLoss: 0.003714\n",
      "tensor(-0.0360, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:797 0.6\tLoss: -0.036030\n",
      "tensor(-0.0017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:797 0.8\tLoss: -0.001721\n",
      "\n",
      "Test Epoch: 797\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 797\tmaintain_Accuracy: 8245/10593 (78%)\n",
      "\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:798 0.0\tLoss: 0.002631\n",
      "tensor(-0.0229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:798 0.2\tLoss: -0.022905\n",
      "tensor(-0.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:798 0.4\tLoss: -0.008251\n",
      "tensor(-0.0303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:798 0.6\tLoss: -0.030301\n",
      "tensor(-0.0101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:798 0.8\tLoss: -0.010058\n",
      "\n",
      "Test Epoch: 798\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 798\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:799 0.0\tLoss: 0.008477\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:799 0.2\tLoss: 0.021373\n",
      "tensor(-0.0245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:799 0.4\tLoss: -0.024549\n",
      "tensor(-0.0120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:799 0.6\tLoss: -0.012005\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:799 0.8\tLoss: 0.019872\n",
      "\n",
      "Test Epoch: 799\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 799\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "tensor(0.0420, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:800 0.0\tLoss: 0.042032\n",
      "tensor(-0.0336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:800 0.2\tLoss: -0.033580\n",
      "tensor(-0.0172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:800 0.4\tLoss: -0.017211\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:800 0.6\tLoss: 0.000378\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:800 0.8\tLoss: 0.018546\n",
      "\n",
      "Train Epoch: 800\tAttack_Accuracy: 4946/6400 (77%)\n",
      "\n",
      "\n",
      "Train Epoch: 800\tmaintain_Accuracy: 9950/12800 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 800\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 800\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#method: DTA\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "model = torch.load('model.pkl')\n",
    "\n",
    "\n",
    "log_interval = 20\n",
    "n_epoch = 800\n",
    "threshold_epoch = 1001\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "losses_t=[]\n",
    "losses_nt = []\n",
    "losses_epoch = []\n",
    "losses_t_epoch=[]\n",
    "losses_nt_epoch = []\n",
    "delta_wav = []\n",
    "delta_sum = []\n",
    "attack_ = []\n",
    "maintain_ = []\n",
    "error_ = []\n",
    "lr = 0.001\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data_size = data.size(1)\n",
    "delta = torch.rand(1,data_size, 16000)-0.5\n",
    "delta = delta.to(device)\n",
    "delta.requires_grad = True\n",
    "optimizer = optim.Adam([delta],lr = 0.003)\n",
    "kpi = 0.5\n",
    "\n",
    "p_index = label_to_index('left').item()\n",
    "t_index = label_to_index('learn').item()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.3)  # reduce the learning after 20 epochs by a factor of 10\n",
    "\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        if epoch%threshold_epoch == 0 and epoch != 0:\n",
    "            threshold = 0.2 + (epoch // threshold_epoch  -1 ) * 0.07\n",
    "            delta_data = delta.data\n",
    "            delta_ = threshold*torch.tanh(delta)\n",
    "            delta_data = torch.arctanh(delta_ / (threshold+0.07))       \n",
    "            optimizer = optim.Adam([delta],lr = 0.001)\n",
    "            print(optimizer.state)\n",
    "        delta = train_attack(model, epoch, log_interval, threshold_epoch, delta)\n",
    "        delta_sum.append(delta.abs().mean())\n",
    "        kpi = test_attack(model, epoch,threshold_epoch, delta=delta)\n",
    "        '''\n",
    "        if epoch % 30 ==0:\n",
    "            delta.data = 0.5 * delta\n",
    "            print('delta',delta.abs().mean())\n",
    "\n",
    "            delta.requires_grad = True\n",
    "            optimizer = optim.Adam([delta],lr = 0.001)\n",
    "        '''\n",
    "\n",
    "        scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.4568e-07, -7.9674e-08,  2.9454e-09,  ...,  1.9256e-09,\n",
      "          -6.9608e-08,  4.5636e-09]]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAh40lEQVR4nO3de5hddX3v8fdn7z33yW2SAUNuQ0qKBgoKIaBVvGNoLfRYPBJsC9SW0/Z4jr1YxYO1FS89h9rqkfIcoRWtNxCpWLRYiAharUDCnQQCgYRkAiGThIRcJpnb9/yx1p7s2bnMnmRm9mTtz+t59pO1fuv2ncyez/7t3157LUUEZmaWXblqF2BmZmPLQW9mlnEOejOzjHPQm5llnIPezCzjHPRmZhnnoLfMkvQWSZ3VrmM0SLpX0u9Xuw47NjnobUKTtE5St6SdkrZL+k9JfyhpxM/ddF/vGIWaviqpR9KuksejR7tfs7HioLdjwW9ExCRgHvC/gY8CX65uSVwTEa0lj9OrXI/ZITno7ZgRETsi4nbgfcClkk6V1CDpc5LWS3pJ0pckNZVvK+nrwFzg+2kP/CNp+3ckbZK0Q9JPJZ1yNDVK6pAUkq6Q9IKkFyV9uGR5g6QvpMteSKcbSpZfKOkRSa9IelbSkpLdz5P08/TdzV2SZhxNrVY7HPR2zImIB4BO4E0kPfxfBl4LnATMAj5xkG1+B1hP8u6gNSKuSRf9EFgAHAc8BHxzlMp8a7rf84CPlgwZXQWck9Z7OrAY+DiApMXA14C/AKYC5wLrSvZ5CXB5Wms98GHMKuCgt2PVC0AbcAXwpxGxLSJ2Ap8FLq50JxFxY0TsjIh9wF8Dp0uaUsGmH04/Myg+/rls+ScjYndEPA58BViatr8fuDoiNkdEF/BJ4HfSZR8AboyIZRExEBEbI+Kpkn1+JSKejohu4BaSFwuzYRWqXYDZEZpF8vxtBh6UVGwXkK9kB5LywGeA9wLtwEC6aAawY5jNPxcRHz/M8g0l088Dv5JOn5DOly47IZ2eA9xxmH1uKpneA7QOU6MZ4B69HYMknUUS9N8DuoFTImJq+pgSEYcKwPJLtV4CXAi8A5gCdBQPMQplzimZnkvyDoT033mHWLYB+KVROLbZEA56O2ZImizp3cDNwDci4lHgH4HPSzouXWeWpHcdYhcvAfNL5icB+4CtJO8MPjuK5f6lpOb0w93LgW+n7TcBH5fUnn6Y+gngG+myLwOXS3q7pFz6s7x6FGuyGuWgt2PB9yXtJOnxXgX8PUl4QnKq5RrgPkmvAD8CTj7Efv6GJGS3p2fCfI1k6GQjsAq4bwQ1faTsPPotZct/ktZ1N8kwz11p+6eBFcBjwOMkHwB/GgY/ZL4c+DzJ0NFPGNr7Nzsi8o1HzEaPpA5gLVAXEX1VLscMcI/ezCzzHPRmByFpZdnQTPHx/mrXZjZSHroxM8s49+jNzDJuwn1hasaMGdHR0VHtMszMjikPPvjglohoP9iyCRf0HR0drFixotplmJkdUyQ9f6hlHroxM8s4B72ZWcY56M3MMs5Bb2aWcQ56M7OMc9CbmWWcg97MLOMyE/S79/Xx93et5uH1L1e7FDOzCSUzQb+vb4Av/ngNj27YXu1SzMwmlMwEfT6X3P2tb8AXaTMzK5WZoK/LO+jNzA4mM0FfyCU/Sl//QJUrMTObWDIU9O7Rm5kdTGaCPpcTOUFfv4PezKxUZoIeoJDP0TvgoRszs1KZCvq6nOh3j97MbIhMBX0+J4/Rm5mVyVTQ1+Vz9PqsGzOzITIV9IW86HeP3sxsiGwFfS5Hr8fozcyGyFbQ50Wfz7oxMxsiW0Gfk8+jNzMrk7Ggz7lHb2ZWpqKgl7RE0mpJayRdeZDlfyZplaTHJN0taV7JskslPZM+Lh3N4ssV8u7Rm5mVGzboJeWB64DzgYXAUkkLy1Z7GFgUEacBtwLXpNu2AX8FnA0sBv5K0rTRK3+o5JuxDnozs1KV9OgXA2si4rmI6AFuBi4sXSEi7omIPensfcDsdPpdwLKI2BYRLwPLgCWjU/qBCjnR76EbM7MhKgn6WcCGkvnOtO1QPgD8cCTbSrpC0gpJK7q6uioo6eAKOfn0SjOzMqP6Yayk3wYWAX87ku0i4oaIWBQRi9rb24/4+HX5nK9Hb2ZWppKg3wjMKZmfnbYNIekdwFXABRGxbyTbjpZ8zt+MNTMrV0nQLwcWSDpRUj1wMXB76QqSXgdcTxLym0sW3QmcJ2la+iHseWnbmGgo5NjX5x69mVmpwnArRESfpA+SBHQeuDEiVkq6GlgREbeTDNW0At+RBLA+Ii6IiG2SPkXyYgFwdURsG5OfBGiqz9Pd2z9WuzczOyYNG/QAEXEHcEdZ2ydKpt9xmG1vBG480gJHoqkuT3ePg97MrFSmvhnbWOcevZlZuUwFfXN9nr0OejOzITIV9E11eXr7wzcfMTMrka2gr88DePjGzKxEpoK+sS4J+r3+QNbMbFCmgr7ZPXozswNkKuib0h79HvfozcwGZSroG92jNzM7QKaCvslj9GZmB8hU0HuM3szsQJkK+mKP3kFvZrZfpoK+0R/GmpkdIFNBX/zClC+DYGa2X7aCvjh04x69mdmgbAa9e/RmZoMyFfS5nGgo5NyjNzMrkamgB99lysysXPaC3neZMjMbIntB7x69mdkQ2Qt69+jNzIbIZtC7R29mNih7Qe+hGzOzITIX9I0eujEzGyJzQd/sHr2Z2RCZC3p/GGtmNlTmgt5DN2ZmQ1UU9JKWSFotaY2kKw+y/FxJD0nqk3RR2bJrJK2U9KSkL0rSaBV/MB66MTMbatigl5QHrgPOBxYCSyUtLFttPXAZ8K2ybd8A/CpwGnAqcBbw5qOu+jCa6vL0DQS9/QNjeRgzs2NGJT36xcCaiHguInqAm4ELS1eIiHUR8RhQnq4BNAL1QANQB7x01FUfRvGa9L75iJlZopKgnwVsKJnvTNuGFRG/AO4BXkwfd0bEk+XrSbpC0gpJK7q6uirZ9SEVg97j9GZmiTH9MFbSScBrgNkkLw5vk/Sm8vUi4oaIWBQRi9rb24/qmL5BuJnZUJUE/UZgTsn87LStEv8FuC8idkXELuCHwOtHVuLINNUVANjT0zeWhzEzO2ZUEvTLgQWSTpRUD1wM3F7h/tcDb5ZUkFRH8kHsAUM3o8lDN2ZmQw0b9BHRB3wQuJMkpG+JiJWSrpZ0AYCksyR1Au8Frpe0Mt38VuBZ4HHgUeDRiPj+GPwcgzx0Y2Y2VKGSlSLiDuCOsrZPlEwvJxnSKd+uH/hvR1njiBTvG+uzbszMEpn7ZqyHbszMhspc0HvoxsxsqOwF/eBZNw56MzPIYNA31ic/UrdPrzQzAzIY9PX5HPmcPHRjZpbKXNBLorku76EbM7NU5oIeoLE+z1736M3MgIwGfXO9e/RmZkWZDPomD92YmQ3KZtB76MbMbFAmg95DN2Zm+2Uy6D10Y2a2XzaDvr7goRszs1Qmgz45j97fjDUzg4wGfZPH6M3MBmU26D10Y2aWyGTQN9fl6e0PevsHql2KmVnVZTLoizcf8fCNmVnGg97DN2ZmWQ163zfWzGxQJoO+eXDoxqdYmpllMuib6pPbCXroxswsq0HvoRszs0GZDPri0E23g97MLJtBXzzrxveNNTOrMOglLZG0WtIaSVceZPm5kh6S1CfporJlcyXdJelJSaskdYxS7YfkoRszs/2GDXpJeeA64HxgIbBU0sKy1dYDlwHfOsguvgb8bUS8BlgMbD6agivhoRszs/0KFayzGFgTEc8BSLoZuBBYVVwhItaly4ZccyB9QShExLJ0vV2jU/bhNadn3eze59MrzcwqGbqZBWwome9M2yrxy8B2Sd+V9LCkv03fIQwh6QpJKySt6OrqqnDXh1ZfyFFfyLHL59GbmY35h7EF4E3Ah4GzgPkkQzxDRMQNEbEoIha1t7ePyoEnNRTYuddBb2ZWSdBvBOaUzM9O2yrRCTwSEc9FRB/wPeCMEVV4hCY1FtjloDczqyjolwMLJJ0oqR64GLi9wv0vB6ZKKnbT30bJ2P5Yam0ssMtj9GZmwwd92hP/IHAn8CRwS0SslHS1pAsAJJ0lqRN4L3C9pJXptv0kwzZ3S3ocEPCPY/OjDDWpoY6de3vH41BmZhNaJWfdEBF3AHeUtX2iZHo5yZDOwbZdBpx2FDUekdbGAhu27Rnvw5qZTTiZ/GYs+MNYM7Oi7Aa9x+jNzIAMB33xw9iIqHYpZmZVldmgn9RYR/9A+MJmZlbzMhv0rQ3J58w+l97Mal1mg35SYxL0Oz1Ob2Y1LvtB7x69mdW4zAb9lKZ6AF7e01PlSszMqiuzQT+jNQn6rbsc9GZW2zIb9G0tSdBv272vypWYmVVXZoO+taFAfSHH1t3u0ZtZbcts0Etieku9h27MrOZlNugBprfWs809ejOrcZkO+raWBrbu8hi9mdW2TAf99JZ6j9GbWc3LftB7jN7Malymg76ttZ7u3n66e3xhMzOrXZkO+hktDQBs9bn0ZlbDMh30xS9NefjGzGpZpoN+emvx27EOejOrXdkO+nToZotPsTSzGpbtoHeP3sws20HfXJ+nwde7MbMal+mg9/VuzMwyHvQA01sbfKliM6tpmQ/6Nl8GwcxqXEVBL2mJpNWS1ki68iDLz5X0kKQ+SRcdZPlkSZ2S/mE0ih6J6a0eujGz2jZs0EvKA9cB5wMLgaWSFpatth64DPjWIXbzKeCnR17mkUsubOahGzOrXZX06BcDayLiuYjoAW4GLixdISLWRcRjwED5xpLOBI4H7hqFekdsemsDe3sH2NPTV43Dm5lVXSVBPwvYUDLfmbYNS1IO+Dvgw8Osd4WkFZJWdHV1VbLrivkyCGZW68b6w9g/Bu6IiM7DrRQRN0TEoohY1N7ePqoFTC8GvT+QNbMaVahgnY3AnJL52WlbJV4PvEnSHwOtQL2kXRFxwAe6Y2V6a3IZBJ9iaWa1qpKgXw4skHQiScBfDFxSyc4j4v3FaUmXAYvGM+Rhf49+i4duzKxGDTt0ExF9wAeBO4EngVsiYqWkqyVdACDpLEmdwHuB6yWtHMuiR8LXuzGzWldJj56IuAO4o6ztEyXTy0mGdA63j68CXx1xhUepub7ApMYCL2zvHu9Dm5lNCJn/ZizA/BktPNe1u9plmJlVRU0E/YkzWli7xUFvZrWpJoJ+fnsrG7d3+ybhZlaTaiToWwDcqzezmlQTQd8xPQn69dsc9GZWe2oi6E+Y2gTAC9v3VrkSM7PxVxNBP625joZCzqdYmllNqomgl8TsaU08v21PtUsxMxt3NRH0AKecMIUnNu6odhlmZuOuZoL+1FmTeXHHXl72pRDMrMbUTNDPn9EKwNqtPvPGzGpLzQR9x4zkFMt1PpfezGpMzQT93LZmcvKXpsys9tRM0NcXcsye1uygN7OaUzNBD764mZnVppoL+nVbdhMR1S7FzGzc1FzQ7+7pp2un7x9rZrWjpoJ+wfHJKZYrX3ilypWYmY2fmgr6182ZRl1e3L92W7VLMTMbNzUV9E31eU6bPZUH1m6tdilmZuOmpoIeYPGJbTzWuYM9PX3VLsXMbFzUZND3DQQPr99e7VLMzMZFzQX9GXOmAfBYp69kaWa1oeaCfkpzHXPamvjXRzbSP+Dz6c0s+2ou6AEuPmsuT23aydotu6pdipnZmKso6CUtkbRa0hpJVx5k+bmSHpLUJ+mikvbXSvqFpJWSHpP0vtEs/ki98aQZADzb5cshmFn2DRv0kvLAdcD5wEJgqaSFZautBy4DvlXWvgf43Yg4BVgCfEHS1KOs+ajNb28hnxN3rXyp2qWYmY25QgXrLAbWRMRzAJJuBi4EVhVXiIh16bKB0g0j4umS6RckbQbage1HW/jRmNRYx7tPm8k9qzdXswwzs3FRydDNLGBDyXxn2jYikhYD9cCzB1l2haQVklZ0dXWNdNdHZOHMyWzb3cOO7t5xOZ6ZWbWMy4exkmYCXwcuj4iB8uURcUNELIqIRe3t7eNREiemd5y64afP0tt/QElmZplRSdBvBOaUzM9O2yoiaTLwb8BVEXHfyMobO29akLygXHfPs3zhR08Ps7aZ2bGrkqBfDiyQdKKkeuBi4PZKdp6ufxvwtYi49cjLHH1N9XnecnIS9v/6yAsM+Jx6M8uoYYM+IvqADwJ3Ak8Ct0TESklXS7oAQNJZkjqB9wLXS1qZbv5fgXOByyQ9kj5eOxY/yJG4dunruOwNHXS+3M2D61+udjlmZmNCE+1uS4sWLYoVK1aM2/Fe2dvLGVcv4w/Onc9Hl7x63I5rZjaaJD0YEYsOtqwmvxlbanJjHYtPbOOOx1+kp88fyppZ9tR80ANccvZcnt+6h+88uMHXvzGzzHHQA+f+cvKh7FW3PcFvXPsz3zzczDLFQU8yfFO06sVXuPfp8fnSlpnZeHDQp7586f7PMLpe2VfFSszMRpeDPvX21xw/OH3bwxt5ZMP26hVjZjaKHPQl/uMjbwXgF89t5Tev+zn/8mBnlSsyMzt6DvoSc9qaedcp+3v2f/6dR1m3xdesN7Njm4O+zDW/dTp3/sm5g/Nv+dy97N7XV8WKzMyOjoO+zJTmOk5+1SSuu+SMwbbvP/oCG7d3c9ZnfsSyVb5ZiZkdW2r+EgiHs2nHXt597c/Ysmv/WTinzZ7C7R98YxWrMjM7kC+BcIReNaWRP3zz/CFtqzftZMuufdyzejNv/7t7WesxfDOb4NyjH8bAQLB+2x46ZrTwzEs7eefnfzpk+dLFc1h4whR+++y5SKpSlWZW6w7Xo6/knrE1LZcTHendqBYcP2mw/T1nzGLtlt3c9MAGYAN7e/r5g3PnH2IvZmbV46GbEbr+d85k6eK5/N17T+dTF57K5MbktfIzdzxJx5X/xk+e7uJLP3nW96I1swnDQzdHKSL4va8u557VQ6+P8z/fdhJ/dt7JVarKzGqNh27GkCS+cvlidu3r469vX8mt6bdpv/Lzdcyc2sS8tmbO7JhGQyFf5UrNrFY56EdJa0OBT//mqRw3qYHNO/dx64OdfOy7jwPQVJfnZx99K9NbG6pcpZnVIgf9KGqsy/ORJa+mfyA46bhWJjfWserFHXzjvvWsfOGVwevem5mNJwf9GMjnxB+++ZcA2LprH9+4bz3PbN7loDezqvBZN2NsemsDbS31PPPSzmqXYmY1ykE/Dk46rpWnNjnozaw6HPTj4Mx503hkw3bueWpztUsxsxrkoB8HH3r7An6pvYXLv7qcpz2EY2bjzEE/Dhrr8ly7NLns8Xmf/ykPrN1W5YrMrJY46MfJwhMm8+0rzmH+jBZ++5/u55v3P8/e3v5ql2VmNaCioJe0RNJqSWskXXmQ5edKekhSn6SLypZdKumZ9HHpaBV+LDp7/nRuvuIcZrc1cdVtT3Dmp5bx6r/8IV+/73n+/YkXWbbqJfb0+G5WZja6hr3WjaQ88DTwTqATWA4sjYhVJet0AJOBDwO3R8StaXsbsAJYBATwIHBmRLx8qOMda9e6ORI79/aybNVLfHv5Bu4vG8ZprMtx4oxW3rnweC57QweFvJjcWAfAExt30N3bz1kdbQwMBLmcL4tsZomjvdbNYmBNRDyX7uxm4EJgMOgjYl26bKBs23cByyJiW7p8GbAEuGmEP0OmTGqs4z1nzOY9Z8ymp2+Aa3/8DO2TGmiuL/DN+5/n4fXbefLFV/jyfzzH7p5+2ic18NaT27llReeQ/bRPauBVkxt5zxmzWLp4Lq9097J+2x6+98hGFs1rY05bM2fOm1aln9LMJopKgn4WsKFkvhM4u8L9H2zbWeUrSboCuAJg7ty5Fe46G+oLOf685CqXv/4rM9m8cy9bdu3j28s3sHrTTh7t3DEk5Kc01TFzSiOdL3fz+MYdPL5xB5/8/qoh+/3GfesBmNFaz/GTGzln/nQ+9I4F/Pvjm2hpKDB7WhOnz5k6Lj+jmVXXhLgEQkTcANwAydBNlcupqqb6PPOmtzBvegtnzmsDkksh7+7pp7WhMDgPyZUzX97dw/1rt/Kfz25lRmsDq154hbe/5jh6+4N7Vm8mL/HCjm5u/PlavvyztUOOtXTxXD7+66+hpWFCPA3MbIxU8he+EZhTMj87bavERuAtZdveW+G2lpI0GPLF+aJpLfUsOXUmS06decB2l5y9/93Rfc9t5d7VXcxorWdqcz3fuv95bnpgPVt37ePK81/N/PbWsf0hzKxqKgn65cACSSeSBPfFwCUV7v9O4LOSigPF5wEfG3GVdtTOmT+dc+ZPH5y/6MzZXP+TZ/mbHz7FXateorEux+vnT2fn3j4KedE/EExpqmNSYx0d01vo2rWXvb0DLJw5mbpCjtaGPKecMIXjJjWwt3eAQl401eV5ccde2ic1sK+3nw0vd9Ncn2dKUx1Tmuro6w/qCzma6vMMDARBcgG4/oEgIijkc/T0DVBf8Fm/ZqOpojtMSfo14AtAHrgxIj4j6WpgRUTcLuks4DZgGrAX2BQRp6Tb/h7wv9JdfSYivnK4Y9XCWTcTybotu/ni3c+wu6ePFeteZmpzHW0t9fT0DbBlVw/7+vrZsquHxroce3vLP2sfOQkmNRTY09NPTmJaS12y/0KOttZ6Ol/uZubkRt58cju/etIM5rW1MLW5jrp8jrq8KORz1KfT+Zx8Q3az1OHOuvGtBO2wBgaCjdu7OWFqE3t6+tjXN8De3n42vtzN2i272d3TT07Q0zdAfwTHT2pk2+4e6gs55rQ1sbd3gB3dvezo7qWQE7v29fH81j1Mb6knnxPbdvdw/ORGtu3pYduuHubNaKZzWzf3rt7M7p7Df6FMInkByIm6Qo66kheBQr44r/RFIkchr3R5Ll1fNBRyNBTyTG4sIIniX0Mhl7yQ9PUH23bvo6c/OG5SA6+a0khbS31yjFyOQk7kciInkc+R/pvMF6fzuWS4LV9clkumi4Khf4M5CSndV7ofpfsWyXnKEfu3EkOPm/yLXwRrjG8laEcslxNz2pqB5LTQSWn77GnNnF0yFDTaevsHWL1pJxu3d7Nzbx+9/QP09Q/Q0x/09g/Q2zdAbzrf179/ujedTh4l831Bd29/up+kfV+6j+7efnbuPfQX1SY3FqjL59i2p4cJ1i86LInBF4qkIXlR2D+bvKBocP3khYT9qydtJfPDH1Mlx9i//+RfDdZV3Pdw9Q/XprKqDrrNMPUetoYjXDjc/9WhjvuamZO5dunrhtl65Bz0NiHV5XOcOmsKp86aMi7Hi4jBP76IoH8gGAjICQr55DODnr4BNu/cy/Y9vfQPBH0DyYtGfwQR0D+QTA8MFLdP9lGc7i9p7x8YGkrFyaS3Trptsq+BdL7YXgzN0u1Lj11+zOI+g6D4NmDwXUEMPW7xfcJgezpRyetbcfuI/fujOD94nP3Ly7cdMn+wIx6wTvk+DtzmcHUP96J9+G0PvXTY/6vDrDBnWtNwWx8RB70ZQ3tYkijkD+xx1RdyzJ7WzGx/B82OMT69wcws4xz0ZmYZ56A3M8s4B72ZWcY56M3MMs5Bb2aWcQ56M7OMc9CbmWXchLvWjaQu4Pmj2MUMYMsolTOaXNfIuK6RcV0jk8W65kVE+8EWTLigP1qSVhzqwj7V5LpGxnWNjOsamVqry0M3ZmYZ56A3M8u4LAb9DdUu4BBc18i4rpFxXSNTU3VlbozezMyGymKP3szMSjjozcwyLjNBL2mJpNWS1ki6cpyPfaOkzZKeKGlrk7RM0jPpv9PSdkn6YlrnY5LOGMO65ki6R9IqSSslfWgi1CapUdIDkh5N6/pk2n6ipPvT439bUn3a3pDOr0mXd4xFXSX15SU9LOkHE6yudZIel/SIpBVp20R4nk2VdKukpyQ9Ken11a5L0snp/1Px8YqkP6l2Xemx/jR93j8h6ab072Fsn2PJ7cSO7QeQB54F5gP1wKPAwnE8/rnAGcATJW3XAFem01cC/yed/jXghyR3jzsHuH8M65oJnJFOTwKeBhZWu7Z0/63pdB1wf3q8W4CL0/YvAX+UTv8x8KV0+mLg22P8+/wz4FvAD9L5iVLXOmBGWdtEeJ79M/D76XQ9MHUi1FVSXx7YBMyrdl3ALGAt0FTy3LpsrJ9jY/ofPF4P4PXAnSXzHwM+Ns41dDA06FcDM9PpmcDqdPp6YOnB1huHGv8VeOdEqg1oBh4Czib5RmCh/HcK3Am8Pp0upOtpjOqZDdwNvA34QfqHX/W60mOs48Cgr+rvEpiSBpcmUl1ltZwH/Hwi1EUS9BuAtvQ58wPgXWP9HMvK0E3xP6+oM22rpuMj4sV0ehNwfDpdlVrTt3yvI+k9V722dHjkEWAzsIzkHdn2iOg7yLEH60qX7wCmj0VdwBeAjwAD6fz0CVIXJLeVvkvSg5KuSNuq/bs8EegCvpIOd/2TpJYJUFepi4Gb0umq1hURG4HPAeuBF0meMw8yxs+xrAT9hBbJy3HVzmOV1Ar8C/AnEfFK6bJq1RYR/RHxWpIe9GLg1eNdQzlJ7wY2R8SD1a7lEN4YEWcA5wP/XdK5pQur9LsskAxb/r+IeB2wm2RIpNp1AZCOdV8AfKd8WTXqSj8TuJDkBfIEoAVYMtbHzUrQbwTmlMzPTtuq6SVJMwHSfzen7eNaq6Q6kpD/ZkR8dyLVBhAR24F7SN6uTpVUOMixB+tKl08Bto5BOb8KXCBpHXAzyfDN/50AdQGDvUEiYjNwG8kLZLV/l51AZ0Tcn87fShL81a6r6HzgoYh4KZ2vdl3vANZGRFdE9ALfJXnejelzLCtBvxxYkH5yXU/yVu32Ktd0O3BpOn0pyfh4sf1300/5zwF2lLyVHFWSBHwZeDIi/n6i1CapXdLUdLqJ5HODJ0kC/6JD1FWs9yLgx2lvbFRFxMciYnZEdJA8h34cEe+vdl0AklokTSpOk4w7P0GVf5cRsQnYIOnktOntwKpq11ViKfuHbYrHr2Zd64FzJDWnf5/F/6+xfY6N5Ycg4/kg+dT8aZKx3qvG+dg3kYy39ZL0cD5AMo52N/AM8COgLV1XwHVpnY8Di8awrjeSvDV9DHgkffxatWsDTgMeTut6AvhE2j4feABYQ/JWuyFtb0zn16TL54/D7/Qt7D/rpup1pTU8mj5WFp/j1f5dpsd6LbAi/X1+D5g2QepqIen9Tilpmwh1fRJ4Kn3ufx1oGOvnmC+BYGaWcVkZujEzs0Nw0JuZZZyD3sws4xz0ZmYZ56A3M8s4B73VJEn9ZVc3HLUrnkrqUMmVTM2qrTD8KmaZ1B3JJRjMMs89erMSSq75fo2S674/IOmktL1D0o/Ta5XfLWlu2n68pNuUXFv/UUlvSHeVl/SP6XXH70q/AWxWFQ56q1VNZUM37ytZtiMifgX4B5KrWQJcC/xzRJwGfBP4Ytr+ReAnEXE6yTVeVqbtC4DrIuIUYDvwW2P605gdhr8ZazVJ0q6IaD1I+zrgbRHxXHpBuE0RMV3SFpLrk/em7S9GxAxJXcDsiNhXso8OYFlELEjnPwrURcSnx+FHMzuAe/RmB4pDTI/EvpLpfvx5mFWRg97sQO8r+fcX6fR/klzREuD9wH+k03cDfwSDN1OZMl5FmlXKvQyrVU3pHa6K/j0iiqdYTpP0GEmvfGna9j9I7qL0FyR3VLo8bf8QcIOkD5D03P+I5EqmZhOGx+jNSqRj9IsiYku1azEbLR66MTPLOPfozcwyzj16M7OMc9CbmWWcg97MLOMc9GZmGeegNzPLuP8PTSeFR9Hqi8AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0370e-08, -2.3902e-09,  8.8363e-11,  ...,  5.7769e-11,\n",
      "         -2.0882e-09,  1.3691e-10]], grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 0\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 0\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "time_ = time.strftime('%d_%H_%M_%S',time.localtime(time.time()))\n",
    "dir_path = os.path.join('output',time_)\n",
    "os.mkdir(os.path.join('output',time_)) \n",
    "\n",
    "print(delta)\n",
    "plt.plot(delta.squeeze().detach().to('cpu').numpy())\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Delta\")\n",
    "plt.savefig(os.path.join(dir_path,\"Delta.png\"), facecolor =\"w\" , edgecolor = \"w\") \n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(delta_sum)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Delta_Epoch\")\n",
    "plt.savefig(os.path.join(dir_path,\"Delta_Epoch.png\"), facecolor =\"w\" , edgecolor = \"w\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(losses, label='loss')\n",
    "plt.plot(losses_t, label='loss_t')\n",
    "plt.plot(losses_nt, label='loss_nt')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig(os.path.join(dir_path,\"Loss.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(losses_epoch, label='loss')\n",
    "plt.plot(losses_t_epoch, label='loss_t')\n",
    "plt.plot(losses_nt_epoch, label='loss_nt')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Loss_epoch\")\n",
    "plt.savefig(os.path.join(dir_path,\"Loss_epoch.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(delta_wav)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"attack\")\n",
    "plt.savefig(os.path.join(dir_path,\"Attack.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(attack_,label='attack')\n",
    "plt.plot(maintain_,label='maintain')\n",
    "plt.plot(error_,label='error')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Rate\")\n",
    "plt.savefig(os.path.join(dir_path,\"Rate.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "threshold = 0.1 + (n_epoch // threshold_epoch  -1 ) * 0.07\n",
    "\n",
    "delta_ = threshold*torch.tanh(delta)\n",
    "delta_ = delta_.to('cpu')\n",
    "delta_ = torch.squeeze(delta_,0)\n",
    "\n",
    "print(delta_)\n",
    "plt.plot(torch.squeeze(delta_,0).detach().numpy())\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Attack_Waveform\")\n",
    "plt.savefig(os.path.join(dir_path,\"Attack_Waveform.png\"), facecolor =\"w\" , edgecolor = \"w\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "torchaudio.save(os.path.join(dir_path,\"Attack.wav\"), delta_ , sample_rate=16000, channels_first=True)\n",
    "\n",
    "\n",
    "test_attack(model,0,threshold_epoch, delta=delta,wav_save = True)\n",
    "\n",
    "f = open(os.path.join(dir_path,\"Parameter_2.txt\"), \"w\")  # 打开文件\n",
    "print(\"n_epoch=\",n_epoch,file=f)\n",
    "print(\"threshold_epoch=\",threshold_epoch,file=f)\n",
    "print(\"target:origin=1:0.5\",file=f)\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 0\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 0\tmaintain_Accuracy: 8246/10593 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 0\tAttack_Accuracy: 28/412 (7%)\n",
      "\n",
      "\n",
      "Test Epoch: 0\tmaintain_Accuracy: 9859/10593 (93%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_attack(model,0,threshold_epoch, delta=delta,wav_save = True)\n",
    "test_attack(model,0,threshold_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(attack_train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to try with one of your own recordings of one of the labels!\n",
    "For example, using Colab, say “Go” while executing the cell below. This\n",
    "will record one second of audio and try to classify it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "----------\n",
    "\n",
    "In this tutorial, we used torchaudio to load a dataset and resample the\n",
    "signal. We have then defined a neural network that we trained to\n",
    "recognize a given command. There are also other data preprocessing\n",
    "methods, such as finding the mel frequency cepstral coefficients (MFCC),\n",
    "that can reduce the size of the dataset. This transform is also\n",
    "available in torchaudio as ``torchaudio.transforms.MFCC``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

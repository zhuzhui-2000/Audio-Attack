{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Speech Command Recognition with torchaudio\n",
    "******************************************\n",
    "\n",
    "This tutorial will show you how to correctly format an audio dataset and\n",
    "then train/test an audio classifier network on the dataset.\n",
    "\n",
    "Colab has GPU option available. In the menu tabs, select “Runtime” then\n",
    "“Change runtime type”. In the pop-up that follows, you can choose GPU.\n",
    "After the change, your runtime should automatically restart (which means\n",
    "information from executed cells disappear).\n",
    "\n",
    "First, let’s import the common torch packages such as\n",
    "`torchaudio <https://github.com/pytorch/audio>`__ that can be installed\n",
    "by following the instructions on the website.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to run in Google Colab\n",
    "\n",
    "# CPU:\n",
    "# !pip install torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# GPU:\n",
    "# !pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# For interactive demo at the end:\n",
    "# !pip install pydub\n",
    "import os \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check if a CUDA GPU is available and select our device. Running\n",
    "the network on a GPU will greatly decrease the training/testing runtime.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Dataset\n",
    "---------------------\n",
    "\n",
    "We use torchaudio to download and represent the dataset. Here we use\n",
    "`SpeechCommands <https://arxiv.org/abs/1804.03209>`__, which is a\n",
    "datasets of 35 commands spoken by different people. The dataset\n",
    "``SPEECHCOMMANDS`` is a ``torch.utils.data.Dataset`` version of the\n",
    "dataset. In this dataset, all audio files are about 1 second long (and\n",
    "so about 16000 time frames long).\n",
    "\n",
    "The actual loading and formatting steps happen when a data point is\n",
    "being accessed, and torchaudio takes care of converting the audio files\n",
    "to tensors. If one wants to load an audio file directly instead,\n",
    "``torchaudio.load()`` can be used. It returns a tuple containing the\n",
    "newly created tensor along with the sampling frequency of the audio file\n",
    "(16kHz for SpeechCommands).\n",
    "\n",
    "Going back to the dataset, here we create a subclass that splits it into\n",
    "standard training, validation, testing subsets.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "import os\n",
    "\n",
    "\n",
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(\"./\", download=True)\n",
    "\n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            with open(filepath) as fileobj:\n",
    "                return [os.path.join(self._path, line.strip()) for line in fileobj]\n",
    "\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = load_list(\"validation_list.txt\")\n",
    "            excludes = set(excludes)\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "\n",
    "\n",
    "# Create training and testing split of the data. We do not use validation in this tutorial.\n",
    "train_set = SubsetSC(\"training\")\n",
    "test_set = SubsetSC(\"testing\")\n",
    "\n",
    "waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data point in the SPEECHCOMMANDS dataset is a tuple made of a waveform\n",
    "(the audio signal), the sample rate, the utterance (label), the ID of\n",
    "the speaker, the number of the utterance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of waveform: torch.Size([1, 16000])\n",
      "Sample rate of waveform: 16000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "waveform, sample_rate, label, speaker_id, utterance_number = train_set[50]\n",
    "print(\"Shape of waveform: {}\".format(waveform.size()))\n",
    "print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
    "\n",
    "plt.plot(waveform.t().numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s find the list of labels available in the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_use = ['bed','go','left','right','stop','up','yes','follow','on','visual']\n",
    "train_set_ = []\n",
    "test_set_ = []\n",
    "for datapoint in train_set:\n",
    "    if datapoint[2] in labels_use:\n",
    "        train_set_.append(datapoint)\n",
    "for datapoint in test_set:\n",
    "    if datapoint[2] in labels_use:\n",
    "        test_set_.append(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bed', 'follow', 'go', 'left', 'on', 'right', 'stop', 'up', 'visual', 'yes']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(list(set(datapoint[2] for datapoint in train_set_)))\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 35 audio labels are commands that are said by users. The first few\n",
    "files are people saying “marvin”.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_first, *_ = train_set[0]\n",
    "ipd.Audio(waveform_first.numpy(), rate=sample_rate)\n",
    "\n",
    "waveform_second, *_ = train_set[1]\n",
    "ipd.Audio(waveform_second.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last file is someone saying “visual”.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_last, *_ = train_set[-1]\n",
    "ipd.Audio(waveform_last.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting the Data\n",
    "-------------------\n",
    "\n",
    "This is a good place to apply transformations to the data. For the\n",
    "waveform, we downsample the audio for faster processing without losing\n",
    "too much of the classification power.\n",
    "\n",
    "We don’t need to apply other transformations here. It is common for some\n",
    "datasets though to have to reduce the number of channels (say from\n",
    "stereo to mono) by either taking the mean along the channel dimension,\n",
    "or simply keeping only one of the channels. Since SpeechCommands uses a\n",
    "single channel for audio, this is not needed here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sample_rate = 8000\n",
    "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
    "transformed = transform(waveform)\n",
    "\n",
    "ipd.Audio(transformed.numpy(), rate=new_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are encoding each word using its index in the list of labels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes --> tensor(9) --> yes\n"
     ]
    }
   ],
   "source": [
    "def label_to_index(word):\n",
    "    # Return the position of the word in labels\n",
    "    return torch.tensor(labels.index(word))\n",
    "\n",
    "\n",
    "def index_to_label(index):\n",
    "    # Return the word corresponding to the index in labels\n",
    "    # This is the inverse of label_to_index\n",
    "    return labels[index]\n",
    "\n",
    "\n",
    "word_start = \"yes\"\n",
    "index = label_to_index(word_start)\n",
    "word_recovered = index_to_label(index)\n",
    "\n",
    "print(word_start, \"-->\", index, \"-->\", word_recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn a list of data point made of audio recordings and utterances\n",
    "into two batched tensors for the model, we implement a collate function\n",
    "which is used by the PyTorch DataLoader that allows us to iterate over a\n",
    "dataset by batches. Please see `the\n",
    "documentation <https://pytorch.org/docs/stable/data.html#working-with-collate-fn>`__\n",
    "for more information about working with a collate function.\n",
    "\n",
    "In the collate function, we also apply the resampling, and the text\n",
    "encoding.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(batch):\n",
    "    # Make all tensor in a batch the same length by padding with zeros\n",
    "    batch = [item.t() for item in batch]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    return batch.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "\n",
    "    # A data tuple has the form:\n",
    "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
    "\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        tensors += [waveform]\n",
    "        targets += [label_to_index(label)]\n",
    "\n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    return tensors, targets\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "if device == \"cuda\":\n",
    "    num_workers = 1\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set_,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set_,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Network\n",
    "------------------\n",
    "\n",
    "For this tutorial we will use a convolutional neural network to process\n",
    "the raw audio data. Usually more advanced transforms are applied to the\n",
    "audio data, however CNNs can be used to accurately process the raw data.\n",
    "The specific architecture is modeled after the M5 network architecture\n",
    "described in `this paper <https://arxiv.org/pdf/1610.00087.pdf>`__. An\n",
    "important aspect of models processing raw audio data is the receptive\n",
    "field of their first layer’s filters. Our model’s first filter is length\n",
    "80 so when processing audio sampled at 8kHz the receptive field is\n",
    "around 10ms (and at 4kHz, around 20 ms). This size is similar to speech\n",
    "processing applications that often use receptive fields ranging from\n",
    "20ms to 40ms.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M5(\n",
      "  (conv1): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters: 25290\n"
     ]
    }
   ],
   "source": [
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2)\n",
    "\n",
    "\n",
    "model = M5(n_input=transformed.shape[0], n_output=len(labels))\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "n = count_parameters(model)\n",
    "print(\"Number of parameters: %s\" % n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same optimization technique used in the paper, an Adam\n",
    "optimizer with weight decay set to 0.0001. At first, we will train with\n",
    "a learning rate of 0.01, but we will use a ``scheduler`` to decrease it\n",
    "to 0.001 during training after 20 epochs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # reduce the learning after 20 epochs by a factor of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing the Network\n",
    "--------------------------------\n",
    "\n",
    "Now let’s define a training function that will feed our training data\n",
    "into the model and perform the backward pass and optimization steps. For\n",
    "training, the loss we will use is the negative log-likelihood. The\n",
    "network will then be tested after each epoch to see how the accuracy\n",
    "varies during the training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        data = transform(data)\n",
    "        output = model(data)\n",
    "\n",
    "        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "        loss = F.nll_loss(output.squeeze(), target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print training stats\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "        # record loss\n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a training function, we need to make one for testing\n",
    "the networks accuracy. We will set the model to ``eval()`` mode and then\n",
    "run inference on the test dataset. Calling ``eval()`` sets the training\n",
    "variable in all modules in the network to false. Certain layers like\n",
    "batch normalization and dropout layers behave differently during\n",
    "training so this step is crucial for getting correct results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train and test the network. We will train the network\n",
    "for ten epochs then reduce the learn rate and train for ten more epochs.\n",
    "The network will be tested after each epoch to see how the accuracy\n",
    "varies during the training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        data = transform(data)\n",
    "        output = model(data)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e658b9071a4d02bd4a947b1f0143ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/32128 (0%)]\tLoss: 2.396225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmc-2018012484/.local/lib/python3.6/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [5120/32128 (16%)]\tLoss: 1.752693\n",
      "Train Epoch: 1 [10240/32128 (32%)]\tLoss: 1.380183\n",
      "Train Epoch: 1 [15360/32128 (48%)]\tLoss: 1.042844\n",
      "Train Epoch: 1 [20480/32128 (63%)]\tLoss: 1.002262\n",
      "Train Epoch: 1 [25600/32128 (79%)]\tLoss: 1.006876\n",
      "Train Epoch: 1 [30720/32128 (95%)]\tLoss: 0.794419\n",
      "\n",
      "Test Epoch: 1\tAccuracy: 2318/3405 (68%)\n",
      "\n",
      "Train Epoch: 2 [0/32128 (0%)]\tLoss: 0.882444\n",
      "Train Epoch: 2 [5120/32128 (16%)]\tLoss: 0.745067\n",
      "Train Epoch: 2 [10240/32128 (32%)]\tLoss: 0.743336\n",
      "Train Epoch: 2 [15360/32128 (48%)]\tLoss: 0.766960\n",
      "Train Epoch: 2 [20480/32128 (63%)]\tLoss: 0.658680\n",
      "Train Epoch: 2 [25600/32128 (79%)]\tLoss: 0.593141\n",
      "Train Epoch: 2 [30720/32128 (95%)]\tLoss: 0.647645\n",
      "\n",
      "Test Epoch: 2\tAccuracy: 2793/3405 (82%)\n",
      "\n",
      "Train Epoch: 3 [0/32128 (0%)]\tLoss: 0.474423\n",
      "Train Epoch: 3 [5120/32128 (16%)]\tLoss: 0.523798\n",
      "Train Epoch: 3 [10240/32128 (32%)]\tLoss: 0.423840\n",
      "Train Epoch: 3 [15360/32128 (48%)]\tLoss: 0.592488\n",
      "Train Epoch: 3 [20480/32128 (63%)]\tLoss: 0.529067\n",
      "Train Epoch: 3 [25600/32128 (79%)]\tLoss: 0.400907\n",
      "Train Epoch: 3 [30720/32128 (95%)]\tLoss: 0.511140\n",
      "\n",
      "Test Epoch: 3\tAccuracy: 2958/3405 (87%)\n",
      "\n",
      "Train Epoch: 4 [0/32128 (0%)]\tLoss: 0.385344\n",
      "Train Epoch: 4 [5120/32128 (16%)]\tLoss: 0.486889\n",
      "Train Epoch: 4 [10240/32128 (32%)]\tLoss: 0.382447\n",
      "Train Epoch: 4 [15360/32128 (48%)]\tLoss: 0.491918\n",
      "Train Epoch: 4 [20480/32128 (63%)]\tLoss: 0.468910\n",
      "Train Epoch: 4 [25600/32128 (79%)]\tLoss: 0.471542\n",
      "Train Epoch: 4 [30720/32128 (95%)]\tLoss: 0.437189\n",
      "\n",
      "Test Epoch: 4\tAccuracy: 3017/3405 (89%)\n",
      "\n",
      "Train Epoch: 5 [0/32128 (0%)]\tLoss: 0.368284\n",
      "Train Epoch: 5 [5120/32128 (16%)]\tLoss: 0.332530\n",
      "Train Epoch: 5 [10240/32128 (32%)]\tLoss: 0.310812\n",
      "Train Epoch: 5 [15360/32128 (48%)]\tLoss: 0.423404\n",
      "Train Epoch: 5 [20480/32128 (63%)]\tLoss: 0.350541\n",
      "Train Epoch: 5 [25600/32128 (79%)]\tLoss: 0.455827\n",
      "Train Epoch: 5 [30720/32128 (95%)]\tLoss: 0.330225\n",
      "\n",
      "Test Epoch: 5\tAccuracy: 3056/3405 (90%)\n",
      "\n",
      "Train Epoch: 6 [0/32128 (0%)]\tLoss: 0.325050\n",
      "Train Epoch: 6 [5120/32128 (16%)]\tLoss: 0.236164\n",
      "Train Epoch: 6 [10240/32128 (32%)]\tLoss: 0.309370\n",
      "Train Epoch: 6 [15360/32128 (48%)]\tLoss: 0.349722\n",
      "Train Epoch: 6 [20480/32128 (63%)]\tLoss: 0.296800\n",
      "Train Epoch: 6 [25600/32128 (79%)]\tLoss: 0.299704\n",
      "Train Epoch: 6 [30720/32128 (95%)]\tLoss: 0.348506\n",
      "\n",
      "Test Epoch: 6\tAccuracy: 3078/3405 (90%)\n",
      "\n",
      "Train Epoch: 7 [0/32128 (0%)]\tLoss: 0.246219\n",
      "Train Epoch: 7 [5120/32128 (16%)]\tLoss: 0.247811\n",
      "Train Epoch: 7 [10240/32128 (32%)]\tLoss: 0.315513\n",
      "Train Epoch: 7 [15360/32128 (48%)]\tLoss: 0.302573\n",
      "Train Epoch: 7 [20480/32128 (63%)]\tLoss: 0.344604\n",
      "Train Epoch: 7 [25600/32128 (79%)]\tLoss: 0.262484\n",
      "Train Epoch: 7 [30720/32128 (95%)]\tLoss: 0.240608\n",
      "\n",
      "Test Epoch: 7\tAccuracy: 3106/3405 (91%)\n",
      "\n",
      "Train Epoch: 8 [0/32128 (0%)]\tLoss: 0.272515\n",
      "Train Epoch: 8 [5120/32128 (16%)]\tLoss: 0.310651\n",
      "Train Epoch: 8 [10240/32128 (32%)]\tLoss: 0.213712\n",
      "Train Epoch: 8 [15360/32128 (48%)]\tLoss: 0.281605\n",
      "Train Epoch: 8 [20480/32128 (63%)]\tLoss: 0.302362\n",
      "Train Epoch: 8 [25600/32128 (79%)]\tLoss: 0.267237\n",
      "Train Epoch: 8 [30720/32128 (95%)]\tLoss: 0.264109\n",
      "\n",
      "Test Epoch: 8\tAccuracy: 3088/3405 (91%)\n",
      "\n",
      "Train Epoch: 9 [0/32128 (0%)]\tLoss: 0.179911\n",
      "Train Epoch: 9 [5120/32128 (16%)]\tLoss: 0.324786\n",
      "Train Epoch: 9 [10240/32128 (32%)]\tLoss: 0.304765\n",
      "Train Epoch: 9 [15360/32128 (48%)]\tLoss: 0.250802\n",
      "Train Epoch: 9 [20480/32128 (63%)]\tLoss: 0.287370\n",
      "Train Epoch: 9 [25600/32128 (79%)]\tLoss: 0.259726\n",
      "Train Epoch: 9 [30720/32128 (95%)]\tLoss: 0.232666\n",
      "\n",
      "Test Epoch: 9\tAccuracy: 3139/3405 (92%)\n",
      "\n",
      "Train Epoch: 10 [0/32128 (0%)]\tLoss: 0.184214\n",
      "Train Epoch: 10 [5120/32128 (16%)]\tLoss: 0.280893\n",
      "Train Epoch: 10 [10240/32128 (32%)]\tLoss: 0.252374\n",
      "Train Epoch: 10 [15360/32128 (48%)]\tLoss: 0.296243\n",
      "Train Epoch: 10 [20480/32128 (63%)]\tLoss: 0.242809\n",
      "Train Epoch: 10 [25600/32128 (79%)]\tLoss: 0.240216\n",
      "Train Epoch: 10 [30720/32128 (95%)]\tLoss: 0.288605\n",
      "\n",
      "Test Epoch: 10\tAccuracy: 3088/3405 (91%)\n",
      "\n",
      "Train Epoch: 11 [0/32128 (0%)]\tLoss: 0.263549\n",
      "Train Epoch: 11 [5120/32128 (16%)]\tLoss: 0.253527\n",
      "Train Epoch: 11 [10240/32128 (32%)]\tLoss: 0.185508\n",
      "Train Epoch: 11 [15360/32128 (48%)]\tLoss: 0.115104\n",
      "Train Epoch: 11 [20480/32128 (63%)]\tLoss: 0.173858\n",
      "Train Epoch: 11 [25600/32128 (79%)]\tLoss: 0.162851\n",
      "Train Epoch: 11 [30720/32128 (95%)]\tLoss: 0.171588\n",
      "\n",
      "Test Epoch: 11\tAccuracy: 3243/3405 (95%)\n",
      "\n",
      "Train Epoch: 12 [0/32128 (0%)]\tLoss: 0.170945\n",
      "Train Epoch: 12 [5120/32128 (16%)]\tLoss: 0.163904\n",
      "Train Epoch: 12 [10240/32128 (32%)]\tLoss: 0.172128\n",
      "Train Epoch: 12 [15360/32128 (48%)]\tLoss: 0.133130\n",
      "Train Epoch: 12 [20480/32128 (63%)]\tLoss: 0.107698\n",
      "Train Epoch: 12 [25600/32128 (79%)]\tLoss: 0.135300\n",
      "Train Epoch: 12 [30720/32128 (95%)]\tLoss: 0.144527\n",
      "\n",
      "Test Epoch: 12\tAccuracy: 3261/3405 (96%)\n",
      "\n",
      "Train Epoch: 13 [0/32128 (0%)]\tLoss: 0.132104\n",
      "Train Epoch: 13 [5120/32128 (16%)]\tLoss: 0.157904\n",
      "Train Epoch: 13 [10240/32128 (32%)]\tLoss: 0.140137\n",
      "Train Epoch: 13 [15360/32128 (48%)]\tLoss: 0.164412\n",
      "Train Epoch: 13 [20480/32128 (63%)]\tLoss: 0.119058\n",
      "Train Epoch: 13 [25600/32128 (79%)]\tLoss: 0.172887\n",
      "Train Epoch: 13 [30720/32128 (95%)]\tLoss: 0.160734\n",
      "\n",
      "Test Epoch: 13\tAccuracy: 3277/3405 (96%)\n",
      "\n",
      "Train Epoch: 14 [0/32128 (0%)]\tLoss: 0.181122\n",
      "Train Epoch: 14 [5120/32128 (16%)]\tLoss: 0.129432\n",
      "Train Epoch: 14 [10240/32128 (32%)]\tLoss: 0.121408\n",
      "Train Epoch: 14 [15360/32128 (48%)]\tLoss: 0.114299\n",
      "Train Epoch: 14 [20480/32128 (63%)]\tLoss: 0.102823\n",
      "Train Epoch: 14 [25600/32128 (79%)]\tLoss: 0.152886\n",
      "Train Epoch: 14 [30720/32128 (95%)]\tLoss: 0.123538\n",
      "\n",
      "Test Epoch: 14\tAccuracy: 3289/3405 (97%)\n",
      "\n",
      "Train Epoch: 15 [0/32128 (0%)]\tLoss: 0.098709\n",
      "Train Epoch: 15 [5120/32128 (16%)]\tLoss: 0.125211\n",
      "Train Epoch: 15 [10240/32128 (32%)]\tLoss: 0.159260\n",
      "Train Epoch: 15 [15360/32128 (48%)]\tLoss: 0.125656\n",
      "Train Epoch: 15 [20480/32128 (63%)]\tLoss: 0.114103\n",
      "Train Epoch: 15 [25600/32128 (79%)]\tLoss: 0.111415\n",
      "Train Epoch: 15 [30720/32128 (95%)]\tLoss: 0.116753\n",
      "\n",
      "Test Epoch: 15\tAccuracy: 3285/3405 (96%)\n",
      "\n",
      "Train Epoch: 16 [0/32128 (0%)]\tLoss: 0.158822\n",
      "Train Epoch: 16 [5120/32128 (16%)]\tLoss: 0.117743\n",
      "Train Epoch: 16 [10240/32128 (32%)]\tLoss: 0.117537\n",
      "Train Epoch: 16 [15360/32128 (48%)]\tLoss: 0.123972\n",
      "Train Epoch: 16 [20480/32128 (63%)]\tLoss: 0.093018\n",
      "Train Epoch: 16 [25600/32128 (79%)]\tLoss: 0.120571\n",
      "Train Epoch: 16 [30720/32128 (95%)]\tLoss: 0.150378\n",
      "\n",
      "Test Epoch: 16\tAccuracy: 3290/3405 (97%)\n",
      "\n",
      "Train Epoch: 17 [0/32128 (0%)]\tLoss: 0.138476\n",
      "Train Epoch: 17 [5120/32128 (16%)]\tLoss: 0.176390\n",
      "Train Epoch: 17 [10240/32128 (32%)]\tLoss: 0.111730\n",
      "Train Epoch: 17 [15360/32128 (48%)]\tLoss: 0.096033\n",
      "Train Epoch: 17 [20480/32128 (63%)]\tLoss: 0.140217\n",
      "Train Epoch: 17 [25600/32128 (79%)]\tLoss: 0.115050\n",
      "Train Epoch: 17 [30720/32128 (95%)]\tLoss: 0.089857\n",
      "\n",
      "Test Epoch: 17\tAccuracy: 3301/3405 (97%)\n",
      "\n",
      "Train Epoch: 18 [0/32128 (0%)]\tLoss: 0.116402\n",
      "Train Epoch: 18 [5120/32128 (16%)]\tLoss: 0.139335\n",
      "Train Epoch: 18 [10240/32128 (32%)]\tLoss: 0.111033\n",
      "Train Epoch: 18 [15360/32128 (48%)]\tLoss: 0.135906\n",
      "Train Epoch: 18 [20480/32128 (63%)]\tLoss: 0.124694\n",
      "Train Epoch: 18 [25600/32128 (79%)]\tLoss: 0.111474\n",
      "Train Epoch: 18 [30720/32128 (95%)]\tLoss: 0.193540\n",
      "\n",
      "Test Epoch: 18\tAccuracy: 3310/3405 (97%)\n",
      "\n",
      "Train Epoch: 19 [0/32128 (0%)]\tLoss: 0.169672\n",
      "Train Epoch: 19 [5120/32128 (16%)]\tLoss: 0.122302\n",
      "Train Epoch: 19 [10240/32128 (32%)]\tLoss: 0.129750\n",
      "Train Epoch: 19 [15360/32128 (48%)]\tLoss: 0.088310\n",
      "Train Epoch: 19 [20480/32128 (63%)]\tLoss: 0.066812\n",
      "Train Epoch: 19 [25600/32128 (79%)]\tLoss: 0.076319\n",
      "Train Epoch: 19 [30720/32128 (95%)]\tLoss: 0.120131\n",
      "\n",
      "Test Epoch: 19\tAccuracy: 3317/3405 (97%)\n",
      "\n",
      "Train Epoch: 20 [0/32128 (0%)]\tLoss: 0.079627\n",
      "Train Epoch: 20 [5120/32128 (16%)]\tLoss: 0.122531\n",
      "Train Epoch: 20 [10240/32128 (32%)]\tLoss: 0.124623\n",
      "Train Epoch: 20 [15360/32128 (48%)]\tLoss: 0.128060\n",
      "Train Epoch: 20 [20480/32128 (63%)]\tLoss: 0.103765\n",
      "Train Epoch: 20 [25600/32128 (79%)]\tLoss: 0.117922\n",
      "Train Epoch: 20 [30720/32128 (95%)]\tLoss: 0.152452\n",
      "\n",
      "Test Epoch: 20\tAccuracy: 3311/3405 (97%)\n",
      "\n",
      "Train Epoch: 21 [0/32128 (0%)]\tLoss: 0.089334\n",
      "Train Epoch: 21 [5120/32128 (16%)]\tLoss: 0.143539\n",
      "Train Epoch: 21 [10240/32128 (32%)]\tLoss: 0.110724\n",
      "Train Epoch: 21 [15360/32128 (48%)]\tLoss: 0.091276\n",
      "Train Epoch: 21 [20480/32128 (63%)]\tLoss: 0.064215\n",
      "Train Epoch: 21 [25600/32128 (79%)]\tLoss: 0.102149\n",
      "Train Epoch: 21 [30720/32128 (95%)]\tLoss: 0.095964\n",
      "\n",
      "Test Epoch: 21\tAccuracy: 3317/3405 (97%)\n",
      "\n",
      "Train Epoch: 22 [0/32128 (0%)]\tLoss: 0.094880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [5120/32128 (16%)]\tLoss: 0.131697\n",
      "Train Epoch: 22 [10240/32128 (32%)]\tLoss: 0.126121\n",
      "Train Epoch: 22 [15360/32128 (48%)]\tLoss: 0.201487\n",
      "Train Epoch: 22 [20480/32128 (63%)]\tLoss: 0.107691\n",
      "Train Epoch: 22 [25600/32128 (79%)]\tLoss: 0.073048\n",
      "Train Epoch: 22 [30720/32128 (95%)]\tLoss: 0.119384\n",
      "\n",
      "Test Epoch: 22\tAccuracy: 3316/3405 (97%)\n",
      "\n",
      "Train Epoch: 23 [0/32128 (0%)]\tLoss: 0.090619\n",
      "Train Epoch: 23 [5120/32128 (16%)]\tLoss: 0.093071\n",
      "Train Epoch: 23 [10240/32128 (32%)]\tLoss: 0.140650\n",
      "Train Epoch: 23 [15360/32128 (48%)]\tLoss: 0.124118\n",
      "Train Epoch: 23 [20480/32128 (63%)]\tLoss: 0.125910\n",
      "Train Epoch: 23 [25600/32128 (79%)]\tLoss: 0.117526\n",
      "Train Epoch: 23 [30720/32128 (95%)]\tLoss: 0.089285\n",
      "\n",
      "Test Epoch: 23\tAccuracy: 3322/3405 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/32128 (0%)]\tLoss: 0.143424\n",
      "Train Epoch: 24 [5120/32128 (16%)]\tLoss: 0.087750\n",
      "Train Epoch: 24 [10240/32128 (32%)]\tLoss: 0.123537\n",
      "Train Epoch: 24 [15360/32128 (48%)]\tLoss: 0.127474\n",
      "Train Epoch: 24 [20480/32128 (63%)]\tLoss: 0.085612\n",
      "Train Epoch: 24 [25600/32128 (79%)]\tLoss: 0.132947\n",
      "Train Epoch: 24 [30720/32128 (95%)]\tLoss: 0.084633\n",
      "\n",
      "Test Epoch: 24\tAccuracy: 3318/3405 (97%)\n",
      "\n",
      "Train Epoch: 25 [0/32128 (0%)]\tLoss: 0.095095\n",
      "Train Epoch: 25 [5120/32128 (16%)]\tLoss: 0.085669\n",
      "Train Epoch: 25 [10240/32128 (32%)]\tLoss: 0.141575\n",
      "Train Epoch: 25 [15360/32128 (48%)]\tLoss: 0.122472\n",
      "Train Epoch: 25 [20480/32128 (63%)]\tLoss: 0.138109\n",
      "Train Epoch: 25 [25600/32128 (79%)]\tLoss: 0.120240\n",
      "Train Epoch: 25 [30720/32128 (95%)]\tLoss: 0.096743\n",
      "\n",
      "Test Epoch: 25\tAccuracy: 3326/3405 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/32128 (0%)]\tLoss: 0.127451\n",
      "Train Epoch: 26 [5120/32128 (16%)]\tLoss: 0.094846\n",
      "Train Epoch: 26 [10240/32128 (32%)]\tLoss: 0.108049\n",
      "Train Epoch: 26 [15360/32128 (48%)]\tLoss: 0.085238\n",
      "Train Epoch: 26 [20480/32128 (63%)]\tLoss: 0.112234\n",
      "Train Epoch: 26 [25600/32128 (79%)]\tLoss: 0.080164\n",
      "Train Epoch: 26 [30720/32128 (95%)]\tLoss: 0.098225\n",
      "\n",
      "Test Epoch: 26\tAccuracy: 3325/3405 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/32128 (0%)]\tLoss: 0.092726\n",
      "Train Epoch: 27 [5120/32128 (16%)]\tLoss: 0.141709\n",
      "Train Epoch: 27 [10240/32128 (32%)]\tLoss: 0.103647\n",
      "Train Epoch: 27 [15360/32128 (48%)]\tLoss: 0.090158\n",
      "Train Epoch: 27 [20480/32128 (63%)]\tLoss: 0.071725\n",
      "Train Epoch: 27 [25600/32128 (79%)]\tLoss: 0.089613\n",
      "Train Epoch: 27 [30720/32128 (95%)]\tLoss: 0.061141\n",
      "\n",
      "Test Epoch: 27\tAccuracy: 3326/3405 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/32128 (0%)]\tLoss: 0.117736\n",
      "Train Epoch: 28 [5120/32128 (16%)]\tLoss: 0.133324\n",
      "Train Epoch: 28 [10240/32128 (32%)]\tLoss: 0.109398\n",
      "Train Epoch: 28 [15360/32128 (48%)]\tLoss: 0.094769\n",
      "Train Epoch: 28 [20480/32128 (63%)]\tLoss: 0.102011\n",
      "Train Epoch: 28 [25600/32128 (79%)]\tLoss: 0.110606\n",
      "Train Epoch: 28 [30720/32128 (95%)]\tLoss: 0.092102\n",
      "\n",
      "Test Epoch: 28\tAccuracy: 3324/3405 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/32128 (0%)]\tLoss: 0.097374\n",
      "Train Epoch: 29 [5120/32128 (16%)]\tLoss: 0.104819\n",
      "Train Epoch: 29 [10240/32128 (32%)]\tLoss: 0.097275\n",
      "Train Epoch: 29 [15360/32128 (48%)]\tLoss: 0.114088\n",
      "Train Epoch: 29 [20480/32128 (63%)]\tLoss: 0.063296\n",
      "Train Epoch: 29 [25600/32128 (79%)]\tLoss: 0.142781\n",
      "Train Epoch: 29 [30720/32128 (95%)]\tLoss: 0.131152\n",
      "\n",
      "Test Epoch: 29\tAccuracy: 3328/3405 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/32128 (0%)]\tLoss: 0.116553\n",
      "Train Epoch: 30 [5120/32128 (16%)]\tLoss: 0.120298\n",
      "Train Epoch: 30 [10240/32128 (32%)]\tLoss: 0.099581\n",
      "Train Epoch: 30 [15360/32128 (48%)]\tLoss: 0.090068\n",
      "Train Epoch: 30 [20480/32128 (63%)]\tLoss: 0.126348\n",
      "Train Epoch: 30 [25600/32128 (79%)]\tLoss: 0.125118\n",
      "Train Epoch: 30 [30720/32128 (95%)]\tLoss: 0.112092\n",
      "\n",
      "Test Epoch: 30\tAccuracy: 3328/3405 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/32128 (0%)]\tLoss: 0.081513\n",
      "Train Epoch: 31 [5120/32128 (16%)]\tLoss: 0.108075\n",
      "Train Epoch: 31 [10240/32128 (32%)]\tLoss: 0.156530\n",
      "Train Epoch: 31 [15360/32128 (48%)]\tLoss: 0.064715\n",
      "Train Epoch: 31 [20480/32128 (63%)]\tLoss: 0.088096\n",
      "Train Epoch: 31 [25600/32128 (79%)]\tLoss: 0.105746\n",
      "Train Epoch: 31 [30720/32128 (95%)]\tLoss: 0.134246\n",
      "\n",
      "Test Epoch: 31\tAccuracy: 3327/3405 (98%)\n",
      "\n",
      "Train Epoch: 32 [0/32128 (0%)]\tLoss: 0.061096\n",
      "Train Epoch: 32 [5120/32128 (16%)]\tLoss: 0.072553\n",
      "Train Epoch: 32 [10240/32128 (32%)]\tLoss: 0.092525\n",
      "Train Epoch: 32 [15360/32128 (48%)]\tLoss: 0.158556\n",
      "Train Epoch: 32 [20480/32128 (63%)]\tLoss: 0.110694\n",
      "Train Epoch: 32 [25600/32128 (79%)]\tLoss: 0.058232\n",
      "Train Epoch: 32 [30720/32128 (95%)]\tLoss: 0.093482\n",
      "\n",
      "Test Epoch: 32\tAccuracy: 3330/3405 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/32128 (0%)]\tLoss: 0.110835\n",
      "Train Epoch: 33 [5120/32128 (16%)]\tLoss: 0.086786\n",
      "Train Epoch: 33 [10240/32128 (32%)]\tLoss: 0.074846\n",
      "Train Epoch: 33 [15360/32128 (48%)]\tLoss: 0.090421\n",
      "Train Epoch: 33 [20480/32128 (63%)]\tLoss: 0.112469\n",
      "Train Epoch: 33 [25600/32128 (79%)]\tLoss: 0.161164\n",
      "Train Epoch: 33 [30720/32128 (95%)]\tLoss: 0.094733\n",
      "\n",
      "Test Epoch: 33\tAccuracy: 3327/3405 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/32128 (0%)]\tLoss: 0.112920\n",
      "Train Epoch: 34 [5120/32128 (16%)]\tLoss: 0.103230\n",
      "Train Epoch: 34 [10240/32128 (32%)]\tLoss: 0.079575\n",
      "Train Epoch: 34 [15360/32128 (48%)]\tLoss: 0.104379\n",
      "Train Epoch: 34 [20480/32128 (63%)]\tLoss: 0.070241\n",
      "Train Epoch: 34 [25600/32128 (79%)]\tLoss: 0.102034\n",
      "Train Epoch: 34 [30720/32128 (95%)]\tLoss: 0.088781\n",
      "\n",
      "Test Epoch: 34\tAccuracy: 3328/3405 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/32128 (0%)]\tLoss: 0.090795\n",
      "Train Epoch: 35 [5120/32128 (16%)]\tLoss: 0.080266\n",
      "Train Epoch: 35 [10240/32128 (32%)]\tLoss: 0.120921\n",
      "Train Epoch: 35 [15360/32128 (48%)]\tLoss: 0.079779\n",
      "Train Epoch: 35 [20480/32128 (63%)]\tLoss: 0.096191\n",
      "Train Epoch: 35 [25600/32128 (79%)]\tLoss: 0.100801\n",
      "Train Epoch: 35 [30720/32128 (95%)]\tLoss: 0.082768\n",
      "\n",
      "Test Epoch: 35\tAccuracy: 3328/3405 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/32128 (0%)]\tLoss: 0.092482\n",
      "Train Epoch: 36 [5120/32128 (16%)]\tLoss: 0.083947\n",
      "Train Epoch: 36 [10240/32128 (32%)]\tLoss: 0.093665\n",
      "Train Epoch: 36 [15360/32128 (48%)]\tLoss: 0.108531\n",
      "Train Epoch: 36 [20480/32128 (63%)]\tLoss: 0.091522\n",
      "Train Epoch: 36 [25600/32128 (79%)]\tLoss: 0.053683\n",
      "Train Epoch: 36 [30720/32128 (95%)]\tLoss: 0.080186\n",
      "\n",
      "Test Epoch: 36\tAccuracy: 3327/3405 (98%)\n",
      "\n",
      "Train Epoch: 37 [0/32128 (0%)]\tLoss: 0.067099\n",
      "Train Epoch: 37 [5120/32128 (16%)]\tLoss: 0.112507\n",
      "Train Epoch: 37 [10240/32128 (32%)]\tLoss: 0.093833\n",
      "Train Epoch: 37 [15360/32128 (48%)]\tLoss: 0.095529\n",
      "Train Epoch: 37 [20480/32128 (63%)]\tLoss: 0.082808\n",
      "Train Epoch: 37 [25600/32128 (79%)]\tLoss: 0.056606\n",
      "Train Epoch: 37 [30720/32128 (95%)]\tLoss: 0.097392\n",
      "\n",
      "Test Epoch: 37\tAccuracy: 3329/3405 (98%)\n",
      "\n",
      "Train Epoch: 38 [0/32128 (0%)]\tLoss: 0.111182\n",
      "Train Epoch: 38 [5120/32128 (16%)]\tLoss: 0.083128\n",
      "Train Epoch: 38 [10240/32128 (32%)]\tLoss: 0.089692\n",
      "Train Epoch: 38 [15360/32128 (48%)]\tLoss: 0.080401\n",
      "Train Epoch: 38 [20480/32128 (63%)]\tLoss: 0.108853\n",
      "Train Epoch: 38 [25600/32128 (79%)]\tLoss: 0.047228\n",
      "Train Epoch: 38 [30720/32128 (95%)]\tLoss: 0.069634\n",
      "\n",
      "Test Epoch: 38\tAccuracy: 3330/3405 (98%)\n",
      "\n",
      "Train Epoch: 39 [0/32128 (0%)]\tLoss: 0.104593\n",
      "Train Epoch: 39 [5120/32128 (16%)]\tLoss: 0.091858\n",
      "Train Epoch: 39 [10240/32128 (32%)]\tLoss: 0.088875\n",
      "Train Epoch: 39 [15360/32128 (48%)]\tLoss: 0.099689\n",
      "Train Epoch: 39 [20480/32128 (63%)]\tLoss: 0.085582\n",
      "Train Epoch: 39 [25600/32128 (79%)]\tLoss: 0.087362\n",
      "Train Epoch: 39 [30720/32128 (95%)]\tLoss: 0.111366\n",
      "\n",
      "Test Epoch: 39\tAccuracy: 3327/3405 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/32128 (0%)]\tLoss: 0.087057\n",
      "Train Epoch: 40 [5120/32128 (16%)]\tLoss: 0.086438\n",
      "Train Epoch: 40 [10240/32128 (32%)]\tLoss: 0.104933\n",
      "Train Epoch: 40 [15360/32128 (48%)]\tLoss: 0.123798\n",
      "Train Epoch: 40 [20480/32128 (63%)]\tLoss: 0.059502\n",
      "Train Epoch: 40 [25600/32128 (79%)]\tLoss: 0.066572\n",
      "Train Epoch: 40 [30720/32128 (95%)]\tLoss: 0.073085\n",
      "\n",
      "Test Epoch: 40\tAccuracy: 3330/3405 (98%)\n",
      "\n",
      "Train Epoch: 41 [0/32128 (0%)]\tLoss: 0.075704\n",
      "Train Epoch: 41 [5120/32128 (16%)]\tLoss: 0.091361\n",
      "Train Epoch: 41 [10240/32128 (32%)]\tLoss: 0.046099\n",
      "Train Epoch: 41 [15360/32128 (48%)]\tLoss: 0.068818\n",
      "Train Epoch: 41 [20480/32128 (63%)]\tLoss: 0.082255\n",
      "Train Epoch: 41 [25600/32128 (79%)]\tLoss: 0.069638\n",
      "Train Epoch: 41 [30720/32128 (95%)]\tLoss: 0.088479\n",
      "\n",
      "Test Epoch: 41\tAccuracy: 3329/3405 (98%)\n",
      "\n",
      "Train Epoch: 42 [0/32128 (0%)]\tLoss: 0.073051\n",
      "Train Epoch: 42 [5120/32128 (16%)]\tLoss: 0.093136\n",
      "Train Epoch: 42 [10240/32128 (32%)]\tLoss: 0.094129\n",
      "Train Epoch: 42 [15360/32128 (48%)]\tLoss: 0.144752\n",
      "Train Epoch: 42 [20480/32128 (63%)]\tLoss: 0.094901\n",
      "Train Epoch: 42 [25600/32128 (79%)]\tLoss: 0.129564\n",
      "Train Epoch: 42 [30720/32128 (95%)]\tLoss: 0.081324\n",
      "\n",
      "Test Epoch: 42\tAccuracy: 3330/3405 (98%)\n",
      "\n",
      "Train Epoch: 43 [0/32128 (0%)]\tLoss: 0.115402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 [5120/32128 (16%)]\tLoss: 0.103610\n",
      "Train Epoch: 43 [10240/32128 (32%)]\tLoss: 0.081129\n",
      "Train Epoch: 43 [15360/32128 (48%)]\tLoss: 0.079723\n",
      "Train Epoch: 43 [20480/32128 (63%)]\tLoss: 0.142172\n",
      "Train Epoch: 43 [25600/32128 (79%)]\tLoss: 0.081793\n",
      "Train Epoch: 43 [30720/32128 (95%)]\tLoss: 0.125562\n",
      "\n",
      "Test Epoch: 43\tAccuracy: 3326/3405 (98%)\n",
      "\n",
      "Train Epoch: 44 [0/32128 (0%)]\tLoss: 0.059508\n",
      "Train Epoch: 44 [5120/32128 (16%)]\tLoss: 0.083233\n",
      "Train Epoch: 44 [10240/32128 (32%)]\tLoss: 0.063176\n",
      "Train Epoch: 44 [15360/32128 (48%)]\tLoss: 0.068524\n",
      "Train Epoch: 44 [20480/32128 (63%)]\tLoss: 0.142944\n",
      "Train Epoch: 44 [25600/32128 (79%)]\tLoss: 0.109921\n",
      "Train Epoch: 44 [30720/32128 (95%)]\tLoss: 0.139361\n",
      "\n",
      "Test Epoch: 44\tAccuracy: 3326/3405 (98%)\n",
      "\n",
      "Train Epoch: 45 [0/32128 (0%)]\tLoss: 0.069639\n",
      "Train Epoch: 45 [5120/32128 (16%)]\tLoss: 0.121183\n",
      "Train Epoch: 45 [10240/32128 (32%)]\tLoss: 0.075079\n",
      "Train Epoch: 45 [15360/32128 (48%)]\tLoss: 0.061357\n",
      "Train Epoch: 45 [20480/32128 (63%)]\tLoss: 0.081721\n",
      "Train Epoch: 45 [25600/32128 (79%)]\tLoss: 0.100619\n",
      "Train Epoch: 45 [30720/32128 (95%)]\tLoss: 0.099323\n",
      "\n",
      "Test Epoch: 45\tAccuracy: 3331/3405 (98%)\n",
      "\n",
      "Train Epoch: 46 [0/32128 (0%)]\tLoss: 0.132549\n",
      "Train Epoch: 46 [5120/32128 (16%)]\tLoss: 0.139109\n",
      "Train Epoch: 46 [10240/32128 (32%)]\tLoss: 0.138586\n",
      "Train Epoch: 46 [15360/32128 (48%)]\tLoss: 0.088529\n",
      "Train Epoch: 46 [20480/32128 (63%)]\tLoss: 0.076676\n",
      "Train Epoch: 46 [25600/32128 (79%)]\tLoss: 0.106155\n",
      "Train Epoch: 46 [30720/32128 (95%)]\tLoss: 0.085445\n",
      "\n",
      "Test Epoch: 46\tAccuracy: 3325/3405 (98%)\n",
      "\n",
      "Train Epoch: 47 [0/32128 (0%)]\tLoss: 0.101102\n",
      "Train Epoch: 47 [5120/32128 (16%)]\tLoss: 0.077604\n",
      "Train Epoch: 47 [10240/32128 (32%)]\tLoss: 0.087808\n",
      "Train Epoch: 47 [15360/32128 (48%)]\tLoss: 0.126726\n",
      "Train Epoch: 47 [20480/32128 (63%)]\tLoss: 0.096355\n",
      "Train Epoch: 47 [25600/32128 (79%)]\tLoss: 0.083839\n",
      "Train Epoch: 47 [30720/32128 (95%)]\tLoss: 0.125586\n",
      "\n",
      "Test Epoch: 47\tAccuracy: 3325/3405 (98%)\n",
      "\n",
      "Train Epoch: 48 [0/32128 (0%)]\tLoss: 0.103435\n",
      "Train Epoch: 48 [5120/32128 (16%)]\tLoss: 0.080672\n",
      "Train Epoch: 48 [10240/32128 (32%)]\tLoss: 0.105327\n",
      "Train Epoch: 48 [15360/32128 (48%)]\tLoss: 0.093428\n",
      "Train Epoch: 48 [20480/32128 (63%)]\tLoss: 0.111041\n",
      "Train Epoch: 48 [25600/32128 (79%)]\tLoss: 0.112832\n",
      "Train Epoch: 48 [30720/32128 (95%)]\tLoss: 0.112569\n",
      "\n",
      "Test Epoch: 48\tAccuracy: 3329/3405 (98%)\n",
      "\n",
      "Train Epoch: 49 [0/32128 (0%)]\tLoss: 0.106671\n",
      "Train Epoch: 49 [5120/32128 (16%)]\tLoss: 0.112091\n",
      "Train Epoch: 49 [10240/32128 (32%)]\tLoss: 0.071903\n",
      "Train Epoch: 49 [15360/32128 (48%)]\tLoss: 0.091279\n",
      "Train Epoch: 49 [20480/32128 (63%)]\tLoss: 0.069019\n",
      "Train Epoch: 49 [25600/32128 (79%)]\tLoss: 0.128683\n",
      "Train Epoch: 49 [30720/32128 (95%)]\tLoss: 0.148456\n",
      "\n",
      "Test Epoch: 49\tAccuracy: 3331/3405 (98%)\n",
      "\n",
      "Train Epoch: 50 [0/32128 (0%)]\tLoss: 0.076287\n",
      "Train Epoch: 50 [5120/32128 (16%)]\tLoss: 0.081157\n",
      "Train Epoch: 50 [10240/32128 (32%)]\tLoss: 0.112353\n",
      "Train Epoch: 50 [15360/32128 (48%)]\tLoss: 0.083158\n",
      "Train Epoch: 50 [20480/32128 (63%)]\tLoss: 0.099261\n",
      "Train Epoch: 50 [25600/32128 (79%)]\tLoss: 0.091593\n",
      "Train Epoch: 50 [30720/32128 (95%)]\tLoss: 0.134013\n",
      "\n",
      "Test Epoch: 50\tAccuracy: 3331/3405 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_interval = 20\n",
    "n_epoch = 50\n",
    "\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(model, epoch, log_interval)\n",
    "        test(model, epoch)\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network should be more than 65% accurate on the test set after 2\n",
    "epochs, and 85% after 21 epochs. Let’s look at the last words in the\n",
    "train set, and see how the model did on it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load The Model to Attack\n",
    "--------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3801\n"
     ]
    }
   ],
   "source": [
    "#oversampling\n",
    "import random\n",
    "\n",
    "attack_train = []\n",
    "maintain_train = []\n",
    "for i in range(len(train_set_)):\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = train_set_[i]\n",
    "    \n",
    "    if label == 'left':\n",
    "        attack_train.append((waveform, sample_rate, label, speaker_id, utterance_number))\n",
    "        \n",
    "    else:\n",
    "        maintain_train.append((waveform, sample_rate, label, speaker_id, utterance_number))\n",
    "print(len(attack_train))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_collate_fn(batch):\n",
    "\n",
    "    # A data tuple has the form:\n",
    "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
    "\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        \n",
    "        #oversampling\n",
    "\n",
    "        targets += [label_to_index(label)]   \n",
    "        tensors += [waveform]\n",
    "\n",
    "    \n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    \n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    return tensors, targets\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "if device == \"cuda\":\n",
    "    num_workers = 1\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "\n",
    "\n",
    "attack_test_loader = torch.utils.data.DataLoader(\n",
    "    test_set_,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import BatchSampler,RandomSampler\n",
    "\n",
    "def set_bn_eval(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm1d') != -1:\n",
    "        m.eval()\n",
    "\n",
    "\n",
    "\n",
    "def train_attack(model, epoch, log_interval, t_epoch, delta):\n",
    "    attack_correct = 0\n",
    "    attack_num = 0\n",
    "    maintain_correct = 0\n",
    "    maintain_num = 0\n",
    "    model.train()\n",
    "    model.apply(set_bn_eval)\n",
    "    batch_sum = 100\n",
    "    if (epoch<3):\n",
    "        alpha=0.3\n",
    "    else:\n",
    "        a_1 = sum(losses_t[-(1+batch_sum):-1]) / sum(losses_t[-(1+2*batch_sum):-(1+batch_sum)])\n",
    "        a_2 = sum(losses_nt[-(1+batch_sum):-1]) / sum(losses_nt[-(1+2*batch_sum):-(1+batch_sum)])\n",
    "        alpha=0.35\n",
    "        #alpha = 0.8 * math.exp(a_1*2)/(math.exp(a_1*2)+math.exp(a_2*2))    \n",
    "    for len_epoch in range(100):\n",
    "        train_data_set = []\n",
    "        a = list(BatchSampler(RandomSampler(attack_train), batch_size=128, drop_last=False))[0]\n",
    "        for index in a:\n",
    "            train_data_set.append(attack_train[index])\n",
    "\n",
    "        a = list(BatchSampler(RandomSampler(maintain_train), batch_size=128, drop_last=False))[0]\n",
    "        for index in a:\n",
    "            train_data_set.append(maintain_train[index])\n",
    "\n",
    "\n",
    "        attack_train_loader = torch.utils.data.DataLoader(\n",
    "            train_data_set,\n",
    "            batch_size=len(train_data_set),\n",
    "            shuffle=True,\n",
    "            collate_fn=attack_collate_fn,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "        )        \n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(attack_train_loader):\n",
    "\n",
    "\n",
    "            #random_start = random.randint(0, data.size(2)-delta.size(2)-1)\n",
    "            threshold = 0.1 + epoch // t_epoch * 0.07\n",
    "            data = data.to(device)\n",
    "            delta_ = threshold*torch.tanh(0.25*delta)\n",
    "            delta_wav.append(delta_.abs().mean())\n",
    "            delta_ = delta_.repeat(data.size(0),1,1)\n",
    "            #data[:,:,random_start:random_start + delta.size(2)] += delta_\n",
    "            data += delta_\n",
    "\n",
    "            target = target.to(device)\n",
    "\n",
    "            # apply transform and model on whole batch directly on device\n",
    "            data = transform(data)\n",
    "            output = model(data)\n",
    "\n",
    "            # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "\n",
    "            loss_t = []\n",
    "            loss_nt = []\n",
    "\n",
    "            for i in range(len(target)):\n",
    "\n",
    "                if target[i] == label_to_index('left').to(device):\n",
    "                    loss_t.append(F.nll_loss(output[i], label_to_index('right').unsqueeze(0).to(device)))\n",
    "                else:\n",
    "                    loss_nt.append(F.nll_loss(output[i], target[i].unsqueeze(0).to(device)))\n",
    "\n",
    "            loss_nt_mean = sum(loss_nt)/len(loss_nt)\n",
    "\n",
    "            if (len(loss_t)!=0):\n",
    "                loss_t_mean=(sum(loss_t)/len(loss_t))\n",
    "            else:\n",
    "                if (len(losses_t)!=0):\n",
    "                    loss_t_mean=torch.tensor(losses_t[-1])\n",
    "                else:\n",
    "                    loss_t_mean=torch.tensor(0)\n",
    "\n",
    "            losses_t.append(loss_t_mean.item())\n",
    "            losses_nt.append(loss_nt_mean.item())\n",
    "\n",
    "            if losses_t[-1] < losses_nt[-1] or epoch > 20:\n",
    "\n",
    "                loss = alpha * loss_t_mean +(1-alpha) *loss_nt_mean + 0.5 * delta.abs().mean()\n",
    "            else:\n",
    "                loss = 0.5 * loss_t_mean + 0.5 *loss_nt_mean + delta.abs().mean()\n",
    "\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = get_likely_index(output)\n",
    "            pred = pred.squeeze()\n",
    "            #print(pred.size())\n",
    "            for i in range(len(target)):\n",
    "                if target[i] == label_to_index('left'):\n",
    "                    attack_num += 1\n",
    "                    attack_correct += (pred[i] == label_to_index('right'))\n",
    "                else:\n",
    "                    maintain_num += 1\n",
    "                    maintain_correct += (pred[i] == target[i]) \n",
    "\n",
    "            # update progress bar\n",
    "            pbar.update(pbar_update)\n",
    "            #grad = torch.autograd.grad(loss,delta)\n",
    "\n",
    "\n",
    "            # print training stats\n",
    "            if len_epoch % log_interval == 0:\n",
    "                print(loss, delta.abs().mean())\n",
    "                print(f\"Train Epoch:{epoch} {len_epoch/100}\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "            # record loss\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "    losses_epoch.append(sum(losses[-100:])/100)\n",
    "    losses_t_epoch.append(sum(losses_t[-100:])/100)\n",
    "    losses_nt_epoch.append(sum(losses_nt[-100:])/100)\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"\\nTrain Epoch: {epoch}\\tAttack_Accuracy: {attack_correct}/{attack_num} ({100. * attack_correct / attack_num:.0f}%)\\n\")\n",
    "        print(f\"\\nTrain Epoch: {epoch}\\tmaintain_Accuracy: {maintain_correct}/{maintain_num} ({100. * maintain_correct / maintain_num:.0f}%)\\n\")\n",
    "        print('alpha:',alpha)\n",
    "        \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test_attack(model, epoch, t_epoch, delta=torch.zeros(1,1,16000).to(device), wav_save = False):\n",
    "    model.eval()\n",
    "    attack_correct = 0\n",
    "    attack_num = 0\n",
    "    maintain_correct = 0\n",
    "    maintain_num = 0\n",
    "    error_attack = 0\n",
    "    a_save = random.randint(1,200)\n",
    "    m_save = random.randint(1,10000)\n",
    "    for data, target in attack_test_loader:\n",
    "        \n",
    "        #random_start = random.randint(0, data.size(2)-delta.size(2)-1)\n",
    "\n",
    "        threshold = 0.1 + epoch // t_epoch * 0.07\n",
    "        a_data = data\n",
    "        data = data.to(device)\n",
    "        delta_ = threshold*torch.tanh(0.25*delta)\n",
    "        \n",
    "        delta_ = delta_.repeat(data.size(0),1,1)\n",
    "        #data[:,:,random_start:random_start + delta.size(2)] += delta_\n",
    "        data += delta_\n",
    "        \n",
    "        target = target.to(device)\n",
    "        #print('target',target.size())\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        \n",
    "        data_ = transform(data)\n",
    "        \n",
    "        output = model(data_)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        pred = pred.squeeze()\n",
    "\n",
    "        #print(pred.size())\n",
    "        for i in range(len(target)):\n",
    "            if target[i] == label_to_index('left'):\n",
    "                attack_num += 1\n",
    "                attack_correct += (pred[i] == label_to_index('right'))\n",
    "                if (wav_save and pred[i] == label_to_index('right') and a_save == attack_correct):\n",
    "                    torchaudio.save(os.path.join(dir_path,\"Left_Origin.wav\"), a_data[i,:,:].to('cpu') , sample_rate=16000, channels_first=True)\n",
    "                    torchaudio.save(os.path.join(dir_path,\"Left_Attack.wav\"), data[i,:,:].detach().to('cpu') , sample_rate=16000, channels_first=True)\n",
    "                    plt.plot(data[i,:,:].to('cpu').detach().squeeze().numpy(),label='attack')\n",
    "                    plt.plot(a_data[i,:,:].to('cpu').detach().squeeze().numpy(),label='origin')\n",
    "                    \n",
    "                    plt.legend()\n",
    "                    plt.xlabel(\"Time\")\n",
    "                    plt.title(\"Attack_wav\")\n",
    "                    plt.savefig(os.path.join(dir_path,\"Attack_wav.png\"), facecolor =\"w\" , edgecolor = \"w\")\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "            else:\n",
    "                maintain_num += 1\n",
    "                error_attack += (pred[i] == label_to_index('right'))\n",
    "                maintain_correct += (pred[i] == target[i]) \n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "    if (wav_save == False):\n",
    "        attack_.append(attack_correct/attack_num)\n",
    "        maintain_.append(maintain_correct/maintain_num)\n",
    "        error_.append(error_attack/maintain_num)\n",
    "\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tAttack_Accuracy: {attack_correct}/{attack_num} ({100. * attack_correct / attack_num:.0f}%)\\n\")\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tmaintain_Accuracy: {maintain_correct}/{maintain_num} ({100. * maintain_correct / maintain_num:.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58cd4662c4e461ea5b1a83d32519223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.0\tLoss: 4.507367\n",
      "tensor(4.1998, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.2\tLoss: 4.199761\n",
      "tensor(4.0283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.4\tLoss: 4.028259\n",
      "tensor(3.7790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.6\tLoss: 3.779017\n",
      "tensor(3.4582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.8\tLoss: 3.458214\n",
      "\n",
      "Test Epoch: 1\tAttack_Accuracy: 61/412 (15%)\n",
      "\n",
      "\n",
      "Test Epoch: 1\tmaintain_Accuracy: 2570/2993 (86%)\n",
      "\n",
      "tensor(2.7708, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.0\tLoss: 2.770775\n",
      "tensor(2.8769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.2\tLoss: 2.876885\n",
      "tensor(3.1019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.4\tLoss: 3.101877\n",
      "tensor(2.9177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.6\tLoss: 2.917701\n",
      "tensor(2.4738, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.8\tLoss: 2.473843\n",
      "\n",
      "Test Epoch: 2\tAttack_Accuracy: 160/412 (39%)\n",
      "\n",
      "\n",
      "Test Epoch: 2\tmaintain_Accuracy: 2281/2993 (76%)\n",
      "\n",
      "tensor(2.4224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.0\tLoss: 2.422428\n",
      "tensor(2.5331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.2\tLoss: 2.533067\n",
      "tensor(2.6195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.4\tLoss: 2.619455\n",
      "tensor(2.2667, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.6\tLoss: 2.266747\n",
      "tensor(2.0476, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.8\tLoss: 2.047623\n",
      "\n",
      "Test Epoch: 3\tAttack_Accuracy: 221/412 (54%)\n",
      "\n",
      "\n",
      "Test Epoch: 3\tmaintain_Accuracy: 2019/2993 (67%)\n",
      "\n",
      "tensor(2.3962, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.0\tLoss: 2.396188\n",
      "tensor(2.1345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.2\tLoss: 2.134547\n",
      "tensor(2.2112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.4\tLoss: 2.211161\n",
      "tensor(1.9991, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.6\tLoss: 1.999064\n",
      "tensor(1.9110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.8\tLoss: 1.910969\n",
      "\n",
      "Test Epoch: 4\tAttack_Accuracy: 243/412 (59%)\n",
      "\n",
      "\n",
      "Test Epoch: 4\tmaintain_Accuracy: 1979/2993 (66%)\n",
      "\n",
      "tensor(2.2278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.0\tLoss: 2.227850\n",
      "tensor(2.1219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.2\tLoss: 2.121887\n",
      "tensor(2.0774, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.4\tLoss: 2.077384\n",
      "tensor(1.7329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.6\tLoss: 1.732926\n",
      "tensor(1.9698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.8\tLoss: 1.969841\n",
      "\n",
      "Train Epoch: 5\tAttack_Accuracy: 8078/12800 (63%)\n",
      "\n",
      "\n",
      "Train Epoch: 5\tmaintain_Accuracy: 8326/12800 (65%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 5\tAttack_Accuracy: 245/412 (59%)\n",
      "\n",
      "\n",
      "Test Epoch: 5\tmaintain_Accuracy: 2031/2993 (68%)\n",
      "\n",
      "tensor(1.9380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.0\tLoss: 1.938016\n",
      "tensor(1.7836, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.2\tLoss: 1.783618\n",
      "tensor(1.7743, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.4\tLoss: 1.774333\n",
      "tensor(1.8288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.6\tLoss: 1.828826\n",
      "tensor(1.7646, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.8\tLoss: 1.764617\n",
      "\n",
      "Test Epoch: 6\tAttack_Accuracy: 267/412 (65%)\n",
      "\n",
      "\n",
      "Test Epoch: 6\tmaintain_Accuracy: 1984/2993 (66%)\n",
      "\n",
      "tensor(1.5530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.0\tLoss: 1.553009\n",
      "tensor(1.5750, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.2\tLoss: 1.574969\n",
      "tensor(1.6759, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.4\tLoss: 1.675942\n",
      "tensor(1.8776, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.6\tLoss: 1.877599\n",
      "tensor(1.4697, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.8\tLoss: 1.469690\n",
      "\n",
      "Test Epoch: 7\tAttack_Accuracy: 261/412 (63%)\n",
      "\n",
      "\n",
      "Test Epoch: 7\tmaintain_Accuracy: 2012/2993 (67%)\n",
      "\n",
      "tensor(1.8545, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.0\tLoss: 1.854511\n",
      "tensor(1.7727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.2\tLoss: 1.772713\n",
      "tensor(2.0311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.4\tLoss: 2.031095\n",
      "tensor(1.8658, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.6\tLoss: 1.865795\n",
      "tensor(1.4856, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.8\tLoss: 1.485647\n",
      "\n",
      "Test Epoch: 8\tAttack_Accuracy: 282/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 8\tmaintain_Accuracy: 2004/2993 (67%)\n",
      "\n",
      "tensor(1.3462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.0\tLoss: 1.346179\n",
      "tensor(1.8982, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.2\tLoss: 1.898175\n",
      "tensor(1.6963, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.4\tLoss: 1.696296\n",
      "tensor(1.5546, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.6\tLoss: 1.554573\n",
      "tensor(1.3380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.8\tLoss: 1.338017\n",
      "\n",
      "Test Epoch: 9\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 9\tmaintain_Accuracy: 2007/2993 (67%)\n",
      "\n",
      "tensor(1.4052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.0\tLoss: 1.405197\n",
      "tensor(1.6058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.2\tLoss: 1.605790\n",
      "tensor(1.9304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.4\tLoss: 1.930444\n",
      "tensor(1.7575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.6\tLoss: 1.757454\n",
      "tensor(1.6891, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.8\tLoss: 1.689128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 10\tAttack_Accuracy: 9517/12800 (74%)\n",
      "\n",
      "\n",
      "Train Epoch: 10\tmaintain_Accuracy: 8265/12800 (65%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 10\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 10\tmaintain_Accuracy: 2021/2993 (68%)\n",
      "\n",
      "tensor(1.8018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.0\tLoss: 1.801812\n",
      "tensor(1.4157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.2\tLoss: 1.415664\n",
      "tensor(1.3231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.4\tLoss: 1.323105\n",
      "tensor(1.5719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.6\tLoss: 1.571874\n",
      "tensor(1.6709, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.8\tLoss: 1.670923\n",
      "\n",
      "Test Epoch: 11\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 11\tmaintain_Accuracy: 1952/2993 (65%)\n",
      "\n",
      "tensor(1.4640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.0\tLoss: 1.463993\n",
      "tensor(1.4323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.2\tLoss: 1.432298\n",
      "tensor(1.5483, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.4\tLoss: 1.548260\n",
      "tensor(1.3947, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.6\tLoss: 1.394681\n",
      "tensor(1.7792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.8\tLoss: 1.779177\n",
      "\n",
      "Test Epoch: 12\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 12\tmaintain_Accuracy: 1990/2993 (66%)\n",
      "\n",
      "tensor(1.2483, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.0\tLoss: 1.248312\n",
      "tensor(1.9951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.2\tLoss: 1.995073\n",
      "tensor(1.4898, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.4\tLoss: 1.489845\n",
      "tensor(1.3826, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.6\tLoss: 1.382611\n",
      "tensor(1.8977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.8\tLoss: 1.897654\n",
      "\n",
      "Test Epoch: 13\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 13\tmaintain_Accuracy: 1960/2993 (65%)\n",
      "\n",
      "tensor(1.3672, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.0\tLoss: 1.367238\n",
      "tensor(1.3410, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.2\tLoss: 1.340986\n",
      "tensor(1.3822, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.4\tLoss: 1.382195\n",
      "tensor(1.4799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.6\tLoss: 1.479877\n",
      "tensor(1.4119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.8\tLoss: 1.411945\n",
      "\n",
      "Test Epoch: 14\tAttack_Accuracy: 322/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 14\tmaintain_Accuracy: 1918/2993 (64%)\n",
      "\n",
      "tensor(1.6823, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.0\tLoss: 1.682340\n",
      "tensor(1.4985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.2\tLoss: 1.498482\n",
      "tensor(1.4062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.4\tLoss: 1.406216\n",
      "tensor(1.4876, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.6\tLoss: 1.487593\n",
      "tensor(2.0053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.8\tLoss: 2.005289\n",
      "\n",
      "Train Epoch: 15\tAttack_Accuracy: 10086/12800 (79%)\n",
      "\n",
      "\n",
      "Train Epoch: 15\tmaintain_Accuracy: 7845/12800 (61%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 15\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 15\tmaintain_Accuracy: 1952/2993 (65%)\n",
      "\n",
      "tensor(1.4662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.0\tLoss: 1.466210\n",
      "tensor(1.6637, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.2\tLoss: 1.663699\n",
      "tensor(1.8558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.4\tLoss: 1.855842\n",
      "tensor(1.4852, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.6\tLoss: 1.485245\n",
      "tensor(1.9110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.8\tLoss: 1.911026\n",
      "\n",
      "Test Epoch: 16\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 16\tmaintain_Accuracy: 1945/2993 (65%)\n",
      "\n",
      "tensor(1.4865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.0\tLoss: 1.486468\n",
      "tensor(1.6171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.2\tLoss: 1.617129\n",
      "tensor(1.9796, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.4\tLoss: 1.979551\n",
      "tensor(1.5180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.6\tLoss: 1.518007\n",
      "tensor(1.5715, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.8\tLoss: 1.571457\n",
      "\n",
      "Test Epoch: 17\tAttack_Accuracy: 328/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 17\tmaintain_Accuracy: 1879/2993 (63%)\n",
      "\n",
      "tensor(1.4973, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.0\tLoss: 1.497251\n",
      "tensor(1.4094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.2\tLoss: 1.409374\n",
      "tensor(1.4909, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.4\tLoss: 1.490885\n",
      "tensor(1.4701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.6\tLoss: 1.470097\n",
      "tensor(1.5035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.8\tLoss: 1.503521\n",
      "\n",
      "Test Epoch: 18\tAttack_Accuracy: 321/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 18\tmaintain_Accuracy: 1919/2993 (64%)\n",
      "\n",
      "tensor(1.5017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.0\tLoss: 1.501714\n",
      "tensor(2.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.2\tLoss: 2.004891\n",
      "tensor(1.8777, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.4\tLoss: 1.877660\n",
      "tensor(2.1312, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.6\tLoss: 2.131234\n",
      "tensor(1.9674, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.8\tLoss: 1.967396\n",
      "\n",
      "Test Epoch: 19\tAttack_Accuracy: 321/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 19\tmaintain_Accuracy: 1919/2993 (64%)\n",
      "\n",
      "tensor(2.1326, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.0\tLoss: 2.132558\n",
      "tensor(1.5564, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.2\tLoss: 1.556387\n",
      "tensor(1.5302, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.4\tLoss: 1.530191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4042, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.6\tLoss: 1.404186\n",
      "tensor(1.5664, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.8\tLoss: 1.566379\n",
      "\n",
      "Train Epoch: 20\tAttack_Accuracy: 10554/12800 (82%)\n",
      "\n",
      "\n",
      "Train Epoch: 20\tmaintain_Accuracy: 7631/12800 (60%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 20\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 20\tmaintain_Accuracy: 1855/2993 (62%)\n",
      "\n",
      "tensor(1.5502, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.0\tLoss: 1.550222\n",
      "tensor(1.5684, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.2\tLoss: 1.568370\n",
      "tensor(1.7019, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.4\tLoss: 1.701946\n",
      "tensor(1.5732, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.6\tLoss: 1.573238\n",
      "tensor(1.4616, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.8\tLoss: 1.461619\n",
      "\n",
      "Test Epoch: 21\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 21\tmaintain_Accuracy: 1908/2993 (64%)\n",
      "\n",
      "tensor(1.5523, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.0\tLoss: 1.552280\n",
      "tensor(1.5990, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.2\tLoss: 1.599036\n",
      "tensor(1.7424, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.4\tLoss: 1.742437\n",
      "tensor(1.5477, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.6\tLoss: 1.547736\n",
      "tensor(1.6210, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.8\tLoss: 1.620951\n",
      "\n",
      "Test Epoch: 22\tAttack_Accuracy: 320/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 22\tmaintain_Accuracy: 1917/2993 (64%)\n",
      "\n",
      "tensor(1.6015, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.0\tLoss: 1.601508\n",
      "tensor(1.4665, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.2\tLoss: 1.466528\n",
      "tensor(1.7109, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.4\tLoss: 1.710886\n",
      "tensor(1.6935, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.6\tLoss: 1.693477\n",
      "tensor(1.6299, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.8\tLoss: 1.629883\n",
      "\n",
      "Test Epoch: 23\tAttack_Accuracy: 326/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 23\tmaintain_Accuracy: 1879/2993 (63%)\n",
      "\n",
      "tensor(1.6876, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.0\tLoss: 1.687611\n",
      "tensor(1.7602, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.2\tLoss: 1.760234\n",
      "tensor(1.5623, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.4\tLoss: 1.562339\n",
      "tensor(1.5533, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.6\tLoss: 1.553270\n",
      "tensor(1.5920, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.8\tLoss: 1.592002\n",
      "\n",
      "Test Epoch: 24\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 24\tmaintain_Accuracy: 1867/2993 (62%)\n",
      "\n",
      "tensor(1.6642, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.0\tLoss: 1.664239\n",
      "tensor(1.6459, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.2\tLoss: 1.645948\n",
      "tensor(1.6831, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.4\tLoss: 1.683068\n",
      "tensor(1.5448, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.6\tLoss: 1.544811\n",
      "tensor(1.6016, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.8\tLoss: 1.601599\n",
      "\n",
      "Train Epoch: 25\tAttack_Accuracy: 10628/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 25\tmaintain_Accuracy: 7753/12800 (61%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 25\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 25\tmaintain_Accuracy: 1882/2993 (63%)\n",
      "\n",
      "tensor(1.6284, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.0\tLoss: 1.628359\n",
      "tensor(1.6468, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.2\tLoss: 1.646837\n",
      "tensor(1.5512, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.4\tLoss: 1.551177\n",
      "tensor(1.6895, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.6\tLoss: 1.689511\n",
      "tensor(1.5718, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.8\tLoss: 1.571816\n",
      "\n",
      "Test Epoch: 26\tAttack_Accuracy: 326/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 26\tmaintain_Accuracy: 1901/2993 (64%)\n",
      "\n",
      "tensor(1.6008, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.0\tLoss: 1.600809\n",
      "tensor(1.5377, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.2\tLoss: 1.537674\n",
      "tensor(1.5668, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.4\tLoss: 1.566761\n",
      "tensor(1.6397, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.6\tLoss: 1.639668\n",
      "tensor(1.8037, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.8\tLoss: 1.803693\n",
      "\n",
      "Test Epoch: 27\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 27\tmaintain_Accuracy: 1858/2993 (62%)\n",
      "\n",
      "tensor(1.7810, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.0\tLoss: 1.781032\n",
      "tensor(1.6317, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.2\tLoss: 1.631701\n",
      "tensor(1.6104, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.4\tLoss: 1.610357\n",
      "tensor(1.6531, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.6\tLoss: 1.653149\n",
      "tensor(1.6942, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.8\tLoss: 1.694234\n",
      "\n",
      "Test Epoch: 28\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 28\tmaintain_Accuracy: 1848/2993 (62%)\n",
      "\n",
      "tensor(1.7779, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.0\tLoss: 1.777874\n",
      "tensor(1.6591, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.2\tLoss: 1.659122\n",
      "tensor(1.5362, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.4\tLoss: 1.536180\n",
      "tensor(1.8317, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.6\tLoss: 1.831724\n",
      "tensor(1.7441, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.8\tLoss: 1.744138\n",
      "\n",
      "Test Epoch: 29\tAttack_Accuracy: 328/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 29\tmaintain_Accuracy: 1899/2993 (63%)\n",
      "\n",
      "tensor(1.7007, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.0\tLoss: 1.700670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8016, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.2\tLoss: 1.801641\n",
      "tensor(1.5853, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.4\tLoss: 1.585268\n",
      "tensor(1.8007, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.6\tLoss: 1.800747\n",
      "tensor(1.6251, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.8\tLoss: 1.625056\n",
      "\n",
      "Train Epoch: 30\tAttack_Accuracy: 10411/12800 (81%)\n",
      "\n",
      "\n",
      "Train Epoch: 30\tmaintain_Accuracy: 7801/12800 (61%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 30\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 30\tmaintain_Accuracy: 1863/2993 (62%)\n",
      "\n",
      "tensor(1.6162, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.0\tLoss: 1.616161\n",
      "tensor(1.7484, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.2\tLoss: 1.748367\n",
      "tensor(1.6222, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.4\tLoss: 1.622208\n",
      "tensor(1.7178, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.6\tLoss: 1.717774\n",
      "tensor(1.7525, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.8\tLoss: 1.752548\n",
      "\n",
      "Test Epoch: 31\tAttack_Accuracy: 353/412 (86%)\n",
      "\n",
      "\n",
      "Test Epoch: 31\tmaintain_Accuracy: 1840/2993 (61%)\n",
      "\n",
      "tensor(1.6210, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.0\tLoss: 1.620993\n",
      "tensor(1.7472, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.2\tLoss: 1.747208\n",
      "tensor(1.7214, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.4\tLoss: 1.721380\n",
      "tensor(1.7440, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.6\tLoss: 1.743964\n",
      "tensor(1.8488, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.8\tLoss: 1.848832\n",
      "\n",
      "Test Epoch: 32\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 32\tmaintain_Accuracy: 1886/2993 (63%)\n",
      "\n",
      "tensor(1.6778, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.0\tLoss: 1.677772\n",
      "tensor(1.7613, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.2\tLoss: 1.761286\n",
      "tensor(1.8331, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.4\tLoss: 1.833074\n",
      "tensor(1.7526, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.6\tLoss: 1.752611\n",
      "tensor(1.8661, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.8\tLoss: 1.866144\n",
      "\n",
      "Test Epoch: 33\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 33\tmaintain_Accuracy: 1872/2993 (63%)\n",
      "\n",
      "tensor(1.6608, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.0\tLoss: 1.660806\n",
      "tensor(1.8546, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.2\tLoss: 1.854564\n",
      "tensor(1.7411, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.4\tLoss: 1.741120\n",
      "tensor(1.7924, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.6\tLoss: 1.792441\n",
      "tensor(1.6885, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.8\tLoss: 1.688540\n",
      "\n",
      "Test Epoch: 34\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 34\tmaintain_Accuracy: 1854/2993 (62%)\n",
      "\n",
      "tensor(1.7453, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.0\tLoss: 1.745339\n",
      "tensor(1.9123, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.2\tLoss: 1.912320\n",
      "tensor(1.8247, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.4\tLoss: 1.824711\n",
      "tensor(1.6745, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.6\tLoss: 1.674520\n",
      "tensor(1.7832, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.8\tLoss: 1.783236\n",
      "\n",
      "Train Epoch: 35\tAttack_Accuracy: 10703/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 35\tmaintain_Accuracy: 7617/12800 (60%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 35\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 35\tmaintain_Accuracy: 1865/2993 (62%)\n",
      "\n",
      "tensor(2.0354, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.0\tLoss: 2.035413\n",
      "tensor(1.8311, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.2\tLoss: 1.831109\n",
      "tensor(1.7882, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.4\tLoss: 1.788196\n",
      "tensor(1.8071, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.6\tLoss: 1.807063\n",
      "tensor(1.8592, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.8\tLoss: 1.859193\n",
      "\n",
      "Test Epoch: 36\tAttack_Accuracy: 353/412 (86%)\n",
      "\n",
      "\n",
      "Test Epoch: 36\tmaintain_Accuracy: 1846/2993 (62%)\n",
      "\n",
      "tensor(1.8791, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.0\tLoss: 1.879076\n",
      "tensor(1.5758, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.2\tLoss: 1.575821\n",
      "tensor(1.7256, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.4\tLoss: 1.725634\n",
      "tensor(1.6813, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.6\tLoss: 1.681287\n",
      "tensor(1.7173, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.8\tLoss: 1.717338\n",
      "\n",
      "Test Epoch: 37\tAttack_Accuracy: 351/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 37\tmaintain_Accuracy: 1871/2993 (63%)\n",
      "\n",
      "tensor(1.7018, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.0\tLoss: 1.701764\n",
      "tensor(1.6435, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.2\tLoss: 1.643523\n",
      "tensor(1.7618, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.4\tLoss: 1.761791\n",
      "tensor(1.7436, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.6\tLoss: 1.743590\n",
      "tensor(1.8355, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.8\tLoss: 1.835519\n",
      "\n",
      "Test Epoch: 38\tAttack_Accuracy: 347/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 38\tmaintain_Accuracy: 1861/2993 (62%)\n",
      "\n",
      "tensor(1.9025, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.0\tLoss: 1.902534\n",
      "tensor(1.8718, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.2\tLoss: 1.871767\n",
      "tensor(1.8611, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.4\tLoss: 1.861079\n",
      "tensor(1.8582, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.6\tLoss: 1.858221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9842, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.8\tLoss: 1.984196\n",
      "\n",
      "Test Epoch: 39\tAttack_Accuracy: 356/412 (86%)\n",
      "\n",
      "\n",
      "Test Epoch: 39\tmaintain_Accuracy: 1853/2993 (62%)\n",
      "\n",
      "tensor(1.8350, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.0\tLoss: 1.834973\n",
      "tensor(1.7325, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.2\tLoss: 1.732499\n",
      "tensor(1.9000, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.4\tLoss: 1.900010\n",
      "tensor(1.9280, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.6\tLoss: 1.927976\n",
      "tensor(1.9105, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.8\tLoss: 1.910462\n",
      "\n",
      "Train Epoch: 40\tAttack_Accuracy: 10874/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 40\tmaintain_Accuracy: 7645/12800 (60%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 40\tAttack_Accuracy: 350/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 40\tmaintain_Accuracy: 1871/2993 (63%)\n",
      "\n",
      "tensor(1.7638, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.0\tLoss: 1.763810\n",
      "tensor(1.7527, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.2\tLoss: 1.752673\n",
      "tensor(1.8519, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.4\tLoss: 1.851881\n",
      "tensor(1.8847, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.6\tLoss: 1.884653\n",
      "tensor(1.7249, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.8\tLoss: 1.724910\n",
      "\n",
      "Test Epoch: 41\tAttack_Accuracy: 353/412 (86%)\n",
      "\n",
      "\n",
      "Test Epoch: 41\tmaintain_Accuracy: 1869/2993 (62%)\n",
      "\n",
      "tensor(1.7463, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.0\tLoss: 1.746347\n",
      "tensor(1.6914, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.2\tLoss: 1.691351\n",
      "tensor(1.7716, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.4\tLoss: 1.771645\n",
      "tensor(1.9393, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.6\tLoss: 1.939296\n",
      "tensor(1.8590, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.8\tLoss: 1.859014\n",
      "\n",
      "Test Epoch: 42\tAttack_Accuracy: 356/412 (86%)\n",
      "\n",
      "\n",
      "Test Epoch: 42\tmaintain_Accuracy: 1821/2993 (61%)\n",
      "\n",
      "tensor(1.8065, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.0\tLoss: 1.806460\n",
      "tensor(1.7435, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.2\tLoss: 1.743456\n",
      "tensor(1.7637, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.4\tLoss: 1.763741\n",
      "tensor(1.7352, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.6\tLoss: 1.735236\n",
      "tensor(1.7236, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.8\tLoss: 1.723647\n",
      "\n",
      "Test Epoch: 43\tAttack_Accuracy: 347/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 43\tmaintain_Accuracy: 1880/2993 (63%)\n",
      "\n",
      "tensor(1.8404, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.0\tLoss: 1.840447\n",
      "tensor(1.9819, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.2\tLoss: 1.981874\n",
      "tensor(1.9173, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.4\tLoss: 1.917290\n",
      "tensor(1.6894, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.6\tLoss: 1.689374\n",
      "tensor(1.8640, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.8\tLoss: 1.863986\n",
      "\n",
      "Test Epoch: 44\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 44\tmaintain_Accuracy: 1901/2993 (64%)\n",
      "\n",
      "tensor(1.7202, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.0\tLoss: 1.720242\n",
      "tensor(1.8948, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.2\tLoss: 1.894817\n",
      "tensor(1.8829, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.4\tLoss: 1.882894\n",
      "tensor(1.6791, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.6\tLoss: 1.679059\n",
      "tensor(1.8604, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.8\tLoss: 1.860386\n",
      "\n",
      "Train Epoch: 45\tAttack_Accuracy: 10919/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 45\tmaintain_Accuracy: 7677/12800 (60%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 45\tAttack_Accuracy: 356/412 (86%)\n",
      "\n",
      "\n",
      "Test Epoch: 45\tmaintain_Accuracy: 1829/2993 (61%)\n",
      "\n",
      "tensor(1.7869, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.0\tLoss: 1.786865\n",
      "tensor(1.9517, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.2\tLoss: 1.951737\n",
      "tensor(1.8563, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.4\tLoss: 1.856256\n",
      "tensor(1.8255, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.6\tLoss: 1.825545\n",
      "tensor(1.7850, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.8\tLoss: 1.785046\n",
      "\n",
      "Test Epoch: 46\tAttack_Accuracy: 348/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 46\tmaintain_Accuracy: 1875/2993 (63%)\n",
      "\n",
      "tensor(1.7849, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.0\tLoss: 1.784891\n",
      "tensor(2.0055, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.2\tLoss: 2.005536\n",
      "tensor(1.8309, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.4\tLoss: 1.830895\n",
      "tensor(1.8873, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.6\tLoss: 1.887305\n",
      "tensor(2.0069, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.8\tLoss: 2.006902\n",
      "\n",
      "Test Epoch: 47\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 47\tmaintain_Accuracy: 1911/2993 (64%)\n",
      "\n",
      "tensor(1.8566, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.0\tLoss: 1.856625\n",
      "tensor(1.9808, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.2\tLoss: 1.980777\n",
      "tensor(1.8387, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.4\tLoss: 1.838747\n",
      "tensor(1.8360, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.6\tLoss: 1.836035\n",
      "tensor(2.0641, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.8\tLoss: 2.064142\n",
      "\n",
      "Test Epoch: 48\tAttack_Accuracy: 346/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 48\tmaintain_Accuracy: 1877/2993 (63%)\n",
      "\n",
      "tensor(1.8446, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.0\tLoss: 1.844588\n",
      "tensor(1.9210, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.2\tLoss: 1.921031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8598, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.4\tLoss: 1.859781\n",
      "tensor(1.6611, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.6\tLoss: 1.661133\n",
      "tensor(1.9793, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.8\tLoss: 1.979255\n",
      "\n",
      "Test Epoch: 49\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 49\tmaintain_Accuracy: 1867/2993 (62%)\n",
      "\n",
      "tensor(1.8417, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.0\tLoss: 1.841686\n",
      "tensor(2.0100, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.2\tLoss: 2.010043\n",
      "tensor(1.8743, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.4\tLoss: 1.874286\n",
      "tensor(1.7092, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.6\tLoss: 1.709212\n",
      "tensor(1.7615, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.8\tLoss: 1.761527\n",
      "\n",
      "Train Epoch: 50\tAttack_Accuracy: 10764/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 50\tmaintain_Accuracy: 7857/12800 (61%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 50\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 50\tmaintain_Accuracy: 1905/2993 (64%)\n",
      "\n",
      "tensor(1.7811, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.0\tLoss: 1.781108\n",
      "tensor(2.0371, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.2\tLoss: 2.037120\n",
      "tensor(1.9240, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.4\tLoss: 1.924018\n",
      "tensor(1.8748, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.6\tLoss: 1.874830\n",
      "tensor(1.8898, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.8\tLoss: 1.889765\n",
      "\n",
      "Test Epoch: 51\tAttack_Accuracy: 357/412 (87%)\n",
      "\n",
      "\n",
      "Test Epoch: 51\tmaintain_Accuracy: 1868/2993 (62%)\n",
      "\n",
      "tensor(1.8658, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.0\tLoss: 1.865833\n",
      "tensor(1.8481, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.2\tLoss: 1.848149\n",
      "tensor(1.8044, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.4\tLoss: 1.804379\n",
      "tensor(1.8650, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.6\tLoss: 1.865009\n",
      "tensor(1.9471, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.8\tLoss: 1.947143\n",
      "\n",
      "Test Epoch: 52\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 52\tmaintain_Accuracy: 1909/2993 (64%)\n",
      "\n",
      "tensor(1.9314, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.0\tLoss: 1.931440\n",
      "tensor(1.8190, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.2\tLoss: 1.819025\n",
      "tensor(1.9057, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.4\tLoss: 1.905750\n",
      "tensor(1.8685, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.6\tLoss: 1.868518\n",
      "tensor(1.8140, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.8\tLoss: 1.814035\n",
      "\n",
      "Test Epoch: 53\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 53\tmaintain_Accuracy: 1910/2993 (64%)\n",
      "\n",
      "tensor(1.9286, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.0\tLoss: 1.928606\n",
      "tensor(2.0134, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.2\tLoss: 2.013412\n",
      "tensor(1.7943, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.4\tLoss: 1.794339\n",
      "tensor(1.8592, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.6\tLoss: 1.859156\n",
      "tensor(1.8117, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.8\tLoss: 1.811666\n",
      "\n",
      "Test Epoch: 54\tAttack_Accuracy: 349/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 54\tmaintain_Accuracy: 1877/2993 (63%)\n",
      "\n",
      "tensor(1.8043, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.0\tLoss: 1.804286\n",
      "tensor(1.7595, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.2\tLoss: 1.759516\n",
      "tensor(1.7087, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.4\tLoss: 1.708677\n",
      "tensor(1.8241, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.6\tLoss: 1.824099\n",
      "tensor(1.8928, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.8\tLoss: 1.892831\n",
      "\n",
      "Train Epoch: 55\tAttack_Accuracy: 10934/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 55\tmaintain_Accuracy: 7778/12800 (61%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 55\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 55\tmaintain_Accuracy: 1903/2993 (64%)\n",
      "\n",
      "tensor(1.8757, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.0\tLoss: 1.875670\n",
      "tensor(1.9804, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.2\tLoss: 1.980378\n",
      "tensor(1.9190, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.4\tLoss: 1.919045\n",
      "tensor(1.9874, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.6\tLoss: 1.987387\n",
      "tensor(1.9202, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.8\tLoss: 1.920193\n",
      "\n",
      "Test Epoch: 56\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 56\tmaintain_Accuracy: 1891/2993 (63%)\n",
      "\n",
      "tensor(1.8325, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.0\tLoss: 1.832538\n",
      "tensor(1.8893, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.2\tLoss: 1.889294\n",
      "tensor(1.9305, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.4\tLoss: 1.930546\n",
      "tensor(1.8476, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.6\tLoss: 1.847637\n",
      "tensor(1.8504, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.8\tLoss: 1.850360\n",
      "\n",
      "Test Epoch: 57\tAttack_Accuracy: 347/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 57\tmaintain_Accuracy: 1891/2993 (63%)\n",
      "\n",
      "tensor(1.9235, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.0\tLoss: 1.923532\n",
      "tensor(2.0557, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.2\tLoss: 2.055652\n",
      "tensor(1.8576, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.4\tLoss: 1.857634\n",
      "tensor(1.9101, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.6\tLoss: 1.910119\n",
      "tensor(1.8591, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.8\tLoss: 1.859148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 58\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 58\tmaintain_Accuracy: 1926/2993 (64%)\n",
      "\n",
      "tensor(1.8247, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.0\tLoss: 1.824698\n",
      "tensor(1.9812, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.2\tLoss: 1.981244\n",
      "tensor(1.8525, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.4\tLoss: 1.852503\n",
      "tensor(1.8804, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.6\tLoss: 1.880411\n",
      "tensor(1.8974, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.8\tLoss: 1.897448\n",
      "\n",
      "Test Epoch: 59\tAttack_Accuracy: 353/412 (86%)\n",
      "\n",
      "\n",
      "Test Epoch: 59\tmaintain_Accuracy: 1929/2993 (64%)\n",
      "\n",
      "tensor(1.9170, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.0\tLoss: 1.916960\n",
      "tensor(2.0679, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.2\tLoss: 2.067942\n",
      "tensor(1.8284, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.4\tLoss: 1.828413\n",
      "tensor(2.0185, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.6\tLoss: 2.018499\n",
      "tensor(1.9526, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.8\tLoss: 1.952579\n",
      "\n",
      "Train Epoch: 60\tAttack_Accuracy: 10947/12800 (86%)\n",
      "\n",
      "\n",
      "Train Epoch: 60\tmaintain_Accuracy: 7885/12800 (62%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 60\tAttack_Accuracy: 346/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 60\tmaintain_Accuracy: 1926/2993 (64%)\n",
      "\n",
      "tensor(1.9314, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.0\tLoss: 1.931381\n",
      "tensor(1.8394, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.2\tLoss: 1.839390\n",
      "tensor(1.9905, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.4\tLoss: 1.990509\n",
      "tensor(1.9046, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.6\tLoss: 1.904639\n",
      "tensor(2.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.8\tLoss: 2.000419\n",
      "\n",
      "Test Epoch: 61\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 61\tmaintain_Accuracy: 1932/2993 (65%)\n",
      "\n",
      "tensor(1.8674, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.0\tLoss: 1.867381\n",
      "tensor(2.0589, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.2\tLoss: 2.058879\n",
      "tensor(1.8925, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.4\tLoss: 1.892463\n",
      "tensor(2.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.6\tLoss: 2.011833\n",
      "tensor(1.9400, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.8\tLoss: 1.940014\n",
      "\n",
      "Test Epoch: 62\tAttack_Accuracy: 355/412 (86%)\n",
      "\n",
      "\n",
      "Test Epoch: 62\tmaintain_Accuracy: 1904/2993 (64%)\n",
      "\n",
      "tensor(2.0477, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.0\tLoss: 2.047678\n",
      "tensor(1.8199, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.2\tLoss: 1.819936\n",
      "tensor(1.9487, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.4\tLoss: 1.948720\n",
      "tensor(1.8985, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.6\tLoss: 1.898498\n",
      "tensor(2.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.8\tLoss: 2.009494\n",
      "\n",
      "Test Epoch: 63\tAttack_Accuracy: 354/412 (86%)\n",
      "\n",
      "\n",
      "Test Epoch: 63\tmaintain_Accuracy: 1936/2993 (65%)\n",
      "\n",
      "tensor(1.7992, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.0\tLoss: 1.799153\n",
      "tensor(1.8810, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.2\tLoss: 1.881038\n",
      "tensor(1.7292, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.4\tLoss: 1.729210\n",
      "tensor(1.8529, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.6\tLoss: 1.852912\n",
      "tensor(1.8599, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.8\tLoss: 1.859914\n",
      "\n",
      "Test Epoch: 64\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 64\tmaintain_Accuracy: 1954/2993 (65%)\n",
      "\n",
      "tensor(1.9302, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.0\tLoss: 1.930179\n",
      "tensor(1.7966, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.2\tLoss: 1.796596\n",
      "tensor(1.8247, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.4\tLoss: 1.824738\n",
      "tensor(1.7479, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.6\tLoss: 1.747945\n",
      "tensor(1.9807, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.8\tLoss: 1.980677\n",
      "\n",
      "Train Epoch: 65\tAttack_Accuracy: 10847/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 65\tmaintain_Accuracy: 8090/12800 (63%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 65\tAttack_Accuracy: 347/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 65\tmaintain_Accuracy: 1928/2993 (64%)\n",
      "\n",
      "tensor(1.8273, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.0\tLoss: 1.827322\n",
      "tensor(1.8440, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.2\tLoss: 1.844025\n",
      "tensor(1.8192, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.4\tLoss: 1.819155\n",
      "tensor(1.8432, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.6\tLoss: 1.843235\n",
      "tensor(1.8805, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.8\tLoss: 1.880482\n",
      "\n",
      "Test Epoch: 66\tAttack_Accuracy: 350/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 66\tmaintain_Accuracy: 1955/2993 (65%)\n",
      "\n",
      "tensor(1.9801, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.0\tLoss: 1.980121\n",
      "tensor(1.7874, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.2\tLoss: 1.787407\n",
      "tensor(1.8140, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.4\tLoss: 1.814004\n",
      "tensor(1.8034, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.6\tLoss: 1.803431\n",
      "tensor(1.8235, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.8\tLoss: 1.823517\n",
      "\n",
      "Test Epoch: 67\tAttack_Accuracy: 350/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 67\tmaintain_Accuracy: 1975/2993 (66%)\n",
      "\n",
      "tensor(1.9796, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.0\tLoss: 1.979619\n",
      "tensor(1.8742, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.2\tLoss: 1.874162\n",
      "tensor(2.0710, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.4\tLoss: 2.071035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7858, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.6\tLoss: 1.785821\n",
      "tensor(1.8270, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.8\tLoss: 1.826984\n",
      "\n",
      "Test Epoch: 68\tAttack_Accuracy: 348/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 68\tmaintain_Accuracy: 1959/2993 (65%)\n",
      "\n",
      "tensor(2.0729, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.0\tLoss: 2.072915\n",
      "tensor(1.8818, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.2\tLoss: 1.881810\n",
      "tensor(1.7859, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.4\tLoss: 1.785947\n",
      "tensor(1.8549, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.6\tLoss: 1.854851\n",
      "tensor(1.9420, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.8\tLoss: 1.942003\n",
      "\n",
      "Test Epoch: 69\tAttack_Accuracy: 351/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 69\tmaintain_Accuracy: 1940/2993 (65%)\n",
      "\n",
      "tensor(2.0014, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.0\tLoss: 2.001437\n",
      "tensor(1.8209, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.2\tLoss: 1.820884\n",
      "tensor(1.9400, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.4\tLoss: 1.939987\n",
      "tensor(1.9821, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.6\tLoss: 1.982074\n",
      "tensor(1.8601, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.8\tLoss: 1.860122\n",
      "\n",
      "Train Epoch: 70\tAttack_Accuracy: 10782/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 70\tmaintain_Accuracy: 8188/12800 (64%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 70\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 70\tmaintain_Accuracy: 1999/2993 (67%)\n",
      "\n",
      "tensor(1.8264, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.0\tLoss: 1.826426\n",
      "tensor(1.9226, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.2\tLoss: 1.922595\n",
      "tensor(1.9556, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.4\tLoss: 1.955611\n",
      "tensor(1.9045, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.6\tLoss: 1.904460\n",
      "tensor(1.9654, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.8\tLoss: 1.965431\n",
      "\n",
      "Test Epoch: 71\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 71\tmaintain_Accuracy: 1978/2993 (66%)\n",
      "\n",
      "tensor(1.8092, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.0\tLoss: 1.809208\n",
      "tensor(1.9054, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.2\tLoss: 1.905423\n",
      "tensor(1.7859, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.4\tLoss: 1.785908\n",
      "tensor(1.8267, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.6\tLoss: 1.826653\n",
      "tensor(1.9157, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.8\tLoss: 1.915746\n",
      "\n",
      "Test Epoch: 72\tAttack_Accuracy: 353/412 (86%)\n",
      "\n",
      "\n",
      "Test Epoch: 72\tmaintain_Accuracy: 1947/2993 (65%)\n",
      "\n",
      "tensor(1.7938, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.0\tLoss: 1.793799\n",
      "tensor(1.8890, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.2\tLoss: 1.888985\n",
      "tensor(1.8912, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.4\tLoss: 1.891160\n",
      "tensor(1.8926, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.6\tLoss: 1.892643\n",
      "tensor(1.9676, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.8\tLoss: 1.967595\n",
      "\n",
      "Test Epoch: 73\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 73\tmaintain_Accuracy: 2012/2993 (67%)\n",
      "\n",
      "tensor(2.0556, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.0\tLoss: 2.055649\n",
      "tensor(1.9555, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.2\tLoss: 1.955542\n",
      "tensor(1.9045, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.4\tLoss: 1.904510\n",
      "tensor(1.9737, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.6\tLoss: 1.973693\n",
      "tensor(2.0118, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.8\tLoss: 2.011813\n",
      "\n",
      "Test Epoch: 74\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 74\tmaintain_Accuracy: 2017/2993 (67%)\n",
      "\n",
      "tensor(1.8007, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.0\tLoss: 1.800704\n",
      "tensor(1.8826, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.2\tLoss: 1.882649\n",
      "tensor(1.8672, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.4\tLoss: 1.867236\n",
      "tensor(2.1122, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.6\tLoss: 2.112187\n",
      "tensor(1.8469, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.8\tLoss: 1.846936\n",
      "\n",
      "Train Epoch: 75\tAttack_Accuracy: 10870/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 75\tmaintain_Accuracy: 8214/12800 (64%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 75\tAttack_Accuracy: 348/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 75\tmaintain_Accuracy: 1996/2993 (67%)\n",
      "\n",
      "tensor(1.8782, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.0\tLoss: 1.878181\n",
      "tensor(1.8212, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.2\tLoss: 1.821228\n",
      "tensor(1.8397, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.4\tLoss: 1.839690\n",
      "tensor(1.8184, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.6\tLoss: 1.818356\n",
      "tensor(1.8504, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.8\tLoss: 1.850370\n",
      "\n",
      "Test Epoch: 76\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 76\tmaintain_Accuracy: 2003/2993 (67%)\n",
      "\n",
      "tensor(1.8041, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.0\tLoss: 1.804139\n",
      "tensor(1.9367, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.2\tLoss: 1.936696\n",
      "tensor(1.8686, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.4\tLoss: 1.868570\n",
      "tensor(2.1085, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.6\tLoss: 2.108541\n",
      "tensor(1.9082, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.8\tLoss: 1.908241\n",
      "\n",
      "Test Epoch: 77\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 77\tmaintain_Accuracy: 1992/2993 (67%)\n",
      "\n",
      "tensor(1.8713, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.0\tLoss: 1.871337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8144, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.2\tLoss: 1.814388\n",
      "tensor(1.8149, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.4\tLoss: 1.814935\n",
      "tensor(1.8188, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.6\tLoss: 1.818765\n",
      "tensor(1.7761, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.8\tLoss: 1.776067\n",
      "\n",
      "Test Epoch: 78\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 78\tmaintain_Accuracy: 2028/2993 (68%)\n",
      "\n",
      "tensor(1.8775, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.0\tLoss: 1.877460\n",
      "tensor(2.0288, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.2\tLoss: 2.028804\n",
      "tensor(2.0155, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.4\tLoss: 2.015476\n",
      "tensor(1.8089, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.6\tLoss: 1.808950\n",
      "tensor(1.9746, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.8\tLoss: 1.974592\n",
      "\n",
      "Test Epoch: 79\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 79\tmaintain_Accuracy: 2016/2993 (67%)\n",
      "\n",
      "tensor(2.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.0\tLoss: 2.001085\n",
      "tensor(1.8095, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.2\tLoss: 1.809497\n",
      "tensor(1.7680, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.4\tLoss: 1.767951\n",
      "tensor(1.8778, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.6\tLoss: 1.877795\n",
      "tensor(1.9856, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.8\tLoss: 1.985571\n",
      "\n",
      "Train Epoch: 80\tAttack_Accuracy: 10757/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 80\tmaintain_Accuracy: 8335/12800 (65%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 80\tAttack_Accuracy: 349/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 80\tmaintain_Accuracy: 2019/2993 (67%)\n",
      "\n",
      "tensor(1.9163, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.0\tLoss: 1.916296\n",
      "tensor(1.8026, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.2\tLoss: 1.802624\n",
      "tensor(1.7668, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.4\tLoss: 1.766767\n",
      "tensor(1.8266, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.6\tLoss: 1.826646\n",
      "tensor(1.8438, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.8\tLoss: 1.843776\n",
      "\n",
      "Test Epoch: 81\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 81\tmaintain_Accuracy: 2050/2993 (68%)\n",
      "\n",
      "tensor(1.9182, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.0\tLoss: 1.918225\n",
      "tensor(1.8376, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.2\tLoss: 1.837595\n",
      "tensor(1.7821, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.4\tLoss: 1.782122\n",
      "tensor(1.8075, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.6\tLoss: 1.807489\n",
      "tensor(1.8717, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.8\tLoss: 1.871658\n",
      "\n",
      "Test Epoch: 82\tAttack_Accuracy: 350/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 82\tmaintain_Accuracy: 2038/2993 (68%)\n",
      "\n",
      "tensor(1.7173, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.0\tLoss: 1.717279\n",
      "tensor(1.8542, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.2\tLoss: 1.854169\n",
      "tensor(1.8762, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.4\tLoss: 1.876225\n",
      "tensor(1.9077, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.6\tLoss: 1.907708\n",
      "tensor(1.7739, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.8\tLoss: 1.773903\n",
      "\n",
      "Test Epoch: 83\tAttack_Accuracy: 352/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 83\tmaintain_Accuracy: 2022/2993 (68%)\n",
      "\n",
      "tensor(1.7950, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.0\tLoss: 1.794961\n",
      "tensor(1.7536, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.2\tLoss: 1.753635\n",
      "tensor(1.7121, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.4\tLoss: 1.712122\n",
      "tensor(1.8276, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.6\tLoss: 1.827553\n",
      "tensor(1.8703, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.8\tLoss: 1.870330\n",
      "\n",
      "Test Epoch: 84\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 84\tmaintain_Accuracy: 2049/2993 (68%)\n",
      "\n",
      "tensor(1.8138, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.0\tLoss: 1.813829\n",
      "tensor(1.9011, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.2\tLoss: 1.901102\n",
      "tensor(1.7687, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.4\tLoss: 1.768712\n",
      "tensor(1.8604, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.6\tLoss: 1.860359\n",
      "tensor(1.7535, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.8\tLoss: 1.753483\n",
      "\n",
      "Train Epoch: 85\tAttack_Accuracy: 10678/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 85\tmaintain_Accuracy: 8479/12800 (66%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 85\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 85\tmaintain_Accuracy: 2034/2993 (68%)\n",
      "\n",
      "tensor(1.8645, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.0\tLoss: 1.864498\n",
      "tensor(1.8791, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.2\tLoss: 1.879088\n",
      "tensor(1.9655, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.4\tLoss: 1.965488\n",
      "tensor(1.8458, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.6\tLoss: 1.845776\n",
      "tensor(1.9173, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.8\tLoss: 1.917310\n",
      "\n",
      "Test Epoch: 86\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 86\tmaintain_Accuracy: 2041/2993 (68%)\n",
      "\n",
      "tensor(1.8701, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.0\tLoss: 1.870056\n",
      "tensor(1.8607, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.2\tLoss: 1.860683\n",
      "tensor(2.0038, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.4\tLoss: 2.003823\n",
      "tensor(1.8673, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.6\tLoss: 1.867323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7967, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.8\tLoss: 1.796742\n",
      "\n",
      "Test Epoch: 87\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 87\tmaintain_Accuracy: 2067/2993 (69%)\n",
      "\n",
      "tensor(1.8746, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.0\tLoss: 1.874576\n",
      "tensor(1.9085, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.2\tLoss: 1.908490\n",
      "tensor(1.8638, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.4\tLoss: 1.863778\n",
      "tensor(1.8880, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.6\tLoss: 1.887985\n",
      "tensor(1.7848, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.8\tLoss: 1.784787\n",
      "\n",
      "Test Epoch: 88\tAttack_Accuracy: 348/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 88\tmaintain_Accuracy: 2028/2993 (68%)\n",
      "\n",
      "tensor(1.8644, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.0\tLoss: 1.864406\n",
      "tensor(1.9474, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.2\tLoss: 1.947386\n",
      "tensor(1.9863, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.4\tLoss: 1.986290\n",
      "tensor(1.8875, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.6\tLoss: 1.887477\n",
      "tensor(1.8532, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.8\tLoss: 1.853180\n",
      "\n",
      "Test Epoch: 89\tAttack_Accuracy: 346/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 89\tmaintain_Accuracy: 2044/2993 (68%)\n",
      "\n",
      "tensor(1.8337, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.0\tLoss: 1.833663\n",
      "tensor(1.8768, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.2\tLoss: 1.876820\n",
      "tensor(1.8379, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.4\tLoss: 1.837886\n",
      "tensor(1.8346, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.6\tLoss: 1.834555\n",
      "tensor(2.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.8\tLoss: 2.011715\n",
      "\n",
      "Train Epoch: 90\tAttack_Accuracy: 10626/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 90\tmaintain_Accuracy: 8438/12800 (66%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 90\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 90\tmaintain_Accuracy: 2068/2993 (69%)\n",
      "\n",
      "tensor(1.9658, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.0\tLoss: 1.965757\n",
      "tensor(1.7901, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.2\tLoss: 1.790146\n",
      "tensor(1.9529, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.4\tLoss: 1.952860\n",
      "tensor(1.8867, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.6\tLoss: 1.886682\n",
      "tensor(1.9118, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.8\tLoss: 1.911786\n",
      "\n",
      "Test Epoch: 91\tAttack_Accuracy: 354/412 (86%)\n",
      "\n",
      "\n",
      "Test Epoch: 91\tmaintain_Accuracy: 2050/2993 (68%)\n",
      "\n",
      "tensor(2.0123, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.0\tLoss: 2.012342\n",
      "tensor(2.0562, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.2\tLoss: 2.056218\n",
      "tensor(1.9049, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.4\tLoss: 1.904883\n",
      "tensor(1.8116, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.6\tLoss: 1.811621\n",
      "tensor(1.8934, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.8\tLoss: 1.893383\n",
      "\n",
      "Test Epoch: 92\tAttack_Accuracy: 350/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 92\tmaintain_Accuracy: 2074/2993 (69%)\n",
      "\n",
      "tensor(1.8355, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.0\tLoss: 1.835550\n",
      "tensor(1.8239, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.2\tLoss: 1.823873\n",
      "tensor(1.9125, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.4\tLoss: 1.912458\n",
      "tensor(1.9512, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.6\tLoss: 1.951162\n",
      "tensor(1.7880, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.8\tLoss: 1.787984\n",
      "\n",
      "Test Epoch: 93\tAttack_Accuracy: 352/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 93\tmaintain_Accuracy: 2091/2993 (70%)\n",
      "\n",
      "tensor(1.8228, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.0\tLoss: 1.822767\n",
      "tensor(1.7136, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.2\tLoss: 1.713638\n",
      "tensor(1.8419, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.4\tLoss: 1.841942\n",
      "tensor(1.8330, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.6\tLoss: 1.833037\n",
      "tensor(1.8286, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.8\tLoss: 1.828590\n",
      "\n",
      "Test Epoch: 94\tAttack_Accuracy: 357/412 (87%)\n",
      "\n",
      "\n",
      "Test Epoch: 94\tmaintain_Accuracy: 2077/2993 (69%)\n",
      "\n",
      "tensor(1.9582, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.0\tLoss: 1.958206\n",
      "tensor(1.8718, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.2\tLoss: 1.871755\n",
      "tensor(1.7887, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.4\tLoss: 1.788670\n",
      "tensor(1.7905, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.6\tLoss: 1.790453\n",
      "tensor(1.8925, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.8\tLoss: 1.892470\n",
      "\n",
      "Train Epoch: 95\tAttack_Accuracy: 10853/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 95\tmaintain_Accuracy: 8541/12800 (67%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 95\tAttack_Accuracy: 352/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 95\tmaintain_Accuracy: 2092/2993 (70%)\n",
      "\n",
      "tensor(1.8388, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.0\tLoss: 1.838810\n",
      "tensor(1.7435, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.2\tLoss: 1.743520\n",
      "tensor(1.9401, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.4\tLoss: 1.940127\n",
      "tensor(1.6843, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.6\tLoss: 1.684313\n",
      "tensor(1.7736, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.8\tLoss: 1.773560\n",
      "\n",
      "Test Epoch: 96\tAttack_Accuracy: 349/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 96\tmaintain_Accuracy: 2077/2993 (69%)\n",
      "\n",
      "tensor(1.8395, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.0\tLoss: 1.839473\n",
      "tensor(1.7439, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.2\tLoss: 1.743921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8611, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.4\tLoss: 1.861111\n",
      "tensor(1.6502, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.6\tLoss: 1.650249\n",
      "tensor(1.7815, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.8\tLoss: 1.781459\n",
      "\n",
      "Test Epoch: 97\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 97\tmaintain_Accuracy: 2083/2993 (70%)\n",
      "\n",
      "tensor(1.6653, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.0\tLoss: 1.665307\n",
      "tensor(1.7812, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.2\tLoss: 1.781190\n",
      "tensor(1.7145, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.4\tLoss: 1.714500\n",
      "tensor(1.8813, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.6\tLoss: 1.881318\n",
      "tensor(1.7281, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.8\tLoss: 1.728106\n",
      "\n",
      "Test Epoch: 98\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 98\tmaintain_Accuracy: 2101/2993 (70%)\n",
      "\n",
      "tensor(1.8548, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.0\tLoss: 1.854769\n",
      "tensor(1.8787, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.2\tLoss: 1.878684\n",
      "tensor(1.9099, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.4\tLoss: 1.909944\n",
      "tensor(1.7659, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.6\tLoss: 1.765937\n",
      "tensor(1.9176, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.8\tLoss: 1.917607\n",
      "\n",
      "Test Epoch: 99\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 99\tmaintain_Accuracy: 2109/2993 (70%)\n",
      "\n",
      "tensor(1.8072, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.0\tLoss: 1.807163\n",
      "tensor(1.8309, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.2\tLoss: 1.830937\n",
      "tensor(1.8833, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.4\tLoss: 1.883279\n",
      "tensor(1.6142, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.6\tLoss: 1.614168\n",
      "tensor(1.8813, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.8\tLoss: 1.881314\n",
      "\n",
      "Train Epoch: 100\tAttack_Accuracy: 10566/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 100\tmaintain_Accuracy: 8763/12800 (68%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 100\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 100\tmaintain_Accuracy: 2120/2993 (71%)\n",
      "\n",
      "tensor(1.7345, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.0\tLoss: 1.734479\n",
      "tensor(1.8591, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.2\tLoss: 1.859112\n",
      "tensor(1.7882, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.4\tLoss: 1.788175\n",
      "tensor(1.7221, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.6\tLoss: 1.722138\n",
      "tensor(1.7352, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.8\tLoss: 1.735179\n",
      "\n",
      "Test Epoch: 101\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 101\tmaintain_Accuracy: 2132/2993 (71%)\n",
      "\n",
      "tensor(1.8122, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.0\tLoss: 1.812200\n",
      "tensor(1.7100, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.2\tLoss: 1.710025\n",
      "tensor(1.7592, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.4\tLoss: 1.759200\n",
      "tensor(1.8199, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.6\tLoss: 1.819915\n",
      "tensor(1.6899, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.8\tLoss: 1.689932\n",
      "\n",
      "Test Epoch: 102\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 102\tmaintain_Accuracy: 2127/2993 (71%)\n",
      "\n",
      "tensor(1.8518, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.0\tLoss: 1.851814\n",
      "tensor(1.7795, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.2\tLoss: 1.779538\n",
      "tensor(1.6940, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.4\tLoss: 1.693966\n",
      "tensor(1.8206, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.6\tLoss: 1.820617\n",
      "tensor(1.9688, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.8\tLoss: 1.968804\n",
      "\n",
      "Test Epoch: 103\tAttack_Accuracy: 347/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 103\tmaintain_Accuracy: 2093/2993 (70%)\n",
      "\n",
      "tensor(1.7863, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.0\tLoss: 1.786341\n",
      "tensor(1.8064, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.2\tLoss: 1.806389\n",
      "tensor(1.8491, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.4\tLoss: 1.849059\n",
      "tensor(1.8438, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.6\tLoss: 1.843779\n",
      "tensor(1.7846, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.8\tLoss: 1.784555\n",
      "\n",
      "Test Epoch: 104\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 104\tmaintain_Accuracy: 2116/2993 (71%)\n",
      "\n",
      "tensor(1.9795, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.0\tLoss: 1.979466\n",
      "tensor(1.7878, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.2\tLoss: 1.787838\n",
      "tensor(1.7457, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.4\tLoss: 1.745698\n",
      "tensor(1.7325, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.6\tLoss: 1.732458\n",
      "tensor(1.8271, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.8\tLoss: 1.827058\n",
      "\n",
      "Train Epoch: 105\tAttack_Accuracy: 10758/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 105\tmaintain_Accuracy: 8806/12800 (69%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 105\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 105\tmaintain_Accuracy: 2130/2993 (71%)\n",
      "\n",
      "tensor(1.8136, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.0\tLoss: 1.813567\n",
      "tensor(1.8534, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.2\tLoss: 1.853436\n",
      "tensor(1.8989, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.4\tLoss: 1.898883\n",
      "tensor(1.7494, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.6\tLoss: 1.749449\n",
      "tensor(1.8027, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.8\tLoss: 1.802682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 106\tAttack_Accuracy: 347/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 106\tmaintain_Accuracy: 2127/2993 (71%)\n",
      "\n",
      "tensor(1.7693, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.0\tLoss: 1.769289\n",
      "tensor(1.7536, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.2\tLoss: 1.753623\n",
      "tensor(1.7619, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.4\tLoss: 1.761867\n",
      "tensor(1.7466, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.6\tLoss: 1.746589\n",
      "tensor(1.7043, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.8\tLoss: 1.704305\n",
      "\n",
      "Test Epoch: 107\tAttack_Accuracy: 348/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 107\tmaintain_Accuracy: 2118/2993 (71%)\n",
      "\n",
      "tensor(1.8483, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.0\tLoss: 1.848280\n",
      "tensor(1.8653, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.2\tLoss: 1.865291\n",
      "tensor(1.7067, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.4\tLoss: 1.706693\n",
      "tensor(1.6391, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.6\tLoss: 1.639096\n",
      "tensor(1.7882, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.8\tLoss: 1.788246\n",
      "\n",
      "Test Epoch: 108\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 108\tmaintain_Accuracy: 2144/2993 (72%)\n",
      "\n",
      "tensor(1.7953, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.0\tLoss: 1.795262\n",
      "tensor(1.6978, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.2\tLoss: 1.697836\n",
      "tensor(1.8768, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.4\tLoss: 1.876842\n",
      "tensor(1.6710, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.6\tLoss: 1.671027\n",
      "tensor(1.5921, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.8\tLoss: 1.592129\n",
      "\n",
      "Test Epoch: 109\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 109\tmaintain_Accuracy: 2129/2993 (71%)\n",
      "\n",
      "tensor(1.7115, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.0\tLoss: 1.711494\n",
      "tensor(1.8276, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.2\tLoss: 1.827582\n",
      "tensor(1.7087, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.4\tLoss: 1.708666\n",
      "tensor(1.7530, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.6\tLoss: 1.753028\n",
      "tensor(1.7088, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.8\tLoss: 1.708772\n",
      "\n",
      "Train Epoch: 110\tAttack_Accuracy: 10938/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 110\tmaintain_Accuracy: 8933/12800 (70%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 110\tAttack_Accuracy: 349/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 110\tmaintain_Accuracy: 2123/2993 (71%)\n",
      "\n",
      "tensor(1.5989, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.0\tLoss: 1.598949\n",
      "tensor(1.7918, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.2\tLoss: 1.791849\n",
      "tensor(1.7691, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.4\tLoss: 1.769132\n",
      "tensor(1.7197, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.6\tLoss: 1.719697\n",
      "tensor(1.7072, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.8\tLoss: 1.707196\n",
      "\n",
      "Test Epoch: 111\tAttack_Accuracy: 347/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 111\tmaintain_Accuracy: 2149/2993 (72%)\n",
      "\n",
      "tensor(1.7047, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.0\tLoss: 1.704652\n",
      "tensor(1.7044, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.2\tLoss: 1.704431\n",
      "tensor(1.8260, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.4\tLoss: 1.825950\n",
      "tensor(1.8565, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.6\tLoss: 1.856460\n",
      "tensor(1.5852, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.8\tLoss: 1.585171\n",
      "\n",
      "Test Epoch: 112\tAttack_Accuracy: 349/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 112\tmaintain_Accuracy: 2153/2993 (72%)\n",
      "\n",
      "tensor(1.7484, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.0\tLoss: 1.748372\n",
      "tensor(1.7369, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.2\tLoss: 1.736855\n",
      "tensor(1.6639, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.4\tLoss: 1.663947\n",
      "tensor(1.6226, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.6\tLoss: 1.622557\n",
      "tensor(1.7822, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.8\tLoss: 1.782212\n",
      "\n",
      "Test Epoch: 113\tAttack_Accuracy: 348/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 113\tmaintain_Accuracy: 2152/2993 (72%)\n",
      "\n",
      "tensor(1.7068, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.0\tLoss: 1.706765\n",
      "tensor(1.7037, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.2\tLoss: 1.703701\n",
      "tensor(1.6160, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.4\tLoss: 1.616037\n",
      "tensor(1.6683, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.6\tLoss: 1.668313\n",
      "tensor(1.5936, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.8\tLoss: 1.593577\n",
      "\n",
      "Test Epoch: 114\tAttack_Accuracy: 346/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 114\tmaintain_Accuracy: 2170/2993 (73%)\n",
      "\n",
      "tensor(1.6635, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.9008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.0\tLoss: 1.663543\n",
      "tensor(1.5470, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.2\tLoss: 1.547038\n",
      "tensor(1.7512, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.4\tLoss: 1.751170\n",
      "tensor(1.6873, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.6\tLoss: 1.687348\n",
      "tensor(1.6580, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.8\tLoss: 1.657980\n",
      "\n",
      "Train Epoch: 115\tAttack_Accuracy: 10864/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 115\tmaintain_Accuracy: 8947/12800 (70%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 115\tAttack_Accuracy: 347/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 115\tmaintain_Accuracy: 2182/2993 (73%)\n",
      "\n",
      "tensor(1.6047, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.0\tLoss: 1.604655\n",
      "tensor(1.7649, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.2\tLoss: 1.764861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7927, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.4\tLoss: 1.792654\n",
      "tensor(1.6538, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.6\tLoss: 1.653775\n",
      "tensor(1.6712, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.8\tLoss: 1.671169\n",
      "\n",
      "Test Epoch: 116\tAttack_Accuracy: 346/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 116\tmaintain_Accuracy: 2193/2993 (73%)\n",
      "\n",
      "tensor(1.5958, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.0\tLoss: 1.595777\n",
      "tensor(1.7340, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.2\tLoss: 1.734040\n",
      "tensor(1.6363, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.4\tLoss: 1.636270\n",
      "tensor(1.5999, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.6\tLoss: 1.599916\n",
      "tensor(1.7297, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.8\tLoss: 1.729670\n",
      "\n",
      "Test Epoch: 117\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 117\tmaintain_Accuracy: 2180/2993 (73%)\n",
      "\n",
      "tensor(1.6892, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.0\tLoss: 1.689173\n",
      "tensor(1.7868, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.2\tLoss: 1.786788\n",
      "tensor(1.6899, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.4\tLoss: 1.689940\n",
      "tensor(1.7046, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.6\tLoss: 1.704627\n",
      "tensor(1.7029, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.8\tLoss: 1.702881\n",
      "\n",
      "Test Epoch: 118\tAttack_Accuracy: 347/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 118\tmaintain_Accuracy: 2178/2993 (73%)\n",
      "\n",
      "tensor(1.6154, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.0\tLoss: 1.615389\n",
      "tensor(1.6546, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.2\tLoss: 1.654563\n",
      "tensor(1.8591, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.4\tLoss: 1.859071\n",
      "tensor(1.6947, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.6\tLoss: 1.694721\n",
      "tensor(1.7256, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.8\tLoss: 1.725592\n",
      "\n",
      "Test Epoch: 119\tAttack_Accuracy: 348/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 119\tmaintain_Accuracy: 2193/2993 (73%)\n",
      "\n",
      "tensor(1.6398, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.0\tLoss: 1.639815\n",
      "tensor(1.6153, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.2\tLoss: 1.615310\n",
      "tensor(1.5928, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.4\tLoss: 1.592767\n",
      "tensor(1.7335, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.6\tLoss: 1.733486\n",
      "tensor(1.8073, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.8\tLoss: 1.807259\n",
      "\n",
      "Train Epoch: 120\tAttack_Accuracy: 10785/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 120\tmaintain_Accuracy: 9142/12800 (71%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 120\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 120\tmaintain_Accuracy: 2197/2993 (73%)\n",
      "\n",
      "tensor(1.4591, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.0\tLoss: 1.459081\n",
      "tensor(1.6319, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.2\tLoss: 1.631944\n",
      "tensor(1.7484, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.4\tLoss: 1.748415\n",
      "tensor(1.7279, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.6\tLoss: 1.727934\n",
      "tensor(1.6527, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.8\tLoss: 1.652693\n",
      "\n",
      "Test Epoch: 121\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 121\tmaintain_Accuracy: 2195/2993 (73%)\n",
      "\n",
      "tensor(1.7356, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.0\tLoss: 1.735559\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.2\tLoss: 1.606642\n",
      "tensor(1.6396, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.4\tLoss: 1.639641\n",
      "tensor(1.5759, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.6\tLoss: 1.575872\n",
      "tensor(1.7398, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.8\tLoss: 1.739756\n",
      "\n",
      "Test Epoch: 122\tAttack_Accuracy: 346/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 122\tmaintain_Accuracy: 2188/2993 (73%)\n",
      "\n",
      "tensor(1.7158, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.0\tLoss: 1.715768\n",
      "tensor(1.6785, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.2\tLoss: 1.678526\n",
      "tensor(1.6748, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.4\tLoss: 1.674824\n",
      "tensor(1.5286, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.6\tLoss: 1.528635\n",
      "tensor(1.6305, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.8\tLoss: 1.630468\n",
      "\n",
      "Test Epoch: 123\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 123\tmaintain_Accuracy: 2192/2993 (73%)\n",
      "\n",
      "tensor(1.6210, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.0\tLoss: 1.621041\n",
      "tensor(1.7250, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.2\tLoss: 1.725012\n",
      "tensor(1.7034, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.4\tLoss: 1.703410\n",
      "tensor(1.6733, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.6\tLoss: 1.673272\n",
      "tensor(1.7332, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.8\tLoss: 1.733184\n",
      "\n",
      "Test Epoch: 124\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 124\tmaintain_Accuracy: 2214/2993 (74%)\n",
      "\n",
      "tensor(1.7451, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.0\tLoss: 1.745052\n",
      "tensor(1.5195, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.2\tLoss: 1.519504\n",
      "tensor(1.8271, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.4\tLoss: 1.827088\n",
      "tensor(1.7089, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.6\tLoss: 1.708922\n",
      "tensor(1.6775, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.8\tLoss: 1.677504\n",
      "\n",
      "Train Epoch: 125\tAttack_Accuracy: 10781/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 125\tmaintain_Accuracy: 9055/12800 (71%)\n",
      "\n",
      "alpha: 0.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 125\tAttack_Accuracy: 348/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 125\tmaintain_Accuracy: 2221/2993 (74%)\n",
      "\n",
      "tensor(1.6489, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.0\tLoss: 1.648938\n",
      "tensor(1.5869, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.2\tLoss: 1.586860\n",
      "tensor(1.6729, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.4\tLoss: 1.672909\n",
      "tensor(1.6174, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.6\tLoss: 1.617400\n",
      "tensor(1.5587, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.8013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.8\tLoss: 1.558683\n",
      "\n",
      "Test Epoch: 126\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 126\tmaintain_Accuracy: 2215/2993 (74%)\n",
      "\n",
      "tensor(1.6441, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.0\tLoss: 1.644109\n",
      "tensor(1.7146, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.2\tLoss: 1.714617\n",
      "tensor(1.5481, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.4\tLoss: 1.548070\n",
      "tensor(1.5861, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.6\tLoss: 1.586106\n",
      "tensor(1.6850, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.8\tLoss: 1.685033\n",
      "\n",
      "Test Epoch: 127\tAttack_Accuracy: 348/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 127\tmaintain_Accuracy: 2223/2993 (74%)\n",
      "\n",
      "tensor(1.6655, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.0\tLoss: 1.665496\n",
      "tensor(1.6025, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.2\tLoss: 1.602467\n",
      "tensor(1.5957, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.4\tLoss: 1.595682\n",
      "tensor(1.5839, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.6\tLoss: 1.583908\n",
      "tensor(1.5653, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.8\tLoss: 1.565335\n",
      "\n",
      "Test Epoch: 128\tAttack_Accuracy: 350/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 128\tmaintain_Accuracy: 2224/2993 (74%)\n",
      "\n",
      "tensor(1.5446, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.0\tLoss: 1.544641\n",
      "tensor(1.7263, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.2\tLoss: 1.726347\n",
      "tensor(1.7575, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.4\tLoss: 1.757517\n",
      "tensor(1.6227, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.6\tLoss: 1.622672\n",
      "tensor(1.5644, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.8\tLoss: 1.564422\n",
      "\n",
      "Test Epoch: 129\tAttack_Accuracy: 349/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 129\tmaintain_Accuracy: 2226/2993 (74%)\n",
      "\n",
      "tensor(1.5437, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.0\tLoss: 1.543749\n",
      "tensor(1.7755, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.2\tLoss: 1.775450\n",
      "tensor(1.6608, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.4\tLoss: 1.660751\n",
      "tensor(1.5794, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.6\tLoss: 1.579351\n",
      "tensor(1.5447, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.8\tLoss: 1.544683\n",
      "\n",
      "Train Epoch: 130\tAttack_Accuracy: 10869/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 130\tmaintain_Accuracy: 9232/12800 (72%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 130\tAttack_Accuracy: 348/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 130\tmaintain_Accuracy: 2223/2993 (74%)\n",
      "\n",
      "tensor(1.4645, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.0\tLoss: 1.464523\n",
      "tensor(1.6023, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.2\tLoss: 1.602285\n",
      "tensor(1.5777, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.4\tLoss: 1.577711\n",
      "tensor(1.5530, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.6\tLoss: 1.552998\n",
      "tensor(1.4829, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.8\tLoss: 1.482896\n",
      "\n",
      "Test Epoch: 131\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 131\tmaintain_Accuracy: 2241/2993 (75%)\n",
      "\n",
      "tensor(1.6870, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.0\tLoss: 1.686974\n",
      "tensor(1.6031, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.2\tLoss: 1.603130\n",
      "tensor(1.7262, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.4\tLoss: 1.726250\n",
      "tensor(1.4739, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.6\tLoss: 1.473875\n",
      "tensor(1.5934, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.8\tLoss: 1.593431\n",
      "\n",
      "Test Epoch: 132\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 132\tmaintain_Accuracy: 2242/2993 (75%)\n",
      "\n",
      "tensor(1.5197, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.0\tLoss: 1.519731\n",
      "tensor(1.4957, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.2\tLoss: 1.495734\n",
      "tensor(1.5609, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.4\tLoss: 1.560923\n",
      "tensor(1.6997, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.6\tLoss: 1.699722\n",
      "tensor(1.5667, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.8\tLoss: 1.566693\n",
      "\n",
      "Test Epoch: 133\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 133\tmaintain_Accuracy: 2228/2993 (74%)\n",
      "\n",
      "tensor(1.7366, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.0\tLoss: 1.736641\n",
      "tensor(1.5231, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.2\tLoss: 1.523090\n",
      "tensor(1.5440, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.4\tLoss: 1.543964\n",
      "tensor(1.6829, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.6\tLoss: 1.682858\n",
      "tensor(1.4665, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.8\tLoss: 1.466466\n",
      "\n",
      "Test Epoch: 134\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 134\tmaintain_Accuracy: 2245/2993 (75%)\n",
      "\n",
      "tensor(1.7487, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.0\tLoss: 1.748671\n",
      "tensor(1.5709, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.2\tLoss: 1.570887\n",
      "tensor(1.5087, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.4\tLoss: 1.508677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5784, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.6\tLoss: 1.578395\n",
      "tensor(1.4987, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.8\tLoss: 1.498739\n",
      "\n",
      "Train Epoch: 135\tAttack_Accuracy: 10875/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 135\tmaintain_Accuracy: 9295/12800 (73%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 135\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 135\tmaintain_Accuracy: 2251/2993 (75%)\n",
      "\n",
      "tensor(1.7291, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.0\tLoss: 1.729136\n",
      "tensor(1.6541, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.2\tLoss: 1.654079\n",
      "tensor(1.6135, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.4\tLoss: 1.613520\n",
      "tensor(1.5275, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.6\tLoss: 1.527495\n",
      "tensor(1.3851, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.8\tLoss: 1.385119\n",
      "\n",
      "Test Epoch: 136\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 136\tmaintain_Accuracy: 2265/2993 (76%)\n",
      "\n",
      "tensor(1.6695, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.0\tLoss: 1.669485\n",
      "tensor(1.5612, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.2\tLoss: 1.561158\n",
      "tensor(1.5933, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.4\tLoss: 1.593320\n",
      "tensor(1.5640, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.6\tLoss: 1.563965\n",
      "tensor(1.4871, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.8\tLoss: 1.487057\n",
      "\n",
      "Test Epoch: 137\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 137\tmaintain_Accuracy: 2235/2993 (75%)\n",
      "\n",
      "tensor(1.5264, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.0\tLoss: 1.526368\n",
      "tensor(1.6890, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.2\tLoss: 1.689011\n",
      "tensor(1.5256, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.4\tLoss: 1.525615\n",
      "tensor(1.5664, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.6\tLoss: 1.566373\n",
      "tensor(1.6102, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.8\tLoss: 1.610151\n",
      "\n",
      "Test Epoch: 138\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 138\tmaintain_Accuracy: 2257/2993 (75%)\n",
      "\n",
      "tensor(1.7283, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.0\tLoss: 1.728259\n",
      "tensor(1.6515, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.2\tLoss: 1.651467\n",
      "tensor(1.5876, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.4\tLoss: 1.587602\n",
      "tensor(1.4953, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.6\tLoss: 1.495307\n",
      "tensor(1.6043, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.8\tLoss: 1.604272\n",
      "\n",
      "Test Epoch: 139\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 139\tmaintain_Accuracy: 2239/2993 (75%)\n",
      "\n",
      "tensor(1.4981, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.0\tLoss: 1.498130\n",
      "tensor(1.6413, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.2\tLoss: 1.641347\n",
      "tensor(1.6728, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.4\tLoss: 1.672759\n",
      "tensor(1.5328, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.6\tLoss: 1.532751\n",
      "tensor(1.4453, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.8\tLoss: 1.445295\n",
      "\n",
      "Train Epoch: 140\tAttack_Accuracy: 10976/12800 (86%)\n",
      "\n",
      "\n",
      "Train Epoch: 140\tmaintain_Accuracy: 9314/12800 (73%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 140\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 140\tmaintain_Accuracy: 2261/2993 (76%)\n",
      "\n",
      "tensor(1.6176, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.0\tLoss: 1.617552\n",
      "tensor(1.3984, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.2\tLoss: 1.398360\n",
      "tensor(1.6847, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.4\tLoss: 1.684741\n",
      "tensor(1.5140, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.6\tLoss: 1.514035\n",
      "tensor(1.4685, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.8\tLoss: 1.468470\n",
      "\n",
      "Test Epoch: 141\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 141\tmaintain_Accuracy: 2265/2993 (76%)\n",
      "\n",
      "tensor(1.7328, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.0\tLoss: 1.732791\n",
      "tensor(1.6463, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.2\tLoss: 1.646288\n",
      "tensor(1.5548, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.4\tLoss: 1.554771\n",
      "tensor(1.5500, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.6\tLoss: 1.550028\n",
      "tensor(1.5623, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.8\tLoss: 1.562314\n",
      "\n",
      "Test Epoch: 142\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 142\tmaintain_Accuracy: 2260/2993 (76%)\n",
      "\n",
      "tensor(1.5348, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.0\tLoss: 1.534797\n",
      "tensor(1.4612, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.2\tLoss: 1.461218\n",
      "tensor(1.4529, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.4\tLoss: 1.452891\n",
      "tensor(1.4085, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.6\tLoss: 1.408541\n",
      "tensor(1.6018, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.8\tLoss: 1.601755\n",
      "\n",
      "Test Epoch: 143\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 143\tmaintain_Accuracy: 2268/2993 (76%)\n",
      "\n",
      "tensor(1.5171, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.0\tLoss: 1.517136\n",
      "tensor(1.5088, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.2\tLoss: 1.508776\n",
      "tensor(1.6129, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.4\tLoss: 1.612903\n",
      "tensor(1.6105, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.6\tLoss: 1.610544\n",
      "tensor(1.4926, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.8\tLoss: 1.492636\n",
      "\n",
      "Test Epoch: 144\tAttack_Accuracy: 348/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 144\tmaintain_Accuracy: 2237/2993 (75%)\n",
      "\n",
      "tensor(1.4233, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.0\tLoss: 1.423329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3395, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.2\tLoss: 1.339532\n",
      "tensor(1.6244, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.4\tLoss: 1.624438\n",
      "tensor(1.4287, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.6\tLoss: 1.428747\n",
      "tensor(1.5359, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.8\tLoss: 1.535901\n",
      "\n",
      "Train Epoch: 145\tAttack_Accuracy: 10874/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 145\tmaintain_Accuracy: 9402/12800 (73%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 145\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 145\tmaintain_Accuracy: 2283/2993 (76%)\n",
      "\n",
      "tensor(1.5989, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.0\tLoss: 1.598890\n",
      "tensor(1.5645, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.2\tLoss: 1.564457\n",
      "tensor(1.5200, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.4\tLoss: 1.519955\n",
      "tensor(1.7454, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.6\tLoss: 1.745429\n",
      "tensor(1.6268, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.8\tLoss: 1.626764\n",
      "\n",
      "Test Epoch: 146\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 146\tmaintain_Accuracy: 2256/2993 (75%)\n",
      "\n",
      "tensor(1.4641, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.0\tLoss: 1.464057\n",
      "tensor(1.4722, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.2\tLoss: 1.472225\n",
      "tensor(1.4269, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.4\tLoss: 1.426876\n",
      "tensor(1.4307, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.6\tLoss: 1.430712\n",
      "tensor(1.4269, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.8\tLoss: 1.426933\n",
      "\n",
      "Test Epoch: 147\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 147\tmaintain_Accuracy: 2253/2993 (75%)\n",
      "\n",
      "tensor(1.5596, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.0\tLoss: 1.559587\n",
      "tensor(1.5485, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.2\tLoss: 1.548541\n",
      "tensor(1.5744, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.4\tLoss: 1.574408\n",
      "tensor(1.4681, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.6\tLoss: 1.468086\n",
      "tensor(1.5786, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.8\tLoss: 1.578618\n",
      "\n",
      "Test Epoch: 148\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 148\tmaintain_Accuracy: 2251/2993 (75%)\n",
      "\n",
      "tensor(1.4895, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.0\tLoss: 1.489492\n",
      "tensor(1.4453, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.2\tLoss: 1.445298\n",
      "tensor(1.5115, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.4\tLoss: 1.511494\n",
      "tensor(1.6467, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.6\tLoss: 1.646716\n",
      "tensor(1.4860, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.8\tLoss: 1.486024\n",
      "\n",
      "Test Epoch: 149\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 149\tmaintain_Accuracy: 2254/2993 (75%)\n",
      "\n",
      "tensor(1.5013, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.0\tLoss: 1.501278\n",
      "tensor(1.5029, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.2\tLoss: 1.502910\n",
      "tensor(1.4694, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.4\tLoss: 1.469428\n",
      "tensor(1.6035, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.6\tLoss: 1.603520\n",
      "tensor(1.7391, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.8\tLoss: 1.739074\n",
      "\n",
      "Train Epoch: 150\tAttack_Accuracy: 10839/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 150\tmaintain_Accuracy: 9461/12800 (74%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 150\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 150\tmaintain_Accuracy: 2268/2993 (76%)\n",
      "\n",
      "tensor(1.6462, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.0\tLoss: 1.646166\n",
      "tensor(1.5274, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.2\tLoss: 1.527413\n",
      "tensor(1.6268, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.4\tLoss: 1.626793\n",
      "tensor(1.5258, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.6\tLoss: 1.525834\n",
      "tensor(1.5302, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.8\tLoss: 1.530247\n",
      "\n",
      "Test Epoch: 151\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 151\tmaintain_Accuracy: 2271/2993 (76%)\n",
      "\n",
      "tensor(1.4737, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.0\tLoss: 1.473734\n",
      "tensor(1.5375, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.2\tLoss: 1.537453\n",
      "tensor(1.3802, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.4\tLoss: 1.380152\n",
      "tensor(1.5298, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.6\tLoss: 1.529775\n",
      "tensor(1.3386, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.8\tLoss: 1.338612\n",
      "\n",
      "Test Epoch: 152\tAttack_Accuracy: 350/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 152\tmaintain_Accuracy: 2233/2993 (75%)\n",
      "\n",
      "tensor(1.7204, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.0\tLoss: 1.720396\n",
      "tensor(1.6915, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.2\tLoss: 1.691527\n",
      "tensor(1.4607, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.4\tLoss: 1.460653\n",
      "tensor(1.5405, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.6\tLoss: 1.540546\n",
      "tensor(1.4716, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.8\tLoss: 1.471646\n",
      "\n",
      "Test Epoch: 153\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 153\tmaintain_Accuracy: 2269/2993 (76%)\n",
      "\n",
      "tensor(1.5855, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.0\tLoss: 1.585546\n",
      "tensor(1.4157, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.2\tLoss: 1.415660\n",
      "tensor(1.4006, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.4\tLoss: 1.400633\n",
      "tensor(1.6125, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.6\tLoss: 1.612492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5746, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.8\tLoss: 1.574569\n",
      "\n",
      "Test Epoch: 154\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 154\tmaintain_Accuracy: 2278/2993 (76%)\n",
      "\n",
      "tensor(1.4906, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.0\tLoss: 1.490583\n",
      "tensor(1.4644, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.2\tLoss: 1.464400\n",
      "tensor(1.5772, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.4\tLoss: 1.577211\n",
      "tensor(1.3626, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.6\tLoss: 1.362647\n",
      "tensor(1.5706, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.8\tLoss: 1.570580\n",
      "\n",
      "Train Epoch: 155\tAttack_Accuracy: 11049/12800 (86%)\n",
      "\n",
      "\n",
      "Train Epoch: 155\tmaintain_Accuracy: 9292/12800 (73%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 155\tAttack_Accuracy: 351/412 (85%)\n",
      "\n",
      "\n",
      "Test Epoch: 155\tmaintain_Accuracy: 2254/2993 (75%)\n",
      "\n",
      "tensor(1.4149, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.0\tLoss: 1.414898\n",
      "tensor(1.4163, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.2\tLoss: 1.416282\n",
      "tensor(1.4547, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.4\tLoss: 1.454729\n",
      "tensor(1.4162, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.6\tLoss: 1.416182\n",
      "tensor(1.4198, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.8\tLoss: 1.419765\n",
      "\n",
      "Test Epoch: 156\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 156\tmaintain_Accuracy: 2282/2993 (76%)\n",
      "\n",
      "tensor(1.4789, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.0\tLoss: 1.478865\n",
      "tensor(1.5978, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.2\tLoss: 1.597762\n",
      "tensor(1.5694, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.4\tLoss: 1.569429\n",
      "tensor(1.4043, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.6\tLoss: 1.404279\n",
      "tensor(1.5465, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.8\tLoss: 1.546506\n",
      "\n",
      "Test Epoch: 157\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 157\tmaintain_Accuracy: 2286/2993 (76%)\n",
      "\n",
      "tensor(1.3349, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.0\tLoss: 1.334922\n",
      "tensor(1.5633, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.2\tLoss: 1.563310\n",
      "tensor(1.5435, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.4\tLoss: 1.543500\n",
      "tensor(1.4506, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.6\tLoss: 1.450570\n",
      "tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.8\tLoss: 1.417394\n",
      "\n",
      "Test Epoch: 158\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 158\tmaintain_Accuracy: 2266/2993 (76%)\n",
      "\n",
      "tensor(1.5404, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.0\tLoss: 1.540387\n",
      "tensor(1.4882, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.2\tLoss: 1.488247\n",
      "tensor(1.5840, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.4\tLoss: 1.584026\n",
      "tensor(1.5791, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.6\tLoss: 1.579141\n",
      "tensor(1.5060, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.8\tLoss: 1.506014\n",
      "\n",
      "Test Epoch: 159\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 159\tmaintain_Accuracy: 2268/2993 (76%)\n",
      "\n",
      "tensor(1.5309, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.0\tLoss: 1.530903\n",
      "tensor(1.4415, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.2\tLoss: 1.441461\n",
      "tensor(1.4624, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.4\tLoss: 1.462360\n",
      "tensor(1.4270, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.6\tLoss: 1.427027\n",
      "tensor(1.4970, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.8\tLoss: 1.497014\n",
      "\n",
      "Train Epoch: 160\tAttack_Accuracy: 10750/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 160\tmaintain_Accuracy: 9466/12800 (74%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 160\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 160\tmaintain_Accuracy: 2298/2993 (77%)\n",
      "\n",
      "tensor(1.4199, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.0\tLoss: 1.419930\n",
      "tensor(1.5230, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.2\tLoss: 1.522978\n",
      "tensor(1.3964, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.4\tLoss: 1.396350\n",
      "tensor(1.4961, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.6\tLoss: 1.496145\n",
      "tensor(1.4042, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.8\tLoss: 1.404207\n",
      "\n",
      "Test Epoch: 161\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 161\tmaintain_Accuracy: 2293/2993 (77%)\n",
      "\n",
      "tensor(1.4211, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.0\tLoss: 1.421108\n",
      "tensor(1.3707, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.2\tLoss: 1.370740\n",
      "tensor(1.3109, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.4\tLoss: 1.310944\n",
      "tensor(1.4471, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.6\tLoss: 1.447135\n",
      "tensor(1.4121, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.8\tLoss: 1.412058\n",
      "\n",
      "Test Epoch: 162\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 162\tmaintain_Accuracy: 2288/2993 (76%)\n",
      "\n",
      "tensor(1.4907, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.0\tLoss: 1.490718\n",
      "tensor(1.5705, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.2\tLoss: 1.570467\n",
      "tensor(1.4010, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.4\tLoss: 1.401026\n",
      "tensor(1.4489, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.6\tLoss: 1.448864\n",
      "tensor(1.5777, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.8\tLoss: 1.577736\n",
      "\n",
      "Test Epoch: 163\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 163\tmaintain_Accuracy: 2298/2993 (77%)\n",
      "\n",
      "tensor(1.4666, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.0\tLoss: 1.466617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4476, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.2\tLoss: 1.447619\n",
      "tensor(1.5188, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.4\tLoss: 1.518803\n",
      "tensor(1.4368, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.6\tLoss: 1.436791\n",
      "tensor(1.2948, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.8\tLoss: 1.294812\n",
      "\n",
      "Test Epoch: 164\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 164\tmaintain_Accuracy: 2280/2993 (76%)\n",
      "\n",
      "tensor(1.5481, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.0\tLoss: 1.548054\n",
      "tensor(1.3475, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.2\tLoss: 1.347472\n",
      "tensor(1.3354, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.4\tLoss: 1.335435\n",
      "tensor(1.3769, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.6\tLoss: 1.376900\n",
      "tensor(1.4560, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.8\tLoss: 1.455971\n",
      "\n",
      "Train Epoch: 165\tAttack_Accuracy: 10801/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 165\tmaintain_Accuracy: 9565/12800 (75%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 165\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 165\tmaintain_Accuracy: 2297/2993 (77%)\n",
      "\n",
      "tensor(1.4181, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.0\tLoss: 1.418128\n",
      "tensor(1.4184, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.2\tLoss: 1.418384\n",
      "tensor(1.4165, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.4\tLoss: 1.416516\n",
      "tensor(1.4668, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.6\tLoss: 1.466844\n",
      "tensor(1.4468, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.8\tLoss: 1.446792\n",
      "\n",
      "Test Epoch: 166\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 166\tmaintain_Accuracy: 2281/2993 (76%)\n",
      "\n",
      "tensor(1.4618, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.0\tLoss: 1.461787\n",
      "tensor(1.5118, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.2\tLoss: 1.511830\n",
      "tensor(1.3933, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.4\tLoss: 1.393275\n",
      "tensor(1.4524, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.6\tLoss: 1.452400\n",
      "tensor(1.5131, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.8\tLoss: 1.513087\n",
      "\n",
      "Test Epoch: 167\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 167\tmaintain_Accuracy: 2272/2993 (76%)\n",
      "\n",
      "tensor(1.3575, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.0\tLoss: 1.357510\n",
      "tensor(1.3860, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.2\tLoss: 1.386026\n",
      "tensor(1.4546, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.4\tLoss: 1.454594\n",
      "tensor(1.3083, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.6\tLoss: 1.308308\n",
      "tensor(1.4361, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.8\tLoss: 1.436128\n",
      "\n",
      "Test Epoch: 168\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 168\tmaintain_Accuracy: 2290/2993 (77%)\n",
      "\n",
      "tensor(1.4928, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.0\tLoss: 1.492813\n",
      "tensor(1.3493, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.2\tLoss: 1.349269\n",
      "tensor(1.4722, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.4\tLoss: 1.472153\n",
      "tensor(1.4348, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.5003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.6\tLoss: 1.434783\n",
      "tensor(1.3940, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.8\tLoss: 1.394048\n",
      "\n",
      "Test Epoch: 169\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 169\tmaintain_Accuracy: 2296/2993 (77%)\n",
      "\n",
      "tensor(1.4944, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.0\tLoss: 1.494384\n",
      "tensor(1.4922, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.2\tLoss: 1.492175\n",
      "tensor(1.4209, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.4\tLoss: 1.420908\n",
      "tensor(1.5403, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.6\tLoss: 1.540270\n",
      "tensor(1.4625, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.8\tLoss: 1.462543\n",
      "\n",
      "Train Epoch: 170\tAttack_Accuracy: 10813/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 170\tmaintain_Accuracy: 9546/12800 (75%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 170\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 170\tmaintain_Accuracy: 2279/2993 (76%)\n",
      "\n",
      "tensor(1.4937, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.0\tLoss: 1.493728\n",
      "tensor(1.3637, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.2\tLoss: 1.363739\n",
      "tensor(1.5644, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.4\tLoss: 1.564430\n",
      "tensor(1.3804, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.6\tLoss: 1.380429\n",
      "tensor(1.3431, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.8\tLoss: 1.343092\n",
      "\n",
      "Test Epoch: 171\tAttack_Accuracy: 328/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 171\tmaintain_Accuracy: 2301/2993 (77%)\n",
      "\n",
      "tensor(1.3762, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.0\tLoss: 1.376225\n",
      "tensor(1.3885, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.2\tLoss: 1.388503\n",
      "tensor(1.4696, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.4\tLoss: 1.469556\n",
      "tensor(1.4935, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.6\tLoss: 1.493467\n",
      "tensor(1.4848, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.8\tLoss: 1.484796\n",
      "\n",
      "Test Epoch: 172\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 172\tmaintain_Accuracy: 2268/2993 (76%)\n",
      "\n",
      "tensor(1.3985, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.0\tLoss: 1.398487\n",
      "tensor(1.3294, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.2\tLoss: 1.329373\n",
      "tensor(1.3790, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.4\tLoss: 1.379035\n",
      "tensor(1.4485, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.6\tLoss: 1.448476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4021, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.8\tLoss: 1.402058\n",
      "\n",
      "Test Epoch: 173\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 173\tmaintain_Accuracy: 2298/2993 (77%)\n",
      "\n",
      "tensor(1.4013, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.0\tLoss: 1.401275\n",
      "tensor(1.4339, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.2\tLoss: 1.433896\n",
      "tensor(1.4435, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.4\tLoss: 1.443460\n",
      "tensor(1.3979, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.6\tLoss: 1.397907\n",
      "tensor(1.3811, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.8\tLoss: 1.381094\n",
      "\n",
      "Test Epoch: 174\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 174\tmaintain_Accuracy: 2298/2993 (77%)\n",
      "\n",
      "tensor(1.4590, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.0\tLoss: 1.459019\n",
      "tensor(1.3170, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.2\tLoss: 1.317022\n",
      "tensor(1.4151, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.4\tLoss: 1.415050\n",
      "tensor(1.4861, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.6\tLoss: 1.486060\n",
      "tensor(1.4003, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.8\tLoss: 1.400254\n",
      "\n",
      "Train Epoch: 175\tAttack_Accuracy: 10800/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 175\tmaintain_Accuracy: 9574/12800 (75%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 175\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 175\tmaintain_Accuracy: 2283/2993 (76%)\n",
      "\n",
      "tensor(1.3859, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.0\tLoss: 1.385889\n",
      "tensor(1.3948, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.2\tLoss: 1.394835\n",
      "tensor(1.3999, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.4\tLoss: 1.399912\n",
      "tensor(1.4756, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.6\tLoss: 1.475622\n",
      "tensor(1.4544, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.8\tLoss: 1.454435\n",
      "\n",
      "Test Epoch: 176\tAttack_Accuracy: 326/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 176\tmaintain_Accuracy: 2293/2993 (77%)\n",
      "\n",
      "tensor(1.4120, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.0\tLoss: 1.412049\n",
      "tensor(1.3508, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.2\tLoss: 1.350849\n",
      "tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.4\tLoss: 1.342407\n",
      "tensor(1.4699, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.6\tLoss: 1.469907\n",
      "tensor(1.4885, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.8\tLoss: 1.488473\n",
      "\n",
      "Test Epoch: 177\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 177\tmaintain_Accuracy: 2289/2993 (76%)\n",
      "\n",
      "tensor(1.3796, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.0\tLoss: 1.379595\n",
      "tensor(1.3889, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.2\tLoss: 1.388868\n",
      "tensor(1.5146, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.4\tLoss: 1.514617\n",
      "tensor(1.4179, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.6\tLoss: 1.417881\n",
      "tensor(1.3478, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.8\tLoss: 1.347841\n",
      "\n",
      "Test Epoch: 178\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 178\tmaintain_Accuracy: 2277/2993 (76%)\n",
      "\n",
      "tensor(1.4124, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.0\tLoss: 1.412402\n",
      "tensor(1.2934, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.2\tLoss: 1.293410\n",
      "tensor(1.4520, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.4\tLoss: 1.452026\n",
      "tensor(1.3305, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.6\tLoss: 1.330532\n",
      "tensor(1.5450, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.8\tLoss: 1.545041\n",
      "\n",
      "Test Epoch: 179\tAttack_Accuracy: 323/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 179\tmaintain_Accuracy: 2294/2993 (77%)\n",
      "\n",
      "tensor(1.3411, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.0\tLoss: 1.341115\n",
      "tensor(1.3931, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.2\tLoss: 1.393147\n",
      "tensor(1.4524, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.4\tLoss: 1.452439\n",
      "tensor(1.4590, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.6\tLoss: 1.458952\n",
      "tensor(1.4122, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.8\tLoss: 1.412230\n",
      "\n",
      "Train Epoch: 180\tAttack_Accuracy: 10672/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 180\tmaintain_Accuracy: 9663/12800 (75%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 180\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 180\tmaintain_Accuracy: 2275/2993 (76%)\n",
      "\n",
      "tensor(1.4644, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.0\tLoss: 1.464433\n",
      "tensor(1.4202, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.2\tLoss: 1.420214\n",
      "tensor(1.2946, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.4\tLoss: 1.294610\n",
      "tensor(1.3880, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.6\tLoss: 1.388021\n",
      "tensor(1.4015, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.8\tLoss: 1.401498\n",
      "\n",
      "Test Epoch: 181\tAttack_Accuracy: 322/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 181\tmaintain_Accuracy: 2302/2993 (77%)\n",
      "\n",
      "tensor(1.2828, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.0\tLoss: 1.282792\n",
      "tensor(1.4243, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.2\tLoss: 1.424303\n",
      "tensor(1.4494, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.4\tLoss: 1.449380\n",
      "tensor(1.3411, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.6\tLoss: 1.341149\n",
      "tensor(1.4203, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.8\tLoss: 1.420304\n",
      "\n",
      "Test Epoch: 182\tAttack_Accuracy: 328/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 182\tmaintain_Accuracy: 2279/2993 (76%)\n",
      "\n",
      "tensor(1.3805, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.0\tLoss: 1.380475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4639, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.2\tLoss: 1.463894\n",
      "tensor(1.3263, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.4\tLoss: 1.326304\n",
      "tensor(1.4336, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.6\tLoss: 1.433644\n",
      "tensor(1.3100, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.8\tLoss: 1.309966\n",
      "\n",
      "Test Epoch: 183\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 183\tmaintain_Accuracy: 2291/2993 (77%)\n",
      "\n",
      "tensor(1.3336, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.0\tLoss: 1.333617\n",
      "tensor(1.3063, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.2\tLoss: 1.306256\n",
      "tensor(1.3319, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.4\tLoss: 1.331931\n",
      "tensor(1.3490, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.6\tLoss: 1.348979\n",
      "tensor(1.3171, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.8\tLoss: 1.317070\n",
      "\n",
      "Test Epoch: 184\tAttack_Accuracy: 317/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 184\tmaintain_Accuracy: 2315/2993 (77%)\n",
      "\n",
      "tensor(1.2706, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.0\tLoss: 1.270560\n",
      "tensor(1.2448, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.2\tLoss: 1.244810\n",
      "tensor(1.4323, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.4\tLoss: 1.432314\n",
      "tensor(1.3233, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.6\tLoss: 1.323301\n",
      "tensor(1.2456, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.8\tLoss: 1.245575\n",
      "\n",
      "Train Epoch: 185\tAttack_Accuracy: 10639/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 185\tmaintain_Accuracy: 9682/12800 (76%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 185\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 185\tmaintain_Accuracy: 2284/2993 (76%)\n",
      "\n",
      "tensor(1.3830, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.0\tLoss: 1.382959\n",
      "tensor(1.3201, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.2\tLoss: 1.320122\n",
      "tensor(1.3320, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.4\tLoss: 1.332018\n",
      "tensor(1.3941, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.6\tLoss: 1.394120\n",
      "tensor(1.3770, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.8\tLoss: 1.377019\n",
      "\n",
      "Test Epoch: 186\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 186\tmaintain_Accuracy: 2293/2993 (77%)\n",
      "\n",
      "tensor(1.4495, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.0\tLoss: 1.449459\n",
      "tensor(1.3979, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.2\tLoss: 1.397945\n",
      "tensor(1.3099, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.4\tLoss: 1.309885\n",
      "tensor(1.2869, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.6\tLoss: 1.286944\n",
      "tensor(1.4914, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.8\tLoss: 1.491426\n",
      "\n",
      "Test Epoch: 187\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 187\tmaintain_Accuracy: 2318/2993 (77%)\n",
      "\n",
      "tensor(1.3110, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.0\tLoss: 1.310985\n",
      "tensor(1.5495, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.2\tLoss: 1.549487\n",
      "tensor(1.4485, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.4\tLoss: 1.448483\n",
      "tensor(1.5140, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.6\tLoss: 1.513997\n",
      "tensor(1.3219, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.8\tLoss: 1.321854\n",
      "\n",
      "Test Epoch: 188\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 188\tmaintain_Accuracy: 2272/2993 (76%)\n",
      "\n",
      "tensor(1.4614, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.0\tLoss: 1.461441\n",
      "tensor(1.4419, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.2\tLoss: 1.441861\n",
      "tensor(1.4220, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.4\tLoss: 1.422049\n",
      "tensor(1.4741, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.6\tLoss: 1.474102\n",
      "tensor(1.4780, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.8\tLoss: 1.478042\n",
      "\n",
      "Test Epoch: 189\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 189\tmaintain_Accuracy: 2305/2993 (77%)\n",
      "\n",
      "tensor(1.5766, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.0\tLoss: 1.576626\n",
      "tensor(1.4480, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.2\tLoss: 1.447953\n",
      "tensor(1.4230, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.4\tLoss: 1.422981\n",
      "tensor(1.2905, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.6\tLoss: 1.290499\n",
      "tensor(1.4359, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.8\tLoss: 1.435904\n",
      "\n",
      "Train Epoch: 190\tAttack_Accuracy: 10728/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 190\tmaintain_Accuracy: 9665/12800 (76%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 190\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 190\tmaintain_Accuracy: 2286/2993 (76%)\n",
      "\n",
      "tensor(1.3393, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.0\tLoss: 1.339300\n",
      "tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.4007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.2\tLoss: 1.297923\n",
      "tensor(1.4015, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.4\tLoss: 1.401465\n",
      "tensor(1.3649, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.6\tLoss: 1.364892\n",
      "tensor(1.3064, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.8\tLoss: 1.306356\n",
      "\n",
      "Test Epoch: 191\tAttack_Accuracy: 324/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 191\tmaintain_Accuracy: 2314/2993 (77%)\n",
      "\n",
      "tensor(1.3599, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.0\tLoss: 1.359890\n",
      "tensor(1.4218, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.2\tLoss: 1.421776\n",
      "tensor(1.4097, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.4\tLoss: 1.409703\n",
      "tensor(1.4332, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.6\tLoss: 1.433166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5059, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.8\tLoss: 1.505915\n",
      "\n",
      "Test Epoch: 192\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 192\tmaintain_Accuracy: 2285/2993 (76%)\n",
      "\n",
      "tensor(1.4371, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.0\tLoss: 1.437145\n",
      "tensor(1.5084, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.2\tLoss: 1.508368\n",
      "tensor(1.4002, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.4\tLoss: 1.400213\n",
      "tensor(1.4133, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.6\tLoss: 1.413285\n",
      "tensor(1.2832, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.8\tLoss: 1.283206\n",
      "\n",
      "Test Epoch: 193\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 193\tmaintain_Accuracy: 2288/2993 (76%)\n",
      "\n",
      "tensor(1.4486, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.0\tLoss: 1.448553\n",
      "tensor(1.3510, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.2\tLoss: 1.351036\n",
      "tensor(1.3202, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.4\tLoss: 1.320244\n",
      "tensor(1.4341, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.6\tLoss: 1.434110\n",
      "tensor(1.3983, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.8\tLoss: 1.398334\n",
      "\n",
      "Test Epoch: 194\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 194\tmaintain_Accuracy: 2318/2993 (77%)\n",
      "\n",
      "tensor(1.3091, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.0\tLoss: 1.309072\n",
      "tensor(1.3675, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.2\tLoss: 1.367502\n",
      "tensor(1.3321, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.4\tLoss: 1.332064\n",
      "tensor(1.3146, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.6\tLoss: 1.314635\n",
      "tensor(1.3223, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.8\tLoss: 1.322274\n",
      "\n",
      "Train Epoch: 195\tAttack_Accuracy: 10658/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 195\tmaintain_Accuracy: 9802/12800 (77%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 195\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 195\tmaintain_Accuracy: 2295/2993 (77%)\n",
      "\n",
      "tensor(1.4028, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.0\tLoss: 1.402832\n",
      "tensor(1.3006, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.2\tLoss: 1.300609\n",
      "tensor(1.2851, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.4\tLoss: 1.285086\n",
      "tensor(1.3987, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.6\tLoss: 1.398653\n",
      "tensor(1.2965, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.8\tLoss: 1.296494\n",
      "\n",
      "Test Epoch: 196\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 196\tmaintain_Accuracy: 2320/2993 (78%)\n",
      "\n",
      "tensor(1.3970, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.0\tLoss: 1.397031\n",
      "tensor(1.4799, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.2\tLoss: 1.479901\n",
      "tensor(1.3018, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.4\tLoss: 1.301798\n",
      "tensor(1.2621, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.6\tLoss: 1.262127\n",
      "tensor(1.3529, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.8\tLoss: 1.352855\n",
      "\n",
      "Test Epoch: 197\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 197\tmaintain_Accuracy: 2295/2993 (77%)\n",
      "\n",
      "tensor(1.3389, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.0\tLoss: 1.338905\n",
      "tensor(1.4206, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.2\tLoss: 1.420615\n",
      "tensor(1.2788, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.4\tLoss: 1.278818\n",
      "tensor(1.3658, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.6\tLoss: 1.365794\n",
      "tensor(1.2569, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.8\tLoss: 1.256884\n",
      "\n",
      "Test Epoch: 198\tAttack_Accuracy: 327/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 198\tmaintain_Accuracy: 2325/2993 (78%)\n",
      "\n",
      "tensor(1.3615, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.0\tLoss: 1.361534\n",
      "tensor(1.3635, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.2\tLoss: 1.363455\n",
      "tensor(1.4165, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.4\tLoss: 1.416458\n",
      "tensor(1.3103, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.6\tLoss: 1.310262\n",
      "tensor(1.5179, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.8\tLoss: 1.517932\n",
      "\n",
      "Test Epoch: 199\tAttack_Accuracy: 323/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 199\tmaintain_Accuracy: 2352/2993 (79%)\n",
      "\n",
      "tensor(1.3341, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.0\tLoss: 1.334127\n",
      "tensor(1.3102, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.2\tLoss: 1.310246\n",
      "tensor(1.3750, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.4\tLoss: 1.375008\n",
      "tensor(1.4596, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.6\tLoss: 1.459599\n",
      "tensor(1.3174, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.8\tLoss: 1.317398\n",
      "\n",
      "Train Epoch: 200\tAttack_Accuracy: 10595/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 200\tmaintain_Accuracy: 9799/12800 (77%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 200\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 200\tmaintain_Accuracy: 2301/2993 (77%)\n",
      "\n",
      "tensor(1.4415, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.0\tLoss: 1.441495\n",
      "tensor(1.3772, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.2\tLoss: 1.377208\n",
      "tensor(1.4151, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.4\tLoss: 1.415068\n",
      "tensor(1.4222, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.6\tLoss: 1.422246\n",
      "tensor(1.3025, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.8\tLoss: 1.302502\n",
      "\n",
      "Test Epoch: 201\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 201\tmaintain_Accuracy: 2319/2993 (77%)\n",
      "\n",
      "tensor(1.3699, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.0\tLoss: 1.369853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5051, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.2\tLoss: 1.505150\n",
      "tensor(1.3232, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.4\tLoss: 1.323216\n",
      "tensor(1.2676, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.6\tLoss: 1.267583\n",
      "tensor(1.3126, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.8\tLoss: 1.312609\n",
      "\n",
      "Test Epoch: 202\tAttack_Accuracy: 324/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 202\tmaintain_Accuracy: 2339/2993 (78%)\n",
      "\n",
      "tensor(1.3436, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.0\tLoss: 1.343554\n",
      "tensor(1.3309, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.2\tLoss: 1.330949\n",
      "tensor(1.3379, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.4\tLoss: 1.337868\n",
      "tensor(1.2437, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.6\tLoss: 1.243740\n",
      "tensor(1.3081, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.8\tLoss: 1.308124\n",
      "\n",
      "Test Epoch: 203\tAttack_Accuracy: 326/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 203\tmaintain_Accuracy: 2317/2993 (77%)\n",
      "\n",
      "tensor(1.3410, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.0\tLoss: 1.341019\n",
      "tensor(1.2743, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.2\tLoss: 1.274317\n",
      "tensor(1.3980, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.4\tLoss: 1.397995\n",
      "tensor(1.4166, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.6\tLoss: 1.416640\n",
      "tensor(1.1915, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.8\tLoss: 1.191499\n",
      "\n",
      "Test Epoch: 204\tAttack_Accuracy: 326/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 204\tmaintain_Accuracy: 2323/2993 (78%)\n",
      "\n",
      "tensor(1.3397, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.0\tLoss: 1.339737\n",
      "tensor(1.3150, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.2\tLoss: 1.314999\n",
      "tensor(1.2570, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.4\tLoss: 1.256990\n",
      "tensor(1.4149, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.6\tLoss: 1.414925\n",
      "tensor(1.4284, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.8\tLoss: 1.428381\n",
      "\n",
      "Train Epoch: 205\tAttack_Accuracy: 10670/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 205\tmaintain_Accuracy: 9824/12800 (77%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 205\tAttack_Accuracy: 321/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 205\tmaintain_Accuracy: 2344/2993 (78%)\n",
      "\n",
      "tensor(1.3764, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.0\tLoss: 1.376394\n",
      "tensor(1.4012, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.2\tLoss: 1.401167\n",
      "tensor(1.3706, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.4\tLoss: 1.370616\n",
      "tensor(1.2673, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.6\tLoss: 1.267254\n",
      "tensor(1.4428, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.8\tLoss: 1.442809\n",
      "\n",
      "Test Epoch: 206\tAttack_Accuracy: 323/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 206\tmaintain_Accuracy: 2341/2993 (78%)\n",
      "\n",
      "tensor(1.3952, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.0\tLoss: 1.395247\n",
      "tensor(1.3592, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.2\tLoss: 1.359210\n",
      "tensor(1.4195, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.4\tLoss: 1.419456\n",
      "tensor(1.2669, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.6\tLoss: 1.266926\n",
      "tensor(1.2969, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.8\tLoss: 1.296945\n",
      "\n",
      "Test Epoch: 207\tAttack_Accuracy: 326/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 207\tmaintain_Accuracy: 2327/2993 (78%)\n",
      "\n",
      "tensor(1.2699, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.0\tLoss: 1.269939\n",
      "tensor(1.3791, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.2\tLoss: 1.379099\n",
      "tensor(1.2679, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.4\tLoss: 1.267895\n",
      "tensor(1.4686, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.6\tLoss: 1.468563\n",
      "tensor(1.3143, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.8\tLoss: 1.314292\n",
      "\n",
      "Test Epoch: 208\tAttack_Accuracy: 327/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 208\tmaintain_Accuracy: 2332/2993 (78%)\n",
      "\n",
      "tensor(1.3841, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.0\tLoss: 1.384064\n",
      "tensor(1.4849, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.2\tLoss: 1.484945\n",
      "tensor(1.2993, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.4\tLoss: 1.299338\n",
      "tensor(1.2278, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.6\tLoss: 1.227832\n",
      "tensor(1.4246, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.8\tLoss: 1.424627\n",
      "\n",
      "Test Epoch: 209\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 209\tmaintain_Accuracy: 2333/2993 (78%)\n",
      "\n",
      "tensor(1.2842, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.0\tLoss: 1.284241\n",
      "tensor(1.3573, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.2\tLoss: 1.357302\n",
      "tensor(1.2747, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.4\tLoss: 1.274656\n",
      "tensor(1.2603, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.6\tLoss: 1.260345\n",
      "tensor(1.3808, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.8\tLoss: 1.380750\n",
      "\n",
      "Train Epoch: 210\tAttack_Accuracy: 10768/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 210\tmaintain_Accuracy: 9721/12800 (76%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 210\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 210\tmaintain_Accuracy: 2339/2993 (78%)\n",
      "\n",
      "tensor(1.2863, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.0\tLoss: 1.286273\n",
      "tensor(1.3454, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.2\tLoss: 1.345448\n",
      "tensor(1.3807, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.4\tLoss: 1.380734\n",
      "tensor(1.4548, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.6\tLoss: 1.454832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2716, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.8\tLoss: 1.271572\n",
      "\n",
      "Test Epoch: 211\tAttack_Accuracy: 321/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 211\tmaintain_Accuracy: 2362/2993 (79%)\n",
      "\n",
      "tensor(1.3636, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.0\tLoss: 1.363559\n",
      "tensor(1.2054, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.2\tLoss: 1.205390\n",
      "tensor(1.3087, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.4\tLoss: 1.308738\n",
      "tensor(1.2228, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.6\tLoss: 1.222834\n",
      "tensor(1.3686, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.8\tLoss: 1.368581\n",
      "\n",
      "Test Epoch: 212\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 212\tmaintain_Accuracy: 2317/2993 (77%)\n",
      "\n",
      "tensor(1.1895, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.0\tLoss: 1.189509\n",
      "tensor(1.3793, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.2\tLoss: 1.379334\n",
      "tensor(1.3623, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.4\tLoss: 1.362275\n",
      "tensor(1.3332, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.6\tLoss: 1.333184\n",
      "tensor(1.3093, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.8\tLoss: 1.309339\n",
      "\n",
      "Test Epoch: 213\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 213\tmaintain_Accuracy: 2336/2993 (78%)\n",
      "\n",
      "tensor(1.4696, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.0\tLoss: 1.469648\n",
      "tensor(1.3851, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.2\tLoss: 1.385058\n",
      "tensor(1.1985, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.4\tLoss: 1.198495\n",
      "tensor(1.3085, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.6\tLoss: 1.308488\n",
      "tensor(1.3023, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.8\tLoss: 1.302253\n",
      "\n",
      "Test Epoch: 214\tAttack_Accuracy: 325/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 214\tmaintain_Accuracy: 2351/2993 (79%)\n",
      "\n",
      "tensor(1.3577, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.0\tLoss: 1.357724\n",
      "tensor(1.4289, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.2\tLoss: 1.428947\n",
      "tensor(1.2613, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.4\tLoss: 1.261259\n",
      "tensor(1.2618, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.6\tLoss: 1.261814\n",
      "tensor(1.3314, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.8\tLoss: 1.331370\n",
      "\n",
      "Train Epoch: 215\tAttack_Accuracy: 10615/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 215\tmaintain_Accuracy: 9832/12800 (77%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 215\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 215\tmaintain_Accuracy: 2337/2993 (78%)\n",
      "\n",
      "tensor(1.3279, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.0\tLoss: 1.327861\n",
      "tensor(1.3202, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.2\tLoss: 1.320168\n",
      "tensor(1.1768, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.4\tLoss: 1.176779\n",
      "tensor(1.1970, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.6\tLoss: 1.196950\n",
      "tensor(1.1636, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.8\tLoss: 1.163579\n",
      "\n",
      "Test Epoch: 216\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 216\tmaintain_Accuracy: 2334/2993 (78%)\n",
      "\n",
      "tensor(1.2445, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.0\tLoss: 1.244489\n",
      "tensor(1.3322, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.2\tLoss: 1.332169\n",
      "tensor(1.2496, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.4\tLoss: 1.249617\n",
      "tensor(1.2545, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.6\tLoss: 1.254518\n",
      "tensor(1.3032, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.8\tLoss: 1.303183\n",
      "\n",
      "Test Epoch: 217\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 217\tmaintain_Accuracy: 2332/2993 (78%)\n",
      "\n",
      "tensor(1.3383, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.0\tLoss: 1.338263\n",
      "tensor(1.3392, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.2\tLoss: 1.339154\n",
      "tensor(1.3500, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.4\tLoss: 1.350032\n",
      "tensor(1.4174, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.6\tLoss: 1.417352\n",
      "tensor(1.2583, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.8\tLoss: 1.258271\n",
      "\n",
      "Test Epoch: 218\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 218\tmaintain_Accuracy: 2351/2993 (79%)\n",
      "\n",
      "tensor(1.3384, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.0\tLoss: 1.338445\n",
      "tensor(1.3994, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.2\tLoss: 1.399419\n",
      "tensor(1.3122, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.4\tLoss: 1.312183\n",
      "tensor(1.4072, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.6\tLoss: 1.407175\n",
      "tensor(1.3821, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.8\tLoss: 1.382060\n",
      "\n",
      "Test Epoch: 219\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 219\tmaintain_Accuracy: 2343/2993 (78%)\n",
      "\n",
      "tensor(1.3558, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.0\tLoss: 1.355781\n",
      "tensor(1.2312, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.2\tLoss: 1.231232\n",
      "tensor(1.2254, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.4\tLoss: 1.225376\n",
      "tensor(1.2185, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.6\tLoss: 1.218483\n",
      "tensor(1.2937, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.8\tLoss: 1.293675\n",
      "\n",
      "Train Epoch: 220\tAttack_Accuracy: 10685/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 220\tmaintain_Accuracy: 9959/12800 (78%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 220\tAttack_Accuracy: 327/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 220\tmaintain_Accuracy: 2348/2993 (78%)\n",
      "\n",
      "tensor(1.2371, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.0\tLoss: 1.237051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3595, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.2\tLoss: 1.359484\n",
      "tensor(1.3332, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.4\tLoss: 1.333212\n",
      "tensor(1.2769, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.6\tLoss: 1.276881\n",
      "tensor(1.2818, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.8\tLoss: 1.281759\n",
      "\n",
      "Test Epoch: 221\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 221\tmaintain_Accuracy: 2351/2993 (79%)\n",
      "\n",
      "tensor(1.3310, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.0\tLoss: 1.330969\n",
      "tensor(1.2224, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.2\tLoss: 1.222351\n",
      "tensor(1.4095, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.4\tLoss: 1.409485\n",
      "tensor(1.2979, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.6\tLoss: 1.297938\n",
      "tensor(1.2773, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.8\tLoss: 1.277326\n",
      "\n",
      "Test Epoch: 222\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 222\tmaintain_Accuracy: 2351/2993 (79%)\n",
      "\n",
      "tensor(1.3357, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.0\tLoss: 1.335668\n",
      "tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.2\tLoss: 1.342407\n",
      "tensor(1.2520, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.4\tLoss: 1.251995\n",
      "tensor(1.2491, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.6\tLoss: 1.249081\n",
      "tensor(1.2030, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.8\tLoss: 1.203049\n",
      "\n",
      "Test Epoch: 223\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 223\tmaintain_Accuracy: 2343/2993 (78%)\n",
      "\n",
      "tensor(1.3849, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.0\tLoss: 1.384882\n",
      "tensor(1.3024, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.2\tLoss: 1.302445\n",
      "tensor(1.2379, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.4\tLoss: 1.237881\n",
      "tensor(1.1917, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.6\tLoss: 1.191661\n",
      "tensor(1.1381, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.8\tLoss: 1.138085\n",
      "\n",
      "Test Epoch: 224\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 224\tmaintain_Accuracy: 2343/2993 (78%)\n",
      "\n",
      "tensor(1.1962, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.0\tLoss: 1.196189\n",
      "tensor(1.1582, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.2\tLoss: 1.158236\n",
      "tensor(1.3986, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.4\tLoss: 1.398603\n",
      "tensor(1.2160, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.6\tLoss: 1.215979\n",
      "tensor(1.2437, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.8\tLoss: 1.243651\n",
      "\n",
      "Train Epoch: 225\tAttack_Accuracy: 10676/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 225\tmaintain_Accuracy: 9860/12800 (77%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 225\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 225\tmaintain_Accuracy: 2361/2993 (79%)\n",
      "\n",
      "tensor(1.2899, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.0\tLoss: 1.289873\n",
      "tensor(1.2675, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.2\tLoss: 1.267482\n",
      "tensor(1.4217, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.4\tLoss: 1.421725\n",
      "tensor(1.2975, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.6\tLoss: 1.297523\n",
      "tensor(1.2022, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.8\tLoss: 1.202232\n",
      "\n",
      "Test Epoch: 226\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 226\tmaintain_Accuracy: 2370/2993 (79%)\n",
      "\n",
      "tensor(1.1733, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.0\tLoss: 1.173293\n",
      "tensor(1.3424, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.2\tLoss: 1.342447\n",
      "tensor(1.1520, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.4\tLoss: 1.152036\n",
      "tensor(1.2385, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.6\tLoss: 1.238492\n",
      "tensor(1.4165, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.8\tLoss: 1.416473\n",
      "\n",
      "Test Epoch: 227\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 227\tmaintain_Accuracy: 2360/2993 (79%)\n",
      "\n",
      "tensor(1.2188, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.0\tLoss: 1.218754\n",
      "tensor(1.2666, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.2\tLoss: 1.266577\n",
      "tensor(1.2337, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.4\tLoss: 1.233685\n",
      "tensor(1.1771, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.6\tLoss: 1.177112\n",
      "tensor(1.2727, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.8\tLoss: 1.272735\n",
      "\n",
      "Test Epoch: 228\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 228\tmaintain_Accuracy: 2364/2993 (79%)\n",
      "\n",
      "tensor(1.1275, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.0\tLoss: 1.127531\n",
      "tensor(1.2543, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.2\tLoss: 1.254269\n",
      "tensor(1.2605, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.4\tLoss: 1.260528\n",
      "tensor(1.2152, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.6\tLoss: 1.215179\n",
      "tensor(1.2499, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.8\tLoss: 1.249893\n",
      "\n",
      "Test Epoch: 229\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 229\tmaintain_Accuracy: 2357/2993 (79%)\n",
      "\n",
      "tensor(1.2053, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.0\tLoss: 1.205313\n",
      "tensor(1.2734, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.2\tLoss: 1.273384\n",
      "tensor(1.2298, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.4\tLoss: 1.229831\n",
      "tensor(1.3243, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.6\tLoss: 1.324337\n",
      "tensor(1.3639, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.8\tLoss: 1.363925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 230\tAttack_Accuracy: 10789/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 230\tmaintain_Accuracy: 9911/12800 (77%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 230\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 230\tmaintain_Accuracy: 2361/2993 (79%)\n",
      "\n",
      "tensor(1.3496, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.0\tLoss: 1.349618\n",
      "tensor(1.2346, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.2\tLoss: 1.234606\n",
      "tensor(1.1291, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.4\tLoss: 1.129128\n",
      "tensor(1.2458, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.6\tLoss: 1.245790\n",
      "tensor(1.2499, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.8\tLoss: 1.249888\n",
      "\n",
      "Test Epoch: 231\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 231\tmaintain_Accuracy: 2380/2993 (80%)\n",
      "\n",
      "tensor(1.1568, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.0\tLoss: 1.156793\n",
      "tensor(1.2827, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.2\tLoss: 1.282705\n",
      "tensor(1.2567, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.4\tLoss: 1.256673\n",
      "tensor(1.3542, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.6\tLoss: 1.354200\n",
      "tensor(1.2801, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.8\tLoss: 1.280132\n",
      "\n",
      "Test Epoch: 232\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 232\tmaintain_Accuracy: 2349/2993 (78%)\n",
      "\n",
      "tensor(1.2424, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.0\tLoss: 1.242445\n",
      "tensor(1.2510, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.2\tLoss: 1.250969\n",
      "tensor(1.2379, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.4\tLoss: 1.237947\n",
      "tensor(1.2634, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.6\tLoss: 1.263423\n",
      "tensor(1.2364, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.8\tLoss: 1.236358\n",
      "\n",
      "Test Epoch: 233\tAttack_Accuracy: 321/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 233\tmaintain_Accuracy: 2375/2993 (79%)\n",
      "\n",
      "tensor(1.1818, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.0\tLoss: 1.181844\n",
      "tensor(1.3096, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.2\tLoss: 1.309610\n",
      "tensor(1.1493, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.4\tLoss: 1.149309\n",
      "tensor(1.2148, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.6\tLoss: 1.214763\n",
      "tensor(1.1762, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.8\tLoss: 1.176181\n",
      "\n",
      "Test Epoch: 234\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 234\tmaintain_Accuracy: 2371/2993 (79%)\n",
      "\n",
      "tensor(1.3033, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.0\tLoss: 1.303338\n",
      "tensor(1.3171, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.2\tLoss: 1.317112\n",
      "tensor(1.2598, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.4\tLoss: 1.259816\n",
      "tensor(1.1897, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.6\tLoss: 1.189724\n",
      "tensor(1.2807, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.8\tLoss: 1.280704\n",
      "\n",
      "Train Epoch: 235\tAttack_Accuracy: 10622/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 235\tmaintain_Accuracy: 10026/12800 (78%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 235\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 235\tmaintain_Accuracy: 2320/2993 (78%)\n",
      "\n",
      "tensor(1.1984, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.0\tLoss: 1.198413\n",
      "tensor(1.1767, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.2\tLoss: 1.176711\n",
      "tensor(1.3225, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.4\tLoss: 1.322526\n",
      "tensor(1.1116, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.6\tLoss: 1.111604\n",
      "tensor(1.1698, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.8\tLoss: 1.169796\n",
      "\n",
      "Test Epoch: 236\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 236\tmaintain_Accuracy: 2351/2993 (79%)\n",
      "\n",
      "tensor(1.3042, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.2007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.0\tLoss: 1.304240\n",
      "tensor(1.1198, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.2\tLoss: 1.119838\n",
      "tensor(1.1503, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.4\tLoss: 1.150311\n",
      "tensor(1.2403, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.6\tLoss: 1.240290\n",
      "tensor(1.1154, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.8\tLoss: 1.115407\n",
      "\n",
      "Test Epoch: 237\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 237\tmaintain_Accuracy: 2353/2993 (79%)\n",
      "\n",
      "tensor(1.2656, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.0\tLoss: 1.265640\n",
      "tensor(1.2088, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.2\tLoss: 1.208850\n",
      "tensor(1.2321, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.4\tLoss: 1.232116\n",
      "tensor(1.2260, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.6\tLoss: 1.226003\n",
      "tensor(1.2623, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.8\tLoss: 1.262282\n",
      "\n",
      "Test Epoch: 238\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 238\tmaintain_Accuracy: 2356/2993 (79%)\n",
      "\n",
      "tensor(1.2079, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.0\tLoss: 1.207871\n",
      "tensor(1.2115, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.2\tLoss: 1.211529\n",
      "tensor(1.1607, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.4\tLoss: 1.160702\n",
      "tensor(1.2522, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.6\tLoss: 1.252175\n",
      "tensor(1.1034, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.8\tLoss: 1.103415\n",
      "\n",
      "Test Epoch: 239\tAttack_Accuracy: 318/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 239\tmaintain_Accuracy: 2371/2993 (79%)\n",
      "\n",
      "tensor(1.2198, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.0\tLoss: 1.219792\n",
      "tensor(1.1248, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.2\tLoss: 1.124762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3600, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.4\tLoss: 1.360049\n",
      "tensor(1.1275, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.6\tLoss: 1.127548\n",
      "tensor(1.1964, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.8\tLoss: 1.196366\n",
      "\n",
      "Train Epoch: 240\tAttack_Accuracy: 10577/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 240\tmaintain_Accuracy: 9969/12800 (78%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 240\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 240\tmaintain_Accuracy: 2332/2993 (78%)\n",
      "\n",
      "tensor(1.1833, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.0\tLoss: 1.183347\n",
      "tensor(1.2700, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.2\tLoss: 1.270048\n",
      "tensor(1.2960, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.4\tLoss: 1.296005\n",
      "tensor(1.0939, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.6\tLoss: 1.093920\n",
      "tensor(1.1488, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.8\tLoss: 1.148791\n",
      "\n",
      "Test Epoch: 241\tAttack_Accuracy: 324/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 241\tmaintain_Accuracy: 2371/2993 (79%)\n",
      "\n",
      "tensor(1.1095, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.0\tLoss: 1.109486\n",
      "tensor(1.1822, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.2\tLoss: 1.182240\n",
      "tensor(1.0402, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.4\tLoss: 1.040211\n",
      "tensor(1.1704, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.6\tLoss: 1.170355\n",
      "tensor(1.1786, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.8\tLoss: 1.178600\n",
      "\n",
      "Test Epoch: 242\tAttack_Accuracy: 328/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 242\tmaintain_Accuracy: 2359/2993 (79%)\n",
      "\n",
      "tensor(1.2147, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.0\tLoss: 1.214709\n",
      "tensor(1.1883, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.2\tLoss: 1.188330\n",
      "tensor(1.3246, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.4\tLoss: 1.324582\n",
      "tensor(1.3077, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.6\tLoss: 1.307682\n",
      "tensor(1.1706, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.8\tLoss: 1.170624\n",
      "\n",
      "Test Epoch: 243\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 243\tmaintain_Accuracy: 2346/2993 (78%)\n",
      "\n",
      "tensor(1.2474, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.0\tLoss: 1.247395\n",
      "tensor(1.1569, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.2\tLoss: 1.156938\n",
      "tensor(1.1987, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.4\tLoss: 1.198728\n",
      "tensor(1.2596, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.6\tLoss: 1.259573\n",
      "tensor(1.1926, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.8\tLoss: 1.192592\n",
      "\n",
      "Test Epoch: 244\tAttack_Accuracy: 312/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 244\tmaintain_Accuracy: 2397/2993 (80%)\n",
      "\n",
      "tensor(1.1736, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.0\tLoss: 1.173592\n",
      "tensor(1.1557, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.2\tLoss: 1.155720\n",
      "tensor(1.2506, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.4\tLoss: 1.250644\n",
      "tensor(1.1409, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.6\tLoss: 1.140892\n",
      "tensor(1.3642, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.8\tLoss: 1.364177\n",
      "\n",
      "Train Epoch: 245\tAttack_Accuracy: 10526/12800 (82%)\n",
      "\n",
      "\n",
      "Train Epoch: 245\tmaintain_Accuracy: 10027/12800 (78%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 245\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 245\tmaintain_Accuracy: 2355/2993 (79%)\n",
      "\n",
      "tensor(1.2209, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.0\tLoss: 1.220934\n",
      "tensor(1.3504, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.2\tLoss: 1.350429\n",
      "tensor(1.1993, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.4\tLoss: 1.199347\n",
      "tensor(1.4237, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.6\tLoss: 1.423692\n",
      "tensor(1.3887, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.8\tLoss: 1.388657\n",
      "\n",
      "Test Epoch: 246\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 246\tmaintain_Accuracy: 2369/2993 (79%)\n",
      "\n",
      "tensor(1.2351, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.0\tLoss: 1.235119\n",
      "tensor(1.3201, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.2\tLoss: 1.320071\n",
      "tensor(1.1090, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.4\tLoss: 1.109033\n",
      "tensor(1.2777, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.6\tLoss: 1.277689\n",
      "tensor(1.1449, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.8\tLoss: 1.144923\n",
      "\n",
      "Test Epoch: 247\tAttack_Accuracy: 324/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 247\tmaintain_Accuracy: 2375/2993 (79%)\n",
      "\n",
      "tensor(1.0738, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.0\tLoss: 1.073808\n",
      "tensor(1.1472, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.2\tLoss: 1.147198\n",
      "tensor(1.1222, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.4\tLoss: 1.122196\n",
      "tensor(1.0513, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.6\tLoss: 1.051262\n",
      "tensor(1.2438, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.8\tLoss: 1.243850\n",
      "\n",
      "Test Epoch: 248\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 248\tmaintain_Accuracy: 2364/2993 (79%)\n",
      "\n",
      "tensor(1.2620, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.0\tLoss: 1.261997\n",
      "tensor(1.2473, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.2\tLoss: 1.247324\n",
      "tensor(1.3032, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.4\tLoss: 1.303178\n",
      "tensor(1.0920, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.6\tLoss: 1.091980\n",
      "tensor(1.0838, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.8\tLoss: 1.083791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 249\tAttack_Accuracy: 319/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 249\tmaintain_Accuracy: 2392/2993 (80%)\n",
      "\n",
      "tensor(1.2040, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.0\tLoss: 1.204023\n",
      "tensor(1.1727, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.2\tLoss: 1.172686\n",
      "tensor(1.1761, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.4\tLoss: 1.176108\n",
      "tensor(1.2684, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.6\tLoss: 1.268390\n",
      "tensor(1.1917, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.8\tLoss: 1.191672\n",
      "\n",
      "Train Epoch: 250\tAttack_Accuracy: 10492/12800 (82%)\n",
      "\n",
      "\n",
      "Train Epoch: 250\tmaintain_Accuracy: 10107/12800 (79%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 250\tAttack_Accuracy: 326/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 250\tmaintain_Accuracy: 2376/2993 (79%)\n",
      "\n",
      "tensor(1.1414, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.0\tLoss: 1.141435\n",
      "tensor(1.1715, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.2\tLoss: 1.171472\n",
      "tensor(1.1502, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.4\tLoss: 1.150215\n",
      "tensor(1.2250, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.6\tLoss: 1.224986\n",
      "tensor(1.2043, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.8\tLoss: 1.204268\n",
      "\n",
      "Test Epoch: 251\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 251\tmaintain_Accuracy: 2347/2993 (78%)\n",
      "\n",
      "tensor(1.2636, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.0\tLoss: 1.263571\n",
      "tensor(1.0277, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.2\tLoss: 1.027678\n",
      "tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.4\tLoss: 1.304142\n",
      "tensor(1.1509, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.6\tLoss: 1.150870\n",
      "tensor(1.3335, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.8\tLoss: 1.333504\n",
      "\n",
      "Test Epoch: 252\tAttack_Accuracy: 324/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 252\tmaintain_Accuracy: 2377/2993 (79%)\n",
      "\n",
      "tensor(1.2364, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.0\tLoss: 1.236414\n",
      "tensor(1.1490, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.2\tLoss: 1.148960\n",
      "tensor(1.1626, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.4\tLoss: 1.162623\n",
      "tensor(1.3334, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.6\tLoss: 1.333378\n",
      "tensor(1.1509, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.8\tLoss: 1.150872\n",
      "\n",
      "Test Epoch: 253\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 253\tmaintain_Accuracy: 2365/2993 (79%)\n",
      "\n",
      "tensor(1.2917, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.0\tLoss: 1.291665\n",
      "tensor(1.1535, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.2\tLoss: 1.153546\n",
      "tensor(1.2290, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.4\tLoss: 1.229028\n",
      "tensor(1.2047, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.6\tLoss: 1.204723\n",
      "tensor(1.2356, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.8\tLoss: 1.235636\n",
      "\n",
      "Test Epoch: 254\tAttack_Accuracy: 327/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 254\tmaintain_Accuracy: 2363/2993 (79%)\n",
      "\n",
      "tensor(1.3843, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.0\tLoss: 1.384260\n",
      "tensor(1.1856, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.2\tLoss: 1.185627\n",
      "tensor(1.1918, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.4\tLoss: 1.191815\n",
      "tensor(1.2114, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.6\tLoss: 1.211442\n",
      "tensor(1.3430, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.8\tLoss: 1.342972\n",
      "\n",
      "Train Epoch: 255\tAttack_Accuracy: 10596/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 255\tmaintain_Accuracy: 10075/12800 (79%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 255\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 255\tmaintain_Accuracy: 2375/2993 (79%)\n",
      "\n",
      "tensor(1.2713, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.0\tLoss: 1.271266\n",
      "tensor(1.1895, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.2\tLoss: 1.189470\n",
      "tensor(1.2748, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.4\tLoss: 1.274847\n",
      "tensor(1.2784, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.6\tLoss: 1.278388\n",
      "tensor(1.4331, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.8\tLoss: 1.433125\n",
      "\n",
      "Test Epoch: 256\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 256\tmaintain_Accuracy: 2367/2993 (79%)\n",
      "\n",
      "tensor(1.1699, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.0\tLoss: 1.169946\n",
      "tensor(1.2194, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.2\tLoss: 1.219369\n",
      "tensor(1.2540, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.4\tLoss: 1.254021\n",
      "tensor(1.2506, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.6\tLoss: 1.250634\n",
      "tensor(1.1234, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.8\tLoss: 1.123373\n",
      "\n",
      "Test Epoch: 257\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 257\tmaintain_Accuracy: 2371/2993 (79%)\n",
      "\n",
      "tensor(1.1991, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.0\tLoss: 1.199136\n",
      "tensor(1.3050, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.2\tLoss: 1.305015\n",
      "tensor(1.1521, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.4\tLoss: 1.152071\n",
      "tensor(1.1466, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.6\tLoss: 1.146616\n",
      "tensor(1.1304, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.8\tLoss: 1.130388\n",
      "\n",
      "Test Epoch: 258\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 258\tmaintain_Accuracy: 2371/2993 (79%)\n",
      "\n",
      "tensor(1.2299, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.0\tLoss: 1.229909\n",
      "tensor(1.0670, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.2\tLoss: 1.067018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2874, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.4\tLoss: 1.287393\n",
      "tensor(1.1737, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.6\tLoss: 1.173685\n",
      "tensor(1.1003, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.8\tLoss: 1.100349\n",
      "\n",
      "Test Epoch: 259\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 259\tmaintain_Accuracy: 2361/2993 (79%)\n",
      "\n",
      "tensor(1.1878, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.0\tLoss: 1.187847\n",
      "tensor(1.0189, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.2\tLoss: 1.018914\n",
      "tensor(1.2312, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.4\tLoss: 1.231195\n",
      "tensor(1.1833, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.6\tLoss: 1.183265\n",
      "tensor(1.1101, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.8\tLoss: 1.110144\n",
      "\n",
      "Train Epoch: 260\tAttack_Accuracy: 10629/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 260\tmaintain_Accuracy: 10081/12800 (79%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 260\tAttack_Accuracy: 324/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 260\tmaintain_Accuracy: 2394/2993 (80%)\n",
      "\n",
      "tensor(1.1423, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.0\tLoss: 1.142286\n",
      "tensor(1.0740, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.2\tLoss: 1.074048\n",
      "tensor(1.2049, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.4\tLoss: 1.204918\n",
      "tensor(1.2016, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.6\tLoss: 1.201579\n",
      "tensor(1.2675, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.8\tLoss: 1.267544\n",
      "\n",
      "Test Epoch: 261\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 261\tmaintain_Accuracy: 2367/2993 (79%)\n",
      "\n",
      "tensor(1.1796, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.0\tLoss: 1.179563\n",
      "tensor(1.0396, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.2\tLoss: 1.039554\n",
      "tensor(1.2190, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.4\tLoss: 1.219026\n",
      "tensor(1.1606, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.6\tLoss: 1.160592\n",
      "tensor(1.1437, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.8\tLoss: 1.143708\n",
      "\n",
      "Test Epoch: 262\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 262\tmaintain_Accuracy: 2383/2993 (80%)\n",
      "\n",
      "tensor(1.1883, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.0\tLoss: 1.188342\n",
      "tensor(1.2616, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.2\tLoss: 1.261632\n",
      "tensor(1.1905, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.4\tLoss: 1.190458\n",
      "tensor(1.0918, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.6\tLoss: 1.091813\n",
      "tensor(1.2157, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.8\tLoss: 1.215657\n",
      "\n",
      "Test Epoch: 263\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 263\tmaintain_Accuracy: 2392/2993 (80%)\n",
      "\n",
      "tensor(1.2211, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.0\tLoss: 1.221105\n",
      "tensor(1.2587, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.2\tLoss: 1.258747\n",
      "tensor(1.1684, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.4\tLoss: 1.168442\n",
      "tensor(1.1370, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.6\tLoss: 1.136983\n",
      "tensor(1.1728, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.8\tLoss: 1.172765\n",
      "\n",
      "Test Epoch: 264\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 264\tmaintain_Accuracy: 2379/2993 (79%)\n",
      "\n",
      "tensor(1.2814, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.0\tLoss: 1.281392\n",
      "tensor(1.1650, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.2\tLoss: 1.165020\n",
      "tensor(1.2928, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.4\tLoss: 1.292775\n",
      "tensor(1.1736, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.6\tLoss: 1.173586\n",
      "tensor(1.1283, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.8\tLoss: 1.128342\n",
      "\n",
      "Train Epoch: 265\tAttack_Accuracy: 10567/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 265\tmaintain_Accuracy: 9978/12800 (78%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 265\tAttack_Accuracy: 323/412 (78%)\n",
      "\n",
      "\n",
      "Test Epoch: 265\tmaintain_Accuracy: 2400/2993 (80%)\n",
      "\n",
      "tensor(1.2046, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.0\tLoss: 1.204569\n",
      "tensor(1.1995, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.2\tLoss: 1.199452\n",
      "tensor(1.2616, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.4\tLoss: 1.261617\n",
      "tensor(1.1390, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.6\tLoss: 1.138969\n",
      "tensor(1.0594, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.8\tLoss: 1.059391\n",
      "\n",
      "Test Epoch: 266\tAttack_Accuracy: 328/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 266\tmaintain_Accuracy: 2375/2993 (79%)\n",
      "\n",
      "tensor(1.3291, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.0\tLoss: 1.329076\n",
      "tensor(1.1395, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.2\tLoss: 1.139514\n",
      "tensor(1.3394, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.4\tLoss: 1.339384\n",
      "tensor(1.3884, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.6\tLoss: 1.388350\n",
      "tensor(1.2143, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.8\tLoss: 1.214305\n",
      "\n",
      "Test Epoch: 267\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 267\tmaintain_Accuracy: 2390/2993 (80%)\n",
      "\n",
      "tensor(1.3107, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.0\tLoss: 1.310741\n",
      "tensor(1.1817, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.2\tLoss: 1.181682\n",
      "tensor(1.1679, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.4\tLoss: 1.167910\n",
      "tensor(1.1091, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.6\tLoss: 1.109122\n",
      "tensor(1.0606, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.8\tLoss: 1.060603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 268\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 268\tmaintain_Accuracy: 2389/2993 (80%)\n",
      "\n",
      "tensor(1.1435, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.0\tLoss: 1.143547\n",
      "tensor(1.1736, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.2\tLoss: 1.173604\n",
      "tensor(1.2262, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.4\tLoss: 1.226218\n",
      "tensor(1.2263, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.6\tLoss: 1.226317\n",
      "tensor(1.0987, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.8\tLoss: 1.098672\n",
      "\n",
      "Test Epoch: 269\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 269\tmaintain_Accuracy: 2379/2993 (79%)\n",
      "\n",
      "tensor(1.1441, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.0\tLoss: 1.144078\n",
      "tensor(1.1373, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.2\tLoss: 1.137266\n",
      "tensor(1.2911, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.4\tLoss: 1.291092\n",
      "tensor(1.2830, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.6\tLoss: 1.282951\n",
      "tensor(1.0512, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.8\tLoss: 1.051178\n",
      "\n",
      "Train Epoch: 270\tAttack_Accuracy: 10718/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 270\tmaintain_Accuracy: 9980/12800 (78%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 270\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 270\tmaintain_Accuracy: 2394/2993 (80%)\n",
      "\n",
      "tensor(1.1303, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.0\tLoss: 1.130272\n",
      "tensor(1.1010, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.2\tLoss: 1.101025\n",
      "tensor(1.1271, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.4\tLoss: 1.127143\n",
      "tensor(1.2865, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.6\tLoss: 1.286471\n",
      "tensor(1.1931, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.8\tLoss: 1.193096\n",
      "\n",
      "Test Epoch: 271\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 271\tmaintain_Accuracy: 2388/2993 (80%)\n",
      "\n",
      "tensor(1.4011, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.0\tLoss: 1.401144\n",
      "tensor(1.2249, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.2\tLoss: 1.224914\n",
      "tensor(1.2685, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.4\tLoss: 1.268538\n",
      "tensor(1.2356, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.6\tLoss: 1.235633\n",
      "tensor(1.0445, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.8\tLoss: 1.044475\n",
      "\n",
      "Test Epoch: 272\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 272\tmaintain_Accuracy: 2388/2993 (80%)\n",
      "\n",
      "tensor(1.1730, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.0\tLoss: 1.173041\n",
      "tensor(1.1560, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.2\tLoss: 1.156009\n",
      "tensor(1.1940, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.4\tLoss: 1.193955\n",
      "tensor(1.1945, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.6\tLoss: 1.194498\n",
      "tensor(1.1523, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.8\tLoss: 1.152308\n",
      "\n",
      "Test Epoch: 273\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 273\tmaintain_Accuracy: 2387/2993 (80%)\n",
      "\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.0\tLoss: 1.125434\n",
      "tensor(1.0636, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.2\tLoss: 1.063629\n",
      "tensor(1.2026, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.4\tLoss: 1.202558\n",
      "tensor(1.1957, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.6\tLoss: 1.195733\n",
      "tensor(1.0425, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.8\tLoss: 1.042493\n",
      "\n",
      "Test Epoch: 274\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 274\tmaintain_Accuracy: 2388/2993 (80%)\n",
      "\n",
      "tensor(0.9949, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.0\tLoss: 0.994891\n",
      "tensor(1.1596, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.2\tLoss: 1.159601\n",
      "tensor(1.2130, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.4\tLoss: 1.213045\n",
      "tensor(1.0869, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.6\tLoss: 1.086891\n",
      "tensor(1.1586, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.8\tLoss: 1.158606\n",
      "\n",
      "Train Epoch: 275\tAttack_Accuracy: 10563/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 275\tmaintain_Accuracy: 10058/12800 (79%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 275\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 275\tmaintain_Accuracy: 2391/2993 (80%)\n",
      "\n",
      "tensor(1.2654, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.0\tLoss: 1.265377\n",
      "tensor(1.1707, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.2\tLoss: 1.170655\n",
      "tensor(1.1285, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.4\tLoss: 1.128501\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.6\tLoss: 1.123977\n",
      "tensor(1.0381, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.8\tLoss: 1.038059\n",
      "\n",
      "Test Epoch: 276\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 276\tmaintain_Accuracy: 2391/2993 (80%)\n",
      "\n",
      "tensor(1.0706, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.0\tLoss: 1.070563\n",
      "tensor(1.1611, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.2\tLoss: 1.161149\n",
      "tensor(1.3557, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.4\tLoss: 1.355675\n",
      "tensor(1.1964, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.6\tLoss: 1.196445\n",
      "tensor(1.1750, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.8\tLoss: 1.175010\n",
      "\n",
      "Test Epoch: 277\tAttack_Accuracy: 327/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 277\tmaintain_Accuracy: 2413/2993 (81%)\n",
      "\n",
      "tensor(1.2814, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.0\tLoss: 1.281416\n",
      "tensor(1.1582, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.2\tLoss: 1.158236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2486, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.4\tLoss: 1.248632\n",
      "tensor(1.2492, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.6\tLoss: 1.249230\n",
      "tensor(1.1992, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.8\tLoss: 1.199177\n",
      "\n",
      "Test Epoch: 278\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 278\tmaintain_Accuracy: 2376/2993 (79%)\n",
      "\n",
      "tensor(1.1851, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.0\tLoss: 1.185094\n",
      "tensor(1.1931, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.2\tLoss: 1.193131\n",
      "tensor(1.1872, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.4\tLoss: 1.187242\n",
      "tensor(1.0667, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.6\tLoss: 1.066691\n",
      "tensor(1.2508, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.8\tLoss: 1.250846\n",
      "\n",
      "Test Epoch: 279\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 279\tmaintain_Accuracy: 2385/2993 (80%)\n",
      "\n",
      "tensor(1.1773, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.0\tLoss: 1.177295\n",
      "tensor(1.2399, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.2\tLoss: 1.239938\n",
      "tensor(1.2515, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.4\tLoss: 1.251527\n",
      "tensor(1.1199, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.6\tLoss: 1.119910\n",
      "tensor(1.1911, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.8\tLoss: 1.191116\n",
      "\n",
      "Train Epoch: 280\tAttack_Accuracy: 10575/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 280\tmaintain_Accuracy: 10118/12800 (79%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 280\tAttack_Accuracy: 324/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 280\tmaintain_Accuracy: 2399/2993 (80%)\n",
      "\n",
      "tensor(1.1480, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.0\tLoss: 1.147962\n",
      "tensor(1.1892, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.2\tLoss: 1.189232\n",
      "tensor(1.1793, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.4\tLoss: 1.179260\n",
      "tensor(1.0752, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.6\tLoss: 1.075223\n",
      "tensor(1.2462, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.8\tLoss: 1.246186\n",
      "\n",
      "Test Epoch: 281\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 281\tmaintain_Accuracy: 2396/2993 (80%)\n",
      "\n",
      "tensor(1.2317, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.0\tLoss: 1.231666\n",
      "tensor(1.0779, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.2\tLoss: 1.077913\n",
      "tensor(1.1984, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.4\tLoss: 1.198415\n",
      "tensor(1.1430, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.6\tLoss: 1.143048\n",
      "tensor(1.1638, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.8\tLoss: 1.163836\n",
      "\n",
      "Test Epoch: 282\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 282\tmaintain_Accuracy: 2401/2993 (80%)\n",
      "\n",
      "tensor(1.1903, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.0\tLoss: 1.190311\n",
      "tensor(1.1870, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.2\tLoss: 1.186970\n",
      "tensor(1.1238, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.4\tLoss: 1.123800\n",
      "tensor(1.1243, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.6\tLoss: 1.124335\n",
      "tensor(1.1052, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.8\tLoss: 1.105163\n",
      "\n",
      "Test Epoch: 283\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 283\tmaintain_Accuracy: 2397/2993 (80%)\n",
      "\n",
      "tensor(1.2239, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.0\tLoss: 1.223950\n",
      "tensor(1.1207, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.2\tLoss: 1.120733\n",
      "tensor(1.1063, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.4\tLoss: 1.106309\n",
      "tensor(1.2440, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.6\tLoss: 1.244020\n",
      "tensor(1.0600, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.8\tLoss: 1.059975\n",
      "\n",
      "Test Epoch: 284\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 284\tmaintain_Accuracy: 2378/2993 (79%)\n",
      "\n",
      "tensor(1.1486, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.0\tLoss: 1.148633\n",
      "tensor(1.0812, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.2\tLoss: 1.081158\n",
      "tensor(1.2593, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.4\tLoss: 1.259272\n",
      "tensor(1.0960, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.6\tLoss: 1.096034\n",
      "tensor(1.1286, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.8\tLoss: 1.128636\n",
      "\n",
      "Train Epoch: 285\tAttack_Accuracy: 10692/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 285\tmaintain_Accuracy: 10165/12800 (79%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 285\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 285\tmaintain_Accuracy: 2405/2993 (80%)\n",
      "\n",
      "tensor(1.2626, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.0\tLoss: 1.262638\n",
      "tensor(1.1535, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.2\tLoss: 1.153472\n",
      "tensor(1.2200, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.4\tLoss: 1.220035\n",
      "tensor(1.1466, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.6\tLoss: 1.146623\n",
      "tensor(1.1990, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.8\tLoss: 1.199034\n",
      "\n",
      "Test Epoch: 286\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 286\tmaintain_Accuracy: 2383/2993 (80%)\n",
      "\n",
      "tensor(1.1295, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.0\tLoss: 1.129522\n",
      "tensor(1.1804, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.2\tLoss: 1.180413\n",
      "tensor(1.0777, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.4\tLoss: 1.077662\n",
      "tensor(1.1514, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.6\tLoss: 1.151424\n",
      "tensor(1.0077, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.8\tLoss: 1.007695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 287\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 287\tmaintain_Accuracy: 2390/2993 (80%)\n",
      "\n",
      "tensor(1.0470, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.0\tLoss: 1.046976\n",
      "tensor(1.0885, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.2\tLoss: 1.088517\n",
      "tensor(1.2069, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.4\tLoss: 1.206897\n",
      "tensor(1.0982, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.6\tLoss: 1.098249\n",
      "tensor(1.1713, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.8\tLoss: 1.171268\n",
      "\n",
      "Test Epoch: 288\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 288\tmaintain_Accuracy: 2400/2993 (80%)\n",
      "\n",
      "tensor(1.0890, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.0\tLoss: 1.089010\n",
      "tensor(1.1432, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.2\tLoss: 1.143191\n",
      "tensor(1.1493, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.4\tLoss: 1.149305\n",
      "tensor(1.1619, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.6\tLoss: 1.161910\n",
      "tensor(1.1586, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.8\tLoss: 1.158645\n",
      "\n",
      "Test Epoch: 289\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 289\tmaintain_Accuracy: 2384/2993 (80%)\n",
      "\n",
      "tensor(1.1098, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.0\tLoss: 1.109755\n",
      "tensor(1.1293, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.2\tLoss: 1.129289\n",
      "tensor(1.1951, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.4\tLoss: 1.195102\n",
      "tensor(1.0593, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.6\tLoss: 1.059306\n",
      "tensor(1.0810, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.8\tLoss: 1.080980\n",
      "\n",
      "Train Epoch: 290\tAttack_Accuracy: 10749/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 290\tmaintain_Accuracy: 10117/12800 (79%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 290\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 290\tmaintain_Accuracy: 2379/2993 (79%)\n",
      "\n",
      "tensor(1.3011, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.0\tLoss: 1.301051\n",
      "tensor(1.1524, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.2\tLoss: 1.152406\n",
      "tensor(1.3041, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.4\tLoss: 1.304114\n",
      "tensor(1.0515, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.6\tLoss: 1.051471\n",
      "tensor(1.3961, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.8\tLoss: 1.396075\n",
      "\n",
      "Test Epoch: 291\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 291\tmaintain_Accuracy: 2392/2993 (80%)\n",
      "\n",
      "tensor(1.3075, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.0\tLoss: 1.307484\n",
      "tensor(1.0501, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.2\tLoss: 1.050070\n",
      "tensor(1.2205, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.4\tLoss: 1.220464\n",
      "tensor(1.2631, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.6\tLoss: 1.263090\n",
      "tensor(1.1610, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.8\tLoss: 1.161007\n",
      "\n",
      "Test Epoch: 292\tAttack_Accuracy: 326/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 292\tmaintain_Accuracy: 2397/2993 (80%)\n",
      "\n",
      "tensor(1.2227, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.0\tLoss: 1.222718\n",
      "tensor(0.9644, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.2\tLoss: 0.964403\n",
      "tensor(1.1526, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.4\tLoss: 1.152607\n",
      "tensor(1.1520, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.6\tLoss: 1.152008\n",
      "tensor(1.1300, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.8\tLoss: 1.129990\n",
      "\n",
      "Test Epoch: 293\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 293\tmaintain_Accuracy: 2379/2993 (79%)\n",
      "\n",
      "tensor(1.1154, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.0\tLoss: 1.115377\n",
      "tensor(1.0438, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.2\tLoss: 1.043845\n",
      "tensor(1.0264, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.4\tLoss: 1.026420\n",
      "tensor(1.3151, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.6\tLoss: 1.315064\n",
      "tensor(1.3279, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.8\tLoss: 1.327924\n",
      "\n",
      "Test Epoch: 294\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 294\tmaintain_Accuracy: 2378/2993 (79%)\n",
      "\n",
      "tensor(1.2716, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.0\tLoss: 1.271645\n",
      "tensor(1.1167, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.2\tLoss: 1.116749\n",
      "tensor(1.1468, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.4\tLoss: 1.146840\n",
      "tensor(1.1573, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.6\tLoss: 1.157318\n",
      "tensor(1.1122, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.8\tLoss: 1.112245\n",
      "\n",
      "Train Epoch: 295\tAttack_Accuracy: 10626/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 295\tmaintain_Accuracy: 10234/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 295\tAttack_Accuracy: 328/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 295\tmaintain_Accuracy: 2389/2993 (80%)\n",
      "\n",
      "tensor(1.1102, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.0\tLoss: 1.110217\n",
      "tensor(1.1192, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.2\tLoss: 1.119155\n",
      "tensor(1.2283, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.4\tLoss: 1.228264\n",
      "tensor(1.3123, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.6\tLoss: 1.312287\n",
      "tensor(0.9409, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.8\tLoss: 0.940881\n",
      "\n",
      "Test Epoch: 296\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 296\tmaintain_Accuracy: 2385/2993 (80%)\n",
      "\n",
      "tensor(1.0679, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.0\tLoss: 1.067950\n",
      "tensor(1.1881, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.2\tLoss: 1.188124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0707, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.4\tLoss: 1.070710\n",
      "tensor(1.2011, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.6\tLoss: 1.201113\n",
      "tensor(1.1174, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.8\tLoss: 1.117441\n",
      "\n",
      "Test Epoch: 297\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 297\tmaintain_Accuracy: 2415/2993 (81%)\n",
      "\n",
      "tensor(1.1762, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.0\tLoss: 1.176162\n",
      "tensor(1.0740, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.2\tLoss: 1.073996\n",
      "tensor(1.0340, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.4\tLoss: 1.034005\n",
      "tensor(1.2328, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.6\tLoss: 1.232819\n",
      "tensor(1.2045, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.8\tLoss: 1.204544\n",
      "\n",
      "Test Epoch: 298\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 298\tmaintain_Accuracy: 2403/2993 (80%)\n",
      "\n",
      "tensor(1.1002, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.0\tLoss: 1.100223\n",
      "tensor(1.0762, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.2\tLoss: 1.076184\n",
      "tensor(1.2129, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.4\tLoss: 1.212864\n",
      "tensor(1.3361, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.6\tLoss: 1.336116\n",
      "tensor(1.0073, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.8\tLoss: 1.007328\n",
      "\n",
      "Test Epoch: 299\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 299\tmaintain_Accuracy: 2390/2993 (80%)\n",
      "\n",
      "tensor(1.0468, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.0\tLoss: 1.046792\n",
      "tensor(1.0388, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.2\tLoss: 1.038775\n",
      "tensor(1.0914, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.4\tLoss: 1.091412\n",
      "tensor(1.1792, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.6\tLoss: 1.179214\n",
      "tensor(1.0533, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.8\tLoss: 1.053308\n",
      "\n",
      "Train Epoch: 300\tAttack_Accuracy: 10708/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 300\tmaintain_Accuracy: 10119/12800 (79%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 300\tAttack_Accuracy: 328/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 300\tmaintain_Accuracy: 2412/2993 (81%)\n",
      "\n",
      "tensor(1.1355, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.0\tLoss: 1.135453\n",
      "tensor(1.2001, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.2\tLoss: 1.200115\n",
      "tensor(1.2843, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.4\tLoss: 1.284275\n",
      "tensor(1.1597, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.6\tLoss: 1.159746\n",
      "tensor(1.1517, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.8\tLoss: 1.151745\n",
      "\n",
      "Test Epoch: 301\tAttack_Accuracy: 327/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 301\tmaintain_Accuracy: 2422/2993 (81%)\n",
      "\n",
      "tensor(0.9612, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.0\tLoss: 0.961169\n",
      "tensor(1.1628, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.2\tLoss: 1.162826\n",
      "tensor(1.0684, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.4\tLoss: 1.068364\n",
      "tensor(0.9163, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.6\tLoss: 0.916317\n",
      "tensor(1.2325, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.8\tLoss: 1.232476\n",
      "\n",
      "Test Epoch: 302\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 302\tmaintain_Accuracy: 2407/2993 (80%)\n",
      "\n",
      "tensor(1.0317, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.0\tLoss: 1.031656\n",
      "tensor(0.9890, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.2\tLoss: 0.989017\n",
      "tensor(1.2407, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.4\tLoss: 1.240668\n",
      "tensor(1.1621, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.6\tLoss: 1.162133\n",
      "tensor(1.1088, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.8\tLoss: 1.108780\n",
      "\n",
      "Test Epoch: 303\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 303\tmaintain_Accuracy: 2387/2993 (80%)\n",
      "\n",
      "tensor(1.1971, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.0\tLoss: 1.197128\n",
      "tensor(1.0690, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.2\tLoss: 1.069044\n",
      "tensor(1.0917, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.4\tLoss: 1.091707\n",
      "tensor(1.1721, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.6\tLoss: 1.172051\n",
      "tensor(1.0590, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.8\tLoss: 1.058954\n",
      "\n",
      "Test Epoch: 304\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 304\tmaintain_Accuracy: 2408/2993 (80%)\n",
      "\n",
      "tensor(1.1617, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.0\tLoss: 1.161716\n",
      "tensor(1.0477, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.2\tLoss: 1.047701\n",
      "tensor(1.0925, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.4\tLoss: 1.092530\n",
      "tensor(0.9743, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.6\tLoss: 0.974282\n",
      "tensor(1.1569, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.8\tLoss: 1.156902\n",
      "\n",
      "Train Epoch: 305\tAttack_Accuracy: 10732/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 305\tmaintain_Accuracy: 10188/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 305\tAttack_Accuracy: 327/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 305\tmaintain_Accuracy: 2415/2993 (81%)\n",
      "\n",
      "tensor(1.1319, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.0\tLoss: 1.131862\n",
      "tensor(1.0667, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.2\tLoss: 1.066718\n",
      "tensor(1.1172, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.4\tLoss: 1.117245\n",
      "tensor(1.1001, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.6\tLoss: 1.100088\n",
      "tensor(1.0164, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.8\tLoss: 1.016365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 306\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 306\tmaintain_Accuracy: 2392/2993 (80%)\n",
      "\n",
      "tensor(1.1190, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.0\tLoss: 1.119038\n",
      "tensor(1.0593, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.2\tLoss: 1.059307\n",
      "tensor(1.0370, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.4\tLoss: 1.037049\n",
      "tensor(1.0516, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.6\tLoss: 1.051556\n",
      "tensor(1.0434, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.8\tLoss: 1.043381\n",
      "\n",
      "Test Epoch: 307\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 307\tmaintain_Accuracy: 2397/2993 (80%)\n",
      "\n",
      "tensor(1.2158, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.0\tLoss: 1.215761\n",
      "tensor(1.1128, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.2\tLoss: 1.112823\n",
      "tensor(1.1748, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.4\tLoss: 1.174829\n",
      "tensor(1.0739, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.6\tLoss: 1.073862\n",
      "tensor(1.1968, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.8\tLoss: 1.196809\n",
      "\n",
      "Test Epoch: 308\tAttack_Accuracy: 327/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 308\tmaintain_Accuracy: 2403/2993 (80%)\n",
      "\n",
      "tensor(1.2987, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.0\tLoss: 1.298661\n",
      "tensor(1.0442, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.2\tLoss: 1.044208\n",
      "tensor(1.0553, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.4\tLoss: 1.055348\n",
      "tensor(1.1494, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.6\tLoss: 1.149438\n",
      "tensor(1.1843, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.8\tLoss: 1.184327\n",
      "\n",
      "Test Epoch: 309\tAttack_Accuracy: 328/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 309\tmaintain_Accuracy: 2411/2993 (81%)\n",
      "\n",
      "tensor(0.9902, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.0\tLoss: 0.990203\n",
      "tensor(1.0733, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.2\tLoss: 1.073314\n",
      "tensor(1.1324, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.4\tLoss: 1.132411\n",
      "tensor(0.9921, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.6\tLoss: 0.992116\n",
      "tensor(1.0251, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.8\tLoss: 1.025085\n",
      "\n",
      "Train Epoch: 310\tAttack_Accuracy: 10661/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 310\tmaintain_Accuracy: 10231/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 310\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 310\tmaintain_Accuracy: 2397/2993 (80%)\n",
      "\n",
      "tensor(1.1238, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.0\tLoss: 1.123818\n",
      "tensor(1.0501, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.2\tLoss: 1.050110\n",
      "tensor(1.0176, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.4\tLoss: 1.017648\n",
      "tensor(1.0325, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.6\tLoss: 1.032465\n",
      "tensor(1.1939, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.8\tLoss: 1.193947\n",
      "\n",
      "Test Epoch: 311\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 311\tmaintain_Accuracy: 2393/2993 (80%)\n",
      "\n",
      "tensor(1.0713, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.0\tLoss: 1.071347\n",
      "tensor(1.0944, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.2\tLoss: 1.094371\n",
      "tensor(1.0398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.4\tLoss: 1.039793\n",
      "tensor(1.1975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.6\tLoss: 1.197472\n",
      "tensor(1.0201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.8\tLoss: 1.020061\n",
      "\n",
      "Test Epoch: 312\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 312\tmaintain_Accuracy: 2393/2993 (80%)\n",
      "\n",
      "tensor(1.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.0\tLoss: 1.015440\n",
      "tensor(1.1522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.2\tLoss: 1.152153\n",
      "tensor(1.0818, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.4\tLoss: 1.081761\n",
      "tensor(1.2018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.6\tLoss: 1.201811\n",
      "tensor(1.0902, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.8\tLoss: 1.090233\n",
      "\n",
      "Test Epoch: 313\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 313\tmaintain_Accuracy: 2395/2993 (80%)\n",
      "\n",
      "tensor(1.0516, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.0\tLoss: 1.051589\n",
      "tensor(1.1635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.2\tLoss: 1.163459\n",
      "tensor(0.9892, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.4\tLoss: 0.989155\n",
      "tensor(1.2818, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.6\tLoss: 1.281831\n",
      "tensor(1.0621, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.8\tLoss: 1.062052\n",
      "\n",
      "Test Epoch: 314\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 314\tmaintain_Accuracy: 2414/2993 (81%)\n",
      "\n",
      "tensor(1.1111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.0\tLoss: 1.111089\n",
      "tensor(0.9464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.2\tLoss: 0.946443\n",
      "tensor(1.1392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.4\tLoss: 1.139220\n",
      "tensor(1.0489, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.6\tLoss: 1.048913\n",
      "tensor(1.1246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.8\tLoss: 1.124634\n",
      "\n",
      "Train Epoch: 315\tAttack_Accuracy: 10656/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 315\tmaintain_Accuracy: 10241/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 315\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 315\tmaintain_Accuracy: 2417/2993 (81%)\n",
      "\n",
      "tensor(1.0538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.0\tLoss: 1.053767\n",
      "tensor(1.1634, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.2\tLoss: 1.163432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9713, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.4\tLoss: 0.971287\n",
      "tensor(1.0790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.6\tLoss: 1.079041\n",
      "tensor(1.0469, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.8\tLoss: 1.046873\n",
      "\n",
      "Test Epoch: 316\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 316\tmaintain_Accuracy: 2405/2993 (80%)\n",
      "\n",
      "tensor(1.1376, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.0\tLoss: 1.137581\n",
      "tensor(1.1678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.2\tLoss: 1.167778\n",
      "tensor(1.0525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.4\tLoss: 1.052501\n",
      "tensor(1.0276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.6\tLoss: 1.027557\n",
      "tensor(1.0189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.8\tLoss: 1.018925\n",
      "\n",
      "Test Epoch: 317\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 317\tmaintain_Accuracy: 2414/2993 (81%)\n",
      "\n",
      "tensor(1.0885, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.0\tLoss: 1.088472\n",
      "tensor(1.0713, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.2\tLoss: 1.071298\n",
      "tensor(1.1038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.4\tLoss: 1.103827\n",
      "tensor(1.0714, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.6\tLoss: 1.071435\n",
      "tensor(1.2083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.8\tLoss: 1.208318\n",
      "\n",
      "Test Epoch: 318\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 318\tmaintain_Accuracy: 2418/2993 (81%)\n",
      "\n",
      "tensor(1.0199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.0\tLoss: 1.019856\n",
      "tensor(1.0646, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.2\tLoss: 1.064572\n",
      "tensor(1.1564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.4\tLoss: 1.156366\n",
      "tensor(1.1660, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.6\tLoss: 1.166011\n",
      "tensor(0.9215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.8\tLoss: 0.921477\n",
      "\n",
      "Test Epoch: 319\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 319\tmaintain_Accuracy: 2417/2993 (81%)\n",
      "\n",
      "tensor(1.1279, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.0\tLoss: 1.127914\n",
      "tensor(1.0392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.2\tLoss: 1.039176\n",
      "tensor(1.1535, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.4\tLoss: 1.153475\n",
      "tensor(1.0746, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.6\tLoss: 1.074650\n",
      "tensor(1.1985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.8\tLoss: 1.198515\n",
      "\n",
      "Train Epoch: 320\tAttack_Accuracy: 10737/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 320\tmaintain_Accuracy: 10212/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 320\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 320\tmaintain_Accuracy: 2422/2993 (81%)\n",
      "\n",
      "tensor(1.0390, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.0\tLoss: 1.038967\n",
      "tensor(0.9915, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.2\tLoss: 0.991454\n",
      "tensor(1.1037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.4\tLoss: 1.103662\n",
      "tensor(1.0449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.6\tLoss: 1.044932\n",
      "tensor(1.1470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.8\tLoss: 1.147031\n",
      "\n",
      "Test Epoch: 321\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 321\tmaintain_Accuracy: 2416/2993 (81%)\n",
      "\n",
      "tensor(1.1010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.0\tLoss: 1.101011\n",
      "tensor(1.2736, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.2\tLoss: 1.273587\n",
      "tensor(0.8913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.4\tLoss: 0.891301\n",
      "tensor(1.1006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.6\tLoss: 1.100551\n",
      "tensor(1.0214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.8\tLoss: 1.021370\n",
      "\n",
      "Test Epoch: 322\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 322\tmaintain_Accuracy: 2406/2993 (80%)\n",
      "\n",
      "tensor(1.1579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.0\tLoss: 1.157881\n",
      "tensor(1.0329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.2\tLoss: 1.032907\n",
      "tensor(1.1853, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.4\tLoss: 1.185253\n",
      "tensor(1.1093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.6\tLoss: 1.109318\n",
      "tensor(1.0964, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.8\tLoss: 1.096404\n",
      "\n",
      "Test Epoch: 323\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 323\tmaintain_Accuracy: 2402/2993 (80%)\n",
      "\n",
      "tensor(1.0746, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.0\tLoss: 1.074573\n",
      "tensor(1.0690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.2\tLoss: 1.068975\n",
      "tensor(1.0701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.4\tLoss: 1.070105\n",
      "tensor(1.1188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.6\tLoss: 1.118765\n",
      "tensor(1.0129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.8\tLoss: 1.012949\n",
      "\n",
      "Test Epoch: 324\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 324\tmaintain_Accuracy: 2410/2993 (81%)\n",
      "\n",
      "tensor(0.9907, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.0\tLoss: 0.990705\n",
      "tensor(1.1349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.2\tLoss: 1.134857\n",
      "tensor(1.0914, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.4\tLoss: 1.091426\n",
      "tensor(1.0684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.6\tLoss: 1.068356\n",
      "tensor(0.9992, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.8\tLoss: 0.999194\n",
      "\n",
      "Train Epoch: 325\tAttack_Accuracy: 10721/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 325\tmaintain_Accuracy: 10339/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 325\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 325\tmaintain_Accuracy: 2425/2993 (81%)\n",
      "\n",
      "tensor(1.0737, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.0\tLoss: 1.073658\n",
      "tensor(0.9971, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.2\tLoss: 0.997147\n",
      "tensor(1.1850, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.4\tLoss: 1.184963\n",
      "tensor(1.0079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.6\tLoss: 1.007901\n",
      "tensor(1.0145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.8\tLoss: 1.014492\n",
      "\n",
      "Test Epoch: 326\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 326\tmaintain_Accuracy: 2427/2993 (81%)\n",
      "\n",
      "tensor(1.1673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.0\tLoss: 1.167324\n",
      "tensor(1.1210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.2\tLoss: 1.120977\n",
      "tensor(1.0857, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.4\tLoss: 1.085723\n",
      "tensor(1.0297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.6\tLoss: 1.029672\n",
      "tensor(0.9802, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.8\tLoss: 0.980189\n",
      "\n",
      "Test Epoch: 327\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 327\tmaintain_Accuracy: 2417/2993 (81%)\n",
      "\n",
      "tensor(1.0395, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.0\tLoss: 1.039509\n",
      "tensor(1.1931, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.2\tLoss: 1.193092\n",
      "tensor(0.9812, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.4\tLoss: 0.981201\n",
      "tensor(1.1144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.6\tLoss: 1.114376\n",
      "tensor(1.0894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.8\tLoss: 1.089408\n",
      "\n",
      "Test Epoch: 328\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 328\tmaintain_Accuracy: 2417/2993 (81%)\n",
      "\n",
      "tensor(0.9899, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.0\tLoss: 0.989884\n",
      "tensor(1.0956, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.2\tLoss: 1.095605\n",
      "tensor(1.0499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.4\tLoss: 1.049930\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.6\tLoss: 1.123953\n",
      "tensor(1.1730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.8\tLoss: 1.173011\n",
      "\n",
      "Test Epoch: 329\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 329\tmaintain_Accuracy: 2434/2993 (81%)\n",
      "\n",
      "tensor(1.0148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.0\tLoss: 1.014769\n",
      "tensor(0.9940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.2\tLoss: 0.994008\n",
      "tensor(1.1789, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.4\tLoss: 1.178927\n",
      "tensor(1.0575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.6\tLoss: 1.057514\n",
      "tensor(1.0792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.8\tLoss: 1.079182\n",
      "\n",
      "Train Epoch: 330\tAttack_Accuracy: 10641/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 330\tmaintain_Accuracy: 10193/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 330\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 330\tmaintain_Accuracy: 2409/2993 (80%)\n",
      "\n",
      "tensor(1.0203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.0\tLoss: 1.020254\n",
      "tensor(1.0039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.2\tLoss: 1.003941\n",
      "tensor(1.0740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.4\tLoss: 1.073978\n",
      "tensor(1.1794, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.6\tLoss: 1.179370\n",
      "tensor(1.0462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.8\tLoss: 1.046176\n",
      "\n",
      "Test Epoch: 331\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 331\tmaintain_Accuracy: 2401/2993 (80%)\n",
      "\n",
      "tensor(1.0678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.0\tLoss: 1.067804\n",
      "tensor(1.1405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.2\tLoss: 1.140502\n",
      "tensor(1.0647, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.4\tLoss: 1.064659\n",
      "tensor(0.9942, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.6\tLoss: 0.994170\n",
      "tensor(1.1188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.8\tLoss: 1.118819\n",
      "\n",
      "Test Epoch: 332\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 332\tmaintain_Accuracy: 2427/2993 (81%)\n",
      "\n",
      "tensor(1.0361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.0\tLoss: 1.036100\n",
      "tensor(0.9252, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.2\tLoss: 0.925187\n",
      "tensor(1.0282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.4\tLoss: 1.028196\n",
      "tensor(0.9710, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.6\tLoss: 0.970985\n",
      "tensor(1.0137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.8\tLoss: 1.013727\n",
      "\n",
      "Test Epoch: 333\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 333\tmaintain_Accuracy: 2417/2993 (81%)\n",
      "\n",
      "tensor(0.9566, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.0\tLoss: 0.956615\n",
      "tensor(1.0150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.2\tLoss: 1.014968\n",
      "tensor(1.1250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.4\tLoss: 1.124987\n",
      "tensor(1.0685, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.6\tLoss: 1.068479\n",
      "tensor(1.2628, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.8\tLoss: 1.262751\n",
      "\n",
      "Test Epoch: 334\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 334\tmaintain_Accuracy: 2414/2993 (81%)\n",
      "\n",
      "tensor(1.0316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.0\tLoss: 1.031591\n",
      "tensor(1.1075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.2\tLoss: 1.107526\n",
      "tensor(1.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.4\tLoss: 1.010438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.6\tLoss: 1.021920\n",
      "tensor(1.0417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.8\tLoss: 1.041731\n",
      "\n",
      "Train Epoch: 335\tAttack_Accuracy: 10700/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 335\tmaintain_Accuracy: 10245/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 335\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 335\tmaintain_Accuracy: 2430/2993 (81%)\n",
      "\n",
      "tensor(1.0725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.0\tLoss: 1.072475\n",
      "tensor(1.0972, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.2\tLoss: 1.097187\n",
      "tensor(1.0973, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.4\tLoss: 1.097330\n",
      "tensor(1.0607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.6\tLoss: 1.060652\n",
      "tensor(1.0975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.8\tLoss: 1.097477\n",
      "\n",
      "Test Epoch: 336\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 336\tmaintain_Accuracy: 2429/2993 (81%)\n",
      "\n",
      "tensor(1.0777, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.0\tLoss: 1.077694\n",
      "tensor(0.9987, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.2\tLoss: 0.998677\n",
      "tensor(1.1835, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.4\tLoss: 1.183455\n",
      "tensor(0.9187, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.6\tLoss: 0.918718\n",
      "tensor(1.0339, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.8\tLoss: 1.033853\n",
      "\n",
      "Test Epoch: 337\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 337\tmaintain_Accuracy: 2417/2993 (81%)\n",
      "\n",
      "tensor(1.1815, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.0\tLoss: 1.181463\n",
      "tensor(1.0184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.2\tLoss: 1.018392\n",
      "tensor(0.9698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.4\tLoss: 0.969824\n",
      "tensor(1.0922, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.6\tLoss: 1.092223\n",
      "tensor(1.0497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.8\tLoss: 1.049727\n",
      "\n",
      "Test Epoch: 338\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 338\tmaintain_Accuracy: 2422/2993 (81%)\n",
      "\n",
      "tensor(1.0644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.0\tLoss: 1.064425\n",
      "tensor(1.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.2\tLoss: 1.001098\n",
      "tensor(1.0278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.4\tLoss: 1.027803\n",
      "tensor(1.0385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.6\tLoss: 1.038501\n",
      "tensor(1.0729, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.8\tLoss: 1.072944\n",
      "\n",
      "Test Epoch: 339\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 339\tmaintain_Accuracy: 2439/2993 (81%)\n",
      "\n",
      "tensor(1.0706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.0\tLoss: 1.070568\n",
      "tensor(1.0871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.2\tLoss: 1.087117\n",
      "tensor(1.0584, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.4\tLoss: 1.058382\n",
      "tensor(1.0518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.6\tLoss: 1.051849\n",
      "tensor(0.9611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.8\tLoss: 0.961136\n",
      "\n",
      "Train Epoch: 340\tAttack_Accuracy: 10574/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 340\tmaintain_Accuracy: 10303/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 340\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 340\tmaintain_Accuracy: 2429/2993 (81%)\n",
      "\n",
      "tensor(1.1046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.0\tLoss: 1.104579\n",
      "tensor(1.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.2\tLoss: 1.010875\n",
      "tensor(0.9785, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.4\tLoss: 0.978457\n",
      "tensor(1.1180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.6\tLoss: 1.117986\n",
      "tensor(1.0025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.8\tLoss: 1.002478\n",
      "\n",
      "Test Epoch: 341\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 341\tmaintain_Accuracy: 2423/2993 (81%)\n",
      "\n",
      "tensor(0.9979, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.0\tLoss: 0.997889\n",
      "tensor(0.9769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.2\tLoss: 0.976921\n",
      "tensor(1.0813, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.4\tLoss: 1.081331\n",
      "tensor(1.0117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.6\tLoss: 1.011688\n",
      "tensor(0.9851, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.8\tLoss: 0.985053\n",
      "\n",
      "Test Epoch: 342\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 342\tmaintain_Accuracy: 2428/2993 (81%)\n",
      "\n",
      "tensor(0.9809, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.0\tLoss: 0.980880\n",
      "tensor(1.0684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.2\tLoss: 1.068377\n",
      "tensor(1.1519, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.4\tLoss: 1.151868\n",
      "tensor(1.1169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.6\tLoss: 1.116916\n",
      "tensor(1.0706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.8\tLoss: 1.070572\n",
      "\n",
      "Test Epoch: 343\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 343\tmaintain_Accuracy: 2417/2993 (81%)\n",
      "\n",
      "tensor(1.1382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.0\tLoss: 1.138209\n",
      "tensor(1.0807, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.2\tLoss: 1.080661\n",
      "tensor(0.9994, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.4\tLoss: 0.999352\n",
      "tensor(0.8901, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.6\tLoss: 0.890081\n",
      "tensor(0.8698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.8\tLoss: 0.869834\n",
      "\n",
      "Test Epoch: 344\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 344\tmaintain_Accuracy: 2410/2993 (81%)\n",
      "\n",
      "tensor(1.0809, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.0\tLoss: 1.080877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.2\tLoss: 1.005097\n",
      "tensor(0.8951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.4\tLoss: 0.895141\n",
      "tensor(0.9289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.6\tLoss: 0.928898\n",
      "tensor(0.9463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.8\tLoss: 0.946309\n",
      "\n",
      "Train Epoch: 345\tAttack_Accuracy: 10821/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 345\tmaintain_Accuracy: 10177/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 345\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 345\tmaintain_Accuracy: 2419/2993 (81%)\n",
      "\n",
      "tensor(1.0718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.0\tLoss: 1.071795\n",
      "tensor(1.0744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.2\tLoss: 1.074414\n",
      "tensor(1.0461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.4\tLoss: 1.046070\n",
      "tensor(1.0360, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.6\tLoss: 1.036030\n",
      "tensor(1.1786, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.8\tLoss: 1.178605\n",
      "\n",
      "Test Epoch: 346\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 346\tmaintain_Accuracy: 2431/2993 (81%)\n",
      "\n",
      "tensor(1.0712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.0\tLoss: 1.071164\n",
      "tensor(1.0627, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.2\tLoss: 1.062722\n",
      "tensor(1.0714, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.4\tLoss: 1.071385\n",
      "tensor(1.0446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.6\tLoss: 1.044579\n",
      "tensor(1.0241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.8\tLoss: 1.024073\n",
      "\n",
      "Test Epoch: 347\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 347\tmaintain_Accuracy: 2426/2993 (81%)\n",
      "\n",
      "tensor(0.9474, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.0\tLoss: 0.947403\n",
      "tensor(1.0449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.2\tLoss: 1.044891\n",
      "tensor(1.1548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.4\tLoss: 1.154836\n",
      "tensor(1.0393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.6\tLoss: 1.039281\n",
      "tensor(1.1013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.8\tLoss: 1.101291\n",
      "\n",
      "Test Epoch: 348\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 348\tmaintain_Accuracy: 2425/2993 (81%)\n",
      "\n",
      "tensor(0.9893, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.0\tLoss: 0.989322\n",
      "tensor(0.9978, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.2\tLoss: 0.997797\n",
      "tensor(1.1362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.4\tLoss: 1.136212\n",
      "tensor(1.0547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.6\tLoss: 1.054665\n",
      "tensor(1.0657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.8\tLoss: 1.065697\n",
      "\n",
      "Test Epoch: 349\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 349\tmaintain_Accuracy: 2429/2993 (81%)\n",
      "\n",
      "tensor(0.8932, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.0\tLoss: 0.893208\n",
      "tensor(1.1395, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.2\tLoss: 1.139487\n",
      "tensor(0.9409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.4\tLoss: 0.940873\n",
      "tensor(0.9545, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.6\tLoss: 0.954516\n",
      "tensor(1.0704, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.8\tLoss: 1.070401\n",
      "\n",
      "Train Epoch: 350\tAttack_Accuracy: 10749/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 350\tmaintain_Accuracy: 10188/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 350\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 350\tmaintain_Accuracy: 2434/2993 (81%)\n",
      "\n",
      "tensor(0.8900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.0\tLoss: 0.890027\n",
      "tensor(0.9954, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.2\tLoss: 0.995379\n",
      "tensor(0.9022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.4\tLoss: 0.902217\n",
      "tensor(1.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.6\tLoss: 1.017380\n",
      "tensor(0.9494, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.8\tLoss: 0.949357\n",
      "\n",
      "Test Epoch: 351\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 351\tmaintain_Accuracy: 2425/2993 (81%)\n",
      "\n",
      "tensor(1.0128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.0\tLoss: 1.012789\n",
      "tensor(0.9587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.2\tLoss: 0.958732\n",
      "tensor(0.9797, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.4\tLoss: 0.979706\n",
      "tensor(0.9886, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.6\tLoss: 0.988620\n",
      "tensor(1.0454, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.8\tLoss: 1.045370\n",
      "\n",
      "Test Epoch: 352\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 352\tmaintain_Accuracy: 2421/2993 (81%)\n",
      "\n",
      "tensor(1.1304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.0\tLoss: 1.130418\n",
      "tensor(1.0489, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.2\tLoss: 1.048897\n",
      "tensor(1.0073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.4\tLoss: 1.007293\n",
      "tensor(1.0798, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.6\tLoss: 1.079820\n",
      "tensor(1.1869, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.8\tLoss: 1.186939\n",
      "\n",
      "Test Epoch: 353\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 353\tmaintain_Accuracy: 2421/2993 (81%)\n",
      "\n",
      "tensor(1.1214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.0\tLoss: 1.121382\n",
      "tensor(0.8260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.2\tLoss: 0.825993\n",
      "tensor(1.0731, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.4\tLoss: 1.073103\n",
      "tensor(1.1304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.6\tLoss: 1.130441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.8\tLoss: 0.910491\n",
      "\n",
      "Test Epoch: 354\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 354\tmaintain_Accuracy: 2411/2993 (81%)\n",
      "\n",
      "tensor(1.0712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.0\tLoss: 1.071225\n",
      "tensor(0.9537, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.2\tLoss: 0.953702\n",
      "tensor(1.1888, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.4\tLoss: 1.188756\n",
      "tensor(0.9580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.6\tLoss: 0.958018\n",
      "tensor(1.0264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.8\tLoss: 1.026425\n",
      "\n",
      "Train Epoch: 355\tAttack_Accuracy: 10776/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 355\tmaintain_Accuracy: 10204/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 355\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 355\tmaintain_Accuracy: 2418/2993 (81%)\n",
      "\n",
      "tensor(0.9715, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.0\tLoss: 0.971481\n",
      "tensor(1.0139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.2\tLoss: 1.013916\n",
      "tensor(1.0362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.4\tLoss: 1.036233\n",
      "tensor(1.1024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.6\tLoss: 1.102433\n",
      "tensor(0.9717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.8\tLoss: 0.971735\n",
      "\n",
      "Test Epoch: 356\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 356\tmaintain_Accuracy: 2431/2993 (81%)\n",
      "\n",
      "tensor(1.0438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.0\tLoss: 1.043845\n",
      "tensor(0.9846, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.2\tLoss: 0.984568\n",
      "tensor(0.9282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.4\tLoss: 0.928202\n",
      "tensor(1.1883, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.6\tLoss: 1.188278\n",
      "tensor(1.0644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.8\tLoss: 1.064444\n",
      "\n",
      "Test Epoch: 357\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 357\tmaintain_Accuracy: 2437/2993 (81%)\n",
      "\n",
      "tensor(0.9512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.0\tLoss: 0.951218\n",
      "tensor(0.9510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.2\tLoss: 0.951021\n",
      "tensor(1.0216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.4\tLoss: 1.021584\n",
      "tensor(0.9850, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.6\tLoss: 0.984965\n",
      "tensor(1.0788, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.8\tLoss: 1.078801\n",
      "\n",
      "Test Epoch: 358\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 358\tmaintain_Accuracy: 2449/2993 (82%)\n",
      "\n",
      "tensor(1.1049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.0\tLoss: 1.104852\n",
      "tensor(0.9638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.2\tLoss: 0.963771\n",
      "tensor(1.0729, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.4\tLoss: 1.072929\n",
      "tensor(1.0687, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.6\tLoss: 1.068719\n",
      "tensor(1.0965, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.8\tLoss: 1.096509\n",
      "\n",
      "Test Epoch: 359\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 359\tmaintain_Accuracy: 2437/2993 (81%)\n",
      "\n",
      "tensor(1.0821, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.0\tLoss: 1.082111\n",
      "tensor(1.0727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.2\tLoss: 1.072720\n",
      "tensor(1.0587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.4\tLoss: 1.058657\n",
      "tensor(0.9900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.6\tLoss: 0.990020\n",
      "tensor(1.0167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.8\tLoss: 1.016653\n",
      "\n",
      "Train Epoch: 360\tAttack_Accuracy: 10732/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 360\tmaintain_Accuracy: 10272/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 360\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 360\tmaintain_Accuracy: 2439/2993 (81%)\n",
      "\n",
      "tensor(1.0223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.0\tLoss: 1.022278\n",
      "tensor(1.0181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.2\tLoss: 1.018091\n",
      "tensor(0.9529, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.4\tLoss: 0.952894\n",
      "tensor(1.0316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.6\tLoss: 1.031599\n",
      "tensor(1.0212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.8\tLoss: 1.021166\n",
      "\n",
      "Test Epoch: 361\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 361\tmaintain_Accuracy: 2438/2993 (81%)\n",
      "\n",
      "tensor(0.9429, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.0\tLoss: 0.942854\n",
      "tensor(1.0678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.2\tLoss: 1.067823\n",
      "tensor(0.9897, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.4\tLoss: 0.989683\n",
      "tensor(1.0072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.6\tLoss: 1.007175\n",
      "tensor(0.8887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.8\tLoss: 0.888717\n",
      "\n",
      "Test Epoch: 362\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 362\tmaintain_Accuracy: 2419/2993 (81%)\n",
      "\n",
      "tensor(1.2307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.0\tLoss: 1.230698\n",
      "tensor(1.0269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.2\tLoss: 1.026924\n",
      "tensor(0.9204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.4\tLoss: 0.920369\n",
      "tensor(1.0852, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.6\tLoss: 1.085247\n",
      "tensor(1.1092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.8\tLoss: 1.109178\n",
      "\n",
      "Test Epoch: 363\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 363\tmaintain_Accuracy: 2439/2993 (81%)\n",
      "\n",
      "tensor(1.0843, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.0\tLoss: 1.084341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.2\tLoss: 1.022795\n",
      "tensor(1.0378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.4\tLoss: 1.037809\n",
      "tensor(1.1306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.6\tLoss: 1.130563\n",
      "tensor(0.9581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.8\tLoss: 0.958075\n",
      "\n",
      "Test Epoch: 364\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 364\tmaintain_Accuracy: 2443/2993 (82%)\n",
      "\n",
      "tensor(1.0270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.0\tLoss: 1.026952\n",
      "tensor(1.0720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.2\tLoss: 1.071969\n",
      "tensor(0.9584, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.4\tLoss: 0.958417\n",
      "tensor(1.0845, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.6\tLoss: 1.084502\n",
      "tensor(0.9246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.8\tLoss: 0.924584\n",
      "\n",
      "Train Epoch: 365\tAttack_Accuracy: 10794/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 365\tmaintain_Accuracy: 10330/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 365\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 365\tmaintain_Accuracy: 2432/2993 (81%)\n",
      "\n",
      "tensor(1.0837, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.0\tLoss: 1.083728\n",
      "tensor(1.1842, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.2\tLoss: 1.184170\n",
      "tensor(1.0449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.4\tLoss: 1.044854\n",
      "tensor(0.9569, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.6\tLoss: 0.956895\n",
      "tensor(1.0401, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.8\tLoss: 1.040133\n",
      "\n",
      "Test Epoch: 366\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 366\tmaintain_Accuracy: 2428/2993 (81%)\n",
      "\n",
      "tensor(0.9205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.0\tLoss: 0.920496\n",
      "tensor(1.1081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.2\tLoss: 1.108076\n",
      "tensor(1.0444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.4\tLoss: 1.044410\n",
      "tensor(1.1108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.6\tLoss: 1.110837\n",
      "tensor(0.8565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.8\tLoss: 0.856452\n",
      "\n",
      "Test Epoch: 367\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 367\tmaintain_Accuracy: 2448/2993 (82%)\n",
      "\n",
      "tensor(0.9454, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.0\tLoss: 0.945417\n",
      "tensor(1.1639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.2\tLoss: 1.163858\n",
      "tensor(0.9894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.4\tLoss: 0.989437\n",
      "tensor(1.1190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.6\tLoss: 1.119041\n",
      "tensor(1.1450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.8\tLoss: 1.144969\n",
      "\n",
      "Test Epoch: 368\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 368\tmaintain_Accuracy: 2430/2993 (81%)\n",
      "\n",
      "tensor(1.0550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.0\tLoss: 1.054972\n",
      "tensor(0.9857, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.2\tLoss: 0.985732\n",
      "tensor(1.0317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.4\tLoss: 1.031662\n",
      "tensor(0.9652, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.6\tLoss: 0.965197\n",
      "tensor(1.0794, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.8\tLoss: 1.079362\n",
      "\n",
      "Test Epoch: 369\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 369\tmaintain_Accuracy: 2435/2993 (81%)\n",
      "\n",
      "tensor(0.9657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.0\tLoss: 0.965690\n",
      "tensor(0.9053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.2\tLoss: 0.905342\n",
      "tensor(1.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.4\tLoss: 1.010355\n",
      "tensor(1.0674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.6\tLoss: 1.067429\n",
      "tensor(1.1095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.8\tLoss: 1.109503\n",
      "\n",
      "Train Epoch: 370\tAttack_Accuracy: 10631/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 370\tmaintain_Accuracy: 10338/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 370\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 370\tmaintain_Accuracy: 2418/2993 (81%)\n",
      "\n",
      "tensor(1.1419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.0\tLoss: 1.141900\n",
      "tensor(0.9733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.2\tLoss: 0.973349\n",
      "tensor(0.9924, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.4\tLoss: 0.992375\n",
      "tensor(0.8798, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.6\tLoss: 0.879798\n",
      "tensor(1.1185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.8\tLoss: 1.118505\n",
      "\n",
      "Test Epoch: 371\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 371\tmaintain_Accuracy: 2413/2993 (81%)\n",
      "\n",
      "tensor(1.1055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.0\tLoss: 1.105529\n",
      "tensor(0.9664, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.2\tLoss: 0.966360\n",
      "tensor(1.0146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.4\tLoss: 1.014605\n",
      "tensor(0.8642, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.6\tLoss: 0.864242\n",
      "tensor(1.0896, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.8\tLoss: 1.089605\n",
      "\n",
      "Test Epoch: 372\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 372\tmaintain_Accuracy: 2418/2993 (81%)\n",
      "\n",
      "tensor(0.9352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.0\tLoss: 0.935206\n",
      "tensor(1.0292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.2\tLoss: 1.029192\n",
      "tensor(1.1438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.4\tLoss: 1.143829\n",
      "tensor(1.0992, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.6\tLoss: 1.099207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.8\tLoss: 0.928908\n",
      "\n",
      "Test Epoch: 373\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 373\tmaintain_Accuracy: 2423/2993 (81%)\n",
      "\n",
      "tensor(1.0635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.0\tLoss: 1.063455\n",
      "tensor(1.1712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.2\tLoss: 1.171229\n",
      "tensor(1.0692, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.4\tLoss: 1.069152\n",
      "tensor(1.0141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.6\tLoss: 1.014146\n",
      "tensor(0.9597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.8\tLoss: 0.959652\n",
      "\n",
      "Test Epoch: 374\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 374\tmaintain_Accuracy: 2426/2993 (81%)\n",
      "\n",
      "tensor(1.0576, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.0\tLoss: 1.057607\n",
      "tensor(0.8972, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.2\tLoss: 0.897156\n",
      "tensor(0.9918, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.4\tLoss: 0.991819\n",
      "tensor(0.9861, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.6\tLoss: 0.986087\n",
      "tensor(0.9954, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.8\tLoss: 0.995361\n",
      "\n",
      "Train Epoch: 375\tAttack_Accuracy: 10680/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 375\tmaintain_Accuracy: 10264/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 375\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 375\tmaintain_Accuracy: 2429/2993 (81%)\n",
      "\n",
      "tensor(0.9810, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.0\tLoss: 0.981003\n",
      "tensor(0.9244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.2\tLoss: 0.924367\n",
      "tensor(0.9754, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.4\tLoss: 0.975388\n",
      "tensor(0.9296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.6\tLoss: 0.929625\n",
      "tensor(0.9602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.8\tLoss: 0.960183\n",
      "\n",
      "Test Epoch: 376\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 376\tmaintain_Accuracy: 2424/2993 (81%)\n",
      "\n",
      "tensor(0.9730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.0\tLoss: 0.972998\n",
      "tensor(0.9143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.2\tLoss: 0.914341\n",
      "tensor(0.9111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.4\tLoss: 0.911094\n",
      "tensor(0.9574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.6\tLoss: 0.957384\n",
      "tensor(0.9444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.8\tLoss: 0.944392\n",
      "\n",
      "Test Epoch: 377\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 377\tmaintain_Accuracy: 2423/2993 (81%)\n",
      "\n",
      "tensor(0.9962, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.0\tLoss: 0.996195\n",
      "tensor(1.0957, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.2\tLoss: 1.095672\n",
      "tensor(1.0316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.4\tLoss: 1.031619\n",
      "tensor(1.0469, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.6\tLoss: 1.046911\n",
      "tensor(1.0458, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.8\tLoss: 1.045835\n",
      "\n",
      "Test Epoch: 378\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 378\tmaintain_Accuracy: 2425/2993 (81%)\n",
      "\n",
      "tensor(1.1446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.0\tLoss: 1.144581\n",
      "tensor(1.0773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.2\tLoss: 1.077251\n",
      "tensor(0.9610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.4\tLoss: 0.960973\n",
      "tensor(0.9382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.6\tLoss: 0.938178\n",
      "tensor(1.0297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.8\tLoss: 1.029742\n",
      "\n",
      "Test Epoch: 379\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 379\tmaintain_Accuracy: 2417/2993 (81%)\n",
      "\n",
      "tensor(0.9558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.0\tLoss: 0.955814\n",
      "tensor(0.9698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.2\tLoss: 0.969780\n",
      "tensor(0.9804, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.4\tLoss: 0.980419\n",
      "tensor(0.8701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.6\tLoss: 0.870101\n",
      "tensor(1.1428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.8\tLoss: 1.142799\n",
      "\n",
      "Train Epoch: 380\tAttack_Accuracy: 10746/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 380\tmaintain_Accuracy: 10327/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 380\tAttack_Accuracy: 325/412 (79%)\n",
      "\n",
      "\n",
      "Test Epoch: 380\tmaintain_Accuracy: 2444/2993 (82%)\n",
      "\n",
      "tensor(0.9438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.0\tLoss: 0.943795\n",
      "tensor(0.8983, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.2\tLoss: 0.898256\n",
      "tensor(1.0103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.4\tLoss: 1.010285\n",
      "tensor(0.9809, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.6\tLoss: 0.980944\n",
      "tensor(1.0084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.8\tLoss: 1.008412\n",
      "\n",
      "Test Epoch: 381\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 381\tmaintain_Accuracy: 2440/2993 (82%)\n",
      "\n",
      "tensor(1.2078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.0\tLoss: 1.207835\n",
      "tensor(0.9844, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.2\tLoss: 0.984422\n",
      "tensor(1.1360, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.4\tLoss: 1.136045\n",
      "tensor(1.0869, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.6\tLoss: 1.086877\n",
      "tensor(1.1202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.8\tLoss: 1.120223\n",
      "\n",
      "Test Epoch: 382\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 382\tmaintain_Accuracy: 2419/2993 (81%)\n",
      "\n",
      "tensor(1.0099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.0\tLoss: 1.009856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9687, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.2\tLoss: 0.968685\n",
      "tensor(1.0550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.4\tLoss: 1.055045\n",
      "tensor(1.0611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.6\tLoss: 1.061124\n",
      "tensor(1.0112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.8\tLoss: 1.011162\n",
      "\n",
      "Test Epoch: 383\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 383\tmaintain_Accuracy: 2431/2993 (81%)\n",
      "\n",
      "tensor(0.9678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.0\tLoss: 0.967751\n",
      "tensor(1.1402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.2\tLoss: 1.140204\n",
      "tensor(1.0024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.4\tLoss: 1.002369\n",
      "tensor(1.0032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.6\tLoss: 1.003184\n",
      "tensor(1.0183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.8\tLoss: 1.018321\n",
      "\n",
      "Test Epoch: 384\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 384\tmaintain_Accuracy: 2429/2993 (81%)\n",
      "\n",
      "tensor(1.0653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.0\tLoss: 1.065313\n",
      "tensor(0.8871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.2\tLoss: 0.887087\n",
      "tensor(0.9526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.4\tLoss: 0.952642\n",
      "tensor(0.9613, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.6\tLoss: 0.961320\n",
      "tensor(1.0641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.8\tLoss: 1.064149\n",
      "\n",
      "Train Epoch: 385\tAttack_Accuracy: 10640/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 385\tmaintain_Accuracy: 10220/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 385\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 385\tmaintain_Accuracy: 2412/2993 (81%)\n",
      "\n",
      "tensor(0.9884, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.0\tLoss: 0.988356\n",
      "tensor(1.0138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.2\tLoss: 1.013812\n",
      "tensor(1.0489, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.4\tLoss: 1.048863\n",
      "tensor(0.9874, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.6\tLoss: 0.987421\n",
      "tensor(1.0189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.8\tLoss: 1.018940\n",
      "\n",
      "Test Epoch: 386\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 386\tmaintain_Accuracy: 2430/2993 (81%)\n",
      "\n",
      "tensor(0.8661, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.0\tLoss: 0.866135\n",
      "tensor(0.9822, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.2\tLoss: 0.982238\n",
      "tensor(0.9154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.4\tLoss: 0.915362\n",
      "tensor(1.0259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.6\tLoss: 1.025881\n",
      "tensor(1.0176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.8\tLoss: 1.017586\n",
      "\n",
      "Test Epoch: 387\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 387\tmaintain_Accuracy: 2436/2993 (81%)\n",
      "\n",
      "tensor(1.0269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.0\tLoss: 1.026875\n",
      "tensor(1.0577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.2\tLoss: 1.057659\n",
      "tensor(0.9944, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.4\tLoss: 0.994431\n",
      "tensor(0.9078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.6\tLoss: 0.907843\n",
      "tensor(0.8865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.8\tLoss: 0.886501\n",
      "\n",
      "Test Epoch: 388\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 388\tmaintain_Accuracy: 2424/2993 (81%)\n",
      "\n",
      "tensor(0.9077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.0\tLoss: 0.907739\n",
      "tensor(1.0320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.2\tLoss: 1.032046\n",
      "tensor(0.9942, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.4\tLoss: 0.994246\n",
      "tensor(0.9622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.6\tLoss: 0.962236\n",
      "tensor(1.0607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.8\tLoss: 1.060660\n",
      "\n",
      "Test Epoch: 389\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 389\tmaintain_Accuracy: 2426/2993 (81%)\n",
      "\n",
      "tensor(1.0386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.0\tLoss: 1.038553\n",
      "tensor(1.2179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.2\tLoss: 1.217877\n",
      "tensor(0.9702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.4\tLoss: 0.970237\n",
      "tensor(0.8874, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.6\tLoss: 0.887370\n",
      "tensor(1.1001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.8\tLoss: 1.100129\n",
      "\n",
      "Train Epoch: 390\tAttack_Accuracy: 10691/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 390\tmaintain_Accuracy: 10257/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 390\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 390\tmaintain_Accuracy: 2435/2993 (81%)\n",
      "\n",
      "tensor(0.9260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.0\tLoss: 0.926048\n",
      "tensor(0.9556, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.2\tLoss: 0.955635\n",
      "tensor(1.0313, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.4\tLoss: 1.031326\n",
      "tensor(0.9931, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.6\tLoss: 0.993072\n",
      "tensor(0.9727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.8\tLoss: 0.972681\n",
      "\n",
      "Test Epoch: 391\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 391\tmaintain_Accuracy: 2427/2993 (81%)\n",
      "\n",
      "tensor(1.0918, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.0\tLoss: 1.091821\n",
      "tensor(0.9601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.2\tLoss: 0.960148\n",
      "tensor(0.9904, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.4\tLoss: 0.990367\n",
      "tensor(0.9870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.6\tLoss: 0.986980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0789, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.8\tLoss: 1.078876\n",
      "\n",
      "Test Epoch: 392\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 392\tmaintain_Accuracy: 2419/2993 (81%)\n",
      "\n",
      "tensor(1.0652, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.0\tLoss: 1.065191\n",
      "tensor(0.9966, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.2\tLoss: 0.996630\n",
      "tensor(0.9283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.4\tLoss: 0.928304\n",
      "tensor(0.9649, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.6\tLoss: 0.964872\n",
      "tensor(1.0601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.8\tLoss: 1.060124\n",
      "\n",
      "Test Epoch: 393\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 393\tmaintain_Accuracy: 2433/2993 (81%)\n",
      "\n",
      "tensor(1.0944, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.0\tLoss: 1.094443\n",
      "tensor(1.0105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.2\tLoss: 1.010516\n",
      "tensor(1.0351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.4\tLoss: 1.035059\n",
      "tensor(1.0472, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.6\tLoss: 1.047188\n",
      "tensor(0.9642, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.8\tLoss: 0.964214\n",
      "\n",
      "Test Epoch: 394\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 394\tmaintain_Accuracy: 2426/2993 (81%)\n",
      "\n",
      "tensor(1.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.0\tLoss: 1.002024\n",
      "tensor(0.9352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.2\tLoss: 0.935236\n",
      "tensor(1.1092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.4\tLoss: 1.109160\n",
      "tensor(0.9797, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.6\tLoss: 0.979731\n",
      "tensor(0.9510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.8\tLoss: 0.951028\n",
      "\n",
      "Train Epoch: 395\tAttack_Accuracy: 10737/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 395\tmaintain_Accuracy: 10328/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 395\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 395\tmaintain_Accuracy: 2433/2993 (81%)\n",
      "\n",
      "tensor(1.0286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.0\tLoss: 1.028555\n",
      "tensor(1.0591, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.2\tLoss: 1.059112\n",
      "tensor(1.1137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.4\tLoss: 1.113704\n",
      "tensor(0.9451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.6\tLoss: 0.945058\n",
      "tensor(1.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.8\tLoss: 1.000625\n",
      "\n",
      "Test Epoch: 396\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 396\tmaintain_Accuracy: 2439/2993 (81%)\n",
      "\n",
      "tensor(0.9702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.0\tLoss: 0.970245\n",
      "tensor(0.8896, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.2\tLoss: 0.889612\n",
      "tensor(0.9765, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.4\tLoss: 0.976519\n",
      "tensor(1.0984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.6\tLoss: 1.098387\n",
      "tensor(0.9897, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.8\tLoss: 0.989698\n",
      "\n",
      "Test Epoch: 397\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 397\tmaintain_Accuracy: 2419/2993 (81%)\n",
      "\n",
      "tensor(0.9610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.0\tLoss: 0.961040\n",
      "tensor(1.0084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.2\tLoss: 1.008399\n",
      "tensor(1.0109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.4\tLoss: 1.010889\n",
      "tensor(1.0291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.6\tLoss: 1.029081\n",
      "tensor(1.1278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.8\tLoss: 1.127787\n",
      "\n",
      "Test Epoch: 398\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 398\tmaintain_Accuracy: 2433/2993 (81%)\n",
      "\n",
      "tensor(1.0900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.0\tLoss: 1.090006\n",
      "tensor(1.1432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.2\tLoss: 1.143200\n",
      "tensor(1.1344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.4\tLoss: 1.134384\n",
      "tensor(0.9674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.6\tLoss: 0.967429\n",
      "tensor(1.0169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.8\tLoss: 1.016927\n",
      "\n",
      "Test Epoch: 399\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 399\tmaintain_Accuracy: 2431/2993 (81%)\n",
      "\n",
      "tensor(0.9919, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.0\tLoss: 0.991945\n",
      "tensor(0.8696, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.2\tLoss: 0.869636\n",
      "tensor(1.0489, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.4\tLoss: 1.048898\n",
      "tensor(0.8878, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.6\tLoss: 0.887797\n",
      "tensor(0.9504, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.8\tLoss: 0.950385\n",
      "\n",
      "Train Epoch: 400\tAttack_Accuracy: 10713/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 400\tmaintain_Accuracy: 10324/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 400\tAttack_Accuracy: 346/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 400\tmaintain_Accuracy: 2419/2993 (81%)\n",
      "\n",
      "tensor(0.7826, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.0\tLoss: 0.782570\n",
      "tensor(1.0192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.2\tLoss: 1.019230\n",
      "tensor(0.9781, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.4\tLoss: 0.978089\n",
      "tensor(0.9932, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.6\tLoss: 0.993152\n",
      "tensor(0.9121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.8\tLoss: 0.912103\n",
      "\n",
      "Test Epoch: 401\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 401\tmaintain_Accuracy: 2428/2993 (81%)\n",
      "\n",
      "tensor(0.9505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.0\tLoss: 0.950503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.2\tLoss: 1.021029\n",
      "tensor(1.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.4\tLoss: 1.013104\n",
      "tensor(0.9804, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.6\tLoss: 0.980429\n",
      "tensor(1.0424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.8\tLoss: 1.042399\n",
      "\n",
      "Test Epoch: 402\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 402\tmaintain_Accuracy: 2433/2993 (81%)\n",
      "\n",
      "tensor(0.9768, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.0\tLoss: 0.976794\n",
      "tensor(0.9019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.2\tLoss: 0.901911\n",
      "tensor(0.9142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.4\tLoss: 0.914201\n",
      "tensor(1.0151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.6\tLoss: 1.015080\n",
      "tensor(1.0143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.8\tLoss: 1.014277\n",
      "\n",
      "Test Epoch: 403\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 403\tmaintain_Accuracy: 2434/2993 (81%)\n",
      "\n",
      "tensor(0.9445, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.0\tLoss: 0.944458\n",
      "tensor(0.9387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.2\tLoss: 0.938689\n",
      "tensor(0.8641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.4\tLoss: 0.864085\n",
      "tensor(0.9721, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.6\tLoss: 0.972083\n",
      "tensor(1.0563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.8\tLoss: 1.056286\n",
      "\n",
      "Test Epoch: 404\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 404\tmaintain_Accuracy: 2445/2993 (82%)\n",
      "\n",
      "tensor(0.9781, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.0\tLoss: 0.978087\n",
      "tensor(0.9461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.2\tLoss: 0.946141\n",
      "tensor(1.0763, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.4\tLoss: 1.076345\n",
      "tensor(0.9632, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.6\tLoss: 0.963222\n",
      "tensor(0.9043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.8\tLoss: 0.904301\n",
      "\n",
      "Train Epoch: 405\tAttack_Accuracy: 10656/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 405\tmaintain_Accuracy: 10304/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 405\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 405\tmaintain_Accuracy: 2442/2993 (82%)\n",
      "\n",
      "tensor(0.8552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.0\tLoss: 0.855205\n",
      "tensor(0.9505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.2\tLoss: 0.950522\n",
      "tensor(1.0062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.4\tLoss: 1.006230\n",
      "tensor(0.8504, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.6\tLoss: 0.850443\n",
      "tensor(0.9322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.8\tLoss: 0.932233\n",
      "\n",
      "Test Epoch: 406\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 406\tmaintain_Accuracy: 2445/2993 (82%)\n",
      "\n",
      "tensor(1.0557, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.0\tLoss: 1.055668\n",
      "tensor(0.9859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.2\tLoss: 0.985941\n",
      "tensor(1.0004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.4\tLoss: 1.000351\n",
      "tensor(0.9599, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.6\tLoss: 0.959907\n",
      "tensor(0.9272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.8\tLoss: 0.927202\n",
      "\n",
      "Test Epoch: 407\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 407\tmaintain_Accuracy: 2449/2993 (82%)\n",
      "\n",
      "tensor(1.0394, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.0\tLoss: 1.039423\n",
      "tensor(0.9553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.2\tLoss: 0.955342\n",
      "tensor(0.9881, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.4\tLoss: 0.988068\n",
      "tensor(0.9237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.6\tLoss: 0.923737\n",
      "tensor(0.9406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.8\tLoss: 0.940625\n",
      "\n",
      "Test Epoch: 408\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 408\tmaintain_Accuracy: 2447/2993 (82%)\n",
      "\n",
      "tensor(1.1863, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.0\tLoss: 1.186326\n",
      "tensor(1.1822, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.2\tLoss: 1.182249\n",
      "tensor(0.9655, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.4\tLoss: 0.965473\n",
      "tensor(1.0487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.6\tLoss: 1.048700\n",
      "tensor(0.9555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.8\tLoss: 0.955529\n",
      "\n",
      "Test Epoch: 409\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 409\tmaintain_Accuracy: 2435/2993 (81%)\n",
      "\n",
      "tensor(0.9615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.0\tLoss: 0.961493\n",
      "tensor(0.9347, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.2\tLoss: 0.934698\n",
      "tensor(0.9383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.4\tLoss: 0.938304\n",
      "tensor(0.9446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.6\tLoss: 0.944601\n",
      "tensor(1.0945, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.8\tLoss: 1.094468\n",
      "\n",
      "Train Epoch: 410\tAttack_Accuracy: 10621/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 410\tmaintain_Accuracy: 10310/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 410\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 410\tmaintain_Accuracy: 2441/2993 (82%)\n",
      "\n",
      "tensor(1.0261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.0\tLoss: 1.026079\n",
      "tensor(1.0409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.2\tLoss: 1.040929\n",
      "tensor(0.9645, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.4\tLoss: 0.964548\n",
      "tensor(1.0419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.6\tLoss: 1.041899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9965, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.8\tLoss: 0.996533\n",
      "\n",
      "Test Epoch: 411\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 411\tmaintain_Accuracy: 2435/2993 (81%)\n",
      "\n",
      "tensor(0.9965, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.0\tLoss: 0.996522\n",
      "tensor(0.9213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.2\tLoss: 0.921278\n",
      "tensor(0.9290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.4\tLoss: 0.928979\n",
      "tensor(1.0894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.6\tLoss: 1.089383\n",
      "tensor(0.9621, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.8\tLoss: 0.962065\n",
      "\n",
      "Test Epoch: 412\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 412\tmaintain_Accuracy: 2437/2993 (81%)\n",
      "\n",
      "tensor(1.0957, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.0\tLoss: 1.095702\n",
      "tensor(0.9400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.2\tLoss: 0.939981\n",
      "tensor(1.0462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.4\tLoss: 1.046235\n",
      "tensor(0.9095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.6\tLoss: 0.909509\n",
      "tensor(1.0181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.8\tLoss: 1.018138\n",
      "\n",
      "Test Epoch: 413\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 413\tmaintain_Accuracy: 2441/2993 (82%)\n",
      "\n",
      "tensor(1.0348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.0\tLoss: 1.034795\n",
      "tensor(0.9114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.2\tLoss: 0.911404\n",
      "tensor(0.8852, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.4\tLoss: 0.885185\n",
      "tensor(0.9435, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.6\tLoss: 0.943479\n",
      "tensor(0.9941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.8\tLoss: 0.994113\n",
      "\n",
      "Test Epoch: 414\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 414\tmaintain_Accuracy: 2439/2993 (81%)\n",
      "\n",
      "tensor(1.0289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.0\tLoss: 1.028911\n",
      "tensor(1.0244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.2\tLoss: 1.024407\n",
      "tensor(0.8803, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.4\tLoss: 0.880316\n",
      "tensor(1.0274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.6\tLoss: 1.027351\n",
      "tensor(0.9629, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.8\tLoss: 0.962935\n",
      "\n",
      "Train Epoch: 415\tAttack_Accuracy: 10741/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 415\tmaintain_Accuracy: 10277/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 415\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 415\tmaintain_Accuracy: 2425/2993 (81%)\n",
      "\n",
      "tensor(1.0066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.0\tLoss: 1.006557\n",
      "tensor(0.9615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.2\tLoss: 0.961540\n",
      "tensor(0.8105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.4\tLoss: 0.810500\n",
      "tensor(1.0467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.6\tLoss: 1.046745\n",
      "tensor(1.2031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.8\tLoss: 1.203081\n",
      "\n",
      "Test Epoch: 416\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 416\tmaintain_Accuracy: 2435/2993 (81%)\n",
      "\n",
      "tensor(0.9421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.0\tLoss: 0.942086\n",
      "tensor(0.9619, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.2\tLoss: 0.961937\n",
      "tensor(1.0454, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.4\tLoss: 1.045399\n",
      "tensor(1.1044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.6\tLoss: 1.104374\n",
      "tensor(0.9732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.8\tLoss: 0.973205\n",
      "\n",
      "Test Epoch: 417\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 417\tmaintain_Accuracy: 2436/2993 (81%)\n",
      "\n",
      "tensor(0.9398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.0\tLoss: 0.939827\n",
      "tensor(0.8577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.2\tLoss: 0.857689\n",
      "tensor(1.0113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.4\tLoss: 1.011281\n",
      "tensor(0.8630, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.6\tLoss: 0.863013\n",
      "tensor(0.9875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.8\tLoss: 0.987474\n",
      "\n",
      "Test Epoch: 418\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 418\tmaintain_Accuracy: 2438/2993 (81%)\n",
      "\n",
      "tensor(0.9483, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.0\tLoss: 0.948294\n",
      "tensor(0.9996, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.2\tLoss: 0.999563\n",
      "tensor(1.0232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.4\tLoss: 1.023237\n",
      "tensor(1.0093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.6\tLoss: 1.009295\n",
      "tensor(0.9535, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.8\tLoss: 0.953499\n",
      "\n",
      "Test Epoch: 419\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 419\tmaintain_Accuracy: 2451/2993 (82%)\n",
      "\n",
      "tensor(1.0272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.0\tLoss: 1.027167\n",
      "tensor(1.0623, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.2\tLoss: 1.062266\n",
      "tensor(0.9670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.4\tLoss: 0.966958\n",
      "tensor(0.9425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.6\tLoss: 0.942498\n",
      "tensor(1.0882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.8\tLoss: 1.088226\n",
      "\n",
      "Train Epoch: 420\tAttack_Accuracy: 10743/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 420\tmaintain_Accuracy: 10326/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 420\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 420\tmaintain_Accuracy: 2455/2993 (82%)\n",
      "\n",
      "tensor(0.9958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.0\tLoss: 0.995769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8789, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.2\tLoss: 0.878900\n",
      "tensor(1.1235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.4\tLoss: 1.123518\n",
      "tensor(1.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.6\tLoss: 1.015351\n",
      "tensor(0.9573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.8\tLoss: 0.957332\n",
      "\n",
      "Test Epoch: 421\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 421\tmaintain_Accuracy: 2445/2993 (82%)\n",
      "\n",
      "tensor(1.0019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.0\tLoss: 1.001935\n",
      "tensor(0.9693, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.2\tLoss: 0.969280\n",
      "tensor(0.9330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.4\tLoss: 0.933042\n",
      "tensor(0.8786, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.6\tLoss: 0.878570\n",
      "tensor(0.8860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.8\tLoss: 0.886005\n",
      "\n",
      "Test Epoch: 422\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 422\tmaintain_Accuracy: 2442/2993 (82%)\n",
      "\n",
      "tensor(0.9100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.0\tLoss: 0.909956\n",
      "tensor(1.0427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.2\tLoss: 1.042681\n",
      "tensor(1.0762, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.4\tLoss: 1.076209\n",
      "tensor(0.9037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.6\tLoss: 0.903738\n",
      "tensor(1.0249, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.8\tLoss: 1.024939\n",
      "\n",
      "Test Epoch: 423\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 423\tmaintain_Accuracy: 2455/2993 (82%)\n",
      "\n",
      "tensor(0.9225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.0\tLoss: 0.922489\n",
      "tensor(0.8257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.2\tLoss: 0.825729\n",
      "tensor(1.0915, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.4\tLoss: 1.091544\n",
      "tensor(1.0184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.6\tLoss: 1.018366\n",
      "tensor(1.0247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.8\tLoss: 1.024667\n",
      "\n",
      "Test Epoch: 424\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 424\tmaintain_Accuracy: 2462/2993 (82%)\n",
      "\n",
      "tensor(0.8464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.0\tLoss: 0.846436\n",
      "tensor(0.9320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.2\tLoss: 0.931987\n",
      "tensor(1.1623, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.4\tLoss: 1.162334\n",
      "tensor(1.0650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.6\tLoss: 1.064995\n",
      "tensor(1.0248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.8\tLoss: 1.024828\n",
      "\n",
      "Train Epoch: 425\tAttack_Accuracy: 10691/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 425\tmaintain_Accuracy: 10386/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 425\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 425\tmaintain_Accuracy: 2453/2993 (82%)\n",
      "\n",
      "tensor(0.9934, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.0\tLoss: 0.993372\n",
      "tensor(0.9158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.2\tLoss: 0.915795\n",
      "tensor(0.8943, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.4\tLoss: 0.894304\n",
      "tensor(1.0409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.6\tLoss: 1.040922\n",
      "tensor(0.9401, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.8\tLoss: 0.940087\n",
      "\n",
      "Test Epoch: 426\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 426\tmaintain_Accuracy: 2446/2993 (82%)\n",
      "\n",
      "tensor(0.9134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.0\tLoss: 0.913421\n",
      "tensor(0.9055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.2\tLoss: 0.905465\n",
      "tensor(0.9429, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.4\tLoss: 0.942901\n",
      "tensor(0.8695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.6\tLoss: 0.869467\n",
      "tensor(0.9302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.8\tLoss: 0.930248\n",
      "\n",
      "Test Epoch: 427\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 427\tmaintain_Accuracy: 2454/2993 (82%)\n",
      "\n",
      "tensor(0.9654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.0\tLoss: 0.965383\n",
      "tensor(1.1744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.2\tLoss: 1.174445\n",
      "tensor(1.0080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.4\tLoss: 1.007998\n",
      "tensor(1.0047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.6\tLoss: 1.004743\n",
      "tensor(1.0678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.8\tLoss: 1.067786\n",
      "\n",
      "Test Epoch: 428\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 428\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(1.0508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.0\tLoss: 1.050787\n",
      "tensor(0.9960, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.2\tLoss: 0.995993\n",
      "tensor(0.8856, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.4\tLoss: 0.885607\n",
      "tensor(0.9778, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.6\tLoss: 0.977800\n",
      "tensor(1.2307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.8\tLoss: 1.230689\n",
      "\n",
      "Test Epoch: 429\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 429\tmaintain_Accuracy: 2447/2993 (82%)\n",
      "\n",
      "tensor(0.8757, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.0\tLoss: 0.875746\n",
      "tensor(1.0856, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.2\tLoss: 1.085572\n",
      "tensor(0.9207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.4\tLoss: 0.920682\n",
      "tensor(0.8946, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.6\tLoss: 0.894649\n",
      "tensor(0.8799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.8\tLoss: 0.879879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 430\tAttack_Accuracy: 10717/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 430\tmaintain_Accuracy: 10395/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 430\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 430\tmaintain_Accuracy: 2437/2993 (81%)\n",
      "\n",
      "tensor(1.0226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.0\tLoss: 1.022557\n",
      "tensor(0.9819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.2\tLoss: 0.981898\n",
      "tensor(0.9818, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.4\tLoss: 0.981778\n",
      "tensor(0.8610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.6\tLoss: 0.861001\n",
      "tensor(0.9193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.8\tLoss: 0.919311\n",
      "\n",
      "Test Epoch: 431\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 431\tmaintain_Accuracy: 2449/2993 (82%)\n",
      "\n",
      "tensor(0.8787, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.0\tLoss: 0.878655\n",
      "tensor(1.0092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.2\tLoss: 1.009194\n",
      "tensor(0.8781, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.4\tLoss: 0.878138\n",
      "tensor(0.9537, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.6\tLoss: 0.953673\n",
      "tensor(0.9383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.8\tLoss: 0.938315\n",
      "\n",
      "Test Epoch: 432\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 432\tmaintain_Accuracy: 2451/2993 (82%)\n",
      "\n",
      "tensor(0.7294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.0\tLoss: 0.729426\n",
      "tensor(0.9657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.2\tLoss: 0.965689\n",
      "tensor(0.9879, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.4\tLoss: 0.987937\n",
      "tensor(0.9960, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.6\tLoss: 0.995979\n",
      "tensor(0.9536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.8\tLoss: 0.953642\n",
      "\n",
      "Test Epoch: 433\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 433\tmaintain_Accuracy: 2445/2993 (82%)\n",
      "\n",
      "tensor(0.9864, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.0\tLoss: 0.986388\n",
      "tensor(0.9596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.2\tLoss: 0.959550\n",
      "tensor(0.9528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.4\tLoss: 0.952768\n",
      "tensor(0.9871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.6\tLoss: 0.987051\n",
      "tensor(0.8328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.8\tLoss: 0.832815\n",
      "\n",
      "Test Epoch: 434\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 434\tmaintain_Accuracy: 2427/2993 (81%)\n",
      "\n",
      "tensor(0.9309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.0\tLoss: 0.930922\n",
      "tensor(1.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.2\tLoss: 1.006737\n",
      "tensor(0.8863, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.4\tLoss: 0.886269\n",
      "tensor(0.8977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.6\tLoss: 0.897668\n",
      "tensor(0.9536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.8\tLoss: 0.953602\n",
      "\n",
      "Train Epoch: 435\tAttack_Accuracy: 10812/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 435\tmaintain_Accuracy: 10276/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 435\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 435\tmaintain_Accuracy: 2431/2993 (81%)\n",
      "\n",
      "tensor(0.9266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.0\tLoss: 0.926623\n",
      "tensor(0.8966, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.2\tLoss: 0.896589\n",
      "tensor(0.9512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.4\tLoss: 0.951175\n",
      "tensor(0.9772, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.6\tLoss: 0.977175\n",
      "tensor(0.8868, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.8\tLoss: 0.886820\n",
      "\n",
      "Test Epoch: 436\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 436\tmaintain_Accuracy: 2449/2993 (82%)\n",
      "\n",
      "tensor(1.0026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.0\tLoss: 1.002579\n",
      "tensor(0.7689, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.2\tLoss: 0.768913\n",
      "tensor(0.9037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.4\tLoss: 0.903658\n",
      "tensor(0.8619, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.6\tLoss: 0.861917\n",
      "tensor(1.0136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.8\tLoss: 1.013605\n",
      "\n",
      "Test Epoch: 437\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 437\tmaintain_Accuracy: 2438/2993 (81%)\n",
      "\n",
      "tensor(0.8539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.0\tLoss: 0.853913\n",
      "tensor(0.8650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.2\tLoss: 0.864999\n",
      "tensor(1.0638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.4\tLoss: 1.063830\n",
      "tensor(0.9448, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.6\tLoss: 0.944789\n",
      "tensor(0.9967, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.8\tLoss: 0.996734\n",
      "\n",
      "Test Epoch: 438\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 438\tmaintain_Accuracy: 2429/2993 (81%)\n",
      "\n",
      "tensor(0.9540, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.0\tLoss: 0.954030\n",
      "tensor(0.9188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.2\tLoss: 0.918780\n",
      "tensor(0.9346, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.4\tLoss: 0.934608\n",
      "tensor(1.0284, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.6\tLoss: 1.028362\n",
      "tensor(0.9093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.8\tLoss: 0.909317\n",
      "\n",
      "Test Epoch: 439\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 439\tmaintain_Accuracy: 2447/2993 (82%)\n",
      "\n",
      "tensor(0.9104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.0\tLoss: 0.910360\n",
      "tensor(0.9033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.2\tLoss: 0.903253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.4\tLoss: 0.950698\n",
      "tensor(0.7907, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.6\tLoss: 0.790696\n",
      "tensor(1.0186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.8\tLoss: 1.018578\n",
      "\n",
      "Train Epoch: 440\tAttack_Accuracy: 10605/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 440\tmaintain_Accuracy: 10461/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 440\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 440\tmaintain_Accuracy: 2450/2993 (82%)\n",
      "\n",
      "tensor(1.0323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.0\tLoss: 1.032304\n",
      "tensor(0.8576, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.2\tLoss: 0.857604\n",
      "tensor(0.8717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.4\tLoss: 0.871743\n",
      "tensor(1.0154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.6\tLoss: 1.015388\n",
      "tensor(0.9203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.8\tLoss: 0.920311\n",
      "\n",
      "Test Epoch: 441\tAttack_Accuracy: 346/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 441\tmaintain_Accuracy: 2435/2993 (81%)\n",
      "\n",
      "tensor(0.8376, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.0\tLoss: 0.837588\n",
      "tensor(0.9170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.2\tLoss: 0.917009\n",
      "tensor(0.9268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.4\tLoss: 0.926758\n",
      "tensor(1.0370, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.6\tLoss: 1.037008\n",
      "tensor(0.8551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.8\tLoss: 0.855143\n",
      "\n",
      "Test Epoch: 442\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 442\tmaintain_Accuracy: 2452/2993 (82%)\n",
      "\n",
      "tensor(0.9094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.0\tLoss: 0.909440\n",
      "tensor(1.0516, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.2\tLoss: 1.051599\n",
      "tensor(0.7943, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.4\tLoss: 0.794292\n",
      "tensor(1.0496, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.6\tLoss: 1.049620\n",
      "tensor(0.9375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.8\tLoss: 0.937477\n",
      "\n",
      "Test Epoch: 443\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 443\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(0.8363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.0\tLoss: 0.836283\n",
      "tensor(0.9058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.2\tLoss: 0.905804\n",
      "tensor(0.9878, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.4\tLoss: 0.987783\n",
      "tensor(1.0425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.6\tLoss: 1.042534\n",
      "tensor(0.8614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.8\tLoss: 0.861422\n",
      "\n",
      "Test Epoch: 444\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 444\tmaintain_Accuracy: 2434/2993 (81%)\n",
      "\n",
      "tensor(0.8390, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.0\tLoss: 0.838954\n",
      "tensor(0.8941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.2\tLoss: 0.894143\n",
      "tensor(0.9811, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.4\tLoss: 0.981091\n",
      "tensor(0.8939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.6\tLoss: 0.893895\n",
      "tensor(0.8826, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.8\tLoss: 0.882581\n",
      "\n",
      "Train Epoch: 445\tAttack_Accuracy: 10795/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 445\tmaintain_Accuracy: 10369/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 445\tAttack_Accuracy: 347/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 445\tmaintain_Accuracy: 2418/2993 (81%)\n",
      "\n",
      "tensor(0.8333, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.0\tLoss: 0.833290\n",
      "tensor(0.8877, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.2\tLoss: 0.887711\n",
      "tensor(1.0379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.4\tLoss: 1.037909\n",
      "tensor(1.0162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.6\tLoss: 1.016199\n",
      "tensor(1.0113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.8\tLoss: 1.011326\n",
      "\n",
      "Test Epoch: 446\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 446\tmaintain_Accuracy: 2443/2993 (82%)\n",
      "\n",
      "tensor(0.8972, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.0\tLoss: 0.897168\n",
      "tensor(1.0805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.2\tLoss: 1.080479\n",
      "tensor(0.8712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.4\tLoss: 0.871201\n",
      "tensor(0.9389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.6\tLoss: 0.938921\n",
      "tensor(0.9271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.8\tLoss: 0.927061\n",
      "\n",
      "Test Epoch: 447\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 447\tmaintain_Accuracy: 2441/2993 (82%)\n",
      "\n",
      "tensor(0.9854, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.0\tLoss: 0.985401\n",
      "tensor(0.9533, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.2\tLoss: 0.953288\n",
      "tensor(0.9089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.4\tLoss: 0.908892\n",
      "tensor(0.9580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.6\tLoss: 0.957961\n",
      "tensor(0.8939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.8\tLoss: 0.893933\n",
      "\n",
      "Test Epoch: 448\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 448\tmaintain_Accuracy: 2418/2993 (81%)\n",
      "\n",
      "tensor(1.0357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.0\tLoss: 1.035734\n",
      "tensor(0.9827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.2\tLoss: 0.982708\n",
      "tensor(0.9880, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.4\tLoss: 0.988047\n",
      "tensor(0.9114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.6\tLoss: 0.911410\n",
      "tensor(0.8778, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.8\tLoss: 0.877758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 449\tAttack_Accuracy: 347/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 449\tmaintain_Accuracy: 2417/2993 (81%)\n",
      "\n",
      "tensor(0.8730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.0\tLoss: 0.872981\n",
      "tensor(1.0307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.2\tLoss: 1.030663\n",
      "tensor(0.9727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.4\tLoss: 0.972667\n",
      "tensor(1.0313, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.6\tLoss: 1.031291\n",
      "tensor(0.8904, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.8\tLoss: 0.890395\n",
      "\n",
      "Train Epoch: 450\tAttack_Accuracy: 10670/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 450\tmaintain_Accuracy: 10318/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 450\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 450\tmaintain_Accuracy: 2442/2993 (82%)\n",
      "\n",
      "tensor(0.8802, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.0\tLoss: 0.880207\n",
      "tensor(0.8358, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.2\tLoss: 0.835833\n",
      "tensor(1.0377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.4\tLoss: 1.037705\n",
      "tensor(0.9394, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.6\tLoss: 0.939356\n",
      "tensor(0.9544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.8\tLoss: 0.954382\n",
      "\n",
      "Test Epoch: 451\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 451\tmaintain_Accuracy: 2449/2993 (82%)\n",
      "\n",
      "tensor(0.8906, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.0\tLoss: 0.890641\n",
      "tensor(0.9873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.2\tLoss: 0.987305\n",
      "tensor(1.2288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.4\tLoss: 1.228767\n",
      "tensor(0.9480, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.6\tLoss: 0.947965\n",
      "tensor(0.9537, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.8\tLoss: 0.953655\n",
      "\n",
      "Test Epoch: 452\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 452\tmaintain_Accuracy: 2452/2993 (82%)\n",
      "\n",
      "tensor(0.8795, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.0\tLoss: 0.879547\n",
      "tensor(0.8222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.2\tLoss: 0.822229\n",
      "tensor(0.9155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.4\tLoss: 0.915491\n",
      "tensor(0.8595, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.6\tLoss: 0.859452\n",
      "tensor(0.9291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.8\tLoss: 0.929114\n",
      "\n",
      "Test Epoch: 453\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 453\tmaintain_Accuracy: 2456/2993 (82%)\n",
      "\n",
      "tensor(0.8949, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.0\tLoss: 0.894943\n",
      "tensor(0.8905, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.2\tLoss: 0.890520\n",
      "tensor(0.8838, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.4\tLoss: 0.883777\n",
      "tensor(1.0059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.6\tLoss: 1.005858\n",
      "tensor(0.9939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.8\tLoss: 0.993905\n",
      "\n",
      "Test Epoch: 454\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 454\tmaintain_Accuracy: 2433/2993 (81%)\n",
      "\n",
      "tensor(0.8806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.0\tLoss: 0.880646\n",
      "tensor(0.9043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.2\tLoss: 0.904256\n",
      "tensor(0.8292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.4\tLoss: 0.829241\n",
      "tensor(0.9306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.6\tLoss: 0.930576\n",
      "tensor(0.9797, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.8\tLoss: 0.979670\n",
      "\n",
      "Train Epoch: 455\tAttack_Accuracy: 10737/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 455\tmaintain_Accuracy: 10269/12800 (80%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 455\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 455\tmaintain_Accuracy: 2440/2993 (82%)\n",
      "\n",
      "tensor(1.0224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.0\tLoss: 1.022417\n",
      "tensor(0.9819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.2\tLoss: 0.981891\n",
      "tensor(0.8944, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.4\tLoss: 0.894350\n",
      "tensor(0.9210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.6\tLoss: 0.921034\n",
      "tensor(0.7978, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.8\tLoss: 0.797788\n",
      "\n",
      "Test Epoch: 456\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 456\tmaintain_Accuracy: 2456/2993 (82%)\n",
      "\n",
      "tensor(0.9373, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.0\tLoss: 0.937283\n",
      "tensor(0.9531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.2\tLoss: 0.953087\n",
      "tensor(0.9512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.4\tLoss: 0.951245\n",
      "tensor(0.9751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.6\tLoss: 0.975129\n",
      "tensor(0.9513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.8\tLoss: 0.951316\n",
      "\n",
      "Test Epoch: 457\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 457\tmaintain_Accuracy: 2453/2993 (82%)\n",
      "\n",
      "tensor(0.8232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.0\tLoss: 0.823234\n",
      "tensor(1.0262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.2\tLoss: 1.026220\n",
      "tensor(0.9593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.4\tLoss: 0.959322\n",
      "tensor(0.9329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.6\tLoss: 0.932884\n",
      "tensor(0.9434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.8\tLoss: 0.943399\n",
      "\n",
      "Test Epoch: 458\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 458\tmaintain_Accuracy: 2428/2993 (81%)\n",
      "\n",
      "tensor(0.9453, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.0\tLoss: 0.945314\n",
      "tensor(0.9038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.2\tLoss: 0.903770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.4\tLoss: 0.991205\n",
      "tensor(0.8387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.6\tLoss: 0.838675\n",
      "tensor(0.9591, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.8\tLoss: 0.959135\n",
      "\n",
      "Test Epoch: 459\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 459\tmaintain_Accuracy: 2442/2993 (82%)\n",
      "\n",
      "tensor(0.8843, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.0\tLoss: 0.884255\n",
      "tensor(0.9111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.2\tLoss: 0.911078\n",
      "tensor(0.9472, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.4\tLoss: 0.947172\n",
      "tensor(1.1019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.6\tLoss: 1.101902\n",
      "tensor(1.0585, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.8\tLoss: 1.058467\n",
      "\n",
      "Train Epoch: 460\tAttack_Accuracy: 10732/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 460\tmaintain_Accuracy: 10396/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 460\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 460\tmaintain_Accuracy: 2450/2993 (82%)\n",
      "\n",
      "tensor(0.9686, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.0\tLoss: 0.968591\n",
      "tensor(0.9753, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.2\tLoss: 0.975325\n",
      "tensor(0.8762, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.4\tLoss: 0.876165\n",
      "tensor(0.8480, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.6\tLoss: 0.848036\n",
      "tensor(1.0587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.8\tLoss: 1.058691\n",
      "\n",
      "Test Epoch: 461\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 461\tmaintain_Accuracy: 2448/2993 (82%)\n",
      "\n",
      "tensor(0.8524, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.0\tLoss: 0.852439\n",
      "tensor(0.9882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.2\tLoss: 0.988220\n",
      "tensor(0.9928, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.4\tLoss: 0.992822\n",
      "tensor(0.8918, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.6\tLoss: 0.891821\n",
      "tensor(1.0254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.8\tLoss: 1.025442\n",
      "\n",
      "Test Epoch: 462\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 462\tmaintain_Accuracy: 2433/2993 (81%)\n",
      "\n",
      "tensor(0.9481, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.0\tLoss: 0.948140\n",
      "tensor(0.9060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.2\tLoss: 0.905963\n",
      "tensor(0.9704, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.4\tLoss: 0.970439\n",
      "tensor(0.8913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.6\tLoss: 0.891277\n",
      "tensor(0.9657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.8\tLoss: 0.965712\n",
      "\n",
      "Test Epoch: 463\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 463\tmaintain_Accuracy: 2446/2993 (82%)\n",
      "\n",
      "tensor(0.8218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.0\tLoss: 0.821788\n",
      "tensor(1.1075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.2\tLoss: 1.107544\n",
      "tensor(0.8867, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.4\tLoss: 0.886748\n",
      "tensor(0.8288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.6\tLoss: 0.828782\n",
      "tensor(0.9777, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.8\tLoss: 0.977687\n",
      "\n",
      "Test Epoch: 464\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 464\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(0.8357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.0\tLoss: 0.835736\n",
      "tensor(0.9231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.2\tLoss: 0.923145\n",
      "tensor(1.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.4\tLoss: 1.010367\n",
      "tensor(0.9585, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.6\tLoss: 0.958513\n",
      "tensor(0.9741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.8\tLoss: 0.974115\n",
      "\n",
      "Train Epoch: 465\tAttack_Accuracy: 10588/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 465\tmaintain_Accuracy: 10420/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 465\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 465\tmaintain_Accuracy: 2433/2993 (81%)\n",
      "\n",
      "tensor(0.9829, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.0\tLoss: 0.982863\n",
      "tensor(1.0973, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.2\tLoss: 1.097300\n",
      "tensor(0.8691, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.4\tLoss: 0.869139\n",
      "tensor(1.0320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.6\tLoss: 1.032041\n",
      "tensor(0.8199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.8\tLoss: 0.819947\n",
      "\n",
      "Test Epoch: 466\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 466\tmaintain_Accuracy: 2433/2993 (81%)\n",
      "\n",
      "tensor(0.9554, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.0\tLoss: 0.955444\n",
      "tensor(0.9213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.2\tLoss: 0.921263\n",
      "tensor(0.8668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.4\tLoss: 0.866791\n",
      "tensor(0.9806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.6\tLoss: 0.980624\n",
      "tensor(0.9074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.8\tLoss: 0.907405\n",
      "\n",
      "Test Epoch: 467\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 467\tmaintain_Accuracy: 2449/2993 (82%)\n",
      "\n",
      "tensor(0.9239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.0\tLoss: 0.923923\n",
      "tensor(0.8912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.2\tLoss: 0.891245\n",
      "tensor(0.8459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.4\tLoss: 0.845893\n",
      "tensor(0.9425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.6\tLoss: 0.942542\n",
      "tensor(0.9257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.8\tLoss: 0.925713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 468\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 468\tmaintain_Accuracy: 2444/2993 (82%)\n",
      "\n",
      "tensor(0.8549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.0\tLoss: 0.854908\n",
      "tensor(0.8137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.2\tLoss: 0.813671\n",
      "tensor(1.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.4\tLoss: 1.025043\n",
      "tensor(0.8183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.6\tLoss: 0.818323\n",
      "tensor(0.8471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.8\tLoss: 0.847122\n",
      "\n",
      "Test Epoch: 469\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 469\tmaintain_Accuracy: 2437/2993 (81%)\n",
      "\n",
      "tensor(0.9929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.0\tLoss: 0.992919\n",
      "tensor(0.9739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.2\tLoss: 0.973928\n",
      "tensor(1.0806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.4\tLoss: 1.080646\n",
      "tensor(0.9527, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.6\tLoss: 0.952718\n",
      "tensor(0.8946, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.8\tLoss: 0.894618\n",
      "\n",
      "Train Epoch: 470\tAttack_Accuracy: 10709/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 470\tmaintain_Accuracy: 10368/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 470\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 470\tmaintain_Accuracy: 2445/2993 (82%)\n",
      "\n",
      "tensor(1.0436, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.0\tLoss: 1.043566\n",
      "tensor(0.8861, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.2\tLoss: 0.886071\n",
      "tensor(0.9472, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.4\tLoss: 0.947202\n",
      "tensor(0.9954, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.6\tLoss: 0.995382\n",
      "tensor(0.8610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.8\tLoss: 0.860967\n",
      "\n",
      "Test Epoch: 471\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 471\tmaintain_Accuracy: 2453/2993 (82%)\n",
      "\n",
      "tensor(1.0207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.0\tLoss: 1.020748\n",
      "tensor(0.9317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.2\tLoss: 0.931725\n",
      "tensor(0.9109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.4\tLoss: 0.910926\n",
      "tensor(0.9149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.6\tLoss: 0.914873\n",
      "tensor(0.9117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.8\tLoss: 0.911721\n",
      "\n",
      "Test Epoch: 472\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 472\tmaintain_Accuracy: 2452/2993 (82%)\n",
      "\n",
      "tensor(0.9810, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.0\tLoss: 0.980970\n",
      "tensor(0.8727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.2\tLoss: 0.872699\n",
      "tensor(0.9091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.4\tLoss: 0.909068\n",
      "tensor(1.2192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.6\tLoss: 1.219179\n",
      "tensor(1.1181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.8\tLoss: 1.118085\n",
      "\n",
      "Test Epoch: 473\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 473\tmaintain_Accuracy: 2443/2993 (82%)\n",
      "\n",
      "tensor(0.8512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.0\tLoss: 0.851170\n",
      "tensor(0.9101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.2\tLoss: 0.910110\n",
      "tensor(0.8981, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.4\tLoss: 0.898111\n",
      "tensor(0.8673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.6\tLoss: 0.867265\n",
      "tensor(1.0036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.8\tLoss: 1.003624\n",
      "\n",
      "Test Epoch: 474\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 474\tmaintain_Accuracy: 2455/2993 (82%)\n",
      "\n",
      "tensor(0.9654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.0\tLoss: 0.965449\n",
      "tensor(0.7743, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.2\tLoss: 0.774260\n",
      "tensor(0.9235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.4\tLoss: 0.923545\n",
      "tensor(0.8721, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.6\tLoss: 0.872102\n",
      "tensor(1.0201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.8\tLoss: 1.020125\n",
      "\n",
      "Train Epoch: 475\tAttack_Accuracy: 10657/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 475\tmaintain_Accuracy: 10380/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 475\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 475\tmaintain_Accuracy: 2454/2993 (82%)\n",
      "\n",
      "tensor(0.9699, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.0\tLoss: 0.969866\n",
      "tensor(0.9299, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.2\tLoss: 0.929878\n",
      "tensor(0.9707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.4\tLoss: 0.970651\n",
      "tensor(0.9029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.6\tLoss: 0.902897\n",
      "tensor(1.1583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.8\tLoss: 1.158347\n",
      "\n",
      "Test Epoch: 476\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 476\tmaintain_Accuracy: 2439/2993 (81%)\n",
      "\n",
      "tensor(0.8090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.0\tLoss: 0.808965\n",
      "tensor(0.9044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.2\tLoss: 0.904433\n",
      "tensor(0.9806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.4\tLoss: 0.980618\n",
      "tensor(0.7838, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.6\tLoss: 0.783806\n",
      "tensor(0.9599, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.8\tLoss: 0.959854\n",
      "\n",
      "Test Epoch: 477\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 477\tmaintain_Accuracy: 2442/2993 (82%)\n",
      "\n",
      "tensor(0.8345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.0\tLoss: 0.834509\n",
      "tensor(0.8895, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.2\tLoss: 0.889473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.4\tLoss: 0.960142\n",
      "tensor(1.0648, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.6\tLoss: 1.064841\n",
      "tensor(0.9945, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.8\tLoss: 0.994479\n",
      "\n",
      "Test Epoch: 478\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 478\tmaintain_Accuracy: 2453/2993 (82%)\n",
      "\n",
      "tensor(1.0320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.0\tLoss: 1.031966\n",
      "tensor(0.9723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.2\tLoss: 0.972280\n",
      "tensor(1.0513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.4\tLoss: 1.051314\n",
      "tensor(0.9300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.6\tLoss: 0.929997\n",
      "tensor(0.9439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.8\tLoss: 0.943934\n",
      "\n",
      "Test Epoch: 479\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 479\tmaintain_Accuracy: 2446/2993 (82%)\n",
      "\n",
      "tensor(0.9322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.0\tLoss: 0.932217\n",
      "tensor(0.8085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.2\tLoss: 0.808509\n",
      "tensor(0.8827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.4\tLoss: 0.882664\n",
      "tensor(0.8395, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.6\tLoss: 0.839461\n",
      "tensor(0.9238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.8\tLoss: 0.923836\n",
      "\n",
      "Train Epoch: 480\tAttack_Accuracy: 10704/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 480\tmaintain_Accuracy: 10391/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 480\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 480\tmaintain_Accuracy: 2444/2993 (82%)\n",
      "\n",
      "tensor(0.8436, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.0\tLoss: 0.843606\n",
      "tensor(0.9314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.2\tLoss: 0.931400\n",
      "tensor(0.8827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.4\tLoss: 0.882749\n",
      "tensor(0.9986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.6\tLoss: 0.998591\n",
      "tensor(0.8947, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.8\tLoss: 0.894694\n",
      "\n",
      "Test Epoch: 481\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 481\tmaintain_Accuracy: 2448/2993 (82%)\n",
      "\n",
      "tensor(0.7951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.0\tLoss: 0.795054\n",
      "tensor(0.7740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.2\tLoss: 0.773957\n",
      "tensor(0.8898, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.4\tLoss: 0.889833\n",
      "tensor(0.9898, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.6\tLoss: 0.989764\n",
      "tensor(0.8181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.8\tLoss: 0.818092\n",
      "\n",
      "Test Epoch: 482\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 482\tmaintain_Accuracy: 2448/2993 (82%)\n",
      "\n",
      "tensor(0.8728, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.0\tLoss: 0.872831\n",
      "tensor(0.9225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.2\tLoss: 0.922528\n",
      "tensor(0.9065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.4\tLoss: 0.906471\n",
      "tensor(0.9750, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.6\tLoss: 0.975014\n",
      "tensor(0.9309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.8\tLoss: 0.930889\n",
      "\n",
      "Test Epoch: 483\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 483\tmaintain_Accuracy: 2441/2993 (82%)\n",
      "\n",
      "tensor(0.9186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.0\tLoss: 0.918571\n",
      "tensor(0.8795, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.2\tLoss: 0.879519\n",
      "tensor(0.9249, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.4\tLoss: 0.924929\n",
      "tensor(0.8948, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.6\tLoss: 0.894805\n",
      "tensor(0.9306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.8\tLoss: 0.930635\n",
      "\n",
      "Test Epoch: 484\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 484\tmaintain_Accuracy: 2450/2993 (82%)\n",
      "\n",
      "tensor(0.8500, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.0\tLoss: 0.850026\n",
      "tensor(0.8792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.2\tLoss: 0.879198\n",
      "tensor(0.9778, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.4\tLoss: 0.977790\n",
      "tensor(0.8076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.6\tLoss: 0.807566\n",
      "tensor(1.0146, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.8\tLoss: 1.014607\n",
      "\n",
      "Train Epoch: 485\tAttack_Accuracy: 10724/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 485\tmaintain_Accuracy: 10411/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 485\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 485\tmaintain_Accuracy: 2446/2993 (82%)\n",
      "\n",
      "tensor(1.0478, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.0\tLoss: 1.047778\n",
      "tensor(0.9425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.2\tLoss: 0.942498\n",
      "tensor(0.8818, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.4\tLoss: 0.881810\n",
      "tensor(1.0020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.6\tLoss: 1.001957\n",
      "tensor(0.8790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.8\tLoss: 0.878967\n",
      "\n",
      "Test Epoch: 486\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 486\tmaintain_Accuracy: 2449/2993 (82%)\n",
      "\n",
      "tensor(1.0177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.0\tLoss: 1.017663\n",
      "tensor(0.9404, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.2\tLoss: 0.940421\n",
      "tensor(0.8749, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.4\tLoss: 0.874873\n",
      "tensor(0.9761, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.6\tLoss: 0.976068\n",
      "tensor(0.9569, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.8\tLoss: 0.956949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 487\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 487\tmaintain_Accuracy: 2450/2993 (82%)\n",
      "\n",
      "tensor(0.9757, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.0\tLoss: 0.975666\n",
      "tensor(1.0130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.2\tLoss: 1.012981\n",
      "tensor(0.8405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.4\tLoss: 0.840504\n",
      "tensor(0.8770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.6\tLoss: 0.876976\n",
      "tensor(0.9606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.8\tLoss: 0.960641\n",
      "\n",
      "Test Epoch: 488\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 488\tmaintain_Accuracy: 2444/2993 (82%)\n",
      "\n",
      "tensor(0.9247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.0\tLoss: 0.924749\n",
      "tensor(0.8629, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.2\tLoss: 0.862910\n",
      "tensor(0.8926, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.4\tLoss: 0.892590\n",
      "tensor(1.0195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.6\tLoss: 1.019512\n",
      "tensor(1.0702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.8\tLoss: 1.070249\n",
      "\n",
      "Test Epoch: 489\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 489\tmaintain_Accuracy: 2449/2993 (82%)\n",
      "\n",
      "tensor(0.8578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.0\tLoss: 0.857802\n",
      "tensor(0.8539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.2\tLoss: 0.853862\n",
      "tensor(0.8035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.4\tLoss: 0.803509\n",
      "tensor(0.8672, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.6\tLoss: 0.867217\n",
      "tensor(0.9717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.8\tLoss: 0.971749\n",
      "\n",
      "Train Epoch: 490\tAttack_Accuracy: 10682/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 490\tmaintain_Accuracy: 10406/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 490\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 490\tmaintain_Accuracy: 2449/2993 (82%)\n",
      "\n",
      "tensor(0.8427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.0\tLoss: 0.842677\n",
      "tensor(1.0430, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.2\tLoss: 1.043023\n",
      "tensor(0.9220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.4\tLoss: 0.922016\n",
      "tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.6\tLoss: 0.927323\n",
      "tensor(0.9156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.8\tLoss: 0.915640\n",
      "\n",
      "Test Epoch: 491\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 491\tmaintain_Accuracy: 2442/2993 (82%)\n",
      "\n",
      "tensor(1.0174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.0\tLoss: 1.017429\n",
      "tensor(0.8965, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.2\tLoss: 0.896461\n",
      "tensor(0.9195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.4\tLoss: 0.919541\n",
      "tensor(0.8921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.6\tLoss: 0.892138\n",
      "tensor(1.0618, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.8\tLoss: 1.061766\n",
      "\n",
      "Test Epoch: 492\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 492\tmaintain_Accuracy: 2430/2993 (81%)\n",
      "\n",
      "tensor(0.8273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.0\tLoss: 0.827340\n",
      "tensor(1.1103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.2\tLoss: 1.110334\n",
      "tensor(0.8587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.4\tLoss: 0.858670\n",
      "tensor(0.9112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.6\tLoss: 0.911151\n",
      "tensor(0.8727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.8\tLoss: 0.872681\n",
      "\n",
      "Test Epoch: 493\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 493\tmaintain_Accuracy: 2451/2993 (82%)\n",
      "\n",
      "tensor(0.9117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.0\tLoss: 0.911719\n",
      "tensor(0.9709, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.2\tLoss: 0.970931\n",
      "tensor(0.8894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.4\tLoss: 0.889371\n",
      "tensor(0.8115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.6\tLoss: 0.811524\n",
      "tensor(0.8498, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.8\tLoss: 0.849838\n",
      "\n",
      "Test Epoch: 494\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 494\tmaintain_Accuracy: 2448/2993 (82%)\n",
      "\n",
      "tensor(0.8865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.0\tLoss: 0.886544\n",
      "tensor(0.9251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.2\tLoss: 0.925111\n",
      "tensor(0.8697, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.4\tLoss: 0.869729\n",
      "tensor(0.9524, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.6\tLoss: 0.952356\n",
      "tensor(0.9069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.8\tLoss: 0.906911\n",
      "\n",
      "Train Epoch: 495\tAttack_Accuracy: 10687/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 495\tmaintain_Accuracy: 10475/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 495\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 495\tmaintain_Accuracy: 2438/2993 (81%)\n",
      "\n",
      "tensor(0.8783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.0\tLoss: 0.878250\n",
      "tensor(0.9474, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.2\tLoss: 0.947385\n",
      "tensor(0.9670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.4\tLoss: 0.966976\n",
      "tensor(1.0171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.6\tLoss: 1.017051\n",
      "tensor(1.0001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.8\tLoss: 1.000138\n",
      "\n",
      "Test Epoch: 496\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 496\tmaintain_Accuracy: 2444/2993 (82%)\n",
      "\n",
      "tensor(0.9912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.0\tLoss: 0.991246\n",
      "tensor(1.0512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.2\tLoss: 1.051207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.4\tLoss: 0.791224\n",
      "tensor(0.8674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.6\tLoss: 0.867404\n",
      "tensor(0.8696, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.8\tLoss: 0.869568\n",
      "\n",
      "Test Epoch: 497\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 497\tmaintain_Accuracy: 2452/2993 (82%)\n",
      "\n",
      "tensor(0.8690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.0\tLoss: 0.868984\n",
      "tensor(0.8853, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.2\tLoss: 0.885299\n",
      "tensor(0.9144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.4\tLoss: 0.914359\n",
      "tensor(0.8733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.6\tLoss: 0.873308\n",
      "tensor(0.8839, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.8\tLoss: 0.883950\n",
      "\n",
      "Test Epoch: 498\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 498\tmaintain_Accuracy: 2441/2993 (82%)\n",
      "\n",
      "tensor(0.8941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.0\tLoss: 0.894119\n",
      "tensor(0.9109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.2\tLoss: 0.910899\n",
      "tensor(0.9023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.4\tLoss: 0.902287\n",
      "tensor(0.8682, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.6\tLoss: 0.868235\n",
      "tensor(0.9442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.8\tLoss: 0.944177\n",
      "\n",
      "Test Epoch: 499\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 499\tmaintain_Accuracy: 2456/2993 (82%)\n",
      "\n",
      "tensor(0.8207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.0\tLoss: 0.820734\n",
      "tensor(0.9970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.2\tLoss: 0.996976\n",
      "tensor(0.9155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.4\tLoss: 0.915495\n",
      "tensor(0.8288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.6\tLoss: 0.828820\n",
      "tensor(1.0005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.8\tLoss: 1.000461\n",
      "\n",
      "Train Epoch: 500\tAttack_Accuracy: 10737/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 500\tmaintain_Accuracy: 10474/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 500\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 500\tmaintain_Accuracy: 2450/2993 (82%)\n",
      "\n",
      "tensor(0.9352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.0\tLoss: 0.935178\n",
      "tensor(0.9759, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.2\tLoss: 0.975934\n",
      "tensor(0.9188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.4\tLoss: 0.918826\n",
      "tensor(1.0007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.6\tLoss: 1.000745\n",
      "tensor(0.8393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.8\tLoss: 0.839339\n",
      "\n",
      "Test Epoch: 501\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 501\tmaintain_Accuracy: 2455/2993 (82%)\n",
      "\n",
      "tensor(0.9433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.0\tLoss: 0.943318\n",
      "tensor(0.7694, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.2\tLoss: 0.769371\n",
      "tensor(0.8982, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.4\tLoss: 0.898158\n",
      "tensor(1.0848, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.6\tLoss: 1.084825\n",
      "tensor(1.0489, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.8\tLoss: 1.048948\n",
      "\n",
      "Test Epoch: 502\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 502\tmaintain_Accuracy: 2459/2993 (82%)\n",
      "\n",
      "tensor(0.8378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.0\tLoss: 0.837754\n",
      "tensor(0.8707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.2\tLoss: 0.870732\n",
      "tensor(1.0056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.4\tLoss: 1.005551\n",
      "tensor(0.8445, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.6\tLoss: 0.844528\n",
      "tensor(1.1121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.8\tLoss: 1.112138\n",
      "\n",
      "Test Epoch: 503\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 503\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(0.9154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.0\tLoss: 0.915407\n",
      "tensor(0.8270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.2\tLoss: 0.827026\n",
      "tensor(0.8747, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.4\tLoss: 0.874703\n",
      "tensor(0.8356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.6\tLoss: 0.835599\n",
      "tensor(0.9270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.8\tLoss: 0.927007\n",
      "\n",
      "Test Epoch: 504\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 504\tmaintain_Accuracy: 2459/2993 (82%)\n",
      "\n",
      "tensor(0.9195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.0\tLoss: 0.919503\n",
      "tensor(0.8912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.2\tLoss: 0.891162\n",
      "tensor(1.0977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.4\tLoss: 1.097697\n",
      "tensor(0.8339, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.6\tLoss: 0.833883\n",
      "tensor(0.8115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.8\tLoss: 0.811519\n",
      "\n",
      "Train Epoch: 505\tAttack_Accuracy: 10688/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 505\tmaintain_Accuracy: 10436/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 505\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 505\tmaintain_Accuracy: 2462/2993 (82%)\n",
      "\n",
      "tensor(0.9323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.0\tLoss: 0.932263\n",
      "tensor(0.8723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.2\tLoss: 0.872325\n",
      "tensor(0.9494, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.4\tLoss: 0.949433\n",
      "tensor(0.7939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.6\tLoss: 0.793886\n",
      "tensor(0.9470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.8\tLoss: 0.946966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 506\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 506\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.9243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.0\tLoss: 0.924350\n",
      "tensor(0.7895, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.2\tLoss: 0.789522\n",
      "tensor(1.0755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.4\tLoss: 1.075489\n",
      "tensor(0.8659, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.6\tLoss: 0.865862\n",
      "tensor(1.0075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.8\tLoss: 1.007508\n",
      "\n",
      "Test Epoch: 507\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 507\tmaintain_Accuracy: 2459/2993 (82%)\n",
      "\n",
      "tensor(0.9924, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.0\tLoss: 0.992433\n",
      "tensor(0.9960, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.2\tLoss: 0.996007\n",
      "tensor(0.8445, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.4\tLoss: 0.844484\n",
      "tensor(0.8740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.6\tLoss: 0.874030\n",
      "tensor(0.8807, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.8\tLoss: 0.880703\n",
      "\n",
      "Test Epoch: 508\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 508\tmaintain_Accuracy: 2451/2993 (82%)\n",
      "\n",
      "tensor(1.0753, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.0\tLoss: 1.075348\n",
      "tensor(0.9741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.2\tLoss: 0.974128\n",
      "tensor(0.7908, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.4\tLoss: 0.790819\n",
      "tensor(1.0922, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.6\tLoss: 1.092159\n",
      "tensor(1.0387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.8\tLoss: 1.038747\n",
      "\n",
      "Test Epoch: 509\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 509\tmaintain_Accuracy: 2456/2993 (82%)\n",
      "\n",
      "tensor(0.9771, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.0\tLoss: 0.977119\n",
      "tensor(1.0651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.2\tLoss: 1.065145\n",
      "tensor(0.8074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.4\tLoss: 0.807407\n",
      "tensor(0.7701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.6\tLoss: 0.770062\n",
      "tensor(0.8256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.8\tLoss: 0.825640\n",
      "\n",
      "Train Epoch: 510\tAttack_Accuracy: 10729/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 510\tmaintain_Accuracy: 10374/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 510\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 510\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(0.8567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.0\tLoss: 0.856704\n",
      "tensor(0.9639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.2\tLoss: 0.963917\n",
      "tensor(0.9427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.4\tLoss: 0.942698\n",
      "tensor(0.9009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.6\tLoss: 0.900873\n",
      "tensor(0.9410, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.8\tLoss: 0.940979\n",
      "\n",
      "Test Epoch: 511\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 511\tmaintain_Accuracy: 2456/2993 (82%)\n",
      "\n",
      "tensor(0.8194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.0\tLoss: 0.819417\n",
      "tensor(0.9516, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.2\tLoss: 0.951570\n",
      "tensor(0.8001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.4\tLoss: 0.800058\n",
      "tensor(0.8126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.6\tLoss: 0.812638\n",
      "tensor(1.0083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.8\tLoss: 1.008340\n",
      "\n",
      "Test Epoch: 512\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 512\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.9305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.0\tLoss: 0.930497\n",
      "tensor(0.8284, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.2\tLoss: 0.828446\n",
      "tensor(0.8816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.4\tLoss: 0.881638\n",
      "tensor(0.9417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.6\tLoss: 0.941663\n",
      "tensor(0.7841, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.8\tLoss: 0.784119\n",
      "\n",
      "Test Epoch: 513\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 513\tmaintain_Accuracy: 2452/2993 (82%)\n",
      "\n",
      "tensor(0.8122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.0\tLoss: 0.812226\n",
      "tensor(0.8995, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.2\tLoss: 0.899472\n",
      "tensor(0.7994, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.4\tLoss: 0.799448\n",
      "tensor(0.8670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.6\tLoss: 0.866961\n",
      "tensor(0.9291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.8\tLoss: 0.929083\n",
      "\n",
      "Test Epoch: 514\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 514\tmaintain_Accuracy: 2449/2993 (82%)\n",
      "\n",
      "tensor(0.9821, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.0\tLoss: 0.982137\n",
      "tensor(0.9484, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.2\tLoss: 0.948389\n",
      "tensor(0.9230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.4\tLoss: 0.922962\n",
      "tensor(0.8689, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.6\tLoss: 0.868888\n",
      "tensor(1.0052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.8\tLoss: 1.005226\n",
      "\n",
      "Train Epoch: 515\tAttack_Accuracy: 10744/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 515\tmaintain_Accuracy: 10403/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 515\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 515\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(0.7509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.0\tLoss: 0.750893\n",
      "tensor(0.7809, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.2\tLoss: 0.780904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8677, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.4\tLoss: 0.867727\n",
      "tensor(0.9108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.6\tLoss: 0.910781\n",
      "tensor(0.7943, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.8\tLoss: 0.794338\n",
      "\n",
      "Test Epoch: 516\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 516\tmaintain_Accuracy: 2456/2993 (82%)\n",
      "\n",
      "tensor(0.9271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.0\tLoss: 0.927123\n",
      "tensor(0.9008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.2\tLoss: 0.900776\n",
      "tensor(1.0643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.4\tLoss: 1.064306\n",
      "tensor(0.8711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.6\tLoss: 0.871100\n",
      "tensor(0.8694, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.8\tLoss: 0.869373\n",
      "\n",
      "Test Epoch: 517\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 517\tmaintain_Accuracy: 2459/2993 (82%)\n",
      "\n",
      "tensor(0.9667, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.0\tLoss: 0.966733\n",
      "tensor(1.0419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.2\tLoss: 1.041873\n",
      "tensor(0.8502, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.4\tLoss: 0.850224\n",
      "tensor(1.0476, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.6\tLoss: 1.047618\n",
      "tensor(0.8411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.8\tLoss: 0.841144\n",
      "\n",
      "Test Epoch: 518\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 518\tmaintain_Accuracy: 2458/2993 (82%)\n",
      "\n",
      "tensor(1.0761, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.0\tLoss: 1.076056\n",
      "tensor(0.9259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.2\tLoss: 0.925873\n",
      "tensor(0.8786, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.4\tLoss: 0.878613\n",
      "tensor(0.8292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.6\tLoss: 0.829205\n",
      "tensor(0.9209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.8\tLoss: 0.920918\n",
      "\n",
      "Test Epoch: 519\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 519\tmaintain_Accuracy: 2448/2993 (82%)\n",
      "\n",
      "tensor(0.8076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.0\tLoss: 0.807552\n",
      "tensor(0.8681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.2\tLoss: 0.868051\n",
      "tensor(0.8417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.4\tLoss: 0.841702\n",
      "tensor(0.9928, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.6\tLoss: 0.992756\n",
      "tensor(0.8202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.8\tLoss: 0.820247\n",
      "\n",
      "Train Epoch: 520\tAttack_Accuracy: 10660/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 520\tmaintain_Accuracy: 10393/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 520\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 520\tmaintain_Accuracy: 2459/2993 (82%)\n",
      "\n",
      "tensor(0.7380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.0\tLoss: 0.737975\n",
      "tensor(0.9689, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.2\tLoss: 0.968894\n",
      "tensor(0.9811, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.4\tLoss: 0.981131\n",
      "tensor(0.9683, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.6\tLoss: 0.968326\n",
      "tensor(0.9417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.8\tLoss: 0.941719\n",
      "\n",
      "Test Epoch: 521\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 521\tmaintain_Accuracy: 2472/2993 (83%)\n",
      "\n",
      "tensor(0.9557, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.0\tLoss: 0.955687\n",
      "tensor(0.8999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.2\tLoss: 0.899941\n",
      "tensor(0.9454, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.4\tLoss: 0.945385\n",
      "tensor(0.8916, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.6\tLoss: 0.891630\n",
      "tensor(1.0297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.8\tLoss: 1.029709\n",
      "\n",
      "Test Epoch: 522\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 522\tmaintain_Accuracy: 2456/2993 (82%)\n",
      "\n",
      "tensor(0.8395, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.0\tLoss: 0.839457\n",
      "tensor(0.8158, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.2\tLoss: 0.815817\n",
      "tensor(1.0512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.4\tLoss: 1.051221\n",
      "tensor(0.9276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.6\tLoss: 0.927557\n",
      "tensor(0.8842, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.8\tLoss: 0.884229\n",
      "\n",
      "Test Epoch: 523\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 523\tmaintain_Accuracy: 2444/2993 (82%)\n",
      "\n",
      "tensor(0.8320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.0\tLoss: 0.831961\n",
      "tensor(0.9057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.2\tLoss: 0.905678\n",
      "tensor(0.8237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.4\tLoss: 0.823659\n",
      "tensor(0.9151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.6\tLoss: 0.915103\n",
      "tensor(0.9118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.8\tLoss: 0.911818\n",
      "\n",
      "Test Epoch: 524\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 524\tmaintain_Accuracy: 2465/2993 (82%)\n",
      "\n",
      "tensor(0.9031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.0\tLoss: 0.903087\n",
      "tensor(1.0081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.2\tLoss: 1.008085\n",
      "tensor(1.0251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.4\tLoss: 1.025096\n",
      "tensor(0.9008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.6\tLoss: 0.900843\n",
      "tensor(0.8183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.8\tLoss: 0.818290\n",
      "\n",
      "Train Epoch: 525\tAttack_Accuracy: 10641/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 525\tmaintain_Accuracy: 10456/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 525\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 525\tmaintain_Accuracy: 2492/2993 (83%)\n",
      "\n",
      "tensor(0.9023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.0\tLoss: 0.902317\n",
      "tensor(0.8894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.2\tLoss: 0.889367\n",
      "tensor(0.9412, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.4\tLoss: 0.941176\n",
      "tensor(0.9292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.6\tLoss: 0.929235\n",
      "tensor(0.8650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.8\tLoss: 0.864962\n",
      "\n",
      "Test Epoch: 526\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 526\tmaintain_Accuracy: 2490/2993 (83%)\n",
      "\n",
      "tensor(0.9509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.0\tLoss: 0.950903\n",
      "tensor(0.9690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.2\tLoss: 0.969038\n",
      "tensor(0.9516, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.4\tLoss: 0.951613\n",
      "tensor(0.9518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.6\tLoss: 0.951815\n",
      "tensor(0.8667, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.8\tLoss: 0.866679\n",
      "\n",
      "Test Epoch: 527\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 527\tmaintain_Accuracy: 2453/2993 (82%)\n",
      "\n",
      "tensor(0.9240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.0\tLoss: 0.923960\n",
      "tensor(1.0866, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.2\tLoss: 1.086609\n",
      "tensor(0.9052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.4\tLoss: 0.905249\n",
      "tensor(0.8855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.6\tLoss: 0.885546\n",
      "tensor(0.8330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.8\tLoss: 0.833030\n",
      "\n",
      "Test Epoch: 528\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 528\tmaintain_Accuracy: 2445/2993 (82%)\n",
      "\n",
      "tensor(0.8701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.0\tLoss: 0.870057\n",
      "tensor(0.9931, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.2\tLoss: 0.993051\n",
      "tensor(1.0027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.4\tLoss: 1.002742\n",
      "tensor(0.8977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.6\tLoss: 0.897680\n",
      "tensor(1.0189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.8\tLoss: 1.018937\n",
      "\n",
      "Test Epoch: 529\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 529\tmaintain_Accuracy: 2465/2993 (82%)\n",
      "\n",
      "tensor(0.7999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.0\tLoss: 0.799947\n",
      "tensor(0.8755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.2\tLoss: 0.875512\n",
      "tensor(0.9173, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.4\tLoss: 0.917329\n",
      "tensor(0.9915, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.6\tLoss: 0.991476\n",
      "tensor(0.9324, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.8\tLoss: 0.932406\n",
      "\n",
      "Train Epoch: 530\tAttack_Accuracy: 10662/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 530\tmaintain_Accuracy: 10446/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 530\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 530\tmaintain_Accuracy: 2465/2993 (82%)\n",
      "\n",
      "tensor(0.9504, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.0\tLoss: 0.950387\n",
      "tensor(0.8447, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.2\tLoss: 0.844685\n",
      "tensor(0.8984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.4\tLoss: 0.898358\n",
      "tensor(1.0575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.6\tLoss: 1.057484\n",
      "tensor(0.9201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.8\tLoss: 0.920124\n",
      "\n",
      "Test Epoch: 531\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 531\tmaintain_Accuracy: 2458/2993 (82%)\n",
      "\n",
      "tensor(1.0490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.0\tLoss: 1.048958\n",
      "tensor(0.9410, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.2\tLoss: 0.941016\n",
      "tensor(0.8204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.4\tLoss: 0.820439\n",
      "tensor(0.8177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.6\tLoss: 0.817732\n",
      "tensor(0.9706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.8\tLoss: 0.970630\n",
      "\n",
      "Test Epoch: 532\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 532\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.9140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.0\tLoss: 0.913958\n",
      "tensor(0.7883, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.2\tLoss: 0.788277\n",
      "tensor(0.7710, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.4\tLoss: 0.770974\n",
      "tensor(0.8826, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.6\tLoss: 0.882630\n",
      "tensor(1.0230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.8\tLoss: 1.023036\n",
      "\n",
      "Test Epoch: 533\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 533\tmaintain_Accuracy: 2472/2993 (83%)\n",
      "\n",
      "tensor(0.9265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.0\tLoss: 0.926512\n",
      "tensor(0.9789, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.2\tLoss: 0.978908\n",
      "tensor(0.7299, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.4\tLoss: 0.729857\n",
      "tensor(0.8752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.6\tLoss: 0.875213\n",
      "tensor(0.8214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.8\tLoss: 0.821416\n",
      "\n",
      "Test Epoch: 534\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 534\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.8979, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.0\tLoss: 0.897913\n",
      "tensor(0.9665, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.2\tLoss: 0.966504\n",
      "tensor(0.7797, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.4\tLoss: 0.779724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9605, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.6\tLoss: 0.960515\n",
      "tensor(0.8970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.8\tLoss: 0.896973\n",
      "\n",
      "Train Epoch: 535\tAttack_Accuracy: 10706/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 535\tmaintain_Accuracy: 10539/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 535\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 535\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.8303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.0\tLoss: 0.830269\n",
      "tensor(0.8776, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.2\tLoss: 0.877607\n",
      "tensor(0.8359, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.4\tLoss: 0.835856\n",
      "tensor(1.0945, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.6\tLoss: 1.094461\n",
      "tensor(0.8335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.8\tLoss: 0.833546\n",
      "\n",
      "Test Epoch: 536\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 536\tmaintain_Accuracy: 2472/2993 (83%)\n",
      "\n",
      "tensor(1.0011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.0\tLoss: 1.001145\n",
      "tensor(0.9091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.2\tLoss: 0.909150\n",
      "tensor(0.8230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.4\tLoss: 0.823002\n",
      "tensor(0.9085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.6\tLoss: 0.908484\n",
      "tensor(0.8984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.8\tLoss: 0.898437\n",
      "\n",
      "Test Epoch: 537\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 537\tmaintain_Accuracy: 2486/2993 (83%)\n",
      "\n",
      "tensor(0.8221, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.0\tLoss: 0.822079\n",
      "tensor(1.0741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.2\tLoss: 1.074072\n",
      "tensor(0.8957, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.4\tLoss: 0.895725\n",
      "tensor(0.7745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.6\tLoss: 0.774468\n",
      "tensor(0.7638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.8\tLoss: 0.763779\n",
      "\n",
      "Test Epoch: 538\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 538\tmaintain_Accuracy: 2482/2993 (83%)\n",
      "\n",
      "tensor(0.9847, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.0\tLoss: 0.984675\n",
      "tensor(0.7550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.2\tLoss: 0.755042\n",
      "tensor(0.9475, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.4\tLoss: 0.947473\n",
      "tensor(0.8450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.6\tLoss: 0.844976\n",
      "tensor(0.9203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.8\tLoss: 0.920339\n",
      "\n",
      "Test Epoch: 539\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 539\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.7597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.0\tLoss: 0.759658\n",
      "tensor(0.8868, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.2\tLoss: 0.886772\n",
      "tensor(0.8728, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.4\tLoss: 0.872813\n",
      "tensor(0.8237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.6\tLoss: 0.823687\n",
      "tensor(0.8436, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.8\tLoss: 0.843585\n",
      "\n",
      "Train Epoch: 540\tAttack_Accuracy: 10621/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 540\tmaintain_Accuracy: 10407/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 540\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 540\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.9263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.0\tLoss: 0.926308\n",
      "tensor(0.7933, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.2\tLoss: 0.793343\n",
      "tensor(0.8944, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.4\tLoss: 0.894367\n",
      "tensor(0.9909, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.6\tLoss: 0.990934\n",
      "tensor(0.7349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.8\tLoss: 0.734858\n",
      "\n",
      "Test Epoch: 541\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 541\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.8723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.0\tLoss: 0.872321\n",
      "tensor(1.0777, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.2\tLoss: 1.077656\n",
      "tensor(0.8659, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.4\tLoss: 0.865905\n",
      "tensor(0.7963, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.6\tLoss: 0.796318\n",
      "tensor(0.8888, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.8\tLoss: 0.888786\n",
      "\n",
      "Test Epoch: 542\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 542\tmaintain_Accuracy: 2468/2993 (82%)\n",
      "\n",
      "tensor(0.8987, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.0\tLoss: 0.898683\n",
      "tensor(0.9198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.2\tLoss: 0.919779\n",
      "tensor(0.9559, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.4\tLoss: 0.955933\n",
      "tensor(0.8672, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.6\tLoss: 0.867247\n",
      "tensor(0.8690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.8\tLoss: 0.868982\n",
      "\n",
      "Test Epoch: 543\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 543\tmaintain_Accuracy: 2468/2993 (82%)\n",
      "\n",
      "tensor(0.9232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.0\tLoss: 0.923178\n",
      "tensor(0.8505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.2\tLoss: 0.850548\n",
      "tensor(1.0018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.4\tLoss: 1.001769\n",
      "tensor(0.9548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.6\tLoss: 0.954840\n",
      "tensor(0.8579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.8\tLoss: 0.857934\n",
      "\n",
      "Test Epoch: 544\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 544\tmaintain_Accuracy: 2463/2993 (82%)\n",
      "\n",
      "tensor(0.8327, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.0\tLoss: 0.832699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8920, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.2\tLoss: 0.892030\n",
      "tensor(0.9680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.4\tLoss: 0.967982\n",
      "tensor(0.9507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.6\tLoss: 0.950697\n",
      "tensor(0.8818, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.8\tLoss: 0.881795\n",
      "\n",
      "Train Epoch: 545\tAttack_Accuracy: 10774/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 545\tmaintain_Accuracy: 10367/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 545\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 545\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(1.0078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.0\tLoss: 1.007783\n",
      "tensor(0.8498, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.2\tLoss: 0.849758\n",
      "tensor(0.9005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.4\tLoss: 0.900528\n",
      "tensor(0.7531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.6\tLoss: 0.753083\n",
      "tensor(0.7750, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.8\tLoss: 0.775029\n",
      "\n",
      "Test Epoch: 546\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 546\tmaintain_Accuracy: 2483/2993 (83%)\n",
      "\n",
      "tensor(0.9293, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.0\tLoss: 0.929347\n",
      "tensor(0.9820, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.2\tLoss: 0.982048\n",
      "tensor(0.9389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.4\tLoss: 0.938862\n",
      "tensor(0.8751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.6\tLoss: 0.875083\n",
      "tensor(0.8673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.8\tLoss: 0.867251\n",
      "\n",
      "Test Epoch: 547\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 547\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.8839, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.0\tLoss: 0.883899\n",
      "tensor(0.9078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.2\tLoss: 0.907828\n",
      "tensor(0.8612, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.4\tLoss: 0.861242\n",
      "tensor(0.8398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.6\tLoss: 0.839844\n",
      "tensor(0.9172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.8\tLoss: 0.917170\n",
      "\n",
      "Test Epoch: 548\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 548\tmaintain_Accuracy: 2467/2993 (82%)\n",
      "\n",
      "tensor(0.8197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.0\tLoss: 0.819679\n",
      "tensor(0.8501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.2\tLoss: 0.850069\n",
      "tensor(0.7708, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.4\tLoss: 0.770832\n",
      "tensor(0.9471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.6\tLoss: 0.947108\n",
      "tensor(0.9368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.8\tLoss: 0.936797\n",
      "\n",
      "Test Epoch: 549\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 549\tmaintain_Accuracy: 2467/2993 (82%)\n",
      "\n",
      "tensor(0.8372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.0\tLoss: 0.837226\n",
      "tensor(0.8704, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.2\tLoss: 0.870374\n",
      "tensor(0.8417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.4\tLoss: 0.841733\n",
      "tensor(0.7713, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.6\tLoss: 0.771329\n",
      "tensor(1.0068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.8\tLoss: 1.006832\n",
      "\n",
      "Train Epoch: 550\tAttack_Accuracy: 10680/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 550\tmaintain_Accuracy: 10477/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 550\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 550\tmaintain_Accuracy: 2477/2993 (83%)\n",
      "\n",
      "tensor(0.8445, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.0\tLoss: 0.844536\n",
      "tensor(1.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.2\tLoss: 1.017948\n",
      "tensor(0.7926, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.4\tLoss: 0.792578\n",
      "tensor(0.8505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.6\tLoss: 0.850475\n",
      "tensor(0.7366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.8\tLoss: 0.736611\n",
      "\n",
      "Test Epoch: 551\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 551\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.7378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.0\tLoss: 0.737844\n",
      "tensor(0.9688, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.2\tLoss: 0.968752\n",
      "tensor(0.8740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.4\tLoss: 0.874043\n",
      "tensor(0.9326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.6\tLoss: 0.932637\n",
      "tensor(0.8738, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.8\tLoss: 0.873789\n",
      "\n",
      "Test Epoch: 552\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 552\tmaintain_Accuracy: 2459/2993 (82%)\n",
      "\n",
      "tensor(0.9376, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.0\tLoss: 0.937647\n",
      "tensor(0.8101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.2\tLoss: 0.810092\n",
      "tensor(0.7565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.4\tLoss: 0.756549\n",
      "tensor(0.8228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.6\tLoss: 0.822766\n",
      "tensor(0.9150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.8\tLoss: 0.915042\n",
      "\n",
      "Test Epoch: 553\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 553\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.9879, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.0\tLoss: 0.987907\n",
      "tensor(0.8491, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.2\tLoss: 0.849129\n",
      "tensor(0.9258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.4\tLoss: 0.925797\n",
      "tensor(0.8912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.6\tLoss: 0.891228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.8\tLoss: 0.902433\n",
      "\n",
      "Test Epoch: 554\tAttack_Accuracy: 333/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 554\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.8974, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.0\tLoss: 0.897425\n",
      "tensor(0.9262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.2\tLoss: 0.926224\n",
      "tensor(1.0465, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.4\tLoss: 1.046527\n",
      "tensor(0.7921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.6\tLoss: 0.792079\n",
      "tensor(0.7825, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.8\tLoss: 0.782457\n",
      "\n",
      "Train Epoch: 555\tAttack_Accuracy: 10582/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 555\tmaintain_Accuracy: 10525/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 555\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 555\tmaintain_Accuracy: 2472/2993 (83%)\n",
      "\n",
      "tensor(0.9314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.0\tLoss: 0.931354\n",
      "tensor(0.8694, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.2\tLoss: 0.869380\n",
      "tensor(0.7769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.4\tLoss: 0.776943\n",
      "tensor(0.8034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.6\tLoss: 0.803354\n",
      "tensor(0.8748, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.8\tLoss: 0.874795\n",
      "\n",
      "Test Epoch: 556\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 556\tmaintain_Accuracy: 2463/2993 (82%)\n",
      "\n",
      "tensor(0.8751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.0\tLoss: 0.875143\n",
      "tensor(0.9277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.2\tLoss: 0.927676\n",
      "tensor(0.8602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.4\tLoss: 0.860181\n",
      "tensor(0.8137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.6\tLoss: 0.813661\n",
      "tensor(0.9511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.8\tLoss: 0.951069\n",
      "\n",
      "Test Epoch: 557\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 557\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.9812, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.0\tLoss: 0.981199\n",
      "tensor(0.9213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.2\tLoss: 0.921281\n",
      "tensor(0.9114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.4\tLoss: 0.911392\n",
      "tensor(0.9130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.6\tLoss: 0.913015\n",
      "tensor(0.8590, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.8\tLoss: 0.859037\n",
      "\n",
      "Test Epoch: 558\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 558\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.8560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.0\tLoss: 0.856033\n",
      "tensor(0.7962, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.2\tLoss: 0.796176\n",
      "tensor(0.8930, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.4\tLoss: 0.893000\n",
      "tensor(0.8350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.6\tLoss: 0.834987\n",
      "tensor(0.9169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.8\tLoss: 0.916854\n",
      "\n",
      "Test Epoch: 559\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 559\tmaintain_Accuracy: 2485/2993 (83%)\n",
      "\n",
      "tensor(0.9151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.0\tLoss: 0.915088\n",
      "tensor(0.7950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.2\tLoss: 0.795017\n",
      "tensor(0.7970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.4\tLoss: 0.797031\n",
      "tensor(0.8288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.6\tLoss: 0.828799\n",
      "tensor(0.8318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.8\tLoss: 0.831757\n",
      "\n",
      "Train Epoch: 560\tAttack_Accuracy: 10656/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 560\tmaintain_Accuracy: 10436/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 560\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 560\tmaintain_Accuracy: 2472/2993 (83%)\n",
      "\n",
      "tensor(0.8660, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.0\tLoss: 0.865992\n",
      "tensor(0.8757, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.2\tLoss: 0.875652\n",
      "tensor(0.8508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.4\tLoss: 0.850784\n",
      "tensor(0.8653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.6\tLoss: 0.865303\n",
      "tensor(0.7745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.8\tLoss: 0.774493\n",
      "\n",
      "Test Epoch: 561\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 561\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.0\tLoss: 0.680555\n",
      "tensor(0.9097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.2\tLoss: 0.909697\n",
      "tensor(0.8949, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.4\tLoss: 0.894876\n",
      "tensor(0.7771, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.6\tLoss: 0.777134\n",
      "tensor(0.8643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.8\tLoss: 0.864320\n",
      "\n",
      "Test Epoch: 562\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 562\tmaintain_Accuracy: 2476/2993 (83%)\n",
      "\n",
      "tensor(0.8861, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.0\tLoss: 0.886075\n",
      "tensor(1.0067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.2\tLoss: 1.006669\n",
      "tensor(0.7995, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.4\tLoss: 0.799461\n",
      "tensor(0.8519, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.6\tLoss: 0.851935\n",
      "tensor(0.8165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.8\tLoss: 0.816542\n",
      "\n",
      "Test Epoch: 563\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 563\tmaintain_Accuracy: 2470/2993 (83%)\n",
      "\n",
      "tensor(0.9444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.0\tLoss: 0.944409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7370, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.2\tLoss: 0.737038\n",
      "tensor(0.8351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.4\tLoss: 0.835070\n",
      "tensor(0.7966, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.6\tLoss: 0.796621\n",
      "tensor(0.9735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.8\tLoss: 0.973477\n",
      "\n",
      "Test Epoch: 564\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 564\tmaintain_Accuracy: 2470/2993 (83%)\n",
      "\n",
      "tensor(1.0606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.0\tLoss: 1.060619\n",
      "tensor(0.8431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.2\tLoss: 0.843121\n",
      "tensor(0.9290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.4\tLoss: 0.929043\n",
      "tensor(0.8951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.6\tLoss: 0.895057\n",
      "tensor(0.8304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.8\tLoss: 0.830357\n",
      "\n",
      "Train Epoch: 565\tAttack_Accuracy: 10662/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 565\tmaintain_Accuracy: 10485/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 565\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 565\tmaintain_Accuracy: 2472/2993 (83%)\n",
      "\n",
      "tensor(1.0153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.0\tLoss: 1.015334\n",
      "tensor(0.7470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.2\tLoss: 0.746957\n",
      "tensor(0.9510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.4\tLoss: 0.951037\n",
      "tensor(0.9606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.6\tLoss: 0.960562\n",
      "tensor(0.8393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.8\tLoss: 0.839309\n",
      "\n",
      "Test Epoch: 566\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 566\tmaintain_Accuracy: 2476/2993 (83%)\n",
      "\n",
      "tensor(0.7968, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.0\tLoss: 0.796839\n",
      "tensor(0.7206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.2\tLoss: 0.720633\n",
      "tensor(0.8921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.4\tLoss: 0.892066\n",
      "tensor(0.7509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.6\tLoss: 0.750863\n",
      "tensor(0.9917, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.8\tLoss: 0.991666\n",
      "\n",
      "Test Epoch: 567\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 567\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.9213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.0\tLoss: 0.921297\n",
      "tensor(0.8166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.2\tLoss: 0.816585\n",
      "tensor(1.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.4\tLoss: 1.013141\n",
      "tensor(1.0013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.6\tLoss: 1.001265\n",
      "tensor(0.8031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.8\tLoss: 0.803092\n",
      "\n",
      "Test Epoch: 568\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 568\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.9147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.0\tLoss: 0.914662\n",
      "tensor(1.0704, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.2\tLoss: 1.070357\n",
      "tensor(0.8361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.4\tLoss: 0.836078\n",
      "tensor(0.9209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.6\tLoss: 0.920915\n",
      "tensor(0.8108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.8\tLoss: 0.810809\n",
      "\n",
      "Test Epoch: 569\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 569\tmaintain_Accuracy: 2468/2993 (82%)\n",
      "\n",
      "tensor(1.0157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.0\tLoss: 1.015719\n",
      "tensor(0.9543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.2\tLoss: 0.954257\n",
      "tensor(0.9446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.4\tLoss: 0.944575\n",
      "tensor(0.8513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.6\tLoss: 0.851262\n",
      "tensor(0.9115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.8\tLoss: 0.911466\n",
      "\n",
      "Train Epoch: 570\tAttack_Accuracy: 10753/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 570\tmaintain_Accuracy: 10420/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 570\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 570\tmaintain_Accuracy: 2467/2993 (82%)\n",
      "\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.0\tLoss: 0.999768\n",
      "tensor(0.8946, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.2\tLoss: 0.894582\n",
      "tensor(0.9759, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.4\tLoss: 0.975863\n",
      "tensor(0.9688, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.6\tLoss: 0.968818\n",
      "tensor(0.8563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.8\tLoss: 0.856270\n",
      "\n",
      "Test Epoch: 571\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 571\tmaintain_Accuracy: 2461/2993 (82%)\n",
      "\n",
      "tensor(0.8228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.0\tLoss: 0.822762\n",
      "tensor(0.8767, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.2\tLoss: 0.876687\n",
      "tensor(0.7779, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.4\tLoss: 0.777922\n",
      "tensor(0.8548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.6\tLoss: 0.854778\n",
      "tensor(0.6957, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.8\tLoss: 0.695674\n",
      "\n",
      "Test Epoch: 572\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 572\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.9567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.0\tLoss: 0.956699\n",
      "tensor(0.8378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.2\tLoss: 0.837783\n",
      "tensor(0.9006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.4\tLoss: 0.900627\n",
      "tensor(0.9894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.6\tLoss: 0.989354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.8\tLoss: 1.004869\n",
      "\n",
      "Test Epoch: 573\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 573\tmaintain_Accuracy: 2463/2993 (82%)\n",
      "\n",
      "tensor(0.7263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.0\tLoss: 0.726274\n",
      "tensor(0.8674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.2\tLoss: 0.867363\n",
      "tensor(0.7902, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.4\tLoss: 0.790186\n",
      "tensor(0.9340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.6\tLoss: 0.934022\n",
      "tensor(0.8579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.8\tLoss: 0.857882\n",
      "\n",
      "Test Epoch: 574\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 574\tmaintain_Accuracy: 2465/2993 (82%)\n",
      "\n",
      "tensor(0.8095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.0\tLoss: 0.809475\n",
      "tensor(0.8639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.2\tLoss: 0.863888\n",
      "tensor(0.8769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.4\tLoss: 0.876863\n",
      "tensor(0.9695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.6\tLoss: 0.969486\n",
      "tensor(0.7975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.8\tLoss: 0.797451\n",
      "\n",
      "Train Epoch: 575\tAttack_Accuracy: 10622/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 575\tmaintain_Accuracy: 10496/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 575\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 575\tmaintain_Accuracy: 2468/2993 (82%)\n",
      "\n",
      "tensor(0.9866, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.0\tLoss: 0.986562\n",
      "tensor(0.8377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.2\tLoss: 0.837697\n",
      "tensor(0.8512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.4\tLoss: 0.851182\n",
      "tensor(0.9830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.6\tLoss: 0.983045\n",
      "tensor(0.9209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.8\tLoss: 0.920943\n",
      "\n",
      "Test Epoch: 576\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 576\tmaintain_Accuracy: 2461/2993 (82%)\n",
      "\n",
      "tensor(0.9370, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.0\tLoss: 0.936978\n",
      "tensor(0.7197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.2\tLoss: 0.719666\n",
      "tensor(0.8953, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.4\tLoss: 0.895266\n",
      "tensor(0.9403, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.6\tLoss: 0.940275\n",
      "tensor(0.8168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.8\tLoss: 0.816761\n",
      "\n",
      "Test Epoch: 577\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 577\tmaintain_Accuracy: 2458/2993 (82%)\n",
      "\n",
      "tensor(0.8821, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.0\tLoss: 0.882089\n",
      "tensor(1.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.2\tLoss: 1.000635\n",
      "tensor(0.7979, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.4\tLoss: 0.797932\n",
      "tensor(0.8939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.6\tLoss: 0.893932\n",
      "tensor(0.9219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.8\tLoss: 0.921875\n",
      "\n",
      "Test Epoch: 578\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 578\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.8434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.0\tLoss: 0.843412\n",
      "tensor(0.8423, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.2\tLoss: 0.842282\n",
      "tensor(0.8645, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.4\tLoss: 0.864539\n",
      "tensor(0.9056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.6\tLoss: 0.905586\n",
      "tensor(0.9674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.8\tLoss: 0.967445\n",
      "\n",
      "Test Epoch: 579\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 579\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.9374, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.0\tLoss: 0.937366\n",
      "tensor(0.6736, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.2\tLoss: 0.673597\n",
      "tensor(0.9220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.4\tLoss: 0.922050\n",
      "tensor(0.8596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.6\tLoss: 0.859602\n",
      "tensor(0.8856, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.8\tLoss: 0.885558\n",
      "\n",
      "Train Epoch: 580\tAttack_Accuracy: 10642/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 580\tmaintain_Accuracy: 10377/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 580\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 580\tmaintain_Accuracy: 2461/2993 (82%)\n",
      "\n",
      "tensor(1.0521, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.0\tLoss: 1.052058\n",
      "tensor(0.8089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.2\tLoss: 0.808863\n",
      "tensor(0.8655, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.4\tLoss: 0.865465\n",
      "tensor(0.6789, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.6\tLoss: 0.678920\n",
      "tensor(0.9084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.8\tLoss: 0.908427\n",
      "\n",
      "Test Epoch: 581\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 581\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.8385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.0\tLoss: 0.838490\n",
      "tensor(0.7811, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.2\tLoss: 0.781051\n",
      "tensor(0.7959, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.4\tLoss: 0.795922\n",
      "tensor(0.9362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.6\tLoss: 0.936249\n",
      "tensor(0.8528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.8\tLoss: 0.852804\n",
      "\n",
      "Test Epoch: 582\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 582\tmaintain_Accuracy: 2486/2993 (83%)\n",
      "\n",
      "tensor(0.7939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.0\tLoss: 0.793897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.2\tLoss: 0.881570\n",
      "tensor(0.8876, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.4\tLoss: 0.887558\n",
      "tensor(0.9538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.6\tLoss: 0.953756\n",
      "tensor(0.8024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.8\tLoss: 0.802447\n",
      "\n",
      "Test Epoch: 583\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 583\tmaintain_Accuracy: 2478/2993 (83%)\n",
      "\n",
      "tensor(0.7217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.0\tLoss: 0.721717\n",
      "tensor(0.9129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.2\tLoss: 0.912870\n",
      "tensor(0.8990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.4\tLoss: 0.898960\n",
      "tensor(0.8444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.6\tLoss: 0.844435\n",
      "tensor(0.7377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.8\tLoss: 0.737706\n",
      "\n",
      "Test Epoch: 584\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 584\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.8865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.0\tLoss: 0.886454\n",
      "tensor(0.8784, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.2\tLoss: 0.878354\n",
      "tensor(0.8550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.4\tLoss: 0.854986\n",
      "tensor(0.9178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.6\tLoss: 0.917821\n",
      "tensor(0.9102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.8\tLoss: 0.910200\n",
      "\n",
      "Train Epoch: 585\tAttack_Accuracy: 10740/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 585\tmaintain_Accuracy: 10540/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 585\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 585\tmaintain_Accuracy: 2476/2993 (83%)\n",
      "\n",
      "tensor(0.8325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.0\tLoss: 0.832528\n",
      "tensor(1.0570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.2\tLoss: 1.056993\n",
      "tensor(0.8316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.4\tLoss: 0.831570\n",
      "tensor(0.8943, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.6\tLoss: 0.894318\n",
      "tensor(0.9332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.8\tLoss: 0.933212\n",
      "\n",
      "Test Epoch: 586\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 586\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.9781, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.0\tLoss: 0.978083\n",
      "tensor(0.9836, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.2\tLoss: 0.983648\n",
      "tensor(0.8190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.4\tLoss: 0.818953\n",
      "tensor(0.9040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.6\tLoss: 0.904014\n",
      "tensor(0.8072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.8\tLoss: 0.807203\n",
      "\n",
      "Test Epoch: 587\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 587\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.7830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.0\tLoss: 0.782994\n",
      "tensor(0.8999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.2\tLoss: 0.899900\n",
      "tensor(0.8246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.4\tLoss: 0.824627\n",
      "tensor(0.8718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.6\tLoss: 0.871820\n",
      "tensor(0.8526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.8\tLoss: 0.852618\n",
      "\n",
      "Test Epoch: 588\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 588\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.8199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.0\tLoss: 0.819861\n",
      "tensor(0.7841, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.2\tLoss: 0.784150\n",
      "tensor(0.8319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.4\tLoss: 0.831926\n",
      "tensor(0.8584, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.6\tLoss: 0.858416\n",
      "tensor(0.8513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.8\tLoss: 0.851262\n",
      "\n",
      "Test Epoch: 589\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 589\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.8210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.0\tLoss: 0.821037\n",
      "tensor(0.8763, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.2\tLoss: 0.876333\n",
      "tensor(0.8741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.4\tLoss: 0.874113\n",
      "tensor(0.7457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.6\tLoss: 0.745710\n",
      "tensor(0.9045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.8\tLoss: 0.904450\n",
      "\n",
      "Train Epoch: 590\tAttack_Accuracy: 10635/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 590\tmaintain_Accuracy: 10420/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 590\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 590\tmaintain_Accuracy: 2478/2993 (83%)\n",
      "\n",
      "tensor(0.8712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.0\tLoss: 0.871236\n",
      "tensor(0.9250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.2\tLoss: 0.924971\n",
      "tensor(0.7813, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.4\tLoss: 0.781258\n",
      "tensor(0.9863, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.6\tLoss: 0.986306\n",
      "tensor(0.9632, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.8\tLoss: 0.963244\n",
      "\n",
      "Test Epoch: 591\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 591\tmaintain_Accuracy: 2465/2993 (82%)\n",
      "\n",
      "tensor(0.7758, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.0\tLoss: 0.775751\n",
      "tensor(0.9102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.2\tLoss: 0.910245\n",
      "tensor(0.7895, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.4\tLoss: 0.789545\n",
      "tensor(0.8284, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.6\tLoss: 0.828378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.8\tLoss: 0.767142\n",
      "\n",
      "Test Epoch: 592\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 592\tmaintain_Accuracy: 2465/2993 (82%)\n",
      "\n",
      "tensor(0.9848, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.0\tLoss: 0.984824\n",
      "tensor(0.7683, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.2\tLoss: 0.768280\n",
      "tensor(0.9155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.4\tLoss: 0.915501\n",
      "tensor(0.9952, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.6\tLoss: 0.995180\n",
      "tensor(0.8737, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.8\tLoss: 0.873675\n",
      "\n",
      "Test Epoch: 593\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 593\tmaintain_Accuracy: 2482/2993 (83%)\n",
      "\n",
      "tensor(0.8522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.0\tLoss: 0.852246\n",
      "tensor(0.8287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.2\tLoss: 0.828740\n",
      "tensor(0.7366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.4\tLoss: 0.736577\n",
      "tensor(0.8325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.6\tLoss: 0.832539\n",
      "tensor(0.9336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.8\tLoss: 0.933616\n",
      "\n",
      "Test Epoch: 594\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 594\tmaintain_Accuracy: 2470/2993 (83%)\n",
      "\n",
      "tensor(0.9857, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.0\tLoss: 0.985680\n",
      "tensor(0.8896, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.2\tLoss: 0.889554\n",
      "tensor(0.9432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.4\tLoss: 0.943230\n",
      "tensor(0.9377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.6\tLoss: 0.937721\n",
      "tensor(0.8503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.8\tLoss: 0.850298\n",
      "\n",
      "Train Epoch: 595\tAttack_Accuracy: 10798/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 595\tmaintain_Accuracy: 10487/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 595\tAttack_Accuracy: 346/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 595\tmaintain_Accuracy: 2449/2993 (82%)\n",
      "\n",
      "tensor(0.8019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.0\tLoss: 0.801920\n",
      "tensor(0.8339, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.2\tLoss: 0.833904\n",
      "tensor(1.0721, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.4\tLoss: 1.072077\n",
      "tensor(0.8381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.6\tLoss: 0.838140\n",
      "tensor(0.7834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.8\tLoss: 0.783357\n",
      "\n",
      "Test Epoch: 596\tAttack_Accuracy: 347/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 596\tmaintain_Accuracy: 2454/2993 (82%)\n",
      "\n",
      "tensor(0.8990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.0\tLoss: 0.898994\n",
      "tensor(0.9305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.2\tLoss: 0.930507\n",
      "tensor(0.9337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.4\tLoss: 0.933685\n",
      "tensor(0.7599, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.6\tLoss: 0.759902\n",
      "tensor(0.8603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.8\tLoss: 0.860293\n",
      "\n",
      "Test Epoch: 597\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 597\tmaintain_Accuracy: 2470/2993 (83%)\n",
      "\n",
      "tensor(0.9161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.0\tLoss: 0.916113\n",
      "tensor(0.9533, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.2\tLoss: 0.953338\n",
      "tensor(0.8131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.4\tLoss: 0.813094\n",
      "tensor(0.7889, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.6\tLoss: 0.788939\n",
      "tensor(0.8577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.8\tLoss: 0.857735\n",
      "\n",
      "Test Epoch: 598\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 598\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.9274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.0\tLoss: 0.927417\n",
      "tensor(0.9374, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.2\tLoss: 0.937412\n",
      "tensor(0.8937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.4\tLoss: 0.893675\n",
      "tensor(0.7072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.6\tLoss: 0.707239\n",
      "tensor(0.9098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.8\tLoss: 0.909791\n",
      "\n",
      "Test Epoch: 599\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 599\tmaintain_Accuracy: 2467/2993 (82%)\n",
      "\n",
      "tensor(0.8633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.0\tLoss: 0.863283\n",
      "tensor(1.0716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.2\tLoss: 1.071607\n",
      "tensor(0.7503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.4\tLoss: 0.750334\n",
      "tensor(0.7282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.6\tLoss: 0.728202\n",
      "tensor(0.8486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.8\tLoss: 0.848644\n",
      "\n",
      "Train Epoch: 600\tAttack_Accuracy: 10756/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 600\tmaintain_Accuracy: 10456/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 600\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 600\tmaintain_Accuracy: 2463/2993 (82%)\n",
      "\n",
      "tensor(0.8286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.0\tLoss: 0.828572\n",
      "tensor(0.7443, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.2\tLoss: 0.744343\n",
      "tensor(0.9887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.4\tLoss: 0.988704\n",
      "tensor(0.7464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.6\tLoss: 0.746378\n",
      "tensor(0.8626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.8\tLoss: 0.862634\n",
      "\n",
      "Test Epoch: 601\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 601\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.6898, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.0\tLoss: 0.689769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7776, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.2\tLoss: 0.777565\n",
      "tensor(0.8855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.4\tLoss: 0.885489\n",
      "tensor(0.8629, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.6\tLoss: 0.862869\n",
      "tensor(0.8396, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.8\tLoss: 0.839640\n",
      "\n",
      "Test Epoch: 602\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 602\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.8680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.0\tLoss: 0.868003\n",
      "tensor(0.7694, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.2\tLoss: 0.769432\n",
      "tensor(0.9757, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.4\tLoss: 0.975709\n",
      "tensor(0.8762, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.6\tLoss: 0.876203\n",
      "tensor(0.9497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.8\tLoss: 0.949709\n",
      "\n",
      "Test Epoch: 603\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 603\tmaintain_Accuracy: 2460/2993 (82%)\n",
      "\n",
      "tensor(0.9217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.0\tLoss: 0.921692\n",
      "tensor(0.7989, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.2\tLoss: 0.798892\n",
      "tensor(0.9193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.4\tLoss: 0.919282\n",
      "tensor(0.8393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.6\tLoss: 0.839275\n",
      "tensor(0.8287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.8\tLoss: 0.828651\n",
      "\n",
      "Test Epoch: 604\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 604\tmaintain_Accuracy: 2468/2993 (82%)\n",
      "\n",
      "tensor(0.8900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.0\tLoss: 0.890045\n",
      "tensor(0.8206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.2\tLoss: 0.820648\n",
      "tensor(0.9364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.4\tLoss: 0.936436\n",
      "tensor(0.8317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.6\tLoss: 0.831724\n",
      "tensor(0.8887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.8\tLoss: 0.888707\n",
      "\n",
      "Train Epoch: 605\tAttack_Accuracy: 10706/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 605\tmaintain_Accuracy: 10381/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 605\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 605\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.7417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.0\tLoss: 0.741713\n",
      "tensor(0.8495, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.2\tLoss: 0.849501\n",
      "tensor(0.9739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.4\tLoss: 0.973947\n",
      "tensor(0.7561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.6\tLoss: 0.756117\n",
      "tensor(0.9419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.8\tLoss: 0.941860\n",
      "\n",
      "Test Epoch: 606\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 606\tmaintain_Accuracy: 2467/2993 (82%)\n",
      "\n",
      "tensor(0.8004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.0\tLoss: 0.800419\n",
      "tensor(0.8327, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.2\tLoss: 0.832731\n",
      "tensor(0.7639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.4\tLoss: 0.763864\n",
      "tensor(0.8962, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.6\tLoss: 0.896206\n",
      "tensor(0.6870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.8\tLoss: 0.686995\n",
      "\n",
      "Test Epoch: 607\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 607\tmaintain_Accuracy: 2454/2993 (82%)\n",
      "\n",
      "tensor(0.8887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.0\tLoss: 0.888694\n",
      "tensor(0.9172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.2\tLoss: 0.917196\n",
      "tensor(0.8602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.4\tLoss: 0.860237\n",
      "tensor(0.8610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.6\tLoss: 0.860951\n",
      "tensor(0.8033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.8\tLoss: 0.803291\n",
      "\n",
      "Test Epoch: 608\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 608\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(0.7946, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.0\tLoss: 0.794594\n",
      "tensor(0.8905, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.2\tLoss: 0.890464\n",
      "tensor(0.8941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.4\tLoss: 0.894127\n",
      "tensor(0.7662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.6\tLoss: 0.766152\n",
      "tensor(1.0417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.8\tLoss: 1.041680\n",
      "\n",
      "Test Epoch: 609\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 609\tmaintain_Accuracy: 2464/2993 (82%)\n",
      "\n",
      "tensor(0.8117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.0\tLoss: 0.811750\n",
      "tensor(0.8984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.2\tLoss: 0.898418\n",
      "tensor(0.9082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.4\tLoss: 0.908197\n",
      "tensor(0.8304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.6\tLoss: 0.830387\n",
      "tensor(0.8036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.8\tLoss: 0.803623\n",
      "\n",
      "Train Epoch: 610\tAttack_Accuracy: 10651/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 610\tmaintain_Accuracy: 10585/12800 (83%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 610\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 610\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.8772, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.0\tLoss: 0.877176\n",
      "tensor(0.8025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.2\tLoss: 0.802527\n",
      "tensor(0.8042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.4\tLoss: 0.804235\n",
      "tensor(0.9560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.6\tLoss: 0.955958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.8\tLoss: 0.806337\n",
      "\n",
      "Test Epoch: 611\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 611\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.8517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.0\tLoss: 0.851743\n",
      "tensor(0.9973, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.2\tLoss: 0.997307\n",
      "tensor(0.7903, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.4\tLoss: 0.790267\n",
      "tensor(0.9174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.6\tLoss: 0.917402\n",
      "tensor(0.8431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.8\tLoss: 0.843127\n",
      "\n",
      "Test Epoch: 612\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 612\tmaintain_Accuracy: 2462/2993 (82%)\n",
      "\n",
      "tensor(0.9522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.0\tLoss: 0.952159\n",
      "tensor(0.8388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.2\tLoss: 0.838752\n",
      "tensor(0.8244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.4\tLoss: 0.824431\n",
      "tensor(0.7754, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.6\tLoss: 0.775421\n",
      "tensor(0.8040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.8\tLoss: 0.803985\n",
      "\n",
      "Test Epoch: 613\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 613\tmaintain_Accuracy: 2459/2993 (82%)\n",
      "\n",
      "tensor(0.8070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.0\tLoss: 0.807043\n",
      "tensor(0.8721, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.2\tLoss: 0.872121\n",
      "tensor(0.7847, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.4\tLoss: 0.784659\n",
      "tensor(0.8986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.6\tLoss: 0.898617\n",
      "tensor(0.8793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.8\tLoss: 0.879259\n",
      "\n",
      "Test Epoch: 614\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 614\tmaintain_Accuracy: 2468/2993 (82%)\n",
      "\n",
      "tensor(0.6361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.0\tLoss: 0.636138\n",
      "tensor(0.8103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.2\tLoss: 0.810251\n",
      "tensor(1.0119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.4\tLoss: 1.011873\n",
      "tensor(0.9940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.6\tLoss: 0.994024\n",
      "tensor(0.9606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.8\tLoss: 0.960555\n",
      "\n",
      "Train Epoch: 615\tAttack_Accuracy: 10679/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 615\tmaintain_Accuracy: 10514/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 615\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 615\tmaintain_Accuracy: 2480/2993 (83%)\n",
      "\n",
      "tensor(0.7575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.0\tLoss: 0.757498\n",
      "tensor(0.8021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.2\tLoss: 0.802076\n",
      "tensor(0.7746, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.4\tLoss: 0.774633\n",
      "tensor(0.8950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.6\tLoss: 0.895004\n",
      "tensor(0.8702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.8\tLoss: 0.870206\n",
      "\n",
      "Test Epoch: 616\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 616\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.8959, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.0\tLoss: 0.895915\n",
      "tensor(0.9822, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.2\tLoss: 0.982205\n",
      "tensor(0.8645, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.4\tLoss: 0.864469\n",
      "tensor(0.8941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.6\tLoss: 0.894084\n",
      "tensor(0.9185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.8\tLoss: 0.918476\n",
      "\n",
      "Test Epoch: 617\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 617\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.8182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.0\tLoss: 0.818236\n",
      "tensor(0.8726, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.2\tLoss: 0.872606\n",
      "tensor(0.8378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.4\tLoss: 0.837845\n",
      "tensor(0.7668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.6\tLoss: 0.766785\n",
      "tensor(0.7388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.8\tLoss: 0.738751\n",
      "\n",
      "Test Epoch: 618\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 618\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.8530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.0\tLoss: 0.852959\n",
      "tensor(0.9239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.2\tLoss: 0.923882\n",
      "tensor(0.8714, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.4\tLoss: 0.871424\n",
      "tensor(0.8849, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.6\tLoss: 0.884850\n",
      "tensor(0.7725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.8\tLoss: 0.772472\n",
      "\n",
      "Test Epoch: 619\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 619\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.9712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.0\tLoss: 0.971150\n",
      "tensor(0.8829, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.2\tLoss: 0.882850\n",
      "tensor(0.8105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.4\tLoss: 0.810471\n",
      "tensor(0.8427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.6\tLoss: 0.842687\n",
      "tensor(0.7895, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.8\tLoss: 0.789468\n",
      "\n",
      "Train Epoch: 620\tAttack_Accuracy: 10757/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 620\tmaintain_Accuracy: 10481/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 620\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 620\tmaintain_Accuracy: 2470/2993 (83%)\n",
      "\n",
      "tensor(0.8552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.0\tLoss: 0.855235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.2\tLoss: 0.924056\n",
      "tensor(0.7829, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.4\tLoss: 0.782942\n",
      "tensor(0.8960, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.6\tLoss: 0.895970\n",
      "tensor(0.7722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.8\tLoss: 0.772204\n",
      "\n",
      "Test Epoch: 621\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 621\tmaintain_Accuracy: 2481/2993 (83%)\n",
      "\n",
      "tensor(1.0325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.0\tLoss: 1.032492\n",
      "tensor(1.0369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.2\tLoss: 1.036880\n",
      "tensor(0.8120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.4\tLoss: 0.812007\n",
      "tensor(0.7922, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.6\tLoss: 0.792208\n",
      "tensor(0.7241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.8\tLoss: 0.724092\n",
      "\n",
      "Test Epoch: 622\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 622\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.8235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.0\tLoss: 0.823497\n",
      "tensor(0.7340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.2\tLoss: 0.733986\n",
      "tensor(0.9326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.4\tLoss: 0.932576\n",
      "tensor(0.9772, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.6\tLoss: 0.977213\n",
      "tensor(0.7638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.8\tLoss: 0.763798\n",
      "\n",
      "Test Epoch: 623\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 623\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.9077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.0\tLoss: 0.907748\n",
      "tensor(1.0130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.2\tLoss: 1.013036\n",
      "tensor(0.8629, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.4\tLoss: 0.862896\n",
      "tensor(0.8089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.6\tLoss: 0.808941\n",
      "tensor(0.8524, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.8\tLoss: 0.852412\n",
      "\n",
      "Test Epoch: 624\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 624\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.8103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.0\tLoss: 0.810343\n",
      "tensor(0.8904, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.2\tLoss: 0.890372\n",
      "tensor(0.8551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.4\tLoss: 0.855072\n",
      "tensor(0.8730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.6\tLoss: 0.872985\n",
      "tensor(0.8400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.8\tLoss: 0.839980\n",
      "\n",
      "Train Epoch: 625\tAttack_Accuracy: 10810/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 625\tmaintain_Accuracy: 10491/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 625\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 625\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.8547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.0\tLoss: 0.854746\n",
      "tensor(0.8048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.2\tLoss: 0.804760\n",
      "tensor(0.9386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.4\tLoss: 0.938564\n",
      "tensor(0.7755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.6\tLoss: 0.775480\n",
      "tensor(0.7909, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.8\tLoss: 0.790920\n",
      "\n",
      "Test Epoch: 626\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 626\tmaintain_Accuracy: 2472/2993 (83%)\n",
      "\n",
      "tensor(0.7968, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.0\tLoss: 0.796847\n",
      "tensor(0.9577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.2\tLoss: 0.957737\n",
      "tensor(0.8630, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.4\tLoss: 0.863038\n",
      "tensor(0.8738, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.6\tLoss: 0.873767\n",
      "tensor(0.9002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.8\tLoss: 0.900153\n",
      "\n",
      "Test Epoch: 627\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 627\tmaintain_Accuracy: 2478/2993 (83%)\n",
      "\n",
      "tensor(0.7804, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.0\tLoss: 0.780438\n",
      "tensor(0.7415, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.2\tLoss: 0.741536\n",
      "tensor(0.7654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.4\tLoss: 0.765448\n",
      "tensor(0.7974, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.6\tLoss: 0.797384\n",
      "tensor(0.7104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.8\tLoss: 0.710450\n",
      "\n",
      "Test Epoch: 628\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 628\tmaintain_Accuracy: 2472/2993 (83%)\n",
      "\n",
      "tensor(0.7935, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.0\tLoss: 0.793545\n",
      "tensor(0.7314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.2\tLoss: 0.731374\n",
      "tensor(0.8027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.4\tLoss: 0.802705\n",
      "tensor(0.7059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.6\tLoss: 0.705855\n",
      "tensor(0.7313, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.8\tLoss: 0.731329\n",
      "\n",
      "Test Epoch: 629\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 629\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.8102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.0\tLoss: 0.810171\n",
      "tensor(1.0711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.2\tLoss: 1.071094\n",
      "tensor(0.9312, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.4\tLoss: 0.931154\n",
      "tensor(0.7559, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.6\tLoss: 0.755877\n",
      "tensor(0.7622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.8\tLoss: 0.762211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 630\tAttack_Accuracy: 10764/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 630\tmaintain_Accuracy: 10366/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 630\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 630\tmaintain_Accuracy: 2464/2993 (82%)\n",
      "\n",
      "tensor(0.7725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.0\tLoss: 0.772475\n",
      "tensor(0.8654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.2\tLoss: 0.865389\n",
      "tensor(0.8079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.4\tLoss: 0.807869\n",
      "tensor(0.8829, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.6\tLoss: 0.882855\n",
      "tensor(0.8088, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.8\tLoss: 0.808810\n",
      "\n",
      "Test Epoch: 631\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 631\tmaintain_Accuracy: 2464/2993 (82%)\n",
      "\n",
      "tensor(0.9856, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.0\tLoss: 0.985561\n",
      "tensor(0.9705, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.2\tLoss: 0.970482\n",
      "tensor(0.8098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.4\tLoss: 0.809796\n",
      "tensor(0.9184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.6\tLoss: 0.918397\n",
      "tensor(0.9283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.8\tLoss: 0.928336\n",
      "\n",
      "Test Epoch: 632\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 632\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.8290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.0\tLoss: 0.828996\n",
      "tensor(0.8629, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.2\tLoss: 0.862855\n",
      "tensor(0.8534, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.4\tLoss: 0.853409\n",
      "tensor(0.8218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.6\tLoss: 0.821807\n",
      "tensor(0.8511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.8\tLoss: 0.851111\n",
      "\n",
      "Test Epoch: 633\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 633\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.7964, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.0\tLoss: 0.796420\n",
      "tensor(0.8783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.2\tLoss: 0.878293\n",
      "tensor(0.7263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.4\tLoss: 0.726317\n",
      "tensor(0.9279, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.6\tLoss: 0.927928\n",
      "tensor(0.8625, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.8\tLoss: 0.862476\n",
      "\n",
      "Test Epoch: 634\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 634\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.7947, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.0\tLoss: 0.794693\n",
      "tensor(0.8887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.2\tLoss: 0.888661\n",
      "tensor(0.7819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.4\tLoss: 0.781947\n",
      "tensor(0.7974, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.6\tLoss: 0.797385\n",
      "tensor(0.7595, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.8\tLoss: 0.759460\n",
      "\n",
      "Train Epoch: 635\tAttack_Accuracy: 10719/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 635\tmaintain_Accuracy: 10495/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 635\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 635\tmaintain_Accuracy: 2463/2993 (82%)\n",
      "\n",
      "tensor(0.9470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.0\tLoss: 0.946951\n",
      "tensor(0.7879, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.2\tLoss: 0.787896\n",
      "tensor(0.8128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.4\tLoss: 0.812765\n",
      "tensor(0.8631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.6\tLoss: 0.863124\n",
      "tensor(0.8347, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.8\tLoss: 0.834680\n",
      "\n",
      "Test Epoch: 636\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 636\tmaintain_Accuracy: 2467/2993 (82%)\n",
      "\n",
      "tensor(0.7834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.0\tLoss: 0.783436\n",
      "tensor(0.8280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.2\tLoss: 0.828004\n",
      "tensor(0.8628, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.4\tLoss: 0.862772\n",
      "tensor(0.7455, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.6\tLoss: 0.745455\n",
      "tensor(0.9830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.8\tLoss: 0.982972\n",
      "\n",
      "Test Epoch: 637\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 637\tmaintain_Accuracy: 2478/2993 (83%)\n",
      "\n",
      "tensor(0.7924, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.0\tLoss: 0.792442\n",
      "tensor(0.7548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.2\tLoss: 0.754836\n",
      "tensor(0.7290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.4\tLoss: 0.728988\n",
      "tensor(0.7713, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.6\tLoss: 0.771282\n",
      "tensor(0.7549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.8\tLoss: 0.754880\n",
      "\n",
      "Test Epoch: 638\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 638\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.8212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.0\tLoss: 0.821190\n",
      "tensor(0.7303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.2\tLoss: 0.730304\n",
      "tensor(0.9427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.4\tLoss: 0.942712\n",
      "tensor(0.8868, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.6\tLoss: 0.886805\n",
      "tensor(0.8185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.8\tLoss: 0.818511\n",
      "\n",
      "Test Epoch: 639\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 639\tmaintain_Accuracy: 2461/2993 (82%)\n",
      "\n",
      "tensor(0.9812, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.0\tLoss: 0.981232\n",
      "tensor(0.7517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.2\tLoss: 0.751660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.4\tLoss: 0.812259\n",
      "tensor(0.7496, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.6\tLoss: 0.749609\n",
      "tensor(0.9814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.8\tLoss: 0.981381\n",
      "\n",
      "Train Epoch: 640\tAttack_Accuracy: 10847/12800 (85%)\n",
      "\n",
      "\n",
      "Train Epoch: 640\tmaintain_Accuracy: 10451/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 640\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 640\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.9164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.0\tLoss: 0.916414\n",
      "tensor(0.8423, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.2\tLoss: 0.842311\n",
      "tensor(0.8593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.4\tLoss: 0.859332\n",
      "tensor(0.8654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.6\tLoss: 0.865438\n",
      "tensor(1.0061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.8\tLoss: 1.006073\n",
      "\n",
      "Test Epoch: 641\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 641\tmaintain_Accuracy: 2479/2993 (83%)\n",
      "\n",
      "tensor(0.7910, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.0\tLoss: 0.790963\n",
      "tensor(0.7310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.2\tLoss: 0.730955\n",
      "tensor(1.0341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.4\tLoss: 1.034077\n",
      "tensor(0.7253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.6\tLoss: 0.725260\n",
      "tensor(0.8633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.8\tLoss: 0.863327\n",
      "\n",
      "Test Epoch: 642\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 642\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.9098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.0\tLoss: 0.909786\n",
      "tensor(0.8870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.2\tLoss: 0.887046\n",
      "tensor(0.8110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.4\tLoss: 0.810974\n",
      "tensor(0.8298, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.6\tLoss: 0.829826\n",
      "tensor(0.8452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.8\tLoss: 0.845196\n",
      "\n",
      "Test Epoch: 643\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 643\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.8486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.0\tLoss: 0.848606\n",
      "tensor(0.8276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.2\tLoss: 0.827626\n",
      "tensor(0.7914, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.4\tLoss: 0.791392\n",
      "tensor(0.8420, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.6\tLoss: 0.841975\n",
      "tensor(0.6744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.8\tLoss: 0.674448\n",
      "\n",
      "Test Epoch: 644\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 644\tmaintain_Accuracy: 2460/2993 (82%)\n",
      "\n",
      "tensor(0.7828, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.0\tLoss: 0.782822\n",
      "tensor(0.9170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.2\tLoss: 0.917042\n",
      "tensor(0.7057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.4\tLoss: 0.705711\n",
      "tensor(0.7811, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.6\tLoss: 0.781097\n",
      "tensor(0.7969, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.8\tLoss: 0.796894\n",
      "\n",
      "Train Epoch: 645\tAttack_Accuracy: 10741/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 645\tmaintain_Accuracy: 10536/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 645\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 645\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.7815, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.0\tLoss: 0.781505\n",
      "tensor(0.8715, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.2\tLoss: 0.871450\n",
      "tensor(0.9622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.4\tLoss: 0.962160\n",
      "tensor(0.8697, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.6\tLoss: 0.869705\n",
      "tensor(0.8077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.8\tLoss: 0.807685\n",
      "\n",
      "Test Epoch: 646\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 646\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.8381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.0\tLoss: 0.838089\n",
      "tensor(0.6766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.2\tLoss: 0.676622\n",
      "tensor(0.7822, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.4\tLoss: 0.782170\n",
      "tensor(0.9986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.6\tLoss: 0.998610\n",
      "tensor(0.8200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.8\tLoss: 0.819999\n",
      "\n",
      "Test Epoch: 647\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 647\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.7892, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.0\tLoss: 0.789180\n",
      "tensor(0.8967, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.2\tLoss: 0.896731\n",
      "tensor(0.7713, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.4\tLoss: 0.771282\n",
      "tensor(0.8658, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.6\tLoss: 0.865751\n",
      "tensor(0.7941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.8\tLoss: 0.794101\n",
      "\n",
      "Test Epoch: 648\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 648\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.7428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.0\tLoss: 0.742783\n",
      "tensor(0.8027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.2\tLoss: 0.802730\n",
      "tensor(0.7671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.4\tLoss: 0.767053\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.6\tLoss: 0.693009\n",
      "tensor(0.9265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.8\tLoss: 0.926509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 649\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 649\tmaintain_Accuracy: 2455/2993 (82%)\n",
      "\n",
      "tensor(0.8548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.0\tLoss: 0.854826\n",
      "tensor(0.8200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.2\tLoss: 0.819981\n",
      "tensor(0.9615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.4\tLoss: 0.961513\n",
      "tensor(0.8821, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.6\tLoss: 0.882100\n",
      "tensor(0.7884, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.8\tLoss: 0.788399\n",
      "\n",
      "Train Epoch: 650\tAttack_Accuracy: 10753/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 650\tmaintain_Accuracy: 10526/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 650\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 650\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(0.8646, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.0\tLoss: 0.864600\n",
      "tensor(0.8971, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.2\tLoss: 0.897099\n",
      "tensor(0.7762, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.4\tLoss: 0.776216\n",
      "tensor(0.8247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.6\tLoss: 0.824721\n",
      "tensor(0.8820, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.8\tLoss: 0.881995\n",
      "\n",
      "Test Epoch: 651\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 651\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.7018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.0\tLoss: 0.701845\n",
      "tensor(0.8038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.2\tLoss: 0.803750\n",
      "tensor(0.7455, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.4\tLoss: 0.745478\n",
      "tensor(0.8690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.6\tLoss: 0.869043\n",
      "tensor(0.7074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.8\tLoss: 0.707426\n",
      "\n",
      "Test Epoch: 652\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 652\tmaintain_Accuracy: 2465/2993 (82%)\n",
      "\n",
      "tensor(0.8818, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.0\tLoss: 0.881818\n",
      "tensor(0.7859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.2\tLoss: 0.785926\n",
      "tensor(0.8852, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.4\tLoss: 0.885185\n",
      "tensor(0.7860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.6\tLoss: 0.786044\n",
      "tensor(0.8106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.8\tLoss: 0.810590\n",
      "\n",
      "Test Epoch: 653\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 653\tmaintain_Accuracy: 2464/2993 (82%)\n",
      "\n",
      "tensor(0.9154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.0\tLoss: 0.915374\n",
      "tensor(0.8047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.2\tLoss: 0.804713\n",
      "tensor(0.7768, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.4\tLoss: 0.776815\n",
      "tensor(0.7654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.6\tLoss: 0.765391\n",
      "tensor(0.8477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.8\tLoss: 0.847732\n",
      "\n",
      "Test Epoch: 654\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 654\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.9048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.0\tLoss: 0.904782\n",
      "tensor(0.8337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.2\tLoss: 0.833741\n",
      "tensor(0.8685, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.4\tLoss: 0.868496\n",
      "tensor(0.8253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.6\tLoss: 0.825313\n",
      "tensor(0.7741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.8\tLoss: 0.774135\n",
      "\n",
      "Train Epoch: 655\tAttack_Accuracy: 10737/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 655\tmaintain_Accuracy: 10446/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 655\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 655\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.8566, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.0\tLoss: 0.856639\n",
      "tensor(0.8554, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.2\tLoss: 0.855418\n",
      "tensor(0.7894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.4\tLoss: 0.789414\n",
      "tensor(0.8589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.6\tLoss: 0.858936\n",
      "tensor(0.7563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.8\tLoss: 0.756302\n",
      "\n",
      "Test Epoch: 656\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 656\tmaintain_Accuracy: 2470/2993 (83%)\n",
      "\n",
      "tensor(0.8386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.0\tLoss: 0.838629\n",
      "tensor(0.9867, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.2\tLoss: 0.986657\n",
      "tensor(0.8762, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.4\tLoss: 0.876167\n",
      "tensor(0.7235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.6\tLoss: 0.723471\n",
      "tensor(0.7274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.8\tLoss: 0.727363\n",
      "\n",
      "Test Epoch: 657\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 657\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(0.8529, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.0\tLoss: 0.852925\n",
      "tensor(0.8867, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.2\tLoss: 0.886747\n",
      "tensor(0.9403, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.4\tLoss: 0.940277\n",
      "tensor(0.9226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.6\tLoss: 0.922632\n",
      "tensor(0.8684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.8\tLoss: 0.868373\n",
      "\n",
      "Test Epoch: 658\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 658\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.8398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.0\tLoss: 0.839812\n",
      "tensor(0.8862, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.2\tLoss: 0.886217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.4\tLoss: 0.867414\n",
      "tensor(0.9079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.6\tLoss: 0.907879\n",
      "tensor(0.8581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.8\tLoss: 0.858071\n",
      "\n",
      "Test Epoch: 659\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 659\tmaintain_Accuracy: 2476/2993 (83%)\n",
      "\n",
      "tensor(0.7445, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.0\tLoss: 0.744518\n",
      "tensor(0.7582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.2\tLoss: 0.758228\n",
      "tensor(0.9130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.4\tLoss: 0.912964\n",
      "tensor(0.8275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.6\tLoss: 0.827510\n",
      "tensor(0.8273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.8\tLoss: 0.827293\n",
      "\n",
      "Train Epoch: 660\tAttack_Accuracy: 10669/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 660\tmaintain_Accuracy: 10499/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 660\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 660\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.7717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.0\tLoss: 0.771719\n",
      "tensor(0.9211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.2\tLoss: 0.921058\n",
      "tensor(0.7816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.4\tLoss: 0.781629\n",
      "tensor(0.8364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.6\tLoss: 0.836425\n",
      "tensor(0.8039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.8\tLoss: 0.803901\n",
      "\n",
      "Test Epoch: 661\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 661\tmaintain_Accuracy: 2459/2993 (82%)\n",
      "\n",
      "tensor(0.8594, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.0\tLoss: 0.859365\n",
      "tensor(0.8537, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.2\tLoss: 0.853718\n",
      "tensor(1.0134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.4\tLoss: 1.013397\n",
      "tensor(0.9269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.6\tLoss: 0.926904\n",
      "tensor(0.8179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.8\tLoss: 0.817870\n",
      "\n",
      "Test Epoch: 662\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 662\tmaintain_Accuracy: 2460/2993 (82%)\n",
      "\n",
      "tensor(0.8420, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.0\tLoss: 0.841951\n",
      "tensor(0.8472, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.2\tLoss: 0.847214\n",
      "tensor(0.8610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.4\tLoss: 0.861039\n",
      "tensor(0.9279, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.6\tLoss: 0.927919\n",
      "tensor(1.0095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.8\tLoss: 1.009524\n",
      "\n",
      "Test Epoch: 663\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 663\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.8037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.0\tLoss: 0.803722\n",
      "tensor(0.7225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.2\tLoss: 0.722488\n",
      "tensor(0.8119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.4\tLoss: 0.811880\n",
      "tensor(0.8475, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.6\tLoss: 0.847494\n",
      "tensor(0.8785, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.8\tLoss: 0.878467\n",
      "\n",
      "Test Epoch: 664\tAttack_Accuracy: 331/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 664\tmaintain_Accuracy: 2468/2993 (82%)\n",
      "\n",
      "tensor(0.8558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.0\tLoss: 0.855781\n",
      "tensor(0.7226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.2\tLoss: 0.722619\n",
      "tensor(0.7429, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.4\tLoss: 0.742940\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.6\tLoss: 0.690295\n",
      "tensor(0.8082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.8\tLoss: 0.808215\n",
      "\n",
      "Train Epoch: 665\tAttack_Accuracy: 10622/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 665\tmaintain_Accuracy: 10415/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 665\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 665\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.7705, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.0\tLoss: 0.770548\n",
      "tensor(0.8398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.2\tLoss: 0.839815\n",
      "tensor(0.8800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.4\tLoss: 0.879958\n",
      "tensor(0.8760, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.6\tLoss: 0.876012\n",
      "tensor(0.8631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.8\tLoss: 0.863130\n",
      "\n",
      "Test Epoch: 666\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 666\tmaintain_Accuracy: 2462/2993 (82%)\n",
      "\n",
      "tensor(0.8912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.0\tLoss: 0.891167\n",
      "tensor(0.9093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.2\tLoss: 0.909263\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.4\tLoss: 0.680927\n",
      "tensor(0.9633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.6\tLoss: 0.963287\n",
      "tensor(0.9183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.8\tLoss: 0.918346\n",
      "\n",
      "Test Epoch: 667\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 667\tmaintain_Accuracy: 2461/2993 (82%)\n",
      "\n",
      "tensor(0.8236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.0\tLoss: 0.823611\n",
      "tensor(0.8186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.2\tLoss: 0.818594\n",
      "tensor(0.8841, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.4\tLoss: 0.884077\n",
      "tensor(0.7383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.6\tLoss: 0.738272\n",
      "tensor(0.8719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.8\tLoss: 0.871946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 668\tAttack_Accuracy: 329/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 668\tmaintain_Accuracy: 2470/2993 (83%)\n",
      "\n",
      "tensor(0.8270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.0\tLoss: 0.826972\n",
      "tensor(0.8237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.2\tLoss: 0.823718\n",
      "tensor(0.8925, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.4\tLoss: 0.892454\n",
      "tensor(0.7673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.6\tLoss: 0.767323\n",
      "tensor(0.7320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.8\tLoss: 0.732014\n",
      "\n",
      "Test Epoch: 669\tAttack_Accuracy: 330/412 (80%)\n",
      "\n",
      "\n",
      "Test Epoch: 669\tmaintain_Accuracy: 2477/2993 (83%)\n",
      "\n",
      "tensor(0.9917, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.0\tLoss: 0.991744\n",
      "tensor(0.7660, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.2\tLoss: 0.765991\n",
      "tensor(0.8126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.4\tLoss: 0.812642\n",
      "tensor(0.9063, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.6\tLoss: 0.906337\n",
      "tensor(0.8720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.8\tLoss: 0.872022\n",
      "\n",
      "Train Epoch: 670\tAttack_Accuracy: 10621/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 670\tmaintain_Accuracy: 10483/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 670\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 670\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.7416, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.0\tLoss: 0.741588\n",
      "tensor(0.6885, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.2\tLoss: 0.688506\n",
      "tensor(0.6509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.4\tLoss: 0.650875\n",
      "tensor(0.8404, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.6\tLoss: 0.840378\n",
      "tensor(0.7056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.8\tLoss: 0.705583\n",
      "\n",
      "Test Epoch: 671\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 671\tmaintain_Accuracy: 2462/2993 (82%)\n",
      "\n",
      "tensor(0.9480, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.0\tLoss: 0.948000\n",
      "tensor(0.9605, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.2\tLoss: 0.960546\n",
      "tensor(0.8091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.4\tLoss: 0.809146\n",
      "tensor(0.8819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.6\tLoss: 0.881865\n",
      "tensor(0.8182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.8\tLoss: 0.818183\n",
      "\n",
      "Test Epoch: 672\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 672\tmaintain_Accuracy: 2464/2993 (82%)\n",
      "\n",
      "tensor(0.9014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.0\tLoss: 0.901372\n",
      "tensor(0.8244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.2\tLoss: 0.824429\n",
      "tensor(0.7503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.4\tLoss: 0.750324\n",
      "tensor(0.9088, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.6\tLoss: 0.908762\n",
      "tensor(0.9082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.8\tLoss: 0.908174\n",
      "\n",
      "Test Epoch: 673\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 673\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.8275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.0\tLoss: 0.827458\n",
      "tensor(0.8231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.2\tLoss: 0.823140\n",
      "tensor(0.8832, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.4\tLoss: 0.883202\n",
      "tensor(0.8728, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.6\tLoss: 0.872802\n",
      "tensor(0.7054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.8\tLoss: 0.705414\n",
      "\n",
      "Test Epoch: 674\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 674\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.7782, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.0\tLoss: 0.778194\n",
      "tensor(0.9540, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.2\tLoss: 0.954037\n",
      "tensor(0.8700, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.4\tLoss: 0.869987\n",
      "tensor(0.7649, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.6\tLoss: 0.764939\n",
      "tensor(0.9364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.8\tLoss: 0.936412\n",
      "\n",
      "Train Epoch: 675\tAttack_Accuracy: 10749/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 675\tmaintain_Accuracy: 10526/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 675\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 675\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(0.9233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.0\tLoss: 0.923275\n",
      "tensor(0.8818, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.2\tLoss: 0.881830\n",
      "tensor(0.7077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.4\tLoss: 0.707710\n",
      "tensor(0.8880, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.6\tLoss: 0.887967\n",
      "tensor(0.9089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.8\tLoss: 0.908904\n",
      "\n",
      "Test Epoch: 676\tAttack_Accuracy: 346/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 676\tmaintain_Accuracy: 2454/2993 (82%)\n",
      "\n",
      "tensor(0.8296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.0\tLoss: 0.829647\n",
      "tensor(0.8538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.2\tLoss: 0.853786\n",
      "tensor(0.8159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.4\tLoss: 0.815926\n",
      "tensor(0.8065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.6\tLoss: 0.806492\n",
      "tensor(0.9265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.8\tLoss: 0.926473\n",
      "\n",
      "Test Epoch: 677\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 677\tmaintain_Accuracy: 2461/2993 (82%)\n",
      "\n",
      "tensor(0.8479, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.0\tLoss: 0.847869\n",
      "tensor(0.9607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.2\tLoss: 0.960724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.4\tLoss: 0.735348\n",
      "tensor(0.9507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.6\tLoss: 0.950654\n",
      "tensor(0.8318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.8\tLoss: 0.831833\n",
      "\n",
      "Test Epoch: 678\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 678\tmaintain_Accuracy: 2468/2993 (82%)\n",
      "\n",
      "tensor(0.8168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.0\tLoss: 0.816842\n",
      "tensor(0.7453, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.2\tLoss: 0.745350\n",
      "tensor(0.8668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.4\tLoss: 0.866783\n",
      "tensor(0.9898, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.6\tLoss: 0.989751\n",
      "tensor(0.8611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.8\tLoss: 0.861133\n",
      "\n",
      "Test Epoch: 679\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 679\tmaintain_Accuracy: 2462/2993 (82%)\n",
      "\n",
      "tensor(0.8127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.0\tLoss: 0.812740\n",
      "tensor(0.8040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.2\tLoss: 0.803997\n",
      "tensor(0.7301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.4\tLoss: 0.730123\n",
      "tensor(0.9698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.6\tLoss: 0.969750\n",
      "tensor(0.7385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.8\tLoss: 0.738527\n",
      "\n",
      "Train Epoch: 680\tAttack_Accuracy: 10747/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 680\tmaintain_Accuracy: 10406/12800 (81%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 680\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 680\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(0.7744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.0\tLoss: 0.774400\n",
      "tensor(0.7414, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.2\tLoss: 0.741383\n",
      "tensor(0.7596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.4\tLoss: 0.759627\n",
      "tensor(0.7622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.6\tLoss: 0.762198\n",
      "tensor(0.7559, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.8\tLoss: 0.755883\n",
      "\n",
      "Test Epoch: 681\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 681\tmaintain_Accuracy: 2454/2993 (82%)\n",
      "\n",
      "tensor(0.7629, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.0\tLoss: 0.762861\n",
      "tensor(0.9617, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.2\tLoss: 0.961742\n",
      "tensor(0.8693, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.4\tLoss: 0.869345\n",
      "tensor(0.7864, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.6\tLoss: 0.786413\n",
      "tensor(0.8207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.8\tLoss: 0.820683\n",
      "\n",
      "Test Epoch: 682\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 682\tmaintain_Accuracy: 2455/2993 (82%)\n",
      "\n",
      "tensor(0.8323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.0\tLoss: 0.832350\n",
      "tensor(0.8265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.2\tLoss: 0.826509\n",
      "tensor(0.8123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.4\tLoss: 0.812337\n",
      "tensor(0.6921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.6\tLoss: 0.692118\n",
      "tensor(0.7255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.8\tLoss: 0.725495\n",
      "\n",
      "Test Epoch: 683\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 683\tmaintain_Accuracy: 2467/2993 (82%)\n",
      "\n",
      "tensor(0.7432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.0\tLoss: 0.743219\n",
      "tensor(0.9606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.2\tLoss: 0.960586\n",
      "tensor(0.7857, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.4\tLoss: 0.785674\n",
      "tensor(0.7872, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.6\tLoss: 0.787214\n",
      "tensor(0.7247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.8\tLoss: 0.724693\n",
      "\n",
      "Test Epoch: 684\tAttack_Accuracy: 332/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 684\tmaintain_Accuracy: 2476/2993 (83%)\n",
      "\n",
      "tensor(0.9188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.0\tLoss: 0.918798\n",
      "tensor(0.8739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.2\tLoss: 0.873902\n",
      "tensor(0.6758, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.4\tLoss: 0.675772\n",
      "tensor(0.8621, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.6\tLoss: 0.862134\n",
      "tensor(0.7744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.8\tLoss: 0.774445\n",
      "\n",
      "Train Epoch: 685\tAttack_Accuracy: 10620/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 685\tmaintain_Accuracy: 10487/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 685\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 685\tmaintain_Accuracy: 2467/2993 (82%)\n",
      "\n",
      "tensor(0.6794, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.0\tLoss: 0.679365\n",
      "tensor(0.7742, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.2\tLoss: 0.774172\n",
      "tensor(0.8296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.4\tLoss: 0.829598\n",
      "tensor(0.6613, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.6\tLoss: 0.661275\n",
      "tensor(0.7834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.8\tLoss: 0.783443\n",
      "\n",
      "Test Epoch: 686\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 686\tmaintain_Accuracy: 2450/2993 (82%)\n",
      "\n",
      "tensor(0.7958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.0\tLoss: 0.795831\n",
      "tensor(0.7873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.2\tLoss: 0.787303\n",
      "tensor(0.8304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.4\tLoss: 0.830435\n",
      "tensor(0.7888, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.6\tLoss: 0.788781\n",
      "tensor(0.7531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.8\tLoss: 0.753133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 687\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 687\tmaintain_Accuracy: 2459/2993 (82%)\n",
      "\n",
      "tensor(0.8076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.0\tLoss: 0.807619\n",
      "tensor(0.7846, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.2\tLoss: 0.784566\n",
      "tensor(0.8217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.4\tLoss: 0.821655\n",
      "tensor(1.0006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.6\tLoss: 1.000612\n",
      "tensor(0.9150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.8\tLoss: 0.914975\n",
      "\n",
      "Test Epoch: 688\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 688\tmaintain_Accuracy: 2458/2993 (82%)\n",
      "\n",
      "tensor(0.7053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.0\tLoss: 0.705278\n",
      "tensor(0.8741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.2\tLoss: 0.874108\n",
      "tensor(0.8869, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.4\tLoss: 0.886948\n",
      "tensor(0.8898, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.6\tLoss: 0.889785\n",
      "tensor(0.8223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.8\tLoss: 0.822293\n",
      "\n",
      "Test Epoch: 689\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 689\tmaintain_Accuracy: 2459/2993 (82%)\n",
      "\n",
      "tensor(0.8702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.0\tLoss: 0.870179\n",
      "tensor(0.8696, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.2\tLoss: 0.869648\n",
      "tensor(0.8727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.4\tLoss: 0.872688\n",
      "tensor(0.8062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.6\tLoss: 0.806230\n",
      "tensor(0.9068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.8\tLoss: 0.906794\n",
      "\n",
      "Train Epoch: 690\tAttack_Accuracy: 10701/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 690\tmaintain_Accuracy: 10446/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 690\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 690\tmaintain_Accuracy: 2458/2993 (82%)\n",
      "\n",
      "tensor(0.9836, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.0\tLoss: 0.983631\n",
      "tensor(0.8785, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.2\tLoss: 0.878533\n",
      "tensor(0.9731, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.4\tLoss: 0.973080\n",
      "tensor(0.7141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.6\tLoss: 0.714075\n",
      "tensor(0.8253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.8\tLoss: 0.825281\n",
      "\n",
      "Test Epoch: 691\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 691\tmaintain_Accuracy: 2464/2993 (82%)\n",
      "\n",
      "tensor(0.9592, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.0\tLoss: 0.959198\n",
      "tensor(0.7349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.2\tLoss: 0.734946\n",
      "tensor(0.6827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.4\tLoss: 0.682749\n",
      "tensor(0.8631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.6\tLoss: 0.863148\n",
      "tensor(0.9781, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.8\tLoss: 0.978074\n",
      "\n",
      "Test Epoch: 692\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 692\tmaintain_Accuracy: 2462/2993 (82%)\n",
      "\n",
      "tensor(0.7782, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.0\tLoss: 0.778173\n",
      "tensor(0.8497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.2\tLoss: 0.849702\n",
      "tensor(0.9066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.4\tLoss: 0.906598\n",
      "tensor(0.8089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.6\tLoss: 0.808891\n",
      "tensor(0.8061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.8\tLoss: 0.806104\n",
      "\n",
      "Test Epoch: 693\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 693\tmaintain_Accuracy: 2463/2993 (82%)\n",
      "\n",
      "tensor(0.8471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.0\tLoss: 0.847096\n",
      "tensor(1.0597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.2\tLoss: 1.059723\n",
      "tensor(0.7788, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.4\tLoss: 0.778754\n",
      "tensor(0.8190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.6\tLoss: 0.818966\n",
      "tensor(0.8960, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.8\tLoss: 0.896019\n",
      "\n",
      "Test Epoch: 694\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 694\tmaintain_Accuracy: 2458/2993 (82%)\n",
      "\n",
      "tensor(0.7715, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.0\tLoss: 0.771527\n",
      "tensor(0.9486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.2\tLoss: 0.948577\n",
      "tensor(0.9609, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.4\tLoss: 0.960878\n",
      "tensor(0.8882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.6\tLoss: 0.888241\n",
      "tensor(0.8401, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.8\tLoss: 0.840132\n",
      "\n",
      "Train Epoch: 695\tAttack_Accuracy: 10697/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 695\tmaintain_Accuracy: 10493/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 695\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 695\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.0\tLoss: 0.681250\n",
      "tensor(1.0322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.2\tLoss: 1.032201\n",
      "tensor(0.9570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.4\tLoss: 0.956960\n",
      "tensor(0.8722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.6\tLoss: 0.872248\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.8\tLoss: 0.692962\n",
      "\n",
      "Test Epoch: 696\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 696\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.7718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.0\tLoss: 0.771824\n",
      "tensor(0.8081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.2\tLoss: 0.808103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7844, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.4\tLoss: 0.784351\n",
      "tensor(0.8047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.6\tLoss: 0.804659\n",
      "tensor(0.9576, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.8\tLoss: 0.957581\n",
      "\n",
      "Test Epoch: 697\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 697\tmaintain_Accuracy: 2467/2993 (82%)\n",
      "\n",
      "tensor(0.7530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.0\tLoss: 0.753028\n",
      "tensor(0.7870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.2\tLoss: 0.786967\n",
      "tensor(0.8430, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.4\tLoss: 0.843022\n",
      "tensor(0.7064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.6\tLoss: 0.706395\n",
      "tensor(0.7997, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.8\tLoss: 0.799671\n",
      "\n",
      "Test Epoch: 698\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 698\tmaintain_Accuracy: 2461/2993 (82%)\n",
      "\n",
      "tensor(0.8217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.0\tLoss: 0.821716\n",
      "tensor(0.7719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.2\tLoss: 0.771854\n",
      "tensor(0.7879, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.4\tLoss: 0.787871\n",
      "tensor(0.8001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.6\tLoss: 0.800075\n",
      "tensor(0.8047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.8\tLoss: 0.804675\n",
      "\n",
      "Test Epoch: 699\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 699\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.7823, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.0\tLoss: 0.782256\n",
      "tensor(0.8357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.2\tLoss: 0.835736\n",
      "tensor(0.9065, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.4\tLoss: 0.906465\n",
      "tensor(0.8650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.6\tLoss: 0.864990\n",
      "tensor(0.8794, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.8\tLoss: 0.879354\n",
      "\n",
      "Train Epoch: 700\tAttack_Accuracy: 10715/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 700\tmaintain_Accuracy: 10510/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 700\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 700\tmaintain_Accuracy: 2476/2993 (83%)\n",
      "\n",
      "tensor(0.8338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.0\tLoss: 0.833779\n",
      "tensor(0.7671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.2\tLoss: 0.767150\n",
      "tensor(0.8362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.4\tLoss: 0.836163\n",
      "tensor(0.6703, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.6\tLoss: 0.670263\n",
      "tensor(0.9007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.8\tLoss: 0.900697\n",
      "\n",
      "Test Epoch: 701\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 701\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.8901, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.0\tLoss: 0.890081\n",
      "tensor(0.7536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.2\tLoss: 0.753594\n",
      "tensor(0.9143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.4\tLoss: 0.914312\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.6\tLoss: 0.690882\n",
      "tensor(0.9806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.8\tLoss: 0.980569\n",
      "\n",
      "Test Epoch: 702\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 702\tmaintain_Accuracy: 2455/2993 (82%)\n",
      "\n",
      "tensor(0.7664, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.0\tLoss: 0.766379\n",
      "tensor(0.9148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.2\tLoss: 0.914837\n",
      "tensor(0.9488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.4\tLoss: 0.948786\n",
      "tensor(0.8716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.6\tLoss: 0.871581\n",
      "tensor(0.7748, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.8\tLoss: 0.774791\n",
      "\n",
      "Test Epoch: 703\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 703\tmaintain_Accuracy: 2455/2993 (82%)\n",
      "\n",
      "tensor(0.8392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.0\tLoss: 0.839164\n",
      "tensor(0.9135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.2\tLoss: 0.913450\n",
      "tensor(0.8956, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.4\tLoss: 0.895616\n",
      "tensor(0.7796, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.6\tLoss: 0.779566\n",
      "tensor(0.7953, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.8\tLoss: 0.795339\n",
      "\n",
      "Test Epoch: 704\tAttack_Accuracy: 345/412 (84%)\n",
      "\n",
      "\n",
      "Test Epoch: 704\tmaintain_Accuracy: 2453/2993 (82%)\n",
      "\n",
      "tensor(0.8259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.0\tLoss: 0.825910\n",
      "tensor(0.8626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.2\tLoss: 0.862608\n",
      "tensor(0.8459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.4\tLoss: 0.845925\n",
      "tensor(0.6711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.6\tLoss: 0.671115\n",
      "tensor(0.7769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.8\tLoss: 0.776931\n",
      "\n",
      "Train Epoch: 705\tAttack_Accuracy: 10735/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 705\tmaintain_Accuracy: 10536/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 705\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 705\tmaintain_Accuracy: 2452/2993 (82%)\n",
      "\n",
      "tensor(0.8165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.0\tLoss: 0.816535\n",
      "tensor(0.8400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.2\tLoss: 0.839971\n",
      "tensor(0.8328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.4\tLoss: 0.832793\n",
      "tensor(0.8438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.6\tLoss: 0.843839\n",
      "tensor(0.7323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.8\tLoss: 0.732303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 706\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 706\tmaintain_Accuracy: 2454/2993 (82%)\n",
      "\n",
      "tensor(0.7317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.0\tLoss: 0.731657\n",
      "tensor(0.7168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.2\tLoss: 0.716776\n",
      "tensor(0.8371, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.4\tLoss: 0.837086\n",
      "tensor(0.8624, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.6\tLoss: 0.862391\n",
      "tensor(0.8672, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.8\tLoss: 0.867215\n",
      "\n",
      "Test Epoch: 707\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 707\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(0.8639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.0\tLoss: 0.863873\n",
      "tensor(0.8166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.2\tLoss: 0.816555\n",
      "tensor(0.8571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.4\tLoss: 0.857141\n",
      "tensor(0.8947, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.6\tLoss: 0.894712\n",
      "tensor(0.7436, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.8\tLoss: 0.743553\n",
      "\n",
      "Test Epoch: 708\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 708\tmaintain_Accuracy: 2467/2993 (82%)\n",
      "\n",
      "tensor(0.7727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.0\tLoss: 0.772713\n",
      "tensor(0.8223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.2\tLoss: 0.822340\n",
      "tensor(0.7016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.4\tLoss: 0.701586\n",
      "tensor(0.7652, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.6\tLoss: 0.765211\n",
      "tensor(0.8011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.8\tLoss: 0.801108\n",
      "\n",
      "Test Epoch: 709\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 709\tmaintain_Accuracy: 2468/2993 (82%)\n",
      "\n",
      "tensor(0.7636, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.0\tLoss: 0.763645\n",
      "tensor(0.6905, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.2\tLoss: 0.690482\n",
      "tensor(0.8284, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.4\tLoss: 0.828390\n",
      "tensor(0.7886, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.6\tLoss: 0.788552\n",
      "tensor(0.7461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.8\tLoss: 0.746107\n",
      "\n",
      "Train Epoch: 710\tAttack_Accuracy: 10711/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 710\tmaintain_Accuracy: 10492/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 710\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 710\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.9261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.0\tLoss: 0.926125\n",
      "tensor(1.0848, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.2\tLoss: 1.084836\n",
      "tensor(0.7766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.4\tLoss: 0.776553\n",
      "tensor(0.7772, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.6\tLoss: 0.777211\n",
      "tensor(0.7649, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.8\tLoss: 0.764908\n",
      "\n",
      "Test Epoch: 711\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 711\tmaintain_Accuracy: 2465/2993 (82%)\n",
      "\n",
      "tensor(0.8395, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.0\tLoss: 0.839532\n",
      "tensor(0.8029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.2\tLoss: 0.802857\n",
      "tensor(0.7607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.4\tLoss: 0.760750\n",
      "tensor(0.8459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.6\tLoss: 0.845883\n",
      "tensor(0.7912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.8\tLoss: 0.791208\n",
      "\n",
      "Test Epoch: 712\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 712\tmaintain_Accuracy: 2463/2993 (82%)\n",
      "\n",
      "tensor(0.8912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.0\tLoss: 0.891218\n",
      "tensor(0.7880, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.2\tLoss: 0.788020\n",
      "tensor(0.7095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.4\tLoss: 0.709505\n",
      "tensor(0.8085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.6\tLoss: 0.808500\n",
      "tensor(0.8513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.8\tLoss: 0.851264\n",
      "\n",
      "Test Epoch: 713\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 713\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.7900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.0\tLoss: 0.790050\n",
      "tensor(0.8486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.2\tLoss: 0.848570\n",
      "tensor(0.8047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.4\tLoss: 0.804720\n",
      "tensor(0.8329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.6\tLoss: 0.832944\n",
      "tensor(0.8437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.8\tLoss: 0.843666\n",
      "\n",
      "Test Epoch: 714\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 714\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.7676, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.0\tLoss: 0.767566\n",
      "tensor(0.7149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.2\tLoss: 0.714937\n",
      "tensor(0.8982, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.4\tLoss: 0.898243\n",
      "tensor(0.8949, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.6\tLoss: 0.894941\n",
      "tensor(0.8794, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.8\tLoss: 0.879407\n",
      "\n",
      "Train Epoch: 715\tAttack_Accuracy: 10759/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 715\tmaintain_Accuracy: 10457/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 715\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 715\tmaintain_Accuracy: 2472/2993 (83%)\n",
      "\n",
      "tensor(0.8004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.0\tLoss: 0.800397\n",
      "tensor(0.8284, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.2\tLoss: 0.828377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8649, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.4\tLoss: 0.864941\n",
      "tensor(0.8796, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.6\tLoss: 0.879593\n",
      "tensor(0.8923, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.8\tLoss: 0.892335\n",
      "\n",
      "Test Epoch: 716\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 716\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.8243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.0\tLoss: 0.824312\n",
      "tensor(0.7367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.2\tLoss: 0.736726\n",
      "tensor(0.7456, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.4\tLoss: 0.745605\n",
      "tensor(0.7440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.6\tLoss: 0.744048\n",
      "tensor(0.7654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.8\tLoss: 0.765356\n",
      "\n",
      "Test Epoch: 717\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 717\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.8721, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.0\tLoss: 0.872112\n",
      "tensor(0.8723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.2\tLoss: 0.872255\n",
      "tensor(0.7759, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.4\tLoss: 0.775859\n",
      "tensor(0.7853, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.6\tLoss: 0.785255\n",
      "tensor(0.6588, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.8\tLoss: 0.658758\n",
      "\n",
      "Test Epoch: 718\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 718\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.6869, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.0\tLoss: 0.686894\n",
      "tensor(0.8350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.2\tLoss: 0.834961\n",
      "tensor(0.7789, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.4\tLoss: 0.778906\n",
      "tensor(0.8123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.6\tLoss: 0.812330\n",
      "tensor(0.8399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.8\tLoss: 0.839939\n",
      "\n",
      "Test Epoch: 719\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 719\tmaintain_Accuracy: 2464/2993 (82%)\n",
      "\n",
      "tensor(0.8218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.0\tLoss: 0.821759\n",
      "tensor(0.7725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.2\tLoss: 0.772470\n",
      "tensor(0.8198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.4\tLoss: 0.819798\n",
      "tensor(0.7354, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.6\tLoss: 0.735383\n",
      "tensor(0.9329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.8\tLoss: 0.932938\n",
      "\n",
      "Train Epoch: 720\tAttack_Accuracy: 10684/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 720\tmaintain_Accuracy: 10572/12800 (83%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 720\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 720\tmaintain_Accuracy: 2460/2993 (82%)\n",
      "\n",
      "tensor(0.7941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.0\tLoss: 0.794092\n",
      "tensor(0.7631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.2\tLoss: 0.763137\n",
      "tensor(0.7725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.4\tLoss: 0.772545\n",
      "tensor(0.7434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.6\tLoss: 0.743413\n",
      "tensor(0.8728, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.8\tLoss: 0.872774\n",
      "\n",
      "Test Epoch: 721\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 721\tmaintain_Accuracy: 2467/2993 (82%)\n",
      "\n",
      "tensor(0.7266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.0\tLoss: 0.726641\n",
      "tensor(0.7086, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.2\tLoss: 0.708639\n",
      "tensor(0.8117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.4\tLoss: 0.811736\n",
      "tensor(0.8450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.6\tLoss: 0.844998\n",
      "tensor(0.8281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.8\tLoss: 0.828122\n",
      "\n",
      "Test Epoch: 722\tAttack_Accuracy: 344/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 722\tmaintain_Accuracy: 2455/2993 (82%)\n",
      "\n",
      "tensor(0.9207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.0\tLoss: 0.920690\n",
      "tensor(0.9476, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.2\tLoss: 0.947591\n",
      "tensor(0.8449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.4\tLoss: 0.844906\n",
      "tensor(0.8882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.6\tLoss: 0.888184\n",
      "tensor(0.7449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.8\tLoss: 0.744940\n",
      "\n",
      "Test Epoch: 723\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 723\tmaintain_Accuracy: 2461/2993 (82%)\n",
      "\n",
      "tensor(0.9675, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.0\tLoss: 0.967494\n",
      "tensor(0.8171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.2\tLoss: 0.817068\n",
      "tensor(0.7935, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.4\tLoss: 0.793470\n",
      "tensor(0.9402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.6\tLoss: 0.940249\n",
      "tensor(0.7098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.8\tLoss: 0.709775\n",
      "\n",
      "Test Epoch: 724\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 724\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.6829, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.0\tLoss: 0.682924\n",
      "tensor(0.6937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.2\tLoss: 0.693693\n",
      "tensor(0.8753, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.4\tLoss: 0.875318\n",
      "tensor(0.7075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.6\tLoss: 0.707493\n",
      "tensor(0.9111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.8\tLoss: 0.911118\n",
      "\n",
      "Train Epoch: 725\tAttack_Accuracy: 10666/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 725\tmaintain_Accuracy: 10540/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 725\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 725\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.8171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.0\tLoss: 0.817125\n",
      "tensor(0.7982, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.2\tLoss: 0.798239\n",
      "tensor(0.8487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.4\tLoss: 0.848653\n",
      "tensor(0.7440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.6\tLoss: 0.743990\n",
      "tensor(0.8687, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.8\tLoss: 0.868709\n",
      "\n",
      "Test Epoch: 726\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 726\tmaintain_Accuracy: 2457/2993 (82%)\n",
      "\n",
      "tensor(0.8719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.0\tLoss: 0.871858\n",
      "tensor(0.8130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.2\tLoss: 0.813011\n",
      "tensor(0.7741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.4\tLoss: 0.774077\n",
      "tensor(0.7020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.6\tLoss: 0.702020\n",
      "tensor(0.9361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.8\tLoss: 0.936092\n",
      "\n",
      "Test Epoch: 727\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 727\tmaintain_Accuracy: 2451/2993 (82%)\n",
      "\n",
      "tensor(0.8571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.0\tLoss: 0.857124\n",
      "tensor(0.8012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.2\tLoss: 0.801199\n",
      "tensor(0.7538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.4\tLoss: 0.753847\n",
      "tensor(0.8403, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.6\tLoss: 0.840316\n",
      "tensor(0.7113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.8\tLoss: 0.711324\n",
      "\n",
      "Test Epoch: 728\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 728\tmaintain_Accuracy: 2459/2993 (82%)\n",
      "\n",
      "tensor(0.8296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.0\tLoss: 0.829646\n",
      "tensor(0.8127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.2\tLoss: 0.812711\n",
      "tensor(0.8525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.4\tLoss: 0.852461\n",
      "tensor(0.7112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.6\tLoss: 0.711174\n",
      "tensor(0.7870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.8\tLoss: 0.786955\n",
      "\n",
      "Test Epoch: 729\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 729\tmaintain_Accuracy: 2464/2993 (82%)\n",
      "\n",
      "tensor(0.8179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.0\tLoss: 0.817921\n",
      "tensor(0.8266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.2\tLoss: 0.826646\n",
      "tensor(0.8976, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.4\tLoss: 0.897618\n",
      "tensor(0.8858, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.6\tLoss: 0.885766\n",
      "tensor(0.8259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.8\tLoss: 0.825893\n",
      "\n",
      "Train Epoch: 730\tAttack_Accuracy: 10782/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 730\tmaintain_Accuracy: 10520/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 730\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 730\tmaintain_Accuracy: 2465/2993 (82%)\n",
      "\n",
      "tensor(0.7009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.0\tLoss: 0.700906\n",
      "tensor(0.9464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.2\tLoss: 0.946443\n",
      "tensor(0.9290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.4\tLoss: 0.928958\n",
      "tensor(0.8006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.6\tLoss: 0.800600\n",
      "tensor(0.8321, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.8\tLoss: 0.832081\n",
      "\n",
      "Test Epoch: 731\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 731\tmaintain_Accuracy: 2467/2993 (82%)\n",
      "\n",
      "tensor(0.8368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.0\tLoss: 0.836779\n",
      "tensor(0.7762, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.2\tLoss: 0.776214\n",
      "tensor(0.7399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.4\tLoss: 0.739909\n",
      "tensor(0.7304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.6\tLoss: 0.730417\n",
      "tensor(0.8820, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.8\tLoss: 0.881966\n",
      "\n",
      "Test Epoch: 732\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 732\tmaintain_Accuracy: 2462/2993 (82%)\n",
      "\n",
      "tensor(0.8000, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.0\tLoss: 0.800005\n",
      "tensor(0.8332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.2\tLoss: 0.833186\n",
      "tensor(0.8332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.4\tLoss: 0.833225\n",
      "tensor(0.9814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.6\tLoss: 0.981430\n",
      "tensor(0.7443, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.8\tLoss: 0.744279\n",
      "\n",
      "Test Epoch: 733\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 733\tmaintain_Accuracy: 2461/2993 (82%)\n",
      "\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.0\tLoss: 0.688777\n",
      "tensor(0.8203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.2\tLoss: 0.820263\n",
      "tensor(0.8347, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.4\tLoss: 0.834704\n",
      "tensor(0.8807, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.6\tLoss: 0.880717\n",
      "tensor(0.7360, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.8\tLoss: 0.735981\n",
      "\n",
      "Test Epoch: 734\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 734\tmaintain_Accuracy: 2463/2993 (82%)\n",
      "\n",
      "tensor(0.7739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.0\tLoss: 0.773888\n",
      "tensor(0.9356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.2\tLoss: 0.935641\n",
      "tensor(0.8392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.4\tLoss: 0.839247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.6\tLoss: 0.710095\n",
      "tensor(0.8102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.8\tLoss: 0.810155\n",
      "\n",
      "Train Epoch: 735\tAttack_Accuracy: 10685/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 735\tmaintain_Accuracy: 10453/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 735\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 735\tmaintain_Accuracy: 2464/2993 (82%)\n",
      "\n",
      "tensor(0.8575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.0\tLoss: 0.857519\n",
      "tensor(0.8070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.2\tLoss: 0.806953\n",
      "tensor(0.7483, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.4\tLoss: 0.748323\n",
      "tensor(0.8022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.6\tLoss: 0.802197\n",
      "tensor(0.7091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.8\tLoss: 0.709143\n",
      "\n",
      "Test Epoch: 736\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 736\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.8243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.0\tLoss: 0.824331\n",
      "tensor(0.9085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.2\tLoss: 0.908476\n",
      "tensor(0.8795, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.4\tLoss: 0.879511\n",
      "tensor(0.9866, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.6\tLoss: 0.986558\n",
      "tensor(0.8762, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.8\tLoss: 0.876214\n",
      "\n",
      "Test Epoch: 737\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 737\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.7807, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.0\tLoss: 0.780748\n",
      "tensor(0.8534, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.2\tLoss: 0.853408\n",
      "tensor(0.8518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.4\tLoss: 0.851778\n",
      "tensor(0.8947, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.6\tLoss: 0.894695\n",
      "tensor(0.9382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.8\tLoss: 0.938249\n",
      "\n",
      "Test Epoch: 738\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 738\tmaintain_Accuracy: 2468/2993 (82%)\n",
      "\n",
      "tensor(0.7487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.0\tLoss: 0.748732\n",
      "tensor(0.9517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.2\tLoss: 0.951744\n",
      "tensor(0.9961, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.4\tLoss: 0.996113\n",
      "tensor(0.6935, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.6\tLoss: 0.693504\n",
      "tensor(0.7905, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.8\tLoss: 0.790533\n",
      "\n",
      "Test Epoch: 739\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 739\tmaintain_Accuracy: 2468/2993 (82%)\n",
      "\n",
      "tensor(0.6959, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.0\tLoss: 0.695914\n",
      "tensor(0.7889, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.2\tLoss: 0.788937\n",
      "tensor(0.8399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.4\tLoss: 0.839927\n",
      "tensor(0.8615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.6\tLoss: 0.861477\n",
      "tensor(0.8270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.8\tLoss: 0.827019\n",
      "\n",
      "Train Epoch: 740\tAttack_Accuracy: 10682/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 740\tmaintain_Accuracy: 10565/12800 (83%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 740\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 740\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.9582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.0\tLoss: 0.958206\n",
      "tensor(0.9697, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.2\tLoss: 0.969670\n",
      "tensor(0.8141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.4\tLoss: 0.814077\n",
      "tensor(0.8695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.6\tLoss: 0.869536\n",
      "tensor(1.0087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.8\tLoss: 1.008732\n",
      "\n",
      "Test Epoch: 741\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 741\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.7886, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.0\tLoss: 0.788642\n",
      "tensor(0.8961, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.2\tLoss: 0.896098\n",
      "tensor(0.8479, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.4\tLoss: 0.847886\n",
      "tensor(0.7727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.6\tLoss: 0.772737\n",
      "tensor(0.7476, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.8\tLoss: 0.747576\n",
      "\n",
      "Test Epoch: 742\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 742\tmaintain_Accuracy: 2478/2993 (83%)\n",
      "\n",
      "tensor(0.7944, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.0\tLoss: 0.794414\n",
      "tensor(0.7437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.2\tLoss: 0.743741\n",
      "tensor(0.8188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.4\tLoss: 0.818807\n",
      "tensor(0.7900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.6\tLoss: 0.790005\n",
      "tensor(0.8562, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.8\tLoss: 0.856213\n",
      "\n",
      "Test Epoch: 743\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 743\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.8364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.0\tLoss: 0.836378\n",
      "tensor(0.7372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.2\tLoss: 0.737154\n",
      "tensor(0.8097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.4\tLoss: 0.809683\n",
      "tensor(0.8961, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.6\tLoss: 0.896078\n",
      "tensor(0.8893, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.8\tLoss: 0.889339\n",
      "\n",
      "Test Epoch: 744\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 744\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.9238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.0\tLoss: 0.923785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.2\tLoss: 0.673038\n",
      "tensor(0.7221, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.4\tLoss: 0.722095\n",
      "tensor(0.8663, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.6\tLoss: 0.866312\n",
      "tensor(0.8342, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.8\tLoss: 0.834194\n",
      "\n",
      "Train Epoch: 745\tAttack_Accuracy: 10694/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 745\tmaintain_Accuracy: 10515/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 745\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 745\tmaintain_Accuracy: 2477/2993 (83%)\n",
      "\n",
      "tensor(0.8645, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.0\tLoss: 0.864489\n",
      "tensor(0.8153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.2\tLoss: 0.815348\n",
      "tensor(0.8847, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.4\tLoss: 0.884713\n",
      "tensor(0.8615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.6\tLoss: 0.861461\n",
      "tensor(0.7785, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.8\tLoss: 0.778506\n",
      "\n",
      "Test Epoch: 746\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 746\tmaintain_Accuracy: 2480/2993 (83%)\n",
      "\n",
      "tensor(0.7038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.0\tLoss: 0.703849\n",
      "tensor(0.7522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.2\tLoss: 0.752205\n",
      "tensor(0.7635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.4\tLoss: 0.763541\n",
      "tensor(0.7575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.6\tLoss: 0.757522\n",
      "tensor(0.8195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.8\tLoss: 0.819488\n",
      "\n",
      "Test Epoch: 747\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 747\tmaintain_Accuracy: 2481/2993 (83%)\n",
      "\n",
      "tensor(0.7168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.0\tLoss: 0.716840\n",
      "tensor(0.8580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.2\tLoss: 0.857997\n",
      "tensor(0.6715, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.4\tLoss: 0.671452\n",
      "tensor(0.8080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.6\tLoss: 0.808001\n",
      "tensor(0.7818, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.8\tLoss: 0.781751\n",
      "\n",
      "Test Epoch: 748\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 748\tmaintain_Accuracy: 2476/2993 (83%)\n",
      "\n",
      "tensor(0.7722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.0\tLoss: 0.772231\n",
      "tensor(0.8264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.2\tLoss: 0.826374\n",
      "tensor(0.7331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.4\tLoss: 0.733126\n",
      "tensor(0.9560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.6\tLoss: 0.955962\n",
      "tensor(0.8484, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.8\tLoss: 0.848369\n",
      "\n",
      "Test Epoch: 749\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 749\tmaintain_Accuracy: 2476/2993 (83%)\n",
      "\n",
      "tensor(0.6103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.0\tLoss: 0.610313\n",
      "tensor(0.8016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.2\tLoss: 0.801603\n",
      "tensor(0.9521, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.4\tLoss: 0.952128\n",
      "tensor(0.9979, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.6\tLoss: 0.997869\n",
      "tensor(0.9719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.8\tLoss: 0.971851\n",
      "\n",
      "Train Epoch: 750\tAttack_Accuracy: 10760/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 750\tmaintain_Accuracy: 10540/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 750\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 750\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.8851, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.0\tLoss: 0.885052\n",
      "tensor(0.9142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.2\tLoss: 0.914186\n",
      "tensor(0.7398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.4\tLoss: 0.739803\n",
      "tensor(0.7931, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.6\tLoss: 0.793133\n",
      "tensor(0.8277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.8\tLoss: 0.827690\n",
      "\n",
      "Test Epoch: 751\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 751\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.8180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.0\tLoss: 0.818039\n",
      "tensor(0.7492, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.2\tLoss: 0.749172\n",
      "tensor(0.8369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.4\tLoss: 0.836930\n",
      "tensor(0.7736, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.6\tLoss: 0.773578\n",
      "tensor(0.8766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.8\tLoss: 0.876596\n",
      "\n",
      "Test Epoch: 752\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 752\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.6999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.0\tLoss: 0.699907\n",
      "tensor(0.7904, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.2\tLoss: 0.790412\n",
      "tensor(0.9033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.4\tLoss: 0.903314\n",
      "tensor(0.7229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.6\tLoss: 0.722873\n",
      "tensor(0.7004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.8\tLoss: 0.700389\n",
      "\n",
      "Test Epoch: 753\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 753\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.9356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.0\tLoss: 0.935603\n",
      "tensor(0.8704, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.2\tLoss: 0.870355\n",
      "tensor(0.8178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.4\tLoss: 0.817848\n",
      "tensor(0.9212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.6\tLoss: 0.921166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.8\tLoss: 0.637995\n",
      "\n",
      "Test Epoch: 754\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 754\tmaintain_Accuracy: 2472/2993 (83%)\n",
      "\n",
      "tensor(0.8275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.0\tLoss: 0.827450\n",
      "tensor(0.7176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.2\tLoss: 0.717572\n",
      "tensor(0.9424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.4\tLoss: 0.942411\n",
      "tensor(0.7875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.6\tLoss: 0.787548\n",
      "tensor(0.7882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.8\tLoss: 0.788235\n",
      "\n",
      "Train Epoch: 755\tAttack_Accuracy: 10755/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 755\tmaintain_Accuracy: 10492/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 755\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 755\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.8169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.0\tLoss: 0.816895\n",
      "tensor(0.8307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.2\tLoss: 0.830733\n",
      "tensor(0.8712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.4\tLoss: 0.871224\n",
      "tensor(0.7364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.6\tLoss: 0.736390\n",
      "tensor(0.8176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.8\tLoss: 0.817578\n",
      "\n",
      "Test Epoch: 756\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 756\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.7973, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.0\tLoss: 0.797279\n",
      "tensor(0.8263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.2\tLoss: 0.826349\n",
      "tensor(0.8118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.4\tLoss: 0.811762\n",
      "tensor(0.7155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.6\tLoss: 0.715503\n",
      "tensor(0.9341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.8\tLoss: 0.934071\n",
      "\n",
      "Test Epoch: 757\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 757\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.8141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.0\tLoss: 0.814093\n",
      "tensor(0.9259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.2\tLoss: 0.925853\n",
      "tensor(0.7752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.4\tLoss: 0.775152\n",
      "tensor(0.7626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.6\tLoss: 0.762587\n",
      "tensor(0.9009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.8\tLoss: 0.900859\n",
      "\n",
      "Test Epoch: 758\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 758\tmaintain_Accuracy: 2466/2993 (82%)\n",
      "\n",
      "tensor(0.7448, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.0\tLoss: 0.744763\n",
      "tensor(0.8180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.2\tLoss: 0.818042\n",
      "tensor(0.7834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.4\tLoss: 0.783437\n",
      "tensor(0.8429, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.6\tLoss: 0.842896\n",
      "tensor(0.7790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.8\tLoss: 0.778986\n",
      "\n",
      "Test Epoch: 759\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 759\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.8015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.0\tLoss: 0.801503\n",
      "tensor(0.7705, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.2\tLoss: 0.770511\n",
      "tensor(0.7448, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.4\tLoss: 0.744830\n",
      "tensor(0.7876, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.6\tLoss: 0.787596\n",
      "tensor(0.7384, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.8\tLoss: 0.738401\n",
      "\n",
      "Train Epoch: 760\tAttack_Accuracy: 10698/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 760\tmaintain_Accuracy: 10514/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 760\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 760\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(0.8490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.0\tLoss: 0.848996\n",
      "tensor(0.7972, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.2\tLoss: 0.797249\n",
      "tensor(0.7824, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.4\tLoss: 0.782376\n",
      "tensor(0.7348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.6\tLoss: 0.734808\n",
      "tensor(0.6396, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.8\tLoss: 0.639558\n",
      "\n",
      "Test Epoch: 761\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 761\tmaintain_Accuracy: 2478/2993 (83%)\n",
      "\n",
      "tensor(0.8050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.0\tLoss: 0.805045\n",
      "tensor(0.7598, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.2\tLoss: 0.759832\n",
      "tensor(0.7314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.4\tLoss: 0.731384\n",
      "tensor(0.8148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.6\tLoss: 0.814752\n",
      "tensor(0.8569, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.8\tLoss: 0.856902\n",
      "\n",
      "Test Epoch: 762\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 762\tmaintain_Accuracy: 2479/2993 (83%)\n",
      "\n",
      "tensor(0.8288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.0\tLoss: 0.828842\n",
      "tensor(0.8022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.2\tLoss: 0.802192\n",
      "tensor(0.8327, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.4\tLoss: 0.832731\n",
      "tensor(0.7144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.6\tLoss: 0.714411\n",
      "tensor(0.8036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.8\tLoss: 0.803582\n",
      "\n",
      "Test Epoch: 763\tAttack_Accuracy: 343/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 763\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.8883, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.0\tLoss: 0.888285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.2\tLoss: 0.850103\n",
      "tensor(0.8357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.4\tLoss: 0.835672\n",
      "tensor(0.8124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.6\tLoss: 0.812411\n",
      "tensor(0.8496, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.8\tLoss: 0.849597\n",
      "\n",
      "Test Epoch: 764\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 764\tmaintain_Accuracy: 2478/2993 (83%)\n",
      "\n",
      "tensor(0.7826, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.0\tLoss: 0.782628\n",
      "tensor(0.8014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.2\tLoss: 0.801371\n",
      "tensor(0.7960, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.4\tLoss: 0.796035\n",
      "tensor(0.7743, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.6\tLoss: 0.774336\n",
      "tensor(0.8340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.8\tLoss: 0.834049\n",
      "\n",
      "Train Epoch: 765\tAttack_Accuracy: 10678/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 765\tmaintain_Accuracy: 10526/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 765\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 765\tmaintain_Accuracy: 2485/2993 (83%)\n",
      "\n",
      "tensor(0.9290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.0\tLoss: 0.928988\n",
      "tensor(0.8381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.2\tLoss: 0.838057\n",
      "tensor(0.8340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.4\tLoss: 0.833967\n",
      "tensor(0.8171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.6\tLoss: 0.817093\n",
      "tensor(0.7404, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.8\tLoss: 0.740447\n",
      "\n",
      "Test Epoch: 766\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 766\tmaintain_Accuracy: 2477/2993 (83%)\n",
      "\n",
      "tensor(0.8444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.0\tLoss: 0.844387\n",
      "tensor(0.8048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.2\tLoss: 0.804834\n",
      "tensor(0.7754, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.4\tLoss: 0.775380\n",
      "tensor(0.8709, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.6\tLoss: 0.870923\n",
      "tensor(0.8541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.8\tLoss: 0.854079\n",
      "\n",
      "Test Epoch: 767\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 767\tmaintain_Accuracy: 2470/2993 (83%)\n",
      "\n",
      "tensor(0.9235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.0\tLoss: 0.923486\n",
      "tensor(0.8520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.2\tLoss: 0.851957\n",
      "tensor(0.6736, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.4\tLoss: 0.673625\n",
      "tensor(0.7522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.6\tLoss: 0.752198\n",
      "tensor(1.0211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.8\tLoss: 1.021082\n",
      "\n",
      "Test Epoch: 768\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 768\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.8045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.0\tLoss: 0.804500\n",
      "tensor(0.7925, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.2\tLoss: 0.792522\n",
      "tensor(0.7140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.4\tLoss: 0.713980\n",
      "tensor(0.7833, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.6\tLoss: 0.783314\n",
      "tensor(0.7745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.8\tLoss: 0.774545\n",
      "\n",
      "Test Epoch: 769\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 769\tmaintain_Accuracy: 2475/2993 (83%)\n",
      "\n",
      "tensor(1.0204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.0\tLoss: 1.020377\n",
      "tensor(0.8514, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.2\tLoss: 0.851438\n",
      "tensor(0.8169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.4\tLoss: 0.816898\n",
      "tensor(0.9401, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.6\tLoss: 0.940109\n",
      "tensor(0.5957, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.8\tLoss: 0.595720\n",
      "\n",
      "Train Epoch: 770\tAttack_Accuracy: 10726/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 770\tmaintain_Accuracy: 10604/12800 (83%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 770\tAttack_Accuracy: 341/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 770\tmaintain_Accuracy: 2476/2993 (83%)\n",
      "\n",
      "tensor(0.8977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.0\tLoss: 0.897695\n",
      "tensor(0.7277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.2\tLoss: 0.727708\n",
      "tensor(0.8528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.4\tLoss: 0.852765\n",
      "tensor(0.7499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.6\tLoss: 0.749884\n",
      "tensor(0.7524, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.8\tLoss: 0.752353\n",
      "\n",
      "Test Epoch: 771\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 771\tmaintain_Accuracy: 2469/2993 (82%)\n",
      "\n",
      "tensor(0.8517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.0\tLoss: 0.851747\n",
      "tensor(0.6970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.2\tLoss: 0.696991\n",
      "tensor(0.7788, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.4\tLoss: 0.778826\n",
      "tensor(0.7495, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.6\tLoss: 0.749494\n",
      "tensor(0.8036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.8\tLoss: 0.803625\n",
      "\n",
      "Test Epoch: 772\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 772\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.8117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.0\tLoss: 0.811726\n",
      "tensor(0.7764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.2\tLoss: 0.776406\n",
      "tensor(0.7672, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.4\tLoss: 0.767171\n",
      "tensor(0.8268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.6\tLoss: 0.826825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7909, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.8\tLoss: 0.790926\n",
      "\n",
      "Test Epoch: 773\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 773\tmaintain_Accuracy: 2480/2993 (83%)\n",
      "\n",
      "tensor(0.7860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.0\tLoss: 0.785991\n",
      "tensor(0.8120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.2\tLoss: 0.812033\n",
      "tensor(0.7048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.4\tLoss: 0.704802\n",
      "tensor(0.7563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.6\tLoss: 0.756313\n",
      "tensor(0.7277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.8\tLoss: 0.727717\n",
      "\n",
      "Test Epoch: 774\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 774\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.7979, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.0\tLoss: 0.797913\n",
      "tensor(0.7723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.2\tLoss: 0.772266\n",
      "tensor(0.7207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.4\tLoss: 0.720690\n",
      "tensor(0.8431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.6\tLoss: 0.843080\n",
      "tensor(0.7647, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.8\tLoss: 0.764678\n",
      "\n",
      "Train Epoch: 775\tAttack_Accuracy: 10738/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 775\tmaintain_Accuracy: 10554/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 775\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 775\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.8902, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.0\tLoss: 0.890205\n",
      "tensor(0.8004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.2\tLoss: 0.800423\n",
      "tensor(0.6685, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.4\tLoss: 0.668473\n",
      "tensor(0.7634, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.6\tLoss: 0.763359\n",
      "tensor(0.7599, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.8\tLoss: 0.759925\n",
      "\n",
      "Test Epoch: 776\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 776\tmaintain_Accuracy: 2479/2993 (83%)\n",
      "\n",
      "tensor(0.8487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.0\tLoss: 0.848729\n",
      "tensor(0.6954, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.2\tLoss: 0.695398\n",
      "tensor(0.8155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.4\tLoss: 0.815472\n",
      "tensor(0.8337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.6\tLoss: 0.833678\n",
      "tensor(0.8771, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.8\tLoss: 0.877145\n",
      "\n",
      "Test Epoch: 777\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 777\tmaintain_Accuracy: 2477/2993 (83%)\n",
      "\n",
      "tensor(0.8513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.0\tLoss: 0.851288\n",
      "tensor(0.7644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.2\tLoss: 0.764430\n",
      "tensor(0.6675, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.4\tLoss: 0.667455\n",
      "tensor(0.7499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.6\tLoss: 0.749903\n",
      "tensor(0.7607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.8\tLoss: 0.760695\n",
      "\n",
      "Test Epoch: 778\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 778\tmaintain_Accuracy: 2482/2993 (83%)\n",
      "\n",
      "tensor(0.8309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.0\tLoss: 0.830935\n",
      "tensor(0.6770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.2\tLoss: 0.677026\n",
      "tensor(0.8965, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.4\tLoss: 0.896474\n",
      "tensor(0.8650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.6\tLoss: 0.865037\n",
      "tensor(0.7938, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.8\tLoss: 0.793796\n",
      "\n",
      "Test Epoch: 779\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 779\tmaintain_Accuracy: 2482/2993 (83%)\n",
      "\n",
      "tensor(0.8293, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.0\tLoss: 0.829327\n",
      "tensor(0.7958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.2\tLoss: 0.795848\n",
      "tensor(0.7975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.4\tLoss: 0.797535\n",
      "tensor(0.8008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.6\tLoss: 0.800812\n",
      "tensor(0.7671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.8\tLoss: 0.767078\n",
      "\n",
      "Train Epoch: 780\tAttack_Accuracy: 10677/12800 (83%)\n",
      "\n",
      "\n",
      "Train Epoch: 780\tmaintain_Accuracy: 10461/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 780\tAttack_Accuracy: 335/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 780\tmaintain_Accuracy: 2476/2993 (83%)\n",
      "\n",
      "tensor(0.7515, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.0\tLoss: 0.751478\n",
      "tensor(0.8176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.2\tLoss: 0.817604\n",
      "tensor(0.7140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.4\tLoss: 0.713966\n",
      "tensor(0.7143, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.6\tLoss: 0.714288\n",
      "tensor(0.8712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.8\tLoss: 0.871159\n",
      "\n",
      "Test Epoch: 781\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 781\tmaintain_Accuracy: 2476/2993 (83%)\n",
      "\n",
      "tensor(0.8563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.0\tLoss: 0.856303\n",
      "tensor(0.6895, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.2\tLoss: 0.689524\n",
      "tensor(0.7989, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.4\tLoss: 0.798875\n",
      "tensor(0.8205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.6\tLoss: 0.820464\n",
      "tensor(0.6788, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.8\tLoss: 0.678759\n",
      "\n",
      "Test Epoch: 782\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 782\tmaintain_Accuracy: 2481/2993 (83%)\n",
      "\n",
      "tensor(0.7665, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.0\tLoss: 0.766451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.2\tLoss: 0.834859\n",
      "tensor(0.8573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.4\tLoss: 0.857309\n",
      "tensor(0.8059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.6\tLoss: 0.805950\n",
      "tensor(0.7893, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.8\tLoss: 0.789325\n",
      "\n",
      "Test Epoch: 783\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 783\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.8487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.0\tLoss: 0.848745\n",
      "tensor(0.7122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.2\tLoss: 0.712153\n",
      "tensor(0.8658, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.4\tLoss: 0.865817\n",
      "tensor(0.7982, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.6\tLoss: 0.798181\n",
      "tensor(0.8552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.8\tLoss: 0.855249\n",
      "\n",
      "Test Epoch: 784\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 784\tmaintain_Accuracy: 2472/2993 (83%)\n",
      "\n",
      "tensor(0.8089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.0\tLoss: 0.808868\n",
      "tensor(0.8991, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.2\tLoss: 0.899125\n",
      "tensor(0.7649, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.4\tLoss: 0.764879\n",
      "tensor(0.6992, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.6\tLoss: 0.699162\n",
      "tensor(0.6755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.8\tLoss: 0.675476\n",
      "\n",
      "Train Epoch: 785\tAttack_Accuracy: 10738/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 785\tmaintain_Accuracy: 10561/12800 (83%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 785\tAttack_Accuracy: 342/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 785\tmaintain_Accuracy: 2465/2993 (82%)\n",
      "\n",
      "tensor(0.6774, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.0\tLoss: 0.677382\n",
      "tensor(0.8044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.2\tLoss: 0.804354\n",
      "tensor(0.7398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.4\tLoss: 0.739822\n",
      "tensor(0.7669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.6\tLoss: 0.766939\n",
      "tensor(0.8136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.8\tLoss: 0.813647\n",
      "\n",
      "Test Epoch: 786\tAttack_Accuracy: 340/412 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 786\tmaintain_Accuracy: 2465/2993 (82%)\n",
      "\n",
      "tensor(0.7767, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.0\tLoss: 0.776750\n",
      "tensor(0.7388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.2\tLoss: 0.738820\n",
      "tensor(1.0012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.4\tLoss: 1.001170\n",
      "tensor(0.7461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.6\tLoss: 0.746115\n",
      "tensor(0.8422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.8\tLoss: 0.842167\n",
      "\n",
      "Test Epoch: 787\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 787\tmaintain_Accuracy: 2464/2993 (82%)\n",
      "\n",
      "tensor(0.7109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.0\tLoss: 0.710940\n",
      "tensor(0.8172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.2\tLoss: 0.817178\n",
      "tensor(0.7977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.4\tLoss: 0.797671\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.6\tLoss: 0.686804\n",
      "tensor(0.7590, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.8\tLoss: 0.759029\n",
      "\n",
      "Test Epoch: 788\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 788\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.8326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.0\tLoss: 0.832617\n",
      "tensor(0.7264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.2\tLoss: 0.726374\n",
      "tensor(0.7835, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.4\tLoss: 0.783516\n",
      "tensor(0.9739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.6\tLoss: 0.973900\n",
      "tensor(0.7787, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.8\tLoss: 0.778731\n",
      "\n",
      "Test Epoch: 789\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 789\tmaintain_Accuracy: 2470/2993 (83%)\n",
      "\n",
      "tensor(0.8669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.0\tLoss: 0.866917\n",
      "tensor(0.9128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.2\tLoss: 0.912768\n",
      "tensor(0.6803, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.4\tLoss: 0.680252\n",
      "tensor(0.8935, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.6\tLoss: 0.893518\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.8\tLoss: 0.681171\n",
      "\n",
      "Train Epoch: 790\tAttack_Accuracy: 10694/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 790\tmaintain_Accuracy: 10520/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 790\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 790\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.8490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.0\tLoss: 0.848989\n",
      "tensor(0.7273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.2\tLoss: 0.727256\n",
      "tensor(0.7579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.4\tLoss: 0.757888\n",
      "tensor(0.9142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.6\tLoss: 0.914225\n",
      "tensor(0.9526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.8\tLoss: 0.952615\n",
      "\n",
      "Test Epoch: 791\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 791\tmaintain_Accuracy: 2471/2993 (83%)\n",
      "\n",
      "tensor(0.8329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:792 0.0\tLoss: 0.832874\n",
      "tensor(0.7474, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:792 0.2\tLoss: 0.747394\n",
      "tensor(0.8052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:792 0.4\tLoss: 0.805167\n",
      "tensor(0.6593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:792 0.6\tLoss: 0.659306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:792 0.8\tLoss: 0.829599\n",
      "\n",
      "Test Epoch: 792\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 792\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.7486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:793 0.0\tLoss: 0.748590\n",
      "tensor(0.6646, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:793 0.2\tLoss: 0.664560\n",
      "tensor(0.7263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:793 0.4\tLoss: 0.726265\n",
      "tensor(0.7486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:793 0.6\tLoss: 0.748632\n",
      "tensor(0.9040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:793 0.8\tLoss: 0.904050\n",
      "\n",
      "Test Epoch: 793\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 793\tmaintain_Accuracy: 2474/2993 (83%)\n",
      "\n",
      "tensor(0.8749, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:794 0.0\tLoss: 0.874927\n",
      "tensor(0.7727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:794 0.2\tLoss: 0.772667\n",
      "tensor(0.9817, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:794 0.4\tLoss: 0.981740\n",
      "tensor(0.8093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:794 0.6\tLoss: 0.809281\n",
      "tensor(0.9048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:794 0.8\tLoss: 0.904804\n",
      "\n",
      "Test Epoch: 794\tAttack_Accuracy: 339/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 794\tmaintain_Accuracy: 2477/2993 (83%)\n",
      "\n",
      "tensor(0.7904, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:795 0.0\tLoss: 0.790404\n",
      "tensor(0.8360, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:795 0.2\tLoss: 0.835995\n",
      "tensor(0.9413, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:795 0.4\tLoss: 0.941344\n",
      "tensor(0.7935, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:795 0.6\tLoss: 0.793450\n",
      "tensor(0.8792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:795 0.8\tLoss: 0.879163\n",
      "\n",
      "Train Epoch: 795\tAttack_Accuracy: 10732/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 795\tmaintain_Accuracy: 10517/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 795\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 795\tmaintain_Accuracy: 2478/2993 (83%)\n",
      "\n",
      "tensor(0.8722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:796 0.0\tLoss: 0.872199\n",
      "tensor(0.8484, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:796 0.2\tLoss: 0.848352\n",
      "tensor(0.6860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:796 0.4\tLoss: 0.686035\n",
      "tensor(0.7853, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:796 0.6\tLoss: 0.785267\n",
      "tensor(0.7159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:796 0.8\tLoss: 0.715868\n",
      "\n",
      "Test Epoch: 796\tAttack_Accuracy: 336/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 796\tmaintain_Accuracy: 2491/2993 (83%)\n",
      "\n",
      "tensor(0.8184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:797 0.0\tLoss: 0.818404\n",
      "tensor(0.9182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:797 0.2\tLoss: 0.918239\n",
      "tensor(0.8293, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:797 0.4\tLoss: 0.829341\n",
      "tensor(0.7990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:797 0.6\tLoss: 0.799040\n",
      "tensor(0.9393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:797 0.8\tLoss: 0.939319\n",
      "\n",
      "Test Epoch: 797\tAttack_Accuracy: 334/412 (81%)\n",
      "\n",
      "\n",
      "Test Epoch: 797\tmaintain_Accuracy: 2491/2993 (83%)\n",
      "\n",
      "tensor(0.8125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:798 0.0\tLoss: 0.812533\n",
      "tensor(0.7861, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:798 0.2\tLoss: 0.786066\n",
      "tensor(0.7592, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:798 0.4\tLoss: 0.759247\n",
      "tensor(0.7805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:798 0.6\tLoss: 0.780501\n",
      "tensor(0.8667, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:798 0.8\tLoss: 0.866747\n",
      "\n",
      "Test Epoch: 798\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 798\tmaintain_Accuracy: 2480/2993 (83%)\n",
      "\n",
      "tensor(0.8938, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:799 0.0\tLoss: 0.893752\n",
      "tensor(0.7564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:799 0.2\tLoss: 0.756413\n",
      "tensor(0.7734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:799 0.4\tLoss: 0.773432\n",
      "tensor(0.7467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:799 0.6\tLoss: 0.746689\n",
      "tensor(0.8899, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:799 0.8\tLoss: 0.889853\n",
      "\n",
      "Test Epoch: 799\tAttack_Accuracy: 337/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 799\tmaintain_Accuracy: 2473/2993 (83%)\n",
      "\n",
      "tensor(0.7433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:800 0.0\tLoss: 0.743268\n",
      "tensor(0.6340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:800 0.2\tLoss: 0.633994\n",
      "tensor(0.7925, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:800 0.4\tLoss: 0.792527\n",
      "tensor(0.7541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:800 0.6\tLoss: 0.754110\n",
      "tensor(0.8215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:800 0.8\tLoss: 0.821465\n",
      "\n",
      "Train Epoch: 800\tAttack_Accuracy: 10761/12800 (84%)\n",
      "\n",
      "\n",
      "Train Epoch: 800\tmaintain_Accuracy: 10520/12800 (82%)\n",
      "\n",
      "alpha: 0.35\n",
      "\n",
      "Test Epoch: 800\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 800\tmaintain_Accuracy: 2481/2993 (83%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#method: DTA\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "log_interval = 20\n",
    "n_epoch = 800\n",
    "threshold_epoch = 1001\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "losses_t=[]\n",
    "losses_nt = []\n",
    "\n",
    "losses_epoch = []\n",
    "losses_t_epoch=[]\n",
    "losses_nt_epoch = []\n",
    "delta_wav = []\n",
    "delta_sum = []\n",
    "attack_ = []\n",
    "maintain_ = []\n",
    "error_ = []\n",
    "lr = 0.0001\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data_size = data.size(1)\n",
    "delta = torch.rand(1,data_size, 16000)-0.5\n",
    "delta = delta.to(device)\n",
    "delta.requires_grad = True\n",
    "optimizer = optim.Adam([delta],lr = 0.0008)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.7)  # reduce the learning after 20 epochs by a factor of 10\n",
    "\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        if epoch%threshold_epoch == 0 and epoch != 0:\n",
    "            threshold = 0.2 + (epoch // threshold_epoch  -1 ) * 0.07\n",
    "            delta_data = delta.data\n",
    "            delta_ = threshold*torch.tanh(delta)\n",
    "            delta_data = torch.arctanh(delta_ / (threshold+0.07))       \n",
    "            optimizer = optim.Adam([delta],lr = 0.001)\n",
    "            print(optimizer.state)\n",
    "        delta = train_attack(model, epoch, log_interval, threshold_epoch, delta)\n",
    "        delta_sum.append(delta.abs().mean())\n",
    "        test_attack(model, epoch,threshold_epoch, delta=delta)\n",
    "\n",
    "        scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0109, -0.0172,  0.0214,  ..., -0.0183,  0.0121, -0.0206]]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0014, -0.0022,  0.0028,  ..., -0.0024,  0.0016, -0.0027]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 0\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 0\tmaintain_Accuracy: 2481/2993 (83%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "time_ = time.strftime('%d_%H_%M_%S',time.localtime(time.time()))\n",
    "dir_path = os.path.join('output',time_)\n",
    "os.mkdir(os.path.join('output',time_)) \n",
    "\n",
    "print(delta)\n",
    "plt.plot(delta.squeeze().detach().to('cpu').numpy())\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Delta\")\n",
    "plt.savefig(os.path.join(dir_path,\"Delta.png\"), facecolor =\"w\" , edgecolor = \"w\") \n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(delta_sum)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Delta_Epoch\")\n",
    "plt.savefig(os.path.join(dir_path,\"Delta_Epoch.png\"), facecolor =\"w\" , edgecolor = \"w\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(losses, label='loss')\n",
    "plt.plot(losses_t, label='loss_t')\n",
    "plt.plot(losses_nt, label='loss_nt')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig(os.path.join(dir_path,\"Loss.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(losses_epoch, label='loss')\n",
    "plt.plot(losses_t_epoch, label='loss_t')\n",
    "plt.plot(losses_nt_epoch, label='loss_nt')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Loss_epoch\")\n",
    "plt.savefig(os.path.join(dir_path,\"Loss_epoch.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "plt.plot(delta_wav)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"attack\")\n",
    "plt.savefig(os.path.join(dir_path,\"Attack.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(attack_,label='attack')\n",
    "plt.plot(maintain_,label='maintain')\n",
    "plt.plot(error_,label='error')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Rate\")\n",
    "plt.savefig(os.path.join(dir_path,\"Rate.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "threshold = 0.2 + (n_epoch // threshold_epoch  -1 ) * 0.07\n",
    "\n",
    "delta_ = threshold*torch.tanh(delta)\n",
    "delta_ = delta_.to('cpu')\n",
    "delta_ = torch.squeeze(delta_,0)\n",
    "\n",
    "print(delta_)\n",
    "plt.plot(torch.squeeze(delta_,0).detach().numpy())\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Attack_Waveform\")\n",
    "plt.savefig(os.path.join(dir_path,\"Attack_Waveform.png\"), facecolor =\"w\" , edgecolor = \"w\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "torchaudio.save(os.path.join(dir_path,\"Attack.wav\"), delta_ , sample_rate=16000, channels_first=True)\n",
    "\n",
    "\n",
    "test_attack(model,0,threshold_epoch, delta=delta,wav_save = True)\n",
    "\n",
    "f = open(os.path.join(dir_path,\"Parameter_2.txt\"), \"w\")  # 打开文件\n",
    "print(\"n_epoch=\",n_epoch,file=f)\n",
    "print(\"threshold_epoch=\",threshold_epoch,file=f)\n",
    "print(\"target:origin=1:0.5\",file=f)\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 0\tAttack_Accuracy: 338/412 (82%)\n",
      "\n",
      "\n",
      "Test Epoch: 0\tmaintain_Accuracy: 2481/2993 (83%)\n",
      "\n",
      "\n",
      "Test Epoch: 0\tAttack_Accuracy: 0/412 (0%)\n",
      "\n",
      "\n",
      "Test Epoch: 0\tmaintain_Accuracy: 2932/2993 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_attack(model,0,threshold_epoch, delta=delta,wav_save = True)\n",
    "test_attack(model,0,threshold_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.6220e+01, -2.7878e+01, -1.5127e+01, -1.0988e+01, -3.4038e+01,\n",
      "         -9.2945e+00, -1.1277e-04, -3.4483e+01, -1.6618e+01, -1.2540e+01]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "output = model(delta)\n",
    "output = output[0]\n",
    "print(output)\n",
    "pred = get_likely_index(output)\n",
    "print(index_to_label(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = []\n",
    "for i in range(len(train_set_)):\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = train_set_[i]\n",
    "    \n",
    "    if label == 'yes':\n",
    "        val_set.append((waveform, sample_rate, label, speaker_id, utterance_number))\n",
    "\n",
    "val_test_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "204\n",
      "0.7962413452027696\n"
     ]
    }
   ],
   "source": [
    "attack_ = 0\n",
    "for data, target in val_test_loader:\n",
    "    #random_start = random.randint(0, data.size(2)-delta.size(2)-1)\n",
    "\n",
    "    threshold = 0.1\n",
    "    a_data = data\n",
    "    data = data.to(device)\n",
    "    delta_ = threshold*torch.tanh(0.25*delta)\n",
    "        \n",
    "    delta_ = delta_.repeat(data.size(0),1,1)\n",
    "    #data[:,:,random_start:random_start + delta.size(2)] += delta_\n",
    "    data += delta_\n",
    "        \n",
    "    target = target.to(device)\n",
    "    #print('target',target.size())\n",
    "\n",
    "    # apply transform and model on whole batch directly on device\n",
    "        \n",
    "    data_ = transform(data)\n",
    "        \n",
    "    output = model(data_)\n",
    "\n",
    "    pred = get_likely_index(output)\n",
    "    pred = pred.squeeze()\n",
    "    #print(pred.size())\n",
    "    print(len(target))\n",
    "\n",
    "    for i in range(len(target)):\n",
    "        if pred[i] == label_to_index('yes'):\n",
    "            attack_ += 1\n",
    "print(attack_/len(val_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attack_train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e0bd8efab6e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattack_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'attack_train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(attack_train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to try with one of your own recordings of one of the labels!\n",
    "For example, using Colab, say “Go” while executing the cell below. This\n",
    "will record one second of audio and try to classify it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "----------\n",
    "\n",
    "In this tutorial, we used torchaudio to load a dataset and resample the\n",
    "signal. We have then defined a neural network that we trained to\n",
    "recognize a given command. There are also other data preprocessing\n",
    "methods, such as finding the mel frequency cepstral coefficients (MFCC),\n",
    "that can reduce the size of the dataset. This transform is also\n",
    "available in torchaudio as ``torchaudio.transforms.MFCC``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Speech Command Recognition with torchaudio\n",
    "******************************************\n",
    "\n",
    "This tutorial will show you how to correctly format an audio dataset and\n",
    "then train/test an audio classifier network on the dataset.\n",
    "\n",
    "Colab has GPU option available. In the menu tabs, select “Runtime” then\n",
    "“Change runtime type”. In the pop-up that follows, you can choose GPU.\n",
    "After the change, your runtime should automatically restart (which means\n",
    "information from executed cells disappear).\n",
    "\n",
    "First, let’s import the common torch packages such as\n",
    "`torchaudio <https://github.com/pytorch/audio>`__ that can be installed\n",
    "by following the instructions on the website.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to run in Google Colab\n",
    "\n",
    "# CPU:\n",
    "# !pip install torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# GPU:\n",
    "# !pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# For interactive demo at the end:\n",
    "# !pip install pydub\n",
    "import os \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check if a CUDA GPU is available and select our device. Running\n",
    "the network on a GPU will greatly decrease the training/testing runtime.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Dataset\n",
    "---------------------\n",
    "\n",
    "We use torchaudio to download and represent the dataset. Here we use\n",
    "`SpeechCommands <https://arxiv.org/abs/1804.03209>`__, which is a\n",
    "datasets of 35 commands spoken by different people. The dataset\n",
    "``SPEECHCOMMANDS`` is a ``torch.utils.data.Dataset`` version of the\n",
    "dataset. In this dataset, all audio files are about 1 second long (and\n",
    "so about 16000 time frames long).\n",
    "\n",
    "The actual loading and formatting steps happen when a data point is\n",
    "being accessed, and torchaudio takes care of converting the audio files\n",
    "to tensors. If one wants to load an audio file directly instead,\n",
    "``torchaudio.load()`` can be used. It returns a tuple containing the\n",
    "newly created tensor along with the sampling frequency of the audio file\n",
    "(16kHz for SpeechCommands).\n",
    "\n",
    "Going back to the dataset, here we create a subclass that splits it into\n",
    "standard training, validation, testing subsets.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "import os\n",
    "\n",
    "\n",
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(\"./\", download=True)\n",
    "\n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            with open(filepath) as fileobj:\n",
    "                return [os.path.join(self._path, line.strip()) for line in fileobj]\n",
    "\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
    "            excludes = set(excludes)\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "\n",
    "\n",
    "# Create training and testing split of the data. We do not use validation in this tutorial.\n",
    "train_set = SubsetSC(\"training\")\n",
    "test_set = SubsetSC(\"testing\")\n",
    "\n",
    "waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data point in the SPEECHCOMMANDS dataset is a tuple made of a waveform\n",
    "(the audio signal), the sample rate, the utterance (label), the ID of\n",
    "the speaker, the number of the utterance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of waveform: torch.Size([1, 16000])\n",
      "Sample rate of waveform: 16000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA1u0lEQVR4nO2dd5xV1bXHv2s6w9BGqhQHBFRQAR2xxIYiivokicbgM5bY4tOoeWqeGJRETUHTjNFEib23YCyIIGADERikI73XobcBpu33xzn33nPvnDu3zq3r+/nw4ZR9zll3zzm/vfbaTYwxKIqiKNlBTrINUBRFURKHir6iKEoWoaKvKIqSRajoK4qiZBEq+oqiKFlEXrINCEbbtm1NWVlZss1QFEVJK2bPnr3dGNMu2PmUFf2ysjIqKiqSbYaiKEpaISJrGzuv4R1FUZQsQkVfURQli1DRVxRFySJU9BVFUbIIFX1FUZQsQkVfURQli1DRVxRFySJU9NOYNdsPMG3F9mSboShKGpGyg7OU0Jz7p88BWDP6kuQaoihK2qCefgZQNmIcizbtSbYZiqKkASr6GcLERVuTbYKiKGmAin6GoIteKooSDir6mYKudawoShio6GcIKvmKooSDin6GoI6+oijhoKKfIRj19RVFCQMV/QxBPX1FUcJBRT9DqFfRVxQlDFT0FUVRsggV/QxBY/qKooSDin6GoDF9RVHCQUVfURQli1DRzxCMuvqKooSBin6G0FjvnTdnruODeZsSZ4yiKCmLzqefBYwYuwCAy/odmWRLFEVJNurpZwiSbAMURUkLVPTTlF0Hqv32RVVfUZQwiIvoi8hFIrJURFaIyIhG0l0uIkZEyuPx3GxmwCOfJtsERVHSkJhFX0RygaeAoUAf4CoR6eOSrgVwFzAj1mcqsfHGzHWUjRjH9v2Hk22KoigJJh6e/kBghTFmlTGmGngTGOaS7hHgUeBQHJ6pBCAiGGNYsCH0WrnvVKwHYO2OA01tlqIoKUY8RL8zsN6xv8E+5kVETgK6GmPGNXYjEblFRCpEpGLbtm1xMC0zCdYn/4Vpa/ivJ6fy9YrtjV6fm2M1ANTWad9+Rck2mrwhV0RygL8A94RKa4wZY4wpN8aUt2vXrqlNS1vcNF+AJVv2ArB+V5XrdX+csITq2nrE7uujkq8o2Uc8+ulvBLo69rvYxzy0AI4HPheri0lH4AMRucwYUxGH5ysBBBuc+9RnK+nYssi7rx1+FCX7iIenPwvoJSLdRaQAGA584DlpjNljjGlrjCkzxpQB3wAq+DEQykOva2RKhsO19Tojp6JkMTGLvjGmFvg5MAH4DnjbGLNIRB4Wkctivb/SENeYvsNtH/newqDXiqNDv2jnfkXJOuIyDYMx5mPg44Bjo4KkPTcez1QaEs6cayrzipLd6IjcNMRN21dvO+B3vHKfe89YEZ17X1GyGRX9NMRNtCcu3up3fODvJrtem+MX3om3ZYqipDoq+hlEOA20ItpVU1GyGRX9NCSW3jcSZFtRlOxART+NGD1+CS9OWx08Jh9OWaAxHUXJanQRlTTi6S9WAjCkb0fX8/VhtNDmSPhLK742Yy1fLdvO09ecHL6RiqKkNCr6acLYbzd4t88YPcU1TViOPuE35DbW319RlPREwztpwt1vz4vLfbQhV1GyGxX9DCLywVkNXf09B2u4asw3bNx9MF5mKYqSQqjoZxCRt+MaDtXU8d3mvew7VENdveHDeZuYvmoHT05Z0URWKoqSTDSmn0GE00C7avsB9h+qtfeEe9+Zx0fzNwNw1cBu9DmypXVGO/koSkainn4GEY6n/8wXq1heuR+whL1izS7vOWdjsWq+omQmKvppQLhdLCNtoQ0UdhF0Yh5FyXBU9NOA8DU/csEOdk02hne+XLaNbft0sXgls1HRTwPClfJInXRrMfXonpWJXPv8TK58ZrrfscO1dazf6b78pKKkIyr6aUA4I22jQWgo8p5HSZZF9T0htNXbD/gdv/uteZz12Gccrq1LhlmKEndU9NOAcDV//MItMT0nktG6mUZ9kDyesqQSgJq6bK4DKZmEin4a0GSefsCCKhLBvDyZRrA8zrbCT8l8VPQVV7JN6+qCuPqefMjWwlDJPFT004Cm0pvLnpzG9v2+3ipV1XXMWrurkSvSl32Harj8n183iNl7CJbHnsXjg4V/Aqmtq2fngepoTFSUhKCinwY0VXjHjXH26FzJsLjGlCWVzF67iz9PXOp63pnHa3ccoGzEOBZu3OM7b6t+VXUtkxZvDfqcke8t5KRHPtWGXyVlUdFPA2KR/PkbdsfLjIzGKfoTF1mi/t6cjQ3Oj3xvITe9XMHSLftc7/PR/E2ANvwqqYuKfhoQrae/ec9BLntyWpytSU88NZeP5m9m2FMN88QTvskRqLV38nKkQSx/zQ4rPLT/cC2NEXjd3yYtZ0Wle0GhKIlERT8NiDa6s+tATdTPzLDojh/z1u9ucMwj0iLiLWRzc8RbGBhvOu8Vrvf2FC7Os3sP1fDXScsYPuab2AxXlDgQF9EXkYtEZKmIrBCRES7n7xaRxSIyX0Qmi8hR8Xhu1hCl6Ouc+D5ClWFOT98Tv7cWnPHPfM9eYJvHLrvx1lN4mPqGzzhU43JQURJMzKIvIrnAU8BQoA9wlYj0CUg2Byg3xpwIvAs8Futzs4lowzs5MXjr2TYit67e6elbx576bKVXqD1/Ak+BMPrjJdz99lzAmrNnwCOf8sWyba7lsycnE9kgryjBiIenPxBYYYxZZYypBt4EhjkTGGM+M8Z4JjD5BugSh+dmDdFKhWqMj1BZ4fHQc6RxcfYUDjPX7GTst1ZD72y7m+vstbu81zprCA1DQ4qSPOIh+p2B9Y79DfaxYNwIjI/Dc7OGaD3EWDQm02L6oQZX+cI74ppvHhF3+1t4jlQdrvXrz1+57xArt+33hnqimQVVUeJNQhtyReQnQDnwxyDnbxGRChGp2LZtWyJNS2mi9RB1FGlwvv/UNMZ+u4G9h6zG7nqvp9+wx44Tt1Oe9M9OXe2L6Rs4c/RnnP/nL7z3zraQmZKaxGO5xI1AV8d+F/uYHyIyGBgJnGOMcZ203BgzBhgDUF5eroplE614rwoy+jQcMkmelm3dx6cBA6rmrt/NXLsXz5rRlziEOUghax+rcznp9P6dnn51Xb3z0oyrPSnpSTw8/VlALxHpLiIFwHDgA2cCERkAPANcZoypjMMzs4poS7/R45dE/UynQD304SIAXpm+htdnrIv6nsliyF+/9K4DHAzvlNIhYvr1LvMxOA/5YvoNj6nmK6lAzKJvjKkFfg5MAL4D3jbGLBKRh0XkMjvZH4ES4B0RmSsiHwS5neJCsqM0L0xbA8CD7y/iV+8tSK4xTUS9IyzjNs+OCUjndq3n+mDnnd08F27cQ+XeQ9EbrChREo/wDsaYj4GPA46NcmwPjsdzspVkdPXLtLl3QuER+n2HazlUE3zenMACwRhDbYgpF5y1CA+X/n0qhXk5LP3t0GjMVZSo0RG5aYA2bjQ9zqmV3aZY8Ah34BTMb1es57mpqxukX77VN+VCsPDO4VodrKUkHhX9NMAtjtzUZJef799Y3lh+Bzaq/33KCtd0P3ZMuRCqovbJws1UVTc+l4+ixAsVfUXBP2zj1kPH10/f/3hjoSDfve3uoC5DpBdu3MOtr37LqPcXRWCtokSPin6KsnLbfv48cSmVew9x1mOfJd6ADHH1n5i8PKx0znaTYKtoBaazCJ1RvsXmG+IZJ7B+Z5XLWWv+pIc/XNyoTYoSCSr6KcqNL87i71NWMG3l9mSbAsCdb8xJtglR8fikZWGl8+9r7+Lpm+Dnwr13jgiV+w7x2oy13nOeAVszVu+kbMQ41gSMrbj7rbk8P201c9Zl5opmSuKJS+8dJf54Qgxrtrt7gE1N4OjRD+ZtSoodsZKXk+MdJNUYTi3/eMGWoOkCPe5wOjn95oNF3rR3vD6HGat3es/tOOA/TnHhpj2UtW3OyY98ys1n9/AWGOroK/FCPf0EU1NXz91vzWXltv2NpivItf40fwszPKE0pKq6NizBh9AevK+ffsDxMMT4s6XWlCLb91f7CT7Az1/3r0HV1hmWbd3HjgPVjB6/xLFGr6q+Eh/U008wCzfuYeycjazcfoD3b/9eg/NvzFzHiV1aJcGyzGPH/tALlHs89XA96YbiG18xfmf2eqa9tcO7r9MyK/FGRT/BFORZHvzhIL0+7h9rjXjt0a55wmxyI9kzQr41ax0zVu/kL1f2b9LnCFbIZsaqHY2m83TVDOzOGe+wy8KNe/32czylkmq+Eic0vJMklmzZx4RF/rHjWWt2BkmdBJIsMvf9e4F3vvqmJEeEMV+u4g9hzFP02oy1HKj2L6zj7YHvOei/xKXn/v/97AxWhQgJKko4qOgnGKdG/OyV2d7tpVv28aOnpzsSJtAoFxp7/I79rpOkBqVizc6kzDMTjh7niLB2R+jZSCvW7GLkewsbHG/qgXPONoA3Z61vJKWihIeKfoIJ1t96V5V//DnZtfnGpnN2G7zUGFc8PZ2Ln/gqVpMiJhw7q+vqwxLTX7w11/V4IkPtyRiZrWQeKvoJprbevzfJxt0H+XDeJnJjWdC2Cdi2L7g3H81iINvDaFR14x+fr4ha7BIxoCmRMqySr8QDFf0EUxMwI+PNL1VwxxtzGghUsle9+s/c4P3yI7GtNswuk8F47JOlfLUiugFqiejxksi/k/bgUeKBin6CCZyGd7U9AvNAwMyOa3YkZ1BWOEQS3onHTJLVUd4j1JTH8SCRERfVfCUeqOgnmJqA8M5Bu+tmOk2zG0nYJJwJyZqKRIR31PtW0g0V/QQTzPu87bVvE2xJ9NRHUD45C7OaKEM9gbWgcDlU2/QFTiI1f9u+wzGHyxRFRT/BZMJHGxjembZiOysq3fuQOz39wD7o4RKs50wo7krAJHGJ9PTHLdhMz5Hjmbk6hcZzKGmHin6E1NUb/jJxadCpcENRkwHd7ob89Qu//aufncHgv/iOORs3D9X4CrmD1bF53rPX7qJsxDg27zkYVvpNe5p+bEBtEv6eVz4znUWb9iT8ucEY8tcvuPnlimSboYSJin6YLN60l50Hqpm/YTdPTFnBQx8uDvva12es44YXZ7HvUA2/H/ddE1qZGAJ7IDn5eMFm+v56ArvtcQeHHSGW/Ydruea5GYxfsJnJ323lLxOXRtT75bVvrCmJp61ofMqEbOCSJ6YGPXf2Y5/x7FerEmLH4k17WbZ1P58u3pqQ5ymxo6IfBsYYLn7iK4Y9NZUNuywvM7C/fWP86r0FTFlSye2vz2FLEkamNiWBfeifnLKCquo6/jzRmsfe6elX7jvMV8u38z+vfcuNL1XwxJQVfLMq/FCFp5b09Bcr42B5ZnK4to51O6v4bRM5Fwer63hz5jpvYb280rcWcLK7GSvhoaIfBnsPWg2J63ce9K50FE3PkC+XbYurXcnkk4Wb+WbVjgaNpZ7C8JVv1rJ+Z5XfebcBX2t3HOBQTZ1f7D+YeHgadIO1H2Qj9fXGL2z2+ox13m3n8bvfnssL0xou4B6KwDaoK5+ZzoixC7ye/fPT1vhsiVHzv1q+jVterkipwqOqujbscGK6kNWiP23FdspGjAs598rG3b4/uqcASEQf8FTm1le/ZfiYb1i2NbgA1xvDYYenv91lzp7aesOxD37CsQ9+4j0WbMGWNWHMkeNh6ZZ9oRNlAD1+9THHjfrEWyA6w46V+6xa5f7DtYz9diMPfbiYZVvDz5fffrSYniPH+4VuFmy02hJG2xPUOWt6t71mzSVljGHWmp0h52h6d/YG75xM9fWGa56bycTFW6lYG9kqYXuqati0u3Fh/nxpJb0fGB/RAvSb9xykz6gJnP6HKX4F0SvT1zDg4YkR2ZhKZLXoP/OlFff8JsS0un6ib3v6VbZnOvm7rVE36mYCztkjjDFs2u0LX1XX1vvF9N08fU9+ApSNGMecdbvY7NIAW11bz6ptPtEPNjXD4do61u+s4sLHv4zod6Q7fX89gdq6ei45sZP32Bd2zXL0eF+oZ+763WHf89mpVs3A00jrFPFV9qBCTyEAMGGRVTj0e2giP3p6Oif/dlLQe8/fsJt735nHdS/MAmD9Lt839OB/Gk5s1xj9Hp7IGaOn+Nm3cOMePlta6X1Prn9hFtW19Tz0Qfhtcc608zZYv/PLZdt48P1F7KqqYatdYO05WEPZiHFMWRJ5u8ZXy7exZItvOu0563bxo6e/9hbYTUFGiv6978yjbMS4kGLsCSls2HWQqupaznpsius1WxzVu91VlkjtPHCYdTuquPGlCu/C5f/8fCVlI8ZlVfhh/yGf5/Ti12vY7+hTf6im3i9ss9WlPSOwG+dNL1W4dms9O2Bx+FdnrGXS4q2c8rtJlI0Yx/7Dtbw4bTXHPPBJchaSTwIvBoRrfvHWXArzfJ/0qPetZRrblhR6j3lWZKupq+d7o6dQNmIcAJV7D3Hfu/N5p8KafC6wgN5zsIZrn58Z0qa9h2rYe8jfm951oJqyEeO8zwK47MlpAHy32RI853iOJY5amuc6p6ftdCScoZevV1rO2+6qai79+1R++sIs3pi1zs6DAgAK83358+SU5fxuXPBCYJujEPEUKB/N99VCPY3lL3+9BoAbXgzeg+nrFduZ/J1/ofDMFyu55rmZXPS4NRnh3kM1/OAfXzNrzS7+9WXTNcTHRfRF5CIRWSoiK0RkhMv5QhF5yz4/Q0TK4vHcYLw7ewMA9/17PmDFM8tGjKO+3vD+3I0MHzOdunrDSlucV207wKvfrGX9zoNc/s+vqaqu5YVpq70vmvMD8LxkO/dX+y15eLC6jkc/saq871Ss59ZXZvP+3KafDz7ZOKvigfPfL9i4x+9jdvPg9waI/hUnd+HzpQ3bPgIbwEe9v4ibXq7w/m2WbtnLbyLoUZUJBP7ebqXF7D9Uy7EdW3iPVdfWs+uAb7I7z2yuD324yFuDnbhoC1c+M523Ktbzy3etb+bed+b53Xv+ht0s2uS/wMvI9xY0sOnE3zQMewx45FPv9ofzNjUo1Gvq6vnHZysaXOcU+nvemectPI554BNvbcA5ZsGz4PwVjinKt+45RFV1rXfCv512XuzYf5g/TVzGv75azXtzLL2Yunw7f5+8nG/tRei7tmnmvc+/bIGvrTM0y8+1tusNxhj+/OkybzpPzeLPE5dy/9j5VFXXYozhv5+dwY0vVfDYJ751G5xrONTU1fs5i//6KvL2l3CJWfRFJBd4ChgK9AGuEpE+AcluBHYZY3oCfwUejfW5jeH5o3y9cgfrd1Z5xejRCUu46825fLNqJ99t3ssO+wUYv3AzBw5b3kN1XT19Rk3goQ8Xc8cbc3hu6moqHaLvqQkcqK7zE31nvHlF5X4+WbSFu96cm7YLiofLXxwvvLOqD1avJWds3S3GuyWgIKjcdzjimC7A5f+cHjpRhtO9bXP2H66lpDCPVs3yASuuv+dgDZ1bN0MEdlXVsGFXFa9+42vwFRG/uZ4q9x6iQ0urdjDzV+cDuLbdvOZoNA7GvIBw0h1vzOF6O6TjodfI8RTmWd/szWd1J0csEXTWLMZ+u9ErxmB1FDDGcNebc73HDlbXUVdv/MRzxuqdvDfH54x8NH8ze6pq/EJPnyzcwuOTlvGT52bw50+X8cN/fM2eqhoq9x2mX9fWAN5eZqt3HGBAN+vYC9PWNKjVzN+4xyo8pqzgjZnr6TNqAh8v8C2W9I/PV1JTV9+ghrtg4x5++I+vXfMw3sTD0x8IrDDGrDLGVANvAsMC0gwDXrK33wXOF8+Kz3FmT1UNB2vq6NzaKqVfsft2Azzzha/KNPm7Su92vfE1/HnCN2C9II98tJivlvtmefR02QR/kXMK1eQlvnvfmYBRoanMWoeYuK1ZGzixXFPGMjOdA4drLdEvyuMPPzwBsHqc/WfuJjbuPogxVkjovYAa2cvT1/jt3/76t+zYX82xHVvQrkUhhXk5LA7w8sNl2FPTGhyb6jJr6lsV68nLEY46ojn1xnpXnN8dWOLs5PWZvkLn+M4tWbeziul2iOeG73UHLAcs15aaK07uAsDsdb7awVFHFHPgcB2PT1rud+/pq7bz9codlBbne4/V1xtWbz9A97a+pUzf+9aqJfzktG6AVSP6yXMz/O51++v+U6x8vnSbVxf+q9+RAFzpqJ30aNecH5d3DcyiuBEP0e8MOFeh2GAfc01jjKkF9gBHBN5IRG4RkQoRqdi2LbrujZIDD1xyHE9cNQARGOMSG8sRvI0uPzzJMvWr5dsoO6LY9Z7OhtzDtfXeue/nb9hDuxaWR/S2vRDHEc0LorI7k/jlhcd4tyv3HaKkMI+i/Bz2Bcyhk5/bcNWqyr2Rrcql+Bg7ZyPzN+yheWEe+Xbs/v6x8/3S7D1U6w1HnH9sewCvuPbuUAJYXv3kJZV27UA4snUz5m/YHXd7lzxyEV1Lm3Fil1aAFS5pb39PzprzPRf0BuAdO2z7/PXlAIybvxmAl28YSHF+HruqarjnnbkAXDWwK0P6dKBZQa63Rn/7oJ4AvD5jvff3r91R5VcI3T7oaMDqnQbw2dJtnNWrLQATFm1hd1UNJUV5PHbFiYAvxPbzQb0AXzsKwE1ndvf7vZPvOQewGsY9jeyPXm4Vzs0KrJpObo4w5Z5zedS+f1OQUg25xpgxxphyY0x5u3btorpHy6J8bjqrBycf1cY7GVbbkkK++r9BXHJCJ8bfdRbHdWrpbY0/rbtV9hyoruOi4309H5b9diiPXX6itxGsyNEAdJRdOKzefoBjO7agbUkhCzbuoXVxPhef4LvHI98/PqrfkM7k5wpXDezm3d+02xJ9T/XdScdWRd6+3X8b3p8fl3dleRY1gseb+fY7fbimziGevprUf5/azRv6BHju+lP8rv/wjjMBX+P6Z0utGmunVkWu3W0j4YFLjmtwrCg/l/U7DzJ/wx6KC3L56ffKaN+yCMBbGzmtRyk925d4r2lZlMd5x3agU6sib8Ntrw4lXNrP+u622k5Dz/YlLN68lw27DnrHJ5QdUUxhXg6T7AbVx4f3p0+nlt57X9S3I/cO8TksACOGHsvwU6z32RPXH9KnI0e3K/FL17FVkd/+l78cRGmJzwF89PITGlwz+Lj2FBfkcfJRbdhnh4n++uP+LrkXX+Ih+hsBZ12ki33MNY2I5AGtgISNpe9a2oyupcU8dfVJHNepJb07+Bq6ysvaeLd7tS9h3J1nMvW+QRTk5XDlKV3pbDfm/O77J3jTlR3hq951aVPs/SD6d23t9ZaO7diCQcdYBdc1px3VdD8uxSjKy6WNo0q8/3AtW/Ye8utV4mH9Tl8N6qRubejUuqhBmlCMueZkv/07z+sZ8T3SncAaalV1HX2PbOl37Kv/G8TR7Uq8U3l78DT6/ulH/SjMy8UZdL357B6A5UjtcoQ9e7RrTii+e/giv/0bA7xeD5ef1MVrc9c2xd62hLfsXkS//f7xnH9cB2/6n51jeeKeNguAji2L6G/H3gFO6tYaEWH4KZYseRpxRcSvY0GLonzucLwvoy8/ARHhn1ef5D12/Rll3tr8mh1VdC1txslHtaGLo5HXgyckM+iYdnQ7opgr7N8GcEpZaYP0Pz/Pqh3MdoSGnYVQUxEP0Z8F9BKR7iJSAAwHPghI8wFwnb19BTDFJGDY3Tf3W41Qoy71b1f2VNcAupb6PphjOrag75Gt6NLGd+zhy/pyYd8Oftc4PY8ubZrR2ha5i4/vxLH2H+1wbT1d2hSzZvQl/CSLRH/f4VpEpIEwFLiIvpPS5gW0KQ4dGnvscv9q77nHtPfzIk8/um2DanWmEzgX0sGaOvJyc7wOCECHlkV0bOkrVMfedgYA/7n9eyx++EJvvNspnvcPtfL1k0W+WPo9F/Tmyat8ouhLe6zfvidc4UFEmHrfIO/+FDvUMcnRjbFLm2Z+NgJ0K23u9+6cfJTlpHli9p57Ox25s3pZztalJx7pPeaJnXva+n4x2BLcoSd04trTj+Lms7rT2n7/ihy2F+XneguYnQeqvd56O0c3WM/vumtwL04pa8Mffmi9o+1bFjH1vkG8fvOp9LCv+8/t3/Ne58nrSxzRAY99TUlerDcwxtSKyM+BCUAu8LwxZpGIPAxUGGM+AJ4DXhGRFcBOrIKhyenYqog1oy9pcHxwH6t6OPyUbt7YJ+D34njo17U1z1xT7jftQgfHi9mlTTPmjhpCTV09+bk5VFXX0rl1M0Y4PoJQgpeJTPjF2fQaOR6Agd1LvT132pYUeD2vf159Ev9jryNQXJDr9aiCcef5vbjylK4MPaEjJ9hdAwvycrjprB7079qa77bs4/Sjj2BAt9begUXZwKk9Sv26y57T2xK9Ukf7UkFeDi2KfJ/7AFtwivL9xfnNW07jx898w4OXNgzHALQuzqfPkQ29Ubc1no9oXsCOA9XMsHsAOZ0pjwhOv/88+oyaYKUvKUREyMsR7+ylnm9n1KV9mL1uF6f1sMKxV57Slfw84YTODX+Hp4bSzeHQ/fXKfgBMG3FeAzsfHuYfhj21u+WV/8P2+Ns73svWdgGQ4/i9HqE+snUz3rn1DL97dWlT7Pe7+3dtzbg7z6RXe5/W3DOkN+MWbOblGwY2KCybgphFH8AY8zHwccCxUY7tQ8CP4vGseNCyKJ/pdi0AYNLd57Bp98FGxdn5Urd0fDyeP6in8CguyGvwYmW66C/77VB6PzDe75izMB1YVsoUu0dT62Kf6J/R06o9DT2+IyLi95G6cbRde2hRlM9bt5xGXq7vb1JeVkq5XYV2CyVlKrec3YO7L+jtFf17h/T2NlgGTmZ3pC1OF/W18tuNwrxcP28UrFqBpzuh8+/q4eFhfRl0THvvJG+e0MeUe89l0+6Dfk7Sn37Uz28xneKChgXR8t8N5f25mxh0THvvuRvO7M4N+NfgfjCgi9/+yt9fzK6qakoKrXvm5AhzHryAwvwc8lzsDkZxQZ6fs9jGUXg2L/TZ+95tZ7B0y76geRmMvke28tvv0a7E1TltKuIi+ulOz/YlfiGbULQoyuflGwby3NTVnNC5Vcj0BRG8cOlIQV4Ofxven7venNugeg7WEHtPwef8PFo1y/d72Z1d4WY/MLjBMH7ngiWn9mjQ+ctLE/UGTkl6tivx83JLCvO8v79X+xK/hvGe7UuYO+oCbxgjXE7q5mv3chPPa08v89ufep/l9LRqlu8Xewdft0knSx65iAOHa73es4jw/QGBHQBDk5sjfqOPwV+wY+HLXw7iqxXbuNLRlXJAtzYMcORNuqCiHwWlzQsY2L2Us3uH18PIWa3OVIb178yw/u4f6i8vPIZ73rZGeC6v3M8LPz2FUhfhaV5o1ZLaFOf7eYAeAj/obOb6M8qo3HeIi+25dh4Z1pcH31/EOQ7veMy15Qz60+fePvtAxILv4dITO/HR/M3k58a/QC3Kz20QZko1uh1RzNVHZEbbXOarURPQtiSyD6coP5evR5zHGaOnNJFFyeH568vJzQldi+nSptgbimlZlOdXbQ+ksYasM3u2DXoukHdvPd1vOH6m0aFlEb+5rK93/5rTy7gmwOPu3rZ53MIG1Xavl8Cut7/+r8DB90qqo6IfAfdc0Ju/TFrmjY1GQqp7MtHQu0MLv0aqxvAMjb/3wmNCpAxOJGGbcpcucpmES7tpk/Lry/pSlJ/Lucf4125/6uhFs/oPF2dVaC1dUdGPgNsG9eS2QT1deyqEolkGin6oTrePXX6id34iz6AZt7BNOLz9s9Ojui7T+Nvw/ny5bDtXJ7gbcOfWzXjiqgHe/bduOc1vpDpkV1tKOqOiHwHRiL0H54jeTCFUr6QrT2k4f8ihgMFBjTHuzjP5y8RlPDSsb9g1ikynsbaTRNJYQ7qS2mSeEqUoTi/ofwf3TqIlsVOYl8Oz15b7dcULxaS7z6Ff19Zc6ljkIxR9j2zFc9efooKvKHFEPf0E0qFlIZef1IW7BveiKD/Hbz7tdOLO83sxuE+H0Akd9GxfwvsB/b8zgW6lxazL4pXTlPRDPf0EMvW+8/xmoExHrj+jzDv4R4GRLhOJKUoqo6KfQPJzc7xhnnRcVv31m091nS0xW/DMF+Mk0wfeKZmHvrFJoj5I15fhLo2fqUL7FoURDWfPNNwa8t2mJVCUVEbf2CRx/RllDHGJizvLAue0BKlBdnfJy3HpktgUI1QVpSlR0U8SxQV5PGhP+dyxZRFXDezKFSd3wTgCPwmYfToisr0btpun39Q1n6tP7RY6kaJEgIp+EvGIqAj84Ycn8qcf9fPz9FNL8t093WwiGZ6+Z254RYkXKvpJxDOfiXOKBueya3mJHmsfgtSyJn4s/e1FoRMBbtMMNXVMP8VeASUDUNFPIp4ZD4f1963w8/PzenpXIeqcYoOSMtXRd1u/1w03Tz+WUdrhoFMbKPFGB2clkdLmBcz79RBaOBZmKMzL5WfnHM0RJYVccFwH+j08MYkW+pPt4Z3AXy/S9LWfVGvXUdIfFf0kE7jIhAe3xSaU5FLnIsBN7Ymr5CvxRsM7SthkuaNP62b+6ygIwfNkYJymdi5OwJqpSnahoq+ETbqFd2479+i43q8gL4fP7j3X71iwHOnVoYQry2OrreWItZD26zefGtN9FMWJin6Kc+s58RWuWEgzzef/LjrWux242He0NIzrB8+UWMPxq/5wCS2K8jnj6PBXDFOUUKjopzgjhh4bOlGCkDTutNm/a+u43Cfcgk9E4/FKaqKir4SN9hn3L/jcvPxHhvVtcExRUgkVfSV8VPT9PP1Q2REqvOM299IffniCa9pXbhzIhF+cHeKJihKamERfREpF5FMRWW7/38YlTX8RmS4ii0Rkvoj8OJZnKskjncM7sXJhX/dFYxrrR29cAjw/O7tHo8+5aqD7XDtn9WrHMR1bNHqtooRDrJ7+CGCyMaYXMNneD6QKuNYY0xe4CHhcRFrH+Nys4vZBqdGYm83hHc+C7hE1ZruUB/dffFxjpwE4s2dbRl6cvesWKE1LrKI/DHjJ3n4J+H5gAmPMMmPMcnt7E1AJ6CxSEfDLC1OjMTdbpgR4/vryqK81QbYj4dWbTuXmEDUCRYmWWEW/gzFms729BWh04VQRGQgUACtjfK6SBLJD8uEUl4FVnt/uLPgaKwMF0SkUlJQk5DQMIjIJ6OhyaqRzxxhjRCToWy4inYBXgOuMMfVB0twC3ALQrZvOI55qpNvgrGhprEYTeCbYC29cI/oBabRMUJJASNE3xgwOdk5EtopIJ2PMZlvUK4OkawmMA0YaY75p5FljgDEA5eXl+kmkGhms+UOP78j4hVuCJ3CsfeCkvr6Rhlx9g5UUJNbwzgfAdfb2dcD7gQlEpAB4D3jZGPNujM9TEkjZEf5TO2eyo//Pn5zs3W7sZ/r100doW1IYNF1ozddSQUk8sYr+aOACEVkODLb3EZFyEXnWTnMlcDZwvYjMtf/1j/G5SgLo2V67CHrwiH1gwdemeQEzR57veo0npn/D97o3qW2KEgkxTa1sjNkBNHjjjTEVwE329qvAq7E8R0kW/p5otoQrGqvRuOVBsEVYPEn7d2sN0xqer2skNKQoTYWOyFXCRzUqKoKVIYENxjN+5V5jUJR4oqKvBCXQq81t4kXAU4WwRx6HSOYJ77jVHDq0LOT3PziBa08/ynGsqGFCRYkzunKWEpLHrjiRdiWFlBTq6+JGsHBQvd0xObCr63u3nUHX0mLalhTy8LDj+dHJXampd+3FrChxR79iJSgeR7+0uIBBx7ZPqi2JxE3Ew+255KwdeXrq5wgs+M0QbzhnQDf/KapO6NIqKjsVJRpU9JWQZHJXzUhxDrmSgP+diEBdvWdbaFHkvhayoiQajekrQWksJp1teLIg3B5MxvjyL1tGMivpgXr6SlA8+pbOUyrfeV5P2sexgdRN84NN29CmubWQenNd3FxJIVT0laBkQr/8u4ccE/E1Tg1/9PITuO/fC7z7jU2i5rfAisBvLutLv66tOf3oIyK2QVGaChV9JTTp6+jHHafme0Q+WPaUFOZxzWlHBTmrKMlBY/pKUDLA0Xfl2tOPYtXvLw563i2c5RH4YHPtWNc1XhNQlFRARV8JSaY5+g8PO56cMJcBC9TwZgW5zH7Af+JZ1y6e0RqnKE2Mir4SlGz1Wt1FPLSMOxt0szPnlHRARV8JSbYsk+hGOL11/KZbzuK8UtIDFX1FCSDYYKvGznuOZ2vtSEkfVPSVoHj0K5t913A03NuLJ4yCQVGSjYq+4sffhvf3bnumHMi2iIVbiCawD77rdWhMX0l9VPQVPy498cgGx9J5RG5T4pYvHrHXqReUVEVFXwlKJoanWxSFHo8YSq49Ym8C/XkBXQxLSXV0RK7ih1PwTikr5euVO+jYKjMW9xh72xl0bt0somsaCDt4MynQ03c25Kqjr6Qq6umnCf2imHP93iG9Y3rmnef3Yso959CzfUlM90kVTurWJqzVqdwFO3ic361GpOEdJVVR0U8T3rjltIiv+fl5vSK+xqlVuTlCj3aZIfjR4iboQRtyBc4/rgMAPxjQuQmtUpTo0fBOmlBcoH+qRBGy907A/84QUPe2zVkz+pKmM05RYkQ9fcVLr/YlOqI0ALd2We86A3ZeFeRan9HPzj46MUYpSgyo+6gA8LNzenD/0OOSbUbK4jpK1/4/LzdHvXslbVBPX1EawyWob3xLiilK2hGT6ItIqYh8KiLL7f/bNJK2pYhsEJEnY3mmAs9cc3KyTcg6/KJeOj2FksbE6umPACYbY3oBk+39YDwCfBnj8xTgnN7t4n7PwD7nsXb3zBR0rJWSacQa0x8GnGtvvwR8DtwXmEhETgY6AJ8A5TE+M+tp6rZWjU/D7YOO5oI+Hb37Z/Zs6932zUmkvr6SfsQq+h2MMZvt7S1Ywu6HiOQAfwZ+AgwOPB+Q9hbgFoBu3brFaFrmEo+5cNaMvoSyEePiYE1m8ssLj/VuL/jNEFoU5Xv3C/NyARh6fMcG1ylKqhNS9EVkEuD2do907hhjjIi41YZvAz42xmwI5RkZY8YAYwDKy8u1Zh0Fix66kL6/nhD0fJvifP79P2ck0KL0xyn4YC2ZOGvkYNoU5we5QlFSl5Cib4wJ6p2LyFYR6WSM2SwinYBKl2SnA2eJyG1ACVAgIvuNMY3F/5VGaKzsLMxrvJmmVbP8rB9l6+G4Ti1ZumVvVNe2axF8gXRFSWViDe98AFwHjLb/fz8wgTHmas+2iFwPlKvgx0ao4M7g4zqwcOOeiO7ZPgtF7OM7z0y2CYqScGIV/dHA2yJyI7AWuBJARMqBW40xN8V4fyVCRIRnrwveVu4WYvv7VQO4+IROTWlWSqINsUo2EpPoG2N2AOe7HK8AGgi+MeZF4MVYnqk0LlahZMxtDdf/6tdw4ZRspHeHEprl5ybbDEVpUnQahjRE/dOmYeL/npNsExSlydFpGNKQxqISoSIWGtJQlOxGRT/DmTvqgmSboChKCqGin4Y0GtMPONe6uKCpzVEUJY1Q0VcURckiVPSzgJvO7J5sExRFSRFU9LOABy7tw5R7tGeKoigq+lmDTmSkKAqo6GcEx3ZskWwTFEVJE1T0M4An//ukZJugKEqaoKKfRnRo6T4pWiTjrXRolqJkNzoNQxrx/u1nsnhzw9kzXabTacCRrZoB8L8X6DKIipLNqOinER1bFdGxVZHruXdvPZ2Ji7cGvbZZQa4ug6goiop+plBeVkp5WWmyzVAUJcXRmH6aMuiYdsk2QVGUNERFP0154acD6dG2ORBZQ66iKNmNin4GEE5DrqIoCqjopzfq4SuKEiEq+umMeviKokSI9t7JAKKN6X90x5nsPFAdX2MURUlpVPSzmOM7t0q2CYqiJBgN72QA2pCrKEq4qOgriqJkESr6GYD201cUJVxiEn0RKRWRT0Vkuf1/myDpuonIRBH5TkQWi0hZLM9VFEVRoiNWT38EMNkY0wuYbO+78TLwR2PMccBAoDLG5yqKoihREKvoDwNesrdfAr4fmEBE+gB5xphPAYwx+40xVTE+V1EURYmCWEW/gzFms729BejgkqY3sFtExorIHBH5o4jkxvhcRVEUJQpC9tMXkUlAR5dTI507xhgjIm6dB/OAs4ABwDrgLeB64DmXZ90C3ALQrVu3UKYpiqIoERJS9I0xg4OdE5GtItLJGLNZRDrhHqvfAMw1xqyyr/kPcBouom+MGQOMASgvL9fe54qiKHEm1vDOB8B19vZ1wPsuaWYBrUXEMwH8ecDiGJ+roFPvKIoSObGK/mjgAhFZDgy29xGRchF5FsAYUwfcC0wWkQVYc0P+K8bnKg60m76iKOES09w7xpgdwPkuxyuAmxz7nwInxvIspSFG519QFCVCdERuGuORfNEhuYqihImKfhrjcfRV8hVFCRcV/TSmWb413CFHPX1FUcJE59NPY569rpz/zNlI19JmyTZFUZQ0QUU/jelaWswd5/dKthmKoqQRGt5RFEXJIlT0FUVRsggVfUVRlCxCRV9RFCWLUNFXFEXJIlT0FUVRsggVfUVRlCxCRV9RFCWLkFSdqVFEtgFrY7hFW2B7nMyJJ2pXZKhdkaF2RUYm2nWUMaZdsJMpK/qxIiIVxpjyZNsRiNoVGWpXZKhdkZGNdml4R1EUJYtQ0VcURckiMln0xyTbgCCoXZGhdkWG2hUZWWdXxsb0FUVRlIZksqevKIqiBKCiryiKkkVknOiLyEUislREVojIiAQ8r6uIfCYii0VkkYjcZR8vFZFPRWS5/X8b+7iIyBO2ffNF5CTHva6z0y8XkeviZF+uiMwRkY/s/e4iMsN+/lsiUmAfL7T3V9jnyxz3uN8+vlRELoyDTa1F5F0RWSIi34nI6amQXyLyv/bfcKGIvCEiRcnILxF5XkQqRWSh41jc8kdEThaRBfY1T4iEt95mELv+aP8d54vIeyLSOlQ+BPtGg+V1NHY5zt0jIkZE2qZCftnH77DzbJGIPJbo/MIYkzH/gFxgJdADKADmAX2a+JmdgJPs7RbAMqAP8Bgwwj4+AnjU3r4YGI+1nvlpwAz7eCmwyv6/jb3dJg723Q28Dnxk778NDLe3nwb+x96+DXja3h4OvGVv97HzsRDobudvbow2vQTcZG8XAK2TnV9AZ2A10MyRT9cnI7+As4GTgIWOY3HLH2CmnVbsa4fGYNcQIM/eftRhl2s+0Mg3Giyvo7HLPt4VmIA1yLNtiuTXIGASUGjvt094fsXy8abaP+B0YIJj/37g/gTb8D5wAbAU6GQf6wQstbefAa5ypF9qn78KeMZx3C9dlLZ0ASYD5wEf2S/tdsdH6s0v++M43d7Os9NJYB4600VpUysscZWA40nNLyzRX29/9Hl2fl2YrPwCygLEIi75Y59b4jjuly5SuwLO/QB4zd52zQeCfKONvZvR2gW8C/QD1uAT/aTmF5ZQD3ZJl7D8yrTwjufD9bDBPpYQ7Cr+AGAG0MEYs9k+tQXoEMLGprD9ceD/gHp7/whgtzGm1uUZ3ufb5/fY6eNtV3dgG/CCWGGnZ0WkOUnOL2PMRuBPwDpgM9bvn03y88tDvPKns70db/sAbsDyhKOxq7F3M2JEZBiw0RgzL+BUsvOrN3CWHZb5QkROidKuqPMr00Q/aYhICfBv4BfGmL3Oc8YqihPaN1ZELgUqjTGzE/ncMMjDqvL+0xgzADiAFa7wkqT8agMMwyqUjgSaAxcl0oZwSUb+hEJERgK1wGspYEsx8CtgVLJtcSEPqzZ5GvBL4O1w2wjiRaaJ/kasOJ6HLvaxJkVE8rEE/zVjzFj78FYR6WSf7wRUhrAx3rZ/D7hMRNYAb2KFeP4GtBaRPJdneJ9vn28F7GgCuzYAG4wxM+z9d7EKgWTn12BgtTFmmzGmBhiLlYfJzi8P8cqfjfZ23OwTkeuBS4Gr7QIpGrt2EDyvI+VorMJ7nv3+dwG+FZGOUdgV7/zaAIw1FjOxauFto7Ar+vyKNNaYyv+wStFVWH9wT6NH3yZ+pgAvA48HHP8j/g1vj9nbl+DfkDTTPl6KFetuY/9bDZTGycZz8TXkvoN/489t9vbt+DdMvm1v98W/gWkVsTfkfgUcY2//xs6rpOYXcCqwCCi2n/UScEey8ouGseC45Q8NGyYvjsGui4DFQLuAdK75QCPfaLC8jsaugHNr8MX0k51ftwIP29u9sUI3ksj8ajIxTNY/rNb5ZVgt3iMT8Lwzsara84G59r+LsWJuk4HlWK31nhdIgKds+xYA5Y573QCssP/9NI42notP9HvYL/EK+6Xx9CIosvdX2Od7OK4fadu7lDB7LoSwpz9QYefZf+yPLOn5BTwELAEWAq/YH2DC8wt4A6tdoQbLM7wxnvkDlNu/cSXwJAGN6hHatQJLuDzv/tOh8oEg32iwvI7GroDza/CJfrLzqwB41b7ft8B5ic4vnYZBURQli8i0mL6iKIrSCCr6iqIoWYSKvqIoShahoq8oipJFqOgriqJkESr6iqIoWYSKvqIoShbx/002QvlFXU4qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "waveform, sample_rate, label, speaker_id, utterance_number = train_set[50]\n",
    "print(\"Shape of waveform: {}\".format(waveform.size()))\n",
    "print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
    "\n",
    "plt.plot(waveform.t().numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s find the list of labels available in the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['backward',\n",
       " 'bed',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'down',\n",
       " 'eight',\n",
       " 'five',\n",
       " 'follow',\n",
       " 'forward',\n",
       " 'four',\n",
       " 'go',\n",
       " 'happy',\n",
       " 'house',\n",
       " 'learn',\n",
       " 'left',\n",
       " 'marvin',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'off',\n",
       " 'on',\n",
       " 'one',\n",
       " 'right',\n",
       " 'seven',\n",
       " 'sheila',\n",
       " 'six',\n",
       " 'stop',\n",
       " 'three',\n",
       " 'tree',\n",
       " 'two',\n",
       " 'up',\n",
       " 'visual',\n",
       " 'wow',\n",
       " 'yes',\n",
       " 'zero']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(list(set(datapoint[2] for datapoint in train_set)))\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 35 audio labels are commands that are said by users. The first few\n",
    "files are people saying “marvin”.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_first, *_ = train_set[0]\n",
    "ipd.Audio(waveform_first.numpy(), rate=sample_rate)\n",
    "\n",
    "waveform_second, *_ = train_set[1]\n",
    "ipd.Audio(waveform_second.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last file is someone saying “visual”.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,UklGRiR9AABXQVZFZm10IBAAAAABAAEAgD4AAAB9AAACABAAZGF0YQB9AAA8/1X/Ev/a/lX/GP9V/zb/wv4S/1v/JP90/23/4f5V/4b/jP/D/6X/q/+r/8P/w/8MAEMAVQClALcAxAAmAXUBLAF7AZQBlAHFAXsBvwHLAdcB/AHqAdcB8AECAuoB4wGIAWMBUAHoAIAAtwBJABIATwAAAAAAGABbAFsAjACxADgBrAHdAX0CtAJBA9oDzgOcA6MDqQMWA64C0QGZAOj/o/6o/Wr8w/ps+fb3n/YL9cbzRPKN8T3xtvBJ8bfxPvJ38870DPbL96/5UPuW/cP/ywFOBEsG9wc9ClELXwyXDcINvQ7PDnoOqw7gDWANgwxdC+EJfggPB40FiwTGAr8BGQFPABj/VP7N/RX9xvwO/CD8ZPxR/A/9kP2i/XL+wv7t/hj/Bf8w/7f/6P/o/yQAkv+l/0n/YP4E/q79v/wy/A789Ppn+tr5Kfnf+Jz4ffiV+JX4EPmv+VX6H/sO/Dr97P2Y/3oAUAHMAmsDzwSxBXwGIQe0B/EHKAhmCDsItAf2BqAGjQXbBPgDOgNMAnsB7gDi///+Fv53/aH8P/y++437svtK+1b7Vvti+xr8IPx8/Eb9nP2F/mH/t/8eAAEBBwHqAZUClQKEA9oDNgSLBPoE7QTDBLwEiwSwBPgDuwOKA8YCpwInAl0BnwA9AKv/Vf/C/s39tP0D/aH8ZPzd++P7AfyN+2L7jfsM+xP7Bvu3+uj67vqq+oz6mPrb+u76K/tW++/7xvwu/f79VP7a/k//hv/u/9YAdQGyAXACUgJwAroC0gK6AhwDugLLAQgC9QD1APABPgHjAToDHAMoA7UDFwRCBGIF7wU+BqIHBAidCOYIyAhgCNMHWAcNBpkFAAU8BGUDiQICAlsAhv9s/sz8s/zE+3n6Yfpb+mH6kvpb+ir6Bfqd+Qr5+PgQ+Yv5UPvj+1/9jP9VAPABpwIJA84DzgMRBOEE4gVkB6kIfghTCOQGZQMS//P5nfQL8PDtYexs607rf+u16uPoZ+fN5YnlouVC51Tr+fAm97P8oAHvBdoIygonDPgMaQ95EoMVxBidG4Edkx3sG2MZEBa8Er4P4A3ZDP4MyA3HDIILngn2BpwDnwAv/gn9KP1A/RL/NwAHAeIAnv8E/l38aPtt+gD7CPwv/qUAYwEzAi0CygDz/iH9gfsq+gv6bPnC+e764Pnx+D73R/Rd8jzwRe727XDuze+l8WTzKvVJ9sT2PveP+Av6CPyj/rkBhwWpCBoLOgx3DNILMgvdClYKAQvSC4kMHA20DLMLLAvgCHUGQwWQAxwDiQJeAvwBkwBJ/478vfoQ+Wn3y/f89/j4kvos/Cj9Fv75/mf/GAD1AOsCeQRpBp0IZwnDCTEKHQlsCDsInAc2CcMJxAq0DM0MogwyC9UJBAhpBocF4QRjBr8GfAa4BY4Bgfux8eDm590/1mXSXNDJzwHR8NEU0RzOQ8vGyO7GiMcMy5zSx9y25pfw/vjP/8kE6we+CuIOcBX5G6cj7yvlMtM3GDlGNzE1szFSLWAq3SemJ1IoAih0Jj8jcB5oGK4RMgstBz0FqQMFBLEFPgYyBjwEOAGL/pP7Ivkh+Pz3R/mH+9L8Ff39/On7BPnp9gv1qPOJ89LzbPTa9Ar0B/KW7zDszOkw5yflfeWP5ajl/uX25FHkQ+NI4p/jJ+WC6cfvpPUg/MACTQiiDAMRaRR/F6kb8R+zI28nCyq8KuApRSgEJaQhRR7kGXMXmhTHEdYOgQr7BegAe/u99Y3xtO6Y7NTrbOtm607rnOq56Q7puOg56ebq3Oy172TzVPWZ9gL4WPg1+ar6Rfw8/90BRwMbAuP7ZfS97Ork9+DQ3vPdtOAf48rjN+Pl4GLe0tux2RnaDN7F5A3t5/Xn/mQHJA7NEScVQxh4G4sgGCYVLeI0pzsTPwJA1j6zOxs3yjABLCMq0ihFKFYnOiSpIIkaThJuCqkDWv42+uT3ifhP+oT5J/gq9e3wn+y353Dk9OLj49Plpuj+6vTsWO6U7efr1OvD7NHtz/Bs9Bf6PP9SAvcC0gLiAMf9SvtR98r23PbF98P60Pso/XH9c/oJ+Df27PTD9br4Lv39AiQJbA1eEIQRdxFLECsPmg/9EMoTkBYmGZsauho5Gq8WohEFDhkKRAY9BRADAQHKAGD+2/rv9l7zQO8p61Pq9+m/6STsoe6t7q/vjfHg743tuu5m8APvBvG19AX1qPjd+2j7+/uo/e/73PZm8B3rEeeX4fDfbt4F3bnfuuAe3q7bP9tP2bPW5Nam2uXgPOcn7vT1L/5uBYYJbA2wEvoXBh0UI4sqBDNEOmM/KULFRE1GvkPMQP89SD13PD46pTmjODk2FTK8Ko4j7x0LF5UQogxQCs4IIQepAzEAZPzE9n/wsOvj6FXnBOaX5iDptepG6jnpt+ch5cTj/eBj30fhdOPf5Vbo/upb7Fvsx+oa6fXosui56TXrle4/81T1mPWT9qv2F/XH9MDzHfVA+Jv8T/85Ah0J1QlCCToMWg0UCzYOBBJQDycVjxrAFZAW0xrLFL4PkBFnCSwGogz6BFMDpQr1AKP+JQXW9mPyFPz09c/whPn4+MvyQfm//D32wPPo+vb3EvFG+Jv84/YT+4QD+P1q/FsAgfZf7wvwl+YL4tPlW+JA4NviAuDd2vDa/9io0mzTTNei16PcQOUO6Xbu7vX79r77IQKvA8QKwRFyFusfuCddLKIyojffN8k5HDxWOvc7Hj66O3c8aD6eOdA1jzL1K7wl5R/UG/oXyxSBFO0S9A4kDoILaQZZA0P/Mvyp+eX48fgs97L25/XF8onu+eu56dPlueQJ5bnkd+WG52Lo5eVg5jXmk+N25APlnOUT6FHpxe0J7xPtEvFt8KnvjvKN8UryivTo+tX6TPi6At78/vhsDYP9bPSkEsEDSPqVFTwO//4OEIoWHv9lA9MatwCw/nEaywFKAVUYSgEqAHQKrfy0AucE8Pz4/bz+gwdL/AfyZQNQ+8H0Vf+w9RX4VwEg9wv6RfxS+DX+7gCI/CP+vQm3/8LwsPV26WfdOuXs3Afav+T/4crjj+XM4AffKNxC2E7Ytdx749HoPfGy+3T/KQSmBmIF/whXC08O8hZHIDopPjF9N4o8azwZOsw25DFnNBM1CTJiNRs3wDLYMWks7iF8HtIVeg75DdkMPg+rDtYKMgsnB44BgftH9I/z1/IT8iHzQvUK+VL4lPK88Cvt5Omr58Dg3ePV5yXoBezJ7MPsYexo6DTlQOXF5P/hg+U27MburvN/9QL4WPht9dD7DPaq9av/MftQAUEDAgL0DqsA9QD+DG/3SgpPDtHy0wz6CcoAJhnjAR76vRO6B5oBWwDs/W8UfgP09bYXVgVP8SsPcAIC6cACKwU48l/9UwP4/e/7UfzEBcj+jegFBPYGueSpCNsEPezuCaH8U/RwAgH83vep9Kj9bwbR9x4F1QRs/uMPefrd7Z30OuW449HtUOM94zT0mOwK5tfyqus438Lrkufw3wr0q/Fb8ZgEBgABAV8MawMMBR4OMweTD5QZaBhnIbUpcCh5KhMsaigiKUgqLyoYKywspC/cMIQpxynVKlce5xxUHN4QNRKfE1APpg+ZCuEJIghs/nP6SfYB8qXx+/Fs9FLzbvGF8HrsKOpx6lbjrd8A4y/mP+nT5fnmWepb5+DhfORl6oXitOAa6STnMOzx85bq/urb6wDjie709Z76aAAh/V0BDvx6AFUOKQRXBmgdvx5EBgIacSQq8XgWvSsO5OwWMDRB3DgPCzlI4nD87jkw+u/2OinRAR7/lRoFBFUJqQjm+ZESCAdz3eP2RRDA21H3vAQD0tH31gr410zgz/+/34DZXwPs6qDaww567DziXgei78LwQf4B94P9TgkrBcP/3hWfBeT3PgFM81LuXfKz8tftJPrV+rX0v/yz9xTutfS/6UzqwPgt8zz1GwL/A7H/3gaWA/n+Age4BW8G4hORF7YcyiKJKEcpAym+JwgjICj0IQQlaDBrKfYnuDB1IpkdMyNEFOgOhBG9DgAKwhI6FoMHeQmdCCD8Zf3C+b/yG/gg/HT29faU9x31GPYl7VboG+ou6nXoCOkP73PnGulf9CXjyuOl7Lbd5N9c6CXj6+VD7D/p8+YD7zTvEedk6cjrwPga7qT6ngRG+E4EJP/1Cnj+ofwvDR4FnBHhCaAB8htZG24A+xiVI4j3ahqyHTkCTxjPCXwQGQqhC5EXBwHU+ZIE5BA3++L6PP+H6CEVLPe04AsOeOau/RsCrts7+eoB8+Z16MoASOvR39QWy/II0SsFrAFR38v3zQwY3sP64w9C5xMGwgh56zQMPgZ7+0oPHgAi+e8KfO5F7rYEQ+N78t0Koe5X92cJTPO49l38AfJ58D37ufdu+3MJmgF0BSwLSwZNDQUOigh8EDoWSRhwHjMohyJJJlsr9yNlJA0sNSWXG80pMyieHD4n7yu/FFoSpByaDz4GqxMVEVX6uQaKEe7/+/u8+W7xb/ID/Q7ubuMk/zzwYOY3AAnqYuOR8CflYexL6Yjpg+7l4FTwkfAZ453rBuOZ2XPncO6P5R/jz+JG6sHquOgg6Rno/+ul8aD3f/5b9X70NQjYAlT+xACKCDwJZRF4CDAEiDHZB/jqtU/4H8vMXEMTP5HFoSgCZm28pfH/f9fVPdDPXz7yaMZROwwT2s67/aEVA/3fzYwJrxbZv4YA9xU01zbs6vftBMDITOqTIl7DVuhyCCzaG/OS+nHleeJ4/h4AZOC1+YgGCQOk+kf+Bf+ABW8PyvsfChAWxQv9ELof/hb6BEUQERes7aECphSJ+I4B0AVNDV4CgPrUAwcBD+/a/v0CCOnVBKkIOfN7D+oLAvihC8sGfgMnDNAKCw7LFK0ZXySmGWIPzR9UF3MSaBhYGiYZyBJuHSwe9Qr6Dr8UMQBBA+AIlfjaA74F8/nqC0f+5e4CAgf33PYR8LXvKf6b86HzMfYl9nP1MvK67k3v+fDC62rueueU7Q/44OFU8MLd/+Eq8arKB+0u7w/XP/O/7XHgpPXe91zobuxoBSD8r/mkEjD12/paKgUE7vr8GdQWNQj+EXQrpAlnFz0K9RjXOorX5R8QRgzQ1xnnODLfBf8ANYbx9+4aFV74HgCh/NHoxQYV5VXsHiHOzu7nRxZu3mzm0QHz8H/Y0/2b/LrbTe8L/0jwluXa/k714+229Yv5iv1G+Db6+vU7DWQCBfVDCp8F4RLh/nIDCyrm+VoSAzyO9zkQRjw3CsYC8jdiIlboKxiYF/Prsg9yCMf4lQJoADb/GfvD/5HwSvKG8fLvtvUb8+gAzPO59/UF6fbD+t78+vrFBjf7Hf6uEaQJ4A1sEpYD0RTHEdD7gRQdF5H5xxF5Egz7Qx2GDur3RQIIByYLiu8tAjAJ2ep6BYwJFfhb9SP+FPx77RX4PQVe8wPvagKG+k71LPyy9mjxbvti8ZL1KgCH6E35DgIx9sHhUferBWvXJPFt/1PmX/Qq+jT9LfhM+KH8OPc1CBkBe/v0CZUHWwDpFF0ehAPxFRoQkwCNOvwBH+0QLvIMuBSiEQ0PNgkS/w4oRw2m8mLxiiTyG1rAUh/dIu+4jh55EhXEYgU8BN7fSfET8rT46/hV3ovrWAxezSjchiHDyhXSwhdD7BbJLAZW+8/PMfYSEzPb3eNjHojypOePFS4DR+YSHf8INucDLhUagOyOGXkv/wjE+8YygSe5BiIbbzGFF9obASzlGv8bJgagFB8dQ/YF/yEfZf3d7YUNEAP94Pr1ngQV16XjGP9m5gThb/IU7gHkQfmu8+nViOlW9pHrjPWK/YLyBvYeAGT40vya9yIDuQtB9HsK1xQE+RAIJyjlAgf3SSZuCvnwBCArIlr5XxH+KbQHQgkRF+kPPgH8BmEmnP358M85TBFN3MIlExQn4N8CEw+38Xj0ygoc9CD8y/LY6QgCU+pQ2jH2CAcU1izkmgbX7XvosvZI+sbul/Cq+gEBXfwm8owJzg0M3hAglBl6wRIdti/i2WH/6xr4DCr1hxR4FibRPSY+GRPVLxdeFWXlFwnjFMfckwBTFlnhpeOvGwH3UNXyAw3ymeOB+7v0sM9C+sQPNLbN+O4hQMQA9lMWG+DK6F8RaAp+3HMJqBrh4jQRExSW7/IkdAWo+L00Jgvu+tgoeBu5BgA6gR3G83MhITdoE9/9UDqNHYfjVkM/KF3f2S1vLG7xYxmAJubqxPZaF4jkFtxgDYzirdYIAnXt078C6XDzYbcj3ezv08Q92ez09NTW1IAAJN53xPD8UO0F3Z4EE/u47UcNLBQy90H+lBnpD9oD+SUpIBgFsTRqLeoGKDNNG+Ecoy64CoIxzxxEFGRAzBrLAbErCC0B9+oG2DEO83kEJzJ58CLvVh0QDfjSk/t+FtDGzuvJIQHRpd5VE7LaVtDvCqriEcWu/Tjf5tf5CMXkOtdZ9OLsB+TK8YrhltwoG5noVMpmKsr7SLwZIggaGb36/74dtAfU60TyADr96dDeiUo85yPYFEDnDZfhkwrnPU3mfPedRpHdigOHMF33DQG9DswVV/L7Ba4aaPG7A8r7gOyBItvrPeOsLDvmK+3ECoMMVPBZ4cwobwGezwsc4BbHxPgfUSxY0kcI7Spa5p8AIi41+QTwWCj8FPPdvxR6MN7p2fijJQ/4Re5VJg4QQ+OXDf8gp/dW9vsYdwwD6uX92hbJ3ZrfWw7A23PPIAb/5lDQF/V74+DTB/Jv7RvNvezK9obZLvTDBOXgquurAGzrKP2aD5b0dQEUI9MHXAXVIXsZogxyIFQvVhT7GJY35B5DHf4pCCM/KKsYZiA/IzMasBwWKSQYDPuPH2Ygn/tYB9ATVfF3+GoaF/W959oNUuAV5XcMT9QU6YP44Nwp68/nnvXY24XT6Pr63c3cffN/3QXnFOkV5Tb6PdmW6lf8rNr98yz3le778Wz57/vm+VQEFvSCBnkXTuumD0Icpuh/HN8f3PGBFJwpqwDKBbEr0QEE/ps7ZwR49GE5XAWjA38vYvbW/5cqHQSY4v0VmA7j42IY/e6S4kwaFtwl9rEFeNOLBK33xe2iB3bupOfOEtT0DtGpFlYFVN2fCmkBXO0KDTYJtubO/hMUPu31+w8p9P9L5JEgBhjp45UQAwwg5FMubAi92Wo7ugJW1Y8tFBAQ65UQWRZ5CSL5U/lP+tHtNfAI6VPqNvUs3ybpRQLD1LnRl/k54GzTnfRd8nrniPJH+b/35PIh+PUFRQLQADwXARkqDnQY5iBNG4QWCxx+G6UmtyteH0km6SJ2I78j+BZ7FDwhlh/BDJ0gaBM5AlwiXQaS7AMWnwUI7vkNSvsI8wAF4+039vT/r+YX9cH9TOUo70z9DOxl6nfzM/NL7njmjvL4/Q7zE99w8xYIRuVx4D4G9fa23UMAmvfq1rv9FAKA2W31OQs56QftgguM+hrpmhTxB0fvFREFDroHp/xEFLUg8PLjCo0dnfmGGHQYb+1gEswawPPDDt0UbOtpGdcUQNdZEZsQMuRtCSMENvXc5/wGBBIKxYv5hRzD2ej66Ans78bzw/rZB4n48PcQ/gX1OwiLBEb4QBEeAOXzlQc1DSEC9vccDakNBwG/HiUKKeuaGcAHJ/OuH34NW/EIGqAZGfKyD0gXPvLbCYEPWOUi9HoFaOPs4f/0L9102Zjsbtl12vPmW9kH1QjgreSE4bzrOuoA6OT3MPrM8zcAjAm/BpMPRBlkGlEesCWRJbkjMygCMn4unyuSNB04syysJ8QwayndHUseiBn3GmEcAhBXEKAPMweEAygDNwCf+zL33fsA9pHw1Pm88O3wg+6E6jH2oOjn5u76Q+xf4bv0xu7D4tbxK+1R5Mn1jvLv4z7ywPMs6bHsifM676DtRfya8g/qa/jJ9arwjfb++JX8Rfey9jX+c/UnAjwEvfqOBm0O1A0YBUIJUQvNDKMWWAdsDQEZ7AhqEBsMFQdFEAAFWQPCCEYHBQQw9VgHHgUv6+j/bgA/7jH73P/67MrxQvq47XXt8PIT8mH6v/dHA3j+7esiCHwLR/mcBy0ayA0LBMQYwhcHAekP2hauEW0hRBk7DSMcthJx/QgafhuHBZoZFCNJDmMGVwZB5g/S+O+L6+nLgeOh5KTFFMi0vyewTLoZwvbCpcbd0PnYwtPq1m7Z39ta8JL69QCKEVAdsxkVGnUnSCrgLpo6o0GYR95OqErARTNF0EP9QPY6ZDt/QpE9CC30JvweehhrES0HCwktAsQAawON8fDpmOcF54rhDNkG3vnhteH02azau9wg1gLbb99k4BrpE+0a6SzpX+848j7t8e6Y+lUAGQFG/cj+w/8l9nP6v/xG+O7/eAOuAiQA2vlY+NrvHfVNA+X9iQLKBbEFPQUTAUMFGAVLCyUU0Q/pFGsWlAu0DKkIQgkNFAcPzg0nFUAMCQOPAo0FEv/FARoL4wF//moC5/Ve7r31yPDQ8TX5HfCr7D329Owr40To1uwT6HTsmPp89wH3Xvh49AEBmP9jAWUWbA2eDiIbGA6SCYsXQx0TIuEqFTLIMx8d8BT5DZfm9OeO90nsce/F3+/LM8j7uEW5ybfMsF/JnM2cvznIhMlsyW3UHtnK6JH+vATCCBkU3hkQFjwhSTDQNRJIZFMZTZ1LUkphTK5K2ktgVR5R81CWSpE4IjMaKAgaIBkxGPAU2QzoAHH4k+jX31nhsN2e3QfkkOH50xnQdtZr0j/R7Nxt4lXezeWq8N/l2uZ08WLxTP1rB6AG6wzQCscDYgDHAyoOkAz9CyoOmQW0/Xf9nfmL8JjsXu709an+yPny7zrvGumq4oDskPTQ+ygDsP6t91P0O/mO/CH92As4D3gNRBmtFWwImwuPFZ0SRRWZIi0fzRabFZgJRQLzCCEMngkNBkgEC/8L9SXtbOu/6ZrtIfNA6sjmpOdg3fzav9+Y4oDnY+0+7cPn2eqH7d7pC/Xo/xgFbw8FDtQISgoQFkEgKhzXIlIkXRSTDyH9kuf+5aLlS+447dbUdcxXzOzEyMBKvS7EqdMw2ZrVJdWZ2enoz/WM9U0DXBhKIvAjeSVYMnc8qUGiT8BYd11wYSpf9Fp4WSxhn2SsW2Fa71b+RYk7FDZFKAceIR8+FIoDG/0d8DngF9jhz9nNBM4AxqDC0r6PtVS367qEu6/EI8pcyzPNSM+H1TfZ3uTn8KnvG/25Bmf/hwWMCaQJLhGtFSQYWBpzF5wRjxC2DTUNBhO+Ch7/7vqY9cv37v8Q/tH3FfM072nyCvSd9Pf8Hv+h847ygfuGAFgCQwXmCAwFQQhaDZgJ3A7YFX8SbxS/GUMYpxX0E08Tfg20DP4RQAzkBlMDgvzA+LX0gvLA7iDpXOgj4iHggt9V2WjZadWH1UjdpOJC5xHnT+fI5tDjoe4F+s4DQBFnDsgILgxsEkMdUSxsMwUvUij3Gq4R0gsi+U/sNebY5K3uwutE2gbLuL3YuWS6S75Zzg3VjtGczUHJc88f4zv0UgJ8ENATExnXIi0tjzttR6BSnV4YZHNoMmpZZzJq/Wukbf9xtWxFYR5W4UfOOAwwtS7vJzEYqQjl+E7rjt8P1ybRz8o7xW+5e6+wrS6sRbCXspWwira9t8C6WsAavvvGWNLy11Ti/upa8H70Dfe2/jwECAtDEyAQmxAwEz0TyhN8FQobHhiqEgwTWg0SCgUOHA3QCp4J6QqPB6MDoQIh86boeevg73X7xABY+DXwM+mq63XyoPfVBNsJYAiYCaoEggaiEc0W0B18HgYY2hZSFYATpBIUFWIY8xdTETkLFQdt/wH85Pwj/kb9MvdU8NznteEs5L/k/+Ej4mHi4t6D25Dck96o6pn7oAESAMT2d/NXAVkRtRtSHyIbXxZhE6YZRSiKLvswLineFUAMXQGc7xfiDtsa6VLzLuGmzMu05KZDs522PLeVyJ3OA8l1vayvz7xg3a38Ew/eC14HIQyFF6gtRUD0TBZeTmiZaWBo9mX+Z9Fv2XWDdd9wJ2aoXbZQ5DuDMl0sTiUPHyALXvNm5v3bMNSMz6vLMscfvTSxP6byoymtN7NBtni2+q4asMe6o8DxyATTE9qY4hjnrupt8En2qf6tBp0NfxK4FBwWkhOxE7EYmh57JwYrVyMXHLMZnRv6IVkk7CSpILwXSROhEOIOLhHXD3wLVgp0/x313PHf8wb7xvOi6qPrketp8n/1Lu+e8FHyTvWZ9gHyqPhg/kn/WgTU/p/7DABbACgDBgC3+hIA/QLo/7T9mfZw8wz2Yvaq9TLyBvFI8HjvPfFf9Dz1Eva8+VP5K/toABgFEAiTBY0K1RcDHxojIB7eFc8cmicuKagkoSN2KCIuoy5SJN4V5hbKHfMX0Q9PAB7ngdD+usO3Gsye3QbZmbg5kzqGoo9UpJ637cBCxeLBX7bos+PChOEVB94ZjRgPEe0S7SUUO35LiFfPX+xn8Wt3Yr9X1VVFXDJlXGXVWsFKbD1pMVkkbBtiGMEWnBHqBvbyjd6V1r3U8tcF3VvZws4tw965DLg0vzzK3NQJ14LR+8vPynnPXdqv5gXs1vEy90z4W/rH/U4Egwz8FOUauRnYFY4UyxRqGj8j1ydvJ8Ekgh5lFjMVqxhDHa8glh8FF3EMUwgzB0gJzAsZCl0GmP/P+qn0yug14cvkSfHk903vX9yPzQvPzNv85BnoBOtZ6o3j5dty0/rUNueA+hgAbfAp3c7YhOH78QP9avxB+bv0HvHV8C703P+1CLIKoQtQCsULVROeF0MYQhyNIhgrvS+aLKUmhSWzLPU1mzu+OhQ2jDTENQw1+TMhMjYvfCiEIOAbgBi+GAEU3wdM/eT36fbD9cnsj+CW0j++hKwjpBWnlK9Osg+nppdmkGKSkpb8nEeocLWBwgrFlMKhyDDZX+9eAjoM5xJjHj0rCzRlN688HEZOUF1cWWLeXPBXNlXOUBpTvlaKVPxN4UIJN20v2ypyJZYf1RfRDxcJaQHC+Unx0eiT4zvh7d0J3Pza9dVL0X3NystBzovT6ta41dzUm9bx26Tit+dP7Hjv2vTE+5H+gwJsCKUODBMzFQAY/xvVIa0j8yCTHYUcnSDXItgemhk4FH0R8RBiD/QOIw1MBxj/pfZR8tr06fah8xLsueSq4irif91P1FbLLciGz73ZcNvB1+rRT8v3yGDOHtmJ5SXtEuxM5VHffuHb6+b50gIDA+H+qvrb+tICjA76F40dRyCRIGYgrSNAKSYxjDmmP1A/Cj2XPeI+nEHNQQtCukDnPew8vDioMpIvmiy4J30kcxxUEg8MqQhrBycCp/xe+Lzwtuag3/fbQdwY3uvbM9Z5z0nLlslQx4XA87LkoX6V/pT6nz6qHa2gqn+kRKFdoYKhfqjqucPPEuM27A3tMu0u9LwEEhhzKt47yki5ToVQV04qUdNdcmy2dsl3+267YqJd41vbWhJb1FS0SnlCkTj2LIEiWhdYDOADOfxH9Hnr1eIn22vSN8uqxe3ALr+pwAHCS8Prw3PFPsxM0kbXftzx4D/pefXn/rEFUQueDkkTYhjVHKQhICigLD0ryCUwIZ0gBiLeI+sfZxcOEJIJ+AMSAOD5AvPy75TtDukg5CDfktmC1ofV2Nbs1wnX+tQW08jTX9fV2I/W3NTu1FLbsuOT6Nnqw+x27l/vjfG688j5ZAKKCI0KrAqhCzwOtRHcExcXmxpYH6cj/SPTJKcoICzsLtAwdDA9MGgwES8XL0sxojJBM9wwHisFJu8i5B7yG3QYwBWZEzwOwgjP/1r5D/gd9X/wPu3K6Cbk+eGG3gncNNwR3S3bltfC05nQrdGx1KLXJ9vb3dbeK9683QjgfN9P2QjRkMRsu/66m753xKXL0tH11bXX/tI8z8jT/tw27Nf7PAl5F9QgKyelK6MuBjUyP2NJ51CeVVdXBFklWx1a/FecVK5Pc0xsRidAHzrxMi0t3CZjHpkTrwhG/VjzpeyL5o3j1eLf4LnfFtwp2CXVhdN01CnYjt/C5hntR+9z8KHzJ/hl/SYBTgSjCMQPRRUdFwsXcxfKGHUZHhitFQwTcw7jCpQGugJPANf7hfV87nPnquIn4ODcsdm41fjSbNMm1rvX2dcm1pLUFdfl26nhfuYV6rHsVPCm8lLzv/I588P1MPq9APwGZQyiDDkLwghXBogG8AbDCTYOdxGLEu0SzRFTEbwSQRIEEikSzBDTEYcUHRedGzIeRh+aHpUa0BgyGbsbpx4eISYjbyIxImYg3R0KG4oW1RKyD8gNgwxLCxwIeQQ+ART8yvYR8EbqQufF5PXj6eMA4//hwOBE3zzd4Nza3M/d9t+z3yLh++NH5t7pLe6+8Vv1xPZQ9iX2DPbu9e71JvKh6Q/gANWozfvL/85G1/HgU+a25nDkg+BY4ADjH+gp8I73jAB0CnUUmBz3IyQrcy9LMQkyBTQ1OF0/9EdGT6VRf1BKTSZJfUVkQEo6sjVYMm0vByznJXYepBcVEWUMywbT/Zn2KfDN6lDomOfn5s7mBOZI4k/eldva3DLfKuJA5e3muekM7NLu3PEd9V33Mvf79q/0uvON9tP4MPoq+un2G/OG8Vnvmu367ArrcOkg6T7oeud45uTkJuR7467lb+ib6RjsOe4j8Cj0cfgf+/38KP3E+9f7ov2M/2QCoQIfAUkAmP8sAY8CpAS0B7gKLgw6DP0L4QmHCrwNohF+FtAYRBkEG3IbEh2jICsiZCMuJKYiOyCEIFshgyRLKFkp5Sg1JRwgWRtEGZMYkxicFuwRtAzwBtgCWwBt/5z9wPgT8nTsUOjY5IXi3+CU3ybf4d1S273ZKdjh2NfaitwY3hrfB9+g37Xh6OJ35VrmWubD5w3ob+gp6wHt5e5O8D3xM/PB9AL4r/kL+rr4H/YN8jXrjePH3KTYRtdK2jngXenR8jD6C//c/2MBVAR+CLwNhxRIHBclKS+LOB1CWEoeUclVRFcNV5hVtFNDUWVPm04OTppNTEqIRNk8xjL6JmEcHhN/CfsAbvZs6wviVdm209fQv8zByUzIqsUIwxjBQcAjwA7D88VayhTR5tdL3wnlv+nQ7FTwwfRS+AD7TP1V/yYBlgN6BQ8HeQnoCRsHfgND/0r7tPho9tLzGfKe8JfwMfHa7ynwze+c7/Xxd/OQ9Br3hPks/HsBZAezC40POxJuE2QVTRbsFi8XeBYoFjoWsBcZGTkaWRsoG+wbBRy7Gz4ZARR8EC4MmQqSCfwG1QQUAgAAq/9oAD0AJgGS/9L8h/vI+ev4IvmA+vv7f/7P/xIA6P+2/gT+Zf0J/SH9Zf0y/G77SPoC+EX3DfdW9jj3IPe29U30tvBw7iXteuxV7Ejrouo06lnqEOvD7OvuI/AA8Rfw8e5r7wPvF/Dh8LbwQ/Gf8bTzKvWO9xH6Cf0eAD8C5AaTCioOxxFLFeIYBBtNG+gYqxPMC1QE/v1B+WP3Ifj++B/7Cv5t/wgCKAM0AxEEygVyCEUL+g6FEhcXZxz0Ib4nGy2CMU80LDZiNVgyPy1pJ+QjhCDQHTkalRVxEf0L0QYmAR76oPJa66Tigdoq1NjMtMj7xhnHIsn7y+bO9M+/0WvS7dOK16HbKOHU5ufrLPIE+Yv+vAQkCd4LBw+KESoTIRWWFigWPBfNFl8WWRaaFLgUQxNFEDYOlAtvBnIDWwAB/J35jfad9K7zzPNO9Sb33/iG+gH8GvyI/Oz97f6TAAgCTQOqBHUGywbpBVoEAgKmAYAA+v8SAAAASgEoA1QEJQWfBZADoQJoAEb9If0D/dL8ff1H/i/+mP8+AQsErgc2CQAKNwp/CU0ILwgtB6IHsAlcCtYKwwlZCMYHAgdXBgEGFwTQAOH+0Psq+ir6wPgQ+fb3u/RK8kjwP+6H7ZrtE+3D7JfrcutP7Ajuou/58DPznfRR97X5h/sb/ZH+aABFAqkD4QQVByIIAArFC3ALZQw6DCAL8AsWDQ0PlhFoE28UxhUQFiIWvxQJEZQLEAMK+TPuiOQF3eHYQtiS2djbY99I4vHloenh68Hv5PKH9jX5s/zjAZ0ImxDVF6IfnSW8KpAuMC+dLoIsZChgJZ4hkx1qGk0W5xKgDzIL0QYtAt37MPXS7kToQuI93szbmtrp2hbcWOAD5UvpWO658iz3Mftt/18DDwdzCSkNCRHuE8oYSBzeHk8hHiGWHwcexRnlFbsR8AvZB9gCa/3O+fT1E/Ll7lrrSecy5Hjh+97z3dTc8txz3eLeu+FA5ePow+wT8n/1Nvp0/0UCuAUvCM8JgwwYDugOpxAiEXYQcBAfD0ENEA3eC8oKewqECFIHhwVSAiQAov1i+zX52PdJ9tv1OPdd95X4tfmM+jf7dfvp+1L9cv4F/8n/sf/P/4gB7AOxBSgI7AiXCOsHfAZJBf8D5QJwAoEBTwBEAXsBWAJnBNsEqwWUBpkF+gTPBMYCsgGgAeIAmQBjATMCQQOSBLAEAAUwBAICMgE8/6j9L/4W/vL9BP46/bP8g/0u/eT80vxX/Hz8k/sr+3D8BP6IAaAGYgoQDdYOtAyaBoP9+fDL5HrZvc9nyoPI+Mm3z17WI90y5Hbpy+238Rz0DffQ+5MAIgiCEG4YbyJ0K00z6TpEP31AoUB/PZE4FjP2LKAn9SL4HxccVxnMFacQ0guSBIr9w/X67NPlY99Q2v7XWthp2tDeV+Qm6TPubvH386v2UfdG+Nr5yfoj/uMBGga+CtoNlRCtEBoQnQ1VCVwF9QDS/K74u/TE8ezvmu237FXszuud62TpMehn51jlieUF5wDocuv47+b06Pp0ACYGagtvD5cSxRQoFq8WlhZ+FoMVDhXWEx0SKBHJDt4Lowh4Awn9+/Yq8ePt4uwN7anvOfPn9TP4cvmV+BD53/jx+ET7Hf6VAmQHQAxwEEUVdBgWG74dBx6tHsQd1BvvGCEVNRKtEHAQORBqEHMOnwr1BTEA4vo39hvz8/Bz8F/vLu9f76HutvCs8qn04/al9rv0/PLm77LtuO0O7mDwAvPO9Fb2GvdQ9i70RPL+71Luv+177Tnuuu7T7ybyCvT69QL4HPlt+uP7Jftq/Kn+twBLBqIMdBOEG4whECXUJU0gkBYLCc34QOq33i/Y/tep3IfjDOxw8+T3mftk/HD8Zf3O/kUCqQhGESEa5iRfLl02SD3SQPhBCUFxPF02ti8gKKshQhwkGMUUhRKeDrcJigNh+lTw6+UU28fScc08yofL+c5P1JTa/eDz5pjsvvF/9br4pPrM/Lf/2AIbB1IMRhHsFsAa4Bv9GngWiBC3CeoB7/sU96byVPB87jbsqOq46LrlEeJu3rTbMNls2NzZltzU4Wjo9+499rP88AEPB1AKiw1MEeITnBZjGdQbBx7THwshziCDH/ocVRhuEwAP6AnDBNAATP2D+K/0vvH97lbtjOz87c3vDPFw88/1a/hE++H+AwMhBxUMuA8ZFM0WWhdPGOYWbxSLEq0Q8w1UDekKHAhdBj8Cqf4l+w33s/J47/nrzOlX6WrpEOth7CjvP/NO9fz3pPri+hr8Kf56/+4AMwKKA40FrQZYB6IH9gaxBYUERQKA//f8//nY96v2nvUL9ar1dPYJ+Bb5tfno+rL7xvyi/Tz/vwG8BJgJrw2REu0X6xpuHdIeyx6ZHb0c5RqZGD4U5AtPAKLvHd2gzBW/W7e2twG+fslI2APluu4581/0ZPNK8vT1ov31CsYasStiOppEwUpNSzxH8D/NN/gunyYnH/oXWhIjDfcHTAKH+8zzZeqo4C3Wrs38x03EgMY3y0zSWdwE5sfvOvhH/vcCywYGCk0NlhHrFWoajx8+Ii4kiiTcId4e6Bg0EeAIgP+l9nHvV+nF5Mrj7uLu4ofj/+F94CTe8dtS2zTc0d9h59Xwz/q4BXoOBxTKGLQahBueHIwcgh4iIGEhmyODJD8jUyARHOUVbQ5pBhD+0Paq8GfsG+ri57Hn9OfR6Fnqo+vQ7HXtRe7r7lXxxvMN93P60vweAFMDDwdWCowOzBDyEfMSzBDCDQwK9QUFBM4DQQMdBP8DGwJh/7362vTn8MvtsOuS7Gnt8u8c9Jr3cPxSAqYGgQoKDQsOCw5gDRANeA2YDocPOhFlESAQ/w2+CpMFdQHl/f/5zfgB95P2XPY89RH1C/XO9FT12/Vi9kv34/bW9tH3Zvnv+yoA4QRtCWwNMQ++D2cO0guTCugJVgqlCvsKXAqDB4UENwDf/SH9X/1h/yQAMvxi8eTfKco7tt+nMKQdrai/TthJ8eADaQ/4EaELxAUWA9AFTBGhI9M3rkpEV7ZamVYFTGw9Ry6tHnwQ4gWI/If2afJ473vt5+td6Sbkwt111WDOWsqry2fUpOIW9I4GJxVXHsQipCGcHzcdPR0wIQUmsCo7Ltoueit/JRcc0xFxBwP9J/MD6lviidsu1z7V6NTx1pHY1tkO25TaPtpN3A/g5eXr7vb3CAJWCkoPNRJMEckOFQw9CsgI1AjsCLQHywZhBDIBrv1H+fL09fHF7Zfr2+t36hjs3u6G8YX1wPh5+gn9+v8bAogGPwsJEfMXXB0wIcQihyLZHyUdAhrUFrgUnBELDjAJnAM0/ZP2SfEz7kvu9+4x8WTzxvOK9LX0MfZg+Tr9uQEnBw4LPA6CEGsRixKSEzcTIxIuEfMNCAuCBtcBSf/k/Kb71Pkm98Dz/e4Q69znQuey6EHr0+9k89b2i/nV+t37L/6l/3sB9wK1A5kFdAVpBusHIghTCNoIogdvBrgF2gNwAqYB7v/f/bn8EPl29xr33PaL+Sb8Wv4qANb/x/3K+6P5x/i+++7/sAShC5oP4hNNFusVjxWEEagHAfeJ4DnIHLY7rbux98NN3MH0sQVOCdcB2fMt5SbfwOWI91oSAy4aRIVQSFCGR9w5KSrjHUUVaQ+XDX4NOA9MEfIRZBAUC2oC1fVv6JzcJtZ/2CLhwvCUATwO8BQlFLoMCAJI+p/2Afy0B2MUWB99JOojkhyuEZ8FkvoV81LujOx/6+zqzuts6xDrgukw53fl7uIE4TXh7+M/6abyOv3cBZQLbA0fCqsFLQJD/58AkgTVCRkPkBHAEIsN7AhWBV8DCQOeBHwGrgd+CKMIzQe5Bj0FfQLu/4786/gs91T15vSJ+Nj8LAGlBe8FQQPU/s34rvOw8HPwTPMU9wD7Yf8BAR4AsP5n+lz2V/Jw7j/uvPBW9r/8QgTuCQkMcQxoCqgHMQXBAxIF+QhMDO8P2RHkEFsOgwd0AD37SfYb84/z8vSt9wj8VP7iAEwCdQFVALf/TwBFAqUF7gncDioTgxUQFsoTnQ3kBlUAJPom9wD24/bA+Gz5O/lR96DyoO1M6qzofer+7/X2dACKCLYNtRGWEd0PnQ01DcINghBdFFMWdBhnF+gTFBAxCnMEegAk+iL05e5l6hvqB+0g8jr4lfwO/G364PkG+6wBggbdAZHwOtLKs3SgVaC0tWDY7vqXEl0ZKw8D/bXq4eIb6mv9axYoLtE/K0j6R/JBQzlnL04lRBkjDXYCk/vw/KoEAA/PF7UWsgp69vXerczzxcDNLeB3+BgOeBuZHZYWOQvKAO/7f/5TCGgTUR68JawnQSWtHrgUEQky/AnvTeaP4F7g+OW37BPy9vLs79foZOCr2U7YF90v5t/zvwGQDIsSHRK8DYkHxQHz/lABBwalCvoOghACEJwMLQe5Aaz7QvXv8X/wAPG79H34Ufzt/vr/+v+S/1L9ZPxM/cL+IgN8BuMKrA+5EFkRSxADDKgHnAOxAFsAOAEtAoQDVAT9Asn/pvti9qrwBexL6Xnr4fBX91T+JwKbAnQA3vww+iT6jftb/38EEAiDDFUOng7iDq4MEgoNBnUBKf5G/T0AbgXpClQNNAwWCOL/7flU9ZXzpPWP+GT8Hf5//ur84vpz+ub5E/uh/Dn8S/yx+rz5MPr6+tf7xPsR+vr1AvO28EPxKPTx+L3/DAWoBzsIZgjlB3IIwwnwC+IOghDeEIQRmxCjDYILJgZvAZ3+DvwV/eH+1v9oAIb/0PtB+Xf4L/lG/Q4CnQhwECcVSRgSGEEW6xXtF3Ye2SRyIJoGDtsirIWMp4pipe7PyvZcCtEGRPJ/2NHHP8jO2DD1/xJmKkk5pEKfSMJL/kodQuoxuxtdBub5OviVAnsUwiBJIZcSGPYu1zG9/bDftT/If+IA+/0LaBNUEtYKWQMGADz/igNGDMoYGSeeNNk8wDuZMKIaWAIU7kHhjt/K40jrs/Lf8yTxbecl2jXO8sSJwyjJMdVD4/DyFALtDYsXgxp+FtoNkgQtAiQJnhcDKRo2wji4MCUi3hCgAZn24O8U7oTvNPTo+kn/q/9x/UD46PEh7qjqx+pk7nj05/5ICQkRzRajFkwR/gw5B68DuwNnBKAGhgkSCjUIeQT3/GrzrOhE367bPN0x4zbs8vSA+gj84vrW9r318Pe5/J8Fkg4cFsYa8hsWGyca5RW5EJAMAgcDAxIAbf8NAdgCMAS2BIgBJPrS83zu/+uH7dXwmPWA+s393P9FAooDfwSTBVYFXAVDBUgEEAMzAvr/tv5y/kb9qP1H/mv9ZPyM+hr3MPUw9cX3Ff3MAjkHDAoGCpEIWQiuB9QInwrwC0AMvwuZCskJsAlrByUFwAJh/2T8Nfln9YT0xvOv9FD2vfWC9/D8+gSzC5oP/gy7COQGvws4GQ8kgx8cAzPWGKmRkIWVJLMh29/4ugKy+6XsFtw51v3bWep//poPWB+CLMI42UUdUDhSUEhrMk4XlQKx+usCaxa1KToyzyqsFK74ieDM0SjOL9M63B/or/QmAV0LaxEXEkULWALz+fb3l/4hDMse4C5GNx81GiiaFDMCG/PY6QXnc+fe6cLrx+om6X3l4t4H2rbTa82Hy8LOedix5yL5zggQEqQSzAtYAsr72PwTBtYTBiIRKk4qpyNNGzsSGQpfAwz7kvW38VXxjPUr+1X/gACi/W/3bvHt62brfu+q9X39nAMnB+4J3guoDM4NyA1GDGgKYAi5BmQHfQdzBHT/8PeZ8cvtcuvC69zsyezL7Xjvk/GZ9q38FALkBngI8wifCkwMTBGDFdoWUxbbEoYOFAsqCfwGVAQGAAj8Pftf/ZL/dgI2BJoBZ/9S/Vz7w/oA+8b8w//LAVMDsASQA6kD9ASkBLYEGwJZ/d/4mPVU9fX2d/ii+IL3d/Ok8DTvre7+70Px9/MA9pH5Qf7fAmsHmAlXCy4MCAtMDBEOBw9kEKEQlRAwDsoKIAbYAjIBDAC9/1L9yfpB+b/3y/fx+Aj8BwF5BH4IWg3QE00bRR6RErPybcqhq8qliLk520D4kwWKAyf44+1J59XnXu6N9lr+/wOqCXYVmCaoN0FBLTs6KSIR7P1o9j37iQc4FAYdHx3JF54OtQOM+lfybOsq57fnb+379gsEjA5bE8AQIgjc/yr6kfnz/mEJLBSTHfkgpx7qGfIR7wrAAmH6DfIe7ArrH+3q8vb3QPhX8rLoDd/c2QjbTeHG6eHwfPdf/VcBWgT0BNcBi/5W+9D7SQA3BbkLcRGDFVUYnhfzEnwLhQSUAS4DCAcFCZEI5gOe/9P92Pxk/Lz5K/Yk8XDuQO/K8Uv3VP70BDwJKAinArj7afda+Yz/5AaOCzQMNgkxBY8CDADY/PD3JvKi7+XunvAL9bX5wv77AG8BGP8f+2n3OPcB/GMBAgcyC4kMogyiDO4JWAd+A+H+EP5h/5ADfQcfCpkKKgmOBv8D8AEK/nv7W/pt+m77Ff1g/oz/jABoAMoAjAA1/t37sfqA+q38zv49ANEBLAFV/yP+mfuV+EP2F/X29zr9jgHhBMQFFgOJAgkDbQT2Br8GGwdsCNYKow2mD00NLAa8/mz5i/kW/rQCiAauBywGrQYYBRsCYgB6AGEE7wpqEIsNUv3m4UHJV764wpnQq95h573sHfBl9Jj63/0q/wv/kv/2ATIG/w3fGtsqfDZbOe8wOyAzEGkG+gSkCcgN4g4cDTsIqQNdAYX+F/p+9KPr5OTF5Njp2vSlACEHuwiYBBv9bPlC+mb+qwVRC1YPkRLOEm4TsBLcDu4J5gPG/Pb35vTd8qjzifNf9Ef0lPIP71HppeNX39/g0uQ76wfyY/dF/G3/MQA3AFABOQIBBt0KpQ5TER0SbBKVFcUZQx2lHegYpxDJCXUGcwRPBTwE7v/o+qX22fMB8gvw3e0S7NLpferp7SL0pvvjAeEEDAVlA4kChQRoBSgIKwqYCTwJ5gj0CbQMBQ4PDAQIWwBy+Sv2PfaE+SH9+P2I/J357/bF97r4BPnN+J/2+vVe+K38ywEyBtoICgi/Br4FTwUmBqAGRgdHCFMIGwfLBkkFZwRBA+7/m/wt+C70RvPm9EX3gPoT+zD64PlS+Cf4fvn0+gP9Hv/iAIEBewGMAIz/Qf4O/BT8KP3t/g4CqwWuB3gIoAa1A84DowM9BfEHowhtCREJ8Aa4BREE8QIJAz4Bf/4m/ED91v9tBFIHxQZeB9oIww6fE3UPKv+o5YzPt8ZaymLVuuAG6O3r+O+h8wD28fgv+UH5UPsp/osEsxA6Hy0tjTWuMoopdB2aFDUSSBI0EasOmwsGCrQMSQ7rDCYGW/p87vjlJuRz53XtgvKH9vj4yPk2+ub5C/q9+sb8jP/0BD8L/A/LFHYVbhNMEbYNUAr8Bv0CJADt/mX9XfxS+L/y5e6F6/7q2eoJ6pPovedW6BXqde0W75bvEfAS8Sv2yvs4AeIFlAaDB6MImQrDDj0TUxYkGL8ZxRneGY4ZKRdjFLEO8Qf3AnH9gPpt+sL5UvgK9JTtiOkC6Sjq8e448hXzHfVp9638XgI+BpUH5AZzBFgCowMCBzkLNg4FDo4LBAiKA9YAHv9a/n/+W/+2/iH9UPte+Cn5mPoT+0L6Avh69hT3wPis++3+VwGFBIkHZwkRCSgIMwe1CDILBQ5ED1oN2wneBvUFkANTA5QBzv5S/ZL6Ivmt9wf3OPcP+Jn2ePQz8/Dyh/YL+j/8Rv0x+0/6Jfvp+wr+Q/+S/4EBTgQbB70JhwrECgAK5gjGB78G6QWrBbkGAgeoByYGoQLI/vT6cfj897H6XfyW/eX9D/13/SP++v92AqkDxAXbCQ0PYRO5EEwCYexU2O/LPMpyzkfTbNgm31boV/Ii+RP7Y/fc8bruqe9O9VX/yw8cIIgs/jK6Mskv4istKFYijxo7EukPgRSQGxki2iDRGeMPMARi+8bz9Oxq6e7n8OmK78/1Hvoa/FL9ZPxW+/X79/yl/34DXQbsCN0KawwrD+QQSg+NCuUC1/sv+Rr3Bvaj9Ibxx+/l7ifuMu3b6w3oheac5SflT+fM6Sfu9vKz98n65f1VAEgE+gkjDTgPJhA0EasTEhjIG1QcFhsLF+0SdhAFDl8MCwk2BE8AcPzR9/L0OPJ/8OfwI/DM7pHr++g16+DvWfSI99H3yvaP+C79IgMiCAAKpAnVCYcKwwlhCTAJHAgoCDMHJQXsAxwDrgJYApMA3vww+r/3Q/Zi9tX1uPaE+d78ygCmASoANwBXASkE6wcZCpIJ2gg9CuQLHA1fDHkJ0QbaA1UAWf3P+rT4fvnt+Tz6Tfkr9oz1jfZM+Nr5ffgL9Xj0//SH9lP5+fl4+Vr5PfvC/kUCQgSYBEQGogdICcULAwwmC1wKPQp0CiALMQqjCI4GzgMjBPID9wInAkMAW/+fAJoBUgIIAp8AoQJNCIkMAApDAHjvIuFw27Tbyt5d3zngG+U47Wn3DADBA1kDsgHuAEP/L/5P/3gDewoIEBkU5RW4FOgThhMzEKELqwWgARwD0AUECJQGFwQiA08FigidCOsHFwQ3AJMAcAKFBG4FBgX6BI4G4AhqC20Ohw9VDrMLegWM/4r9iPwd/nj+avzz+Yj3b/fW9jD1T/EC7j3skes+7XzuNO/b8Ir0rfce+ub5rfe+9mz0lvQa9yH4zvn7+6j9qwBTA5gEPAS2BHUGWwk0DOsMaQ9WD1APCBAADwUOpwvbCTsITgQq/+763/hr+NT5uPtQ+zf7Jfsm/Ef+bP6j/vj9IPyL+f74r/l2/Lf/VQBMAtcBegBbABIAKf5k/IH7Pfsb/ST/EgAY///+kwDaA5IE3wK9AMf9TP3t/lcBzAJBA5UCKAPPBOcEIAbKBSECCAJ7AeL/JABEAQkD3QEZAUn/Cf25/Iv+If34+CL5ZPjr+Lf6+/tr/ef+pgHHA/ID3QHa/rj7l/mo+Cf4y/cz+DD6ufzh/rEAUgL0BF0GYwYsBh4F7wU9CsgNew9wEPkNTAxaDSsPMxCSDsgI3P/l88rocOQL4l/hXd9p30zlu+p68fH41P4sAT0FVgqqCX0HOwgrCmUM1A1WD/4RhRK9Ey4WfBVxEdMMHAjbBJsCyP5E+zr4Xff0+mX9sP5bAHoAbgBJ/wT+/fy5/JD9egBqAswCBwb/CH0MvQ7gDQgLzQf1BaQEVAR9AoYAdP8Q/ln9rfxn+oP4Rffs9CHzYvG28MLw5u/476rwpPC38WX0jPXa9Mf0QvVX9/P5pPri+sj5ePnu+hv9R/6L/hD+jvx//uMBtgRCBEcDqgS+BeQGKAjPCTEKLAtrDKUK8AYGBXkErwOKA/gDJQUlBY0Fuge7CJUHfAbpBTAEwAK3AEP/T/+G/zgB7gCAAIwAPgEfAZ7/C/+n/D/8If2Q/WD+YP7C/jEAYwHdAV4CsQBb//r/9P89AD0AJADdAawBiAHqAW4AsQDiAB4Af/6//NX6hvpW+2j7gfvK+8r7v/z4/Sj9QP3y/Rj/HgCr/9P9P/x7+xP76Prz+Q/4jvfx+Oj69/xX/Fb74/sP/c//gwL3ApsC/QJYAjgBygCTAJYD0Qa1CMoKUQsbDBAN2AsgBjT9//SW71vsmOe05XzpRO2a8rT4p/zJ/ygD1wbhCQAKmAn9C6gMUgxVDrcOCg26DKkNWw7CDboMwQx3DDcKZghLBk0DTQPPBKMDYgAQ/kz9QP3+/c7+Cv7S/Cj9Kv89APUA/QLSAhADDAVRBkkF5gMFBIkCNwAP/SX7c/rO+f/5fvkz+Nj32fgW+ev4g/gt+An4dveJ+Av6zvlh+sT7bvsT+wv6s/eS9UPxZO7N79XwVPAM8WH1YfqS/zQD5gO4BZwH4wrwC+4JfwmeCb4KfAuTCugJsgrECpMKIAv/CNYF6QXEBecE/wMbAogBDgIcA6MDHAO0Av0CeAOpA3IDKANfA00DQQPBA5IE6QV8BnwGpASsAVX/v/xW++b5IfiH9or0LfM/8/byevHn8BLxBvHE8VfyAvPa9ND2Wvk3+4j8Tv6l/0//sP6K/cb8S/ym+6z7svt3/R3+bgAQA9UE1wb7BZMFPgb6BE4E7AMUAj8ClAGGABIAmQCPAjAEVwaXCPIMSxAbER0SaAohAmD+HPki9Dnu1+1H7z3xhPRr+Az7Jfs4AZMFgAUeBeEEMgbKBQIHcwmeCfMI4QlmDaIM9gudDSMNVQ7oDgcPkg60DDoMCQx/CZMFfwS1A+gABgA1/p/7sfqG+pn7bfpN+WH6jfvk/Gb+VP5F/Nf7Pfvb+pj6ePmA+uP7Dvwb/R3+5Pz9/Cj9rPtB+Zr3hfWh82/yVfHw8jjyjvLA8+TySvK58qn0+/Yv+UL69Pqb/Pj9kv+d/lb7gvyj/rcAGQF2ArMG+wqGDoYOKw+xDjgP9xB6DjkLlwj8Bo8HOQeNBXkE0gI/ApADQgT3AqABJgEtAmUD4wFpAfYBjwIjBH4DewEBAbEA4v+M/9P9gvxZ/a79PP+lAGIAjgGVAtgCtAITAdr+rv3k/Pv7dftT+VL4wPgL+nP6hvqm+wH8R/4Y/08AbwHc/0MAq//N/ff8ZPwy/Gr8/fyI/Pf8A/2O/BX9GvzD+p76SvvM/Eb99ftQ+4b6jPpb+rf62/pE+yP+SQA/AuUCEwEV/eb5QPh29/3zyPCC8hH1U/nE+yH9Hv/jAbYE0AV0BTcF5giyChQLCg34DEULggvwC/IM/w1PDoEP8hEhFakWcxd4FkEWBRfSFcMT+BF7DxgOIQwwCX4IgAXOAy4DEwFn/5b9Afzu+mL7gPr5+WT4GPbc9kX3n/YG9nn1zvTa9Bz0P/Mb86jzlfN383Dz9fGm8svy5PL28lXxBvHK8Qfy6vLf89nzePQ39vH46Pos/Hf9C/+MAN0BEAM2BE4EFwTyA1oETwVJBSID1gCuAuwD2wT/AxEE0QYYBRIFMQWQA4sEXAUXBOYDQgRUBLgFHgXbBDcFIwRlAwAFYgUrBbwEeQSrBfQE/wNyA64CywGnAvECXQGZAKsAsQDiAD0A7f5m/uz9tP2D/Xb8bvsT++35x/iP+K33dPZu9p/2p/dk+KL4HvpC+qP5kfnA+Dv52vnC+ar6hvo//Jf+hv/u/9wAJgEZAQcB+f5y/t/92v7u/57/hv/o/5kAvQAiA4QDowMSBdEGhgnVCdkH5wRBA8sBnwD0+ij0zvT09bL2Afef9n/1iPez/CQAsQB0//ECDweGCbIKIw3gDSsPLBS/FCQTDxGQEfkS/xLVEkgSqBE0EbwSYBKIEGEOtAxFC38JlQfhBHgDoAE/AnUBKv8p/lH8Rfwm/M/6Kflx+K33Ifg1+V74k/YM9h/2SfZ59Rz02fP28g7zUfIe8ZDv6+7e7pTtFO6H7WPt8e7r7mruA++V7pDvpPAS8dnzjPUh+Fz7L/4AAJ8AJwJZA3ACjgFwAhgFugdcCokMKg6tEOkP/A/WDrwNZQxdC0ULnQiwCSsK4Qm9CXIItAfFBkkF9QVLBhoG5Ab8BrQHZAdMB40FBgW1A1ICOQJh///+BP7M/EX84/sl+3n6kvrV+gj8gvy//DL8+/um+w78APuX+XL52fip+ZL6APvX+0v8rfzH/Yb/DADi/yQA1P5t/3/+kP3B/ZP7N/sT+x/7w/ow+sL5C/ro+uL6CPy//F/90/0E/i/+jP+lAE8AAQEIAqUAZv6C/Bf6PPrU+fD32fiR+eD5+vpt+mH6Jftw/AT+Z/+x/xsCtgQyBowJGQqlCjILmQqIC/YLDwyLDXMOUA8DEd4QKBGWEVQSbBIoEd4QURCbEPUPkw9iD5ENOgyNCn4IOQcYBTQD6gFPADEA9P8d/hr83ft1+7H6jPrx+GP3MvfV9dv12vSb8530IvSW9GX0HPSJ8/zy8PKO8sXyvvH58CTxjfG38cvyXvOb8xH1N/Y491f3Yvbc9s348/kh/bf/6ADBA0kFOQdkB0YHugf8Bi8IjwcCB8AH6weXCEcI5ggqCUcInAcnB+QGjQWABVQE2gNtBBADpwKhAqEC3wJNA4MCUgJXAWIAnwBh/zz/kf4p/rb+5/7H/SH9cf37+8T71fr++Ez4WPgP+Ez4hPkK+a/5PPrO+U/6+fk7+YT5Ivk6+Eb4Xvhs+Tf7P/xk/C79YP42/3T/GP8k/2f/yf+9/4AAlAF1AScCagKhAnkEEQROBIcFdAWxBRgFDAUYBR0EFgOuAjMCXgLOA1kDWQPaA4QD2gNyA2UDRwPxAj8CUgKDAmkBagKEA5wDwQPgA2EE7AOFBMkEDAVuBSsFaQYmBogGvwYtB0EIEAhsCOYI1AiVB5wHQAd0BQwFTgQcA34D/QI/AicCxAABAasApf9a/kb9ov1f/Wv9v/zw/GT8UPtK+3P6d/g6+Pb3pfat99b2UPbW9m72Aff89xT3Q/Y99jD12/WY9QX1sPVC9Rf1sPVr+Mj5Qvpo++r8Zv62/qv/DABuACcCQQMhAl4CTAJYAigDrgJFAsUBlAGsARwDtgRoBeQGGwd9B+wIHAiDBw0G2wTnBGcE1AOpAxcEqgRJBbwEYQRfA98CZALcAHQA7v+A/5L/Yf+p/iP+Lv1q/Gr87/ti+/P5Efp5+ir6GfsM+5n70Pti+5n7JvxF/Aj86fsr+3v7rPtW+1D7Jfsm/PL92v6M/4AAoAFkAsACxwPHA2cEfwQdBOYD0gKcA9gCgwK6AhQCdQF6AIAAjABKAUQB4gC/AcUB6gHlAi0CxgIoA30CPwJdAcoASQAYAHr/jP/h/pf+PP+x/wAAqwAZARMBfQKJAoMC9gFEAaYBbwFKAQICagINAaEC6wJSAngDgwJZAyMEHAObAngDcgNlA68DAwN+A3YCxQE/AsUBrAGaAcsBSgEZAZkAkv+Y/zz/Ev8w/2z+ff01/oP91/s//CX7E/uH+xP7n/sF+sj59Pqm+zf7Jft2/B/7h/u5/GX9Wv4K/pH+Sf9H/gr+dP9V/x7/vf9bAD0A1gBEAb8B5QLGApYDqQNNA7sDTgQLBKkD7AMJA/8DHQTyAxEEwALYAn0C1wG5AW8BhgBuABkB4gBV/4D/tv60/VT+cPwU/L77Yvus+4f7pvvj+yb8rPsA+wb7nvru+tX6mPp1+7H66fv1+wH86vw5/Ff8Ff1r/Vn9Tv5m/gv/9P90AOIAoAHwAaABFgN2ApoBOQIbAhsC6wLxAl4C3wK0AgkD9wJwAlgCMwJSAv0C0gLqAWQCjgEHAaABBwFKAeIA9P8xALf/q/88/zz/wv7a/lX/hf5h/0n/2v56/2gAdADKAAEBygD8AbIBRAEhAuMBEwFKAT4BewEOAmoCUwOpA+YDcwTJBIUEHQTgA2sD1APmAykEiwTyAzwEfgNlAxwDOQLjAVcBewGGAD4B+wBh/7f/PP9//kH+X/1X/Jv8vvus+z/8Bvu9+oz6qvqB+437rPvK+6T6kvpi+9D76PrP+sr7bvsa/NL8Ff2K/QT+Hf68/sP/z/8AAPT/9P+OAWMBmgEtAnoALAFEARkBYwEBAQcBMgE+AdAA0QHdAZQBUAGUASYBnwDiAEMABwHW/4b/+v/a/uj/KgBJ/3r/q/9b/+L/t//a/kn/Hv8F/5L/Hv8w/wwAAAAYAKUAjP+3/wwAw/9oALEAHwFVAAAA7v8MADEAq/+9ANwAPQCTAE8AgABjASYBYwECAtwAAQFKAaUAXQGsAbIBiAEBAXoAPQCfAIwAGQEsAYwA9QBQAW8BaQEyAaABAgKOAY4BaQEyAWIA4v8AANb/9P8q/4z/9P+G/+7/4v+r/1v/bP41/jD/hf7I/s//mP9VALcAbf/6/+gAkv83AOL/Q/+A/1X/1v+l/0n/nv9DABgAev90/yT/sP4L/1X/PP90/6v/7f5J/9T+T/+A//L9Nv/O/gv/sf/n/pL/BgD0/zEAPQAk/yr/1v/P/4D/3P+x/4b/VQBPACQAvf8eAFUADABt/yQAbgBJADIBkwClAKwBGQHuAFABaACZAFUA1v9DAIwApf9PAPUASQCAAAAAWwDD/4b/gP+9/x4A9P8NAR4AQ/+Y/2f/Bf8L/2H/zv5h/wYAkwC9AE//Z//c/73/6P/W/yT/BgAAAL3/+v/5/rf/Vf8L/zz/Yf9h/2f/mP/t/jz/Wv5B/tT+//4k/zb/AACY//T/+v8Y/4b/vf/i/5MAVQDEAAcBMgE4AQ0B1wH8ASECIQKPAuMBTAKbAo4BCAIzAnUBYwH2AdcB0QFQAZkAAQFQAYwAdADc/8//PQC3/0kAEgAxAL3/mP9h/7D+1P7f/XL+bP5H/i/+wf0W/lT+Cv7G/GX9QP1k/HH9Ov1f/Zf+Fv6p/gX/Bf8GAIb/gP/i/1v/kv+lAJMAKgBPALEApQAyAYEBywH8AZQBTAKVAqEC3wLlAhQCugLSAl4CCQNSAswCNAMCAtEBpwKPAi0CzAL2AZQBxQHuAEoBdADW/4AAvf9t/3r/o/6p/uf++f6M/0P/bP4j/rb+eP6F/vP+ov1y/vP+L/5y/jv+8v1B/mD+lv3I/sj+VP75/pH+wv5//pb95f2x/8//Vf+S/0n/W//0/zD/T/9J/9r+7v+G/1v/sf82/3/+Hv+Y/4b/Z//I/mb+Vf8Y///+t//n/u7/vf9V/7H/Z/8e/2H/1v8eAJkAT//D/9AAEwFpAVcBsgGsASECUgIUAjMC2AL9AuUCPwLAAqEC8AHfAtcBFALGAhsC3QEzArkBSgH8ATIBjgE5AhkBGQHQAMQAgQG3AKUAegCMAIwAEgBh/xL/Hv9H/sj+7f6w/iP+Nf4Q/pb9zf1A/X392f0p/kH+nf6R/lT+4f7C/tr+eP7C/m3/4f6A/xIA7v/W/7H/vf9JAAYAkv9JAPr/YgCZAEkAWwBuAFUAt/9iADcANwCZAJkAUAENAfr/1v+GAEMAbgDW/1X/9P9J/4D/WwBJ//n+pf/h/v/+Bf8L/xgA4v/z/nT/Hv+L/lv/vP7h/pj/yP68/hL/l/7t/sL+bP5V/8//Vf/P/2IAGAABARMBMgGUAW8BxQHqAW8BbwEUAr0ABwGyAYwApQDKAGgA4gD7ABgAUAGZAOL/AQFDAAYAMQBDAD0AJAD0/4z/sf9b/+3+bf///ir/GAB6//T/pf9y/gAAMQBb/x7/Vf+G/wYAKgDP/70AnwCGAEQBnwC3AD4BOAHRARkBsQBiAIAAtwBEAcUBEwGmAZQBywFYApoBSgECAssBoAG/AYAA4gCAAID/MQD6/+L/EgDJ/xj/EgAeACoAKgAq/3QA1v/n/iT/i/5//jD/cv5a/h3+rv0d/gT+NP2Q/eX9A/0d/gr+Tv54/mX9Uv1Z/fD8NP3k/OT8Kf4Q/i/+4f62/qP++v/u/+j/egAxAHQAxAClALcAMQBt/xIAWwClAG8BCAJSAo8CjwICAnACagLwAVICAgJvATMCOQJXAawBVwFpAfABpQBbANwAhgCxAE8AJACrAJ8ATwAYAGgAaACZAGIATwBPAD0AEgDD/+j/bf9J/4v+W/8GAAAAAAB6/wAAw/96AEMAw/9PANz/4v8xAG4AgACAAPr/yf8MACr/sP7h/tr+sf/u//P+vP5y/vL9Nf4K/v798v3Z/Tv+YP7O/pH+bf8w/9r+1v+e/x4AVQAkAEMAYgDJ/yoAHgASAD4BTwB6AHsBTwBVAG8BRAGmAQICPwJqAvYBrAHqAbIB+wBjARMBbwH2AYwA3ABpAe4A9QCMAKUAqwAmAR8BKgB6AGIAvQBoAKv/yf+x/+f+Tv7//k7+bP6L/sj+JP9y/hL/Sf/a/k7+GP+2/gT+tv6d/k7+zv7a/uH+Ev9s/s7+sP42/zcAQwAxAA0BGQHEAAcB4gC9AGMBjgHwAScCGQHXAdAAygAtArkBjgHXAYgBPgHwAQcBYwGgAaUAdAC3/8n/nv/o/wwAQwDD/yT/bf9//sL+Yf+p/mb+MP82//n+Nv81/sH9kf7f/ZD9/v3N/Wz+Tv7f/Tb/8/5g/hj/cv7U/ir/Bf96/7f/PP9J/zb/Tv4Y/zz/dP/c/7f/kv8L/xL/MP96APT/hv+3AGgAEwGOAfsAbwHFAQEB9QBKAWgA1gAsAZMAJgG9AG4AygCAAHoA+wCZAD4BywG5AYgBJgGOAfUAjgHFAdEBjgEZAUoBnwBoANAA+wBDAOgADABt/5kAJAC3/9z/W/88/xgANv9t/9z/t/9DABIAEgBJACQAAACZAJMAjADWABgAEgA9ANb/SQAAAEMAkwCx/0P/Q/+G/+3+sf/J/xL/q//D/yQAKgAGALH/z/82/9T+vf96/4b/dP8k/6X/nv9V/8//bf82/2H/PP/0/1UAq/+M/xIAHgC9/+j/Vf/U/h7/+f5b/2f/dP+S/zEAW/+M/zEAGP8xABgADAAHAaUAWwB0AFUAnwDoAMP/JAAGAKX/4v+Y/+7/+v8GAAwA+v+A/0P/GP88/yr/1v+x/0n/6P+A/0n/sf9P/x7/t/8w/3T/jP9P/57/9P/D/4YAVQCx/2gAhv8qAGgAQwCGAG4AYgB0AEMAVQClAE8ABwGTAIYAdAAkAB4A0AAmAb0A1gATAbkBoAHRAaYBJgHXAY4B6ACaAQEBpgGIAUQBIQIsAZkAVQBoACQAGAB0AAAAAADi/3r/yf/0/3r/Nv+A/7D+MP9t/xL/pf8e/0P/Hv+d/pf+C/+R/tT+ev8w/+L/z/9D//P+//4q/6v/kv9t/6X/8/6d/gv/Kv+j/vP+1P7I/rH/w/+3/2f/nv+r/5j/Sf9D/x4At//J/1v/5/5J//n+Yf88/9T+t/8YAM//7v/iAMoAhgDiAD0AQwDKAJkAegDQAOgAHwHFAdcBHwEIApoBgQEbAkQBsgHqAeUC0gI/AggCFALRASwBywEsAV0BVwGxAKUATwBVAD0AkwC3AJMANwCY//T/jABJ/yr/GABt/8P/MP9m/rz+1P4S/23/wv54/uH+BP4v/ov+Wv7h/mz+0/1a/kH+qP3f/SP+BP75/tT+Wv4k///+Z/96/57/GABbAEMAvf89AMn/bgBVANb/SgEHAb0AnwCAAJkA9QB0ACQAvQBVACQAHgDc/0MA+v9t/0MAw//P/08AdP/W/zcAw/9h/0n/dP+9/3oAsf90/7H/Yf8YAAAAz/8AAHQAKgD6/6X/PP89APT/hv+xAIwAhgC3AAYAWwBuAL0AxABbAHQAegAqADcAPQDc/zEAbgA9AJMAegA9AE8AJAAMACoA1gDoAIAA6AB0AIYAmQAGAGIAaAA3AEkADADW/z0AVQAqAFsAhgAqAPUAqwCAAHUBegDWANYAhgC3AHoAmQDcACYB7gCAAJ8AbgBPAKUAAADW/z0AMQCr/7H/5/6M/0n/nf6r/8L+Z/96/4D/6P/o/+j/Sf+M/6X/4v+r/8L+1P6M/23/bf+Y/wv/q/9P/yr/4v/t/uf+T/9P/3T/6P+3/4D/hv+8/qP+8/5B/vn+Vf+2/m3/l/4v/hL/sP4S/1X/o/5h/8n/hv+A/7H/Yf+Y/xIA6P+fADEAHgCrAMoAgADcACwB+wB1AUQBHwFvAXUB7gBpAWkBEwE4ARkBaQEyAbEAVwENAYYA3ADWAMoAgAAkANYA4gDW/1UAjABPADcAVQA9AB4AWwCx/zcAegAGADEAHgBiAKsAVQBDALcAnwCfACoAw/+TAJMA6P/J/9b/q//6/8//hv+S/0n/yf/0/+j/mP+Y/4z/kv8AANb/yf8e/wX/+f6F/nL+Tv75/qn+wv4S/0H+//6F/pH+Vf/z/jD/Vf+r/yoAHgCM/8//dADu/wAAsQCl/7f/DADD/wwAmP9DAPsAgABVAB4AYgBDAEkAsQBV/yQADACx/wwASf/J/9z/4v8AAHQAhv/i/7EAJACAAIwANwDJ/7f/dP+Y/x7/Q//0/zD/PP8GAOj/nv9oAMn/AAB6ALH/NwCZAKX/DABiAHT/gAAkAEMA4gBiACoAEgAkAE8AAQENASwBbwFvAcUBuQEsAdcBMgGrAB8BdQGBAfsAvwEmAcsBxQGMAPUANwAxAD4B4gC9ACwBpQBVAHQApQAkACQA9P/u/zcAhv/6/1X/yP7o/2f/Yf9h/7D+GP8Y/53+VP7I/n/+nf4S/53+nf5m/lT+VP4S/zz/sf8GAHT/6P9J/0P/4v+A/57/aAAMAE//hv/W/4b/1v/J/0n/z/90/4D/q/+A/1X/jP9n/7f/kv8F/7f/Sf8S/6X/Nv8e/0n/Ev/c/6v/MP+G//r/yf/J/+j/mP8MAMn/4v+rAIwAMQBuAGgAWwDcAGgAMQCTAMQA1gDcANwAVwGUAbcAJgFpAbEA9QD1AG4A3ACAAJkAdQGrAOgAJgGfAB8BMgHEAAcBJgGGAIYApQDWAD4BDQHKAG4AegCrAG4AHgDJ/6X/q/+x/6v/Sf9b/wYAhv9h/4D/qf7h/mH/C/8q/0n/hf7t/jb/C/+Y/1X/7f4w/xj/Nv9n/xL/nv/6/1v/dP/0/70A7gDcAL0AkwBVAIYA7gB6AMoAJgGIAdAAkwB0AO7/dAD6/58AVQC9/zEAPP/t/hj/Q/9b/0P/o/5y/qP+f/4S//n+GP/t/vn+w/+Y/6X/nv/i/8n/+v/P/yoAMQCM/3QABgDu/5MAnwAxAJMAdABbAOgAKgD7APsA7gA4AXQAbgBiALEAqwAHAbcAEgAkANz/T/+S//T/q//u/9b/jP/u/7H/gP8eAL3/HgBuAOj/mQClAAYAGABbACQA9P8qAFsAbgAxAAYAhgA3AO7/VQASAEMASQAGAEMAMQDJ/wAAEgC9/yoAHgDJ/wYAmP8q/7H/6P/D/wwAmP9J/8P/mP/o/yQA3P+9/zb/T//W/6v/w/8YANz/mP+A/yr/GP9h/1X/bf/D/3r/T/+S/wX/GP9t/+f+MP90/3T/dP/z/u3+Z/+Y/3r/t/9b/23/TwAMAOL/PQAYAGIAmQCMAMQApQCrACYBHwG3AEoBUAFEAawBSgF7AcUBBwEmAZQB9QBvAV0B+wCyAWkB6AANAeIApQDQAFsAegDcAG4AWwBiAOL/3P9uAAYA6P8xANz/DADc/6v/QwAAAKv/yf+r/8//EgDc/7H/QwAxAMn/DADD/8P/BgCx/9z/7v+S/4D/bf8Y/2H/kv8S/0//Sf8q/4D/JP/5/jD/Q/8k/xj/7f7U/mf/Nv8w/7H/PP///ir/7f7n/mf/Z/+9/z0AMQAqAM//gP+e/2H/Vf/0/+L/+v90ALH/GABbAJj/w//u/73/yf83AAAAMQBVAB4ApQClACQAsQDKALcAGQEfAb0AhgBoAB4AnwCGAOIAAQFiAJkAVQDW/9b/gP9t/wYAyf90/4z/W/9J/57/Z/9V//r/Q/9h/9z/Vf/c/wAAjP9iAIYABgCxAHoAw/8AAOj/mP8kABIAKgCGAPT/1v89AAwAyf89ABgA9P9bAG4AygD1ADcAtwAmAZkAXQHcALcASgHWAAcBMgGZAKUAHwFoAG4AMQCS/2IAYgD6/2IAHgAAADcAt/8SADcAnv+M/+7/HgAGAAAAJP+Y/9z/kv9iABgAz/9DAMP/w/8qADD/dP8kAEn/gP90/8L+hv///mz+o/6j/sL+hf42/0n/Ev+A/x7/GP9D/xL/gP90//P+W/+Y/0//gP9h/wv/AAC9/zD/TwAAAPT/7gCTAPsARAFbANwA7gAAAHQAgAAYAMQAsQA9AOIAtwCZAOIATwBuABMBxACfANYAKgCZAJ8AbgDKAFUApQBPAPr/+v8AAAYAev8AAAYA7v8AANb/4v90/+7/TwBoADcA6P96AEMATwBJAM//MQAqAD0AegDEAB4AEgBiAD0A+wAGABgA3P9J/23/dP+l/x7/vf9D/xj/Vf96/6v/sf9b/zD/bf8L/9b/Vf8k/0//T//J/5j/Vf9J/0P/5/5n/+L/DACr/8//KgA3AAwAz/8eAJj/z/83ABIA7v8xAJ8Az/8YACQAw/89AGIAegB0AEMAKgCfAHQAaABiAPr/QwCAAJkAqwA+ASwB0AATATEAkwDcADEAHwFPAGgAAQEMAAYAmQCAAID/w//0/6X/MQCS/zb/4v8k/+7/7v+M/+j/w//J/7f/MQCe/wwAkv9J/+L/mP/P/8P/z//P/xIAq/8YAHQAt//6/4wAqwBJAMoAegAeAFsAhgDEAGIATwBVACQAHgCfAIwAxACGABgADAAMAMn/sf/u/8n/AAAGAOL/VQAqALH/hgAqAMn/3P/o/9b/9P8xAJL/AACS/4b/3P+l/xIA9P8AANb/BgDo/x4A6P+Y/0kAt//c/xgAz/+9/yoAsf8e/57/Q/9h/1X/MP9h/0P/hv/P/7f/Z/+e/0P/1P6G/0//GP9J/4z/bf+M/0n/Ev/o/0n/w/8qAEP/AAASANz/MQAAAAwAPQBPAJj/EgAkAG3/SQDo/+7/hgAeAE8ANwC3/zcAJABiAIYAJABDAJMAvQAxANAAGACS/2IA+v9DAHoAvQCrAMoAxACfAB8BBwETATgB+wBpATIB9QB7AegASgH7APUAOAEHAbkBMgEZAb0AegCTAJ8AkwCMALEAkwCTAKsA3P+A/0P/GP+M/7b+JP8k/8j+4f7t/vP+i/7U/kH+tv5//nj+Ev/h/rD+sP4w/4X+Bf/t/gX/kv8k/3T/4v9t/1v/VQCl/xIAbgC3/+7/BgCY/xgA9P8e/zEAZ/8e/z0AdP+3/5kA7v8MAAAApf/6/wYAz/9uAGgAw/+lAKUAegCfAPsAdAAeAFUAAAC3ACQATwDQALf/3P9JAD0AAADi/wYABgAqAPT/3P/i/8//3P+S/+7/TwB0AIwAnwBiAFUAkwDcAEMAkwDKACQAUAEmAeIAPgGZALEA4gBDAIYAjAAGAL0AygBVAG4Ayf/c/24A9P82/9b/HgCl/5L/nv8e/wv/sf88/7H/Q/8w/xIAKv8Y/xIAbf8k/73/mP96/73/sf+G/8P/q/8kALH/q/9JAMn/w//i/+L/DADEAKUAnwBJAIwA0AAeAPT/egDcAIb/DAB6AOL/3P/P/7H/z/+Y/1X/KgBh/2H/sf8Y/0//GP8e//r/t/8F/6X/Q//n/ob/Yf/D/7f/PP+3/6X/mP/J/wAAt/+x/73/mP/6/9b/7v/o/wAAPQCAAFUAEgCTAGIA9QB6AD0ABwE3AJkADQGZAG8BFAJ7AcUBlAETAawBVwEfAY4BsgF1AfYBmgHWABMB0ADEAIwAYgA9AG4A1gB0ANAAaADu/2IAPQAMAMP/kv9V/yr/Hv+r/wX/1P7W/1v/C//P/4z/4f5V/+3+4f7h/n/+nf6L/in+f/5U/k7+sP7I/n/+eP7//mz+l/62/qP+2v5P/zb/gP/P/4D/+v9n/3T/6P/i/9z/PQBVACoATwA9ALEAgABVAL0A4gBuAIwAxABoAIwAQwAkAD0ABgD0/24A6P9PAHQABgDoAGIAMQCxAFsAmP9VAMoADABiAIwAMQDEABgAWwAZAb3/VQAkAAYAPQAxAFUAPQCfABIAgABoAHQAqwD7AFUAtwBpASQAtwCfAPr/MQAqAOL/VQAYAB4AbgC9/xgASQCe/9z/JADi/2IASQD6/58AdAASADEAw/9JAGIA9P8kAPr/TwBJAEMA3P+x/+j/nv/P/4D/JP89AD0Aw/9DAAwA9P/D/3T/hv/u/2f/Sf/i/7H/q//P/+H+MP90/9T+Q/82/xL/sP7z/gX/Kv/t/qP++f68/s7+wv5D/3T/W/96/5j/1v9n/z0AkwD6/2IAgADi/xgAYgBuAKUAVQCMAEkAnwCZALcAkwCGAMoAPQCTACoA4v9bAFUA+v8GADcA9P+M/73/dP8kAD0A6P/oALEAWwAeAAYANwC3ACQAEgBVABgA4gBDAD0AmQBoAGgA7v/P/8n/z/+9/1UAdAA3AHoAbgA9AJ8AVQB6ANYAVQDiAIAAHwFEAbEADQEmAUoBxADQAB8B9QDKAMQAkwBJAG4AdADc/8n/W/8YAE8Aev/i/3T/ev8F///+Z////pH+l/6M/7D+Kf75/n/++f4e/4X+8/62/rD+qf7h/kn/sf8kAL3/nv89AMn/MQAMAJj/MQDD/yoABgDJ/6v/EgDi/+L/vQBJAGIADADi/wAAz/9t/7H/w/8w/+7/Vf/5/nT/8/54/iT/GP/n/p7/JP+3/+7/t/83AFsAkwCTAAwAKgBuADEAAAB6AEMAWwAfAcoA7gCrAPUA9QBXAYEBUAF7AQEBVwETAdwADQHXAY4BgQFXAb0AXQFPAGgASgHcAMoALAGrAG4AvQA9AEkAGADu/0MA7v+3/x4Ayf90/8//Sf9P/5L/5/4S//n+Hv9D//P+tv7O/uH+VP42/wX/i/7a/mD+2v4w/8L+7f6S/yr/t/83AGH/z/+S/8//JADc/8n/EgC3ACoAgACGAIAA6ADQAA0BaQEZAb0AdQHuAKsA1gCfABMBBwGMAGIAdADu/2gAegCS/zcAGACe//r/+v+e/9b/+v/D/wwAjP9b/5L/q/9P/1X/BgC3/7f/bgBoAO7/bgAkANz/6P/o//T/1v/u/5L/PP/0//r/hv/W/4z/Nv9P/1v/GP88//n+MP/5/p3+Kv+Y/+j/Yf+r/2H/T/+A/7H/MQDW/8P/QwCfAAwA6P+A/6v/BgBn/yoAdAB6AMQAtwCTAJMAxAANAW8BVwENASYBdQETAYEBMgFKAXsBEwGaAe4AegDuAIAAbgDcAKUAkwBiAHoADABPANz/hv8YADz/q/+x/1v/T//D/3T/Q/8Y/53+hv/C/rz+Yf8L//n+GP94/hb+bP5y/tT+vP6w/uf+5/4L/53+tv7I/hj/mP90/+7/7v/W/xIAHgDu/4wAegDc/6sABgA9ACYBWwDWAA0BNwA4AcoANwA4AfsAtwAfAUoBVQAfAR8BmQAHAT0AVQD7AEkAMQC9AOj/gACxACQAegBoAO7/MQBoANz/QwBJAAAA+v+9/57/3P9h/wYAYgCG/zcApf+3/8QAygCGAKUAsQA3AL0AkwBDAB4A6P83APr/+v90AEkAt//D/xL/Hv88///+Sf9J/2H/GP9t/1X/kv8kALf/AAAMAAYAPQA3AL3/z/8MAHr/9P+x/6X/yf8S/5L/w/8AAAwADAC9AHQAqwDoAIAAgABJAJMAYgBDAEkAw/+x/3T/DAB0ALH/3P9b/x7/+v+l/+L/Yf9P//T/mP+9/8n/gP9J/6v/sf8k/9z/yf9n/9z/7v8MABgAQwA9ADEAWwDD/x4ADABt/5MABgDJ/0kA4v9DACoA7v8eAGgAJAASADEApf90/73/1v8eALf/3P9bABgA3P8qAFsAKgDEAAwAaADoAL0AEwG3AAEBEwHiAJkASgGlAB4A+wBVAIAAmQAMACoApQBoAOL/TwBVAJj/PQBJANz/AAAq/3r/7v9P/57/hv+G/6v/ev9n/0P/dP/5/jz/7f4e/+L/2v5b/73/nv8YACoAw//6/1sAMQB6AAYAAAB0AKsApf8SAIwAPP/i/+j/3P83AAAAt/+x/4D/q/8AAL3/QwBDACQAsQBiAGIAygAqAM//+v+3/2H/bf8k/x7/hv8w/0//gP8L/xL/dP8k/5L/1v+M/z0A4v+l/8n/VQASABIANwDu/z0AjP90AHQAHgCMAIwAkwC3AMoAWwDoAL0ASQAHAaUAaADuADcAdAB0AAYAkwAYALf/BgDD//T/DAAMABIA4v+GAPr/HgAYAGH/dADi/2f/JACx/6X/NwD6/8//3P8AAMn/PQAeABgAgADo/58AjABPAL0AAAAkAIYADAASADEAEgC9/xgAgP+x/zEAW/8SACoAGAD0/xgA4v9DALEAAAB6AAwAPQB6AJj/6P8xAAYAKgDP/xIAMQC3/6v/t//0/+j/KgD0/5L/+v+S/5L/mP8w/2H/pf9t/yT/nv9D/0n/W/8e/8P/vf9J/5L/AAC3/5j/z/9h/6v/GADi//r/Yf+e/9b/t/+r/8P/DAC9/z0ASQAqAE8AnwDWAHoAjACfAL0AxACAAL0AhgAxANYATwA3ADEA1v9iADcAgABJAEMAVQBJALcAJAAeANz/nv89ANb/7v8kAD0AHgAAAOL/sf9uAPT/KgBbAL3/6P/0/0kAbgCG/9b/egAMACoA9P+3//r/TwD0/wwAVQD6/wAAbgAeAPT/YgB6/+j/6P+M/+L/t/8SAAwAmP+G/9z/mP+Y/9z/7v/u/yQA3P8qAOj/ev8YACr/t//D/6X/hv9J/8P/Q/8SAM//3P9PAKX/1v/o/2f/BgDi/5j/4v90/1sAdAAxADEANwClAGIAkwCGAIYADQFoAO4ALAG9AEQBGQHcAIwAqwCMAD4B4gAeAIYAq//D/+j/t//i/4D/4v+3/yT/ev/5/ob/pf8w/zD/kf5t/zz/sP4q//P+2v5t/0//Bf8w/zD/dP8Y/yT/mP+Y/57/EgBVAB4AbgDcAKUAqwCZAEkAxACZAJ8A0ABiAB4ADABoABgAvQDuAIYA9QA3ADEAsQBuANAAAQFoAJ8ApQBPAL0AjAB6ACYBnwBPAHQA1v/c/xgAq/8eAAwAJABPAJL/mP90/4z/Vf+M/3T/Sf+r/1X/Bf+R/qn+i/4F/7z+kf69/wv/l/75/sj+hf4q/x7/Sf+e/+H+Ev9b/4z/4v+x/7H/7v/0//T/DADP/6v/TwAqAAAATwB0AJMA0AABAegA9QDQAF0BuQEfASYBEwHcACwBGQG9AHUBJgHiAF0BPgFvAQEB+wAZAbcANwBVAGIABgB0AIAAWwAkAOj/+v/J/zEAjP+e/2gAMQBoAFsAdACAAFsA7v8xAAAADAAAAGH/1v+S/5L/w/+Y/4b/4v/c/1v/t/9h/0//jP+x/3r/C/+M/yT///48//P+C/8q/9r+4f7h/hj/Yf8Y/3T/pf8q/zb/Vf8w/8n/yf82/2f/nv+3/9z/kv+9/xgAnv+Y/8n/4v/6/9z/q/8xAG4AVQClAJMAWwBbAIAAWwCrAL3/WwCxAO7/3ACGADcAhgDWAG4A1gDEAHQAkwBbAE8AegCZAKv/WwAAAD0AdAC9/1sAQwA9AMQA3AASAIYAAQH1ANwAygA9ALEAnwCr/zcAEgDD//T/3P+r/yQAAAD6/73/w/9PAMn/z/8qAOj/BgBPAOj/sf8kALf/gP90AEMAYgBoAOj/mQBDALf/HgDu/73/pf+l/5L/Q/9J/yr/kv+x/yr/Nv8Y/zz/dP9J/+7/w/8L/+7/DAAAAAAA+v/J/73/6P+M/yQA7v+3/0kA1v+A/08A4v/6//T/pf8MAMn/3P/J/+L/W//W/4z/kv9VAMn/EgCGADcAAADWAFsAQwCTACQAnwCZAEMASQB6ACQATwBoAG4AbgDP/1UASQAGAFUAWwAYAE8AVQD6/yQANwDu/wAAmQCMAKsAVQAYAFsAYgD6/08AkwDW/1UA4v9h/wAAdP8k/5L/wv5n/0//o/5J//n+MP8k/zz/4f7O/vP+zv5n///+Hv+M/4b/t/+Y/57/+v8MANb/VQCAACQAaADWAOgAHwFQAZkA3ADKAOgADQGZACwBGQE+AR8B0ACTAOgAtwBbAPUAGAB0ANwAMQAeAAwAHgBDAPr/q/8MAG4Az//i/1sAbf9bAJ8AGABuAPr/EgBDAJj/kv8xAKv/t/9n/0n/dP88/87+o/7t/pf+2v6p/rz+7f4L/6n+tv4w//P+bf9P/zz///5h/9z/DAASAOj/VQC3/3oALAFuANwABwGGABkBsQClAGMB3AC3AO4ApQCxAOgAaACZANAAsQBXAUQBgABKASwB7gDcAEkAYgA9AFUA6P9DANb/nv/P/23/ev8S//n+Bf+G//P+Nv+l//P+kv/D/6v/jP+9/1v/Z/+r/zz/3P/u/x4AVQAqACQAMQBoADcAHgD6/1sAxABiAD0AWwA3APT/+v+M/wAA6P9P/z0Asf9D/8P/nv+l/wAAvf/J/xgAYf/u/yQAYf/D/wwA4v/u/yQAVQBVAD0AKgCAAGIAMQCxAG4A6P8GAPr/q//6/5j/q//0/8P/nv9V/xj/+f42/53+dP+A/zb/w/8w/23/gP8q/xL/hv8F/2H/6P88/5j/w/+G/zz/mP/u//r/AABiAKsA3ADoAOgADQENAXUBHwEyATgB1gAHAUQB4gDcAOIAYgD1AJ8AqwAyAW4AmQDEAO7/aAB6AKX/WwD0/8P/NwD6/wwAMQD6/x4AdAAeAIwAHgAkANwAvQBbAA0B0AB0AF0BhgAHAfsAdABuAFUASQDo/+L/w/8eABIAkv/o/73/Yf+Y/2f/mP/u/+L/hv+Y/zD/vf8MAID/7v+A/0//PP9h/0P/ev9J/xL/SQB6/+3+pf9D/1X/bf/5/jD/MP+d/ir/T/+R/rb+4f7h/jz/PP8k/+L/Z/9n/8//+f5n/4D/MP/W/9z/ev/0/6v/1v8qAFX/6P9iADcAhgCZAJkAygB6AMQApQBPAPUAhgCxAJ8AegBJAAAAWwCl/yQA9P9b/yQA+v/P/+j/9P83ABIADADu/2IAKgC3/0MAjP8YAIAAQwCMAFsAegAfAegABgCAABgAKgB0AGIAqwCrAPUA6AAmAQcBBwFKASwBOAGaASYBdAAHAcQAdAD7AKsAMQBuADcAegBiAOL/YgD0/6X/6P+S/4b/sf8q/1X/gP8e/5j/PP8F/6X/Z/8e/0P/C/9P/yT/Q/9D/5j/7v82/wYAMP///oD/MP+r/3T/nv+l/6X/nv9t/0P/Ev9n//r/t//J//r/nv/P/3T/hv+e/+L/PQAMAD0AQwBiAD0AKgA3ACoAKgCMAIYASQBoAAYAJAA3APr/PQCfAHoAHgAAAOj/t//J/+L/EgAqAAwAhgASAO7/JACl/z0AdAAGAGgAjABVAFsANwDJ/8//PQAGAFsASQD0/5MASQB0AIYASQCrANAAjABbANwAtwCrADIBjACrAPUAVQB6AIwAJABoAIwA9P8SADcA9P/u/3r/ev+r/0//Yf+G/x7/Kv9J/6P+i/7z/qP++f50/+H+T/+S/zb/kv8F/1v/BgCl/7f/sf/D/7H/AADi/wwAWwAMADcApf+l/8n/7v/P/yoAKgC3/4YA+v/J/x4Avf8AADcA3P/0/x4Az/83AGIA4v/u/xIApf90//r/4v+Y/9z/W/90/xIA3P/u/z0AEgAqAM//yf9VAOj/TwCGACQAgAB0AG4A1gC3ACoAygB6AE8A+wCfAAcBsQAkAMoAhgD0/9AAqwBVAHoA9P/W/08AEgD6/4YAbgAMAB4AHgBVAMQAtwDuAIwAYgBPAJMAKgCrALEA1v/1AMQAjACfAHQADABbAEMAgP+e/yr/T/9P/5j/z//D/0n/JP90/x7/dP9V/7f/EgAeAJj/mP8AAIz/+v/P/4z/Hv/h/gv/Ev8e/wv/dP96/2H/Sf///qX/AACY/9b/dP/J/xIAsf90/5L/t/+r/0MAmP9t/23/T//6/1UAw/8MAJkA1v96AG4AegAmAcQANwD0/9z/QwBuAHT/7v+ZAAYAhgDi/4b/TwCx/73/qwB0AB4ApQD6/+j/bgAqAEkAdABiACoAbgAeAB4ApQBDAJkANwDi/6sAPQBJAD0AAAAqAPT/+v83AFsAJACMAKUAPQCxAE8A3P+lADEAEgB0ACoAmQCGAIAAnwDcAHoApQDWAOj/dABbANz/GADD/4b/AADu/+7/HgCS/3r/9P+Y/0n/gP/h/jb/W/+R/tr+Bf94/s7+8/54/gv/5/7h/ir/1P5t/4b/PP/P//T/q//W/+j/yf90/xj/C/9b/2H/T//J/5j/bf+9/5L/t/8GAMP/3P8xADEA6P/o/yQA7v/J/7H/GABVAPr/SQAxAOj/EgBPAO4AGQGxAA0BlAEsAegADQHoACYBOAE4AV0BRAFQATIB9QAHATgBMgHoANYA1gDWAMoAnwClABkBpQC3APsATwAHAVUAGACMAB4ADAAGADEA7v8xAPr/Vf/W/4z/PP/P/3T/w//W/0//t/+9/wYAKgAGAAYA+v9JAOj/4v+3/4D/TwB6/4b/3P8S/yT/Sf8L/7z+2v6F/uH+8/75/mH/C/8w/0n/Z/8F/0//hv/z/jb/W/8S/7H/9P+Y/wAAyf/c/zcATwASAFUAMQBPAHQAz/8qAGIAKgBuAE8AEgBVAAYADAAeAEkAJAA3AEkAHgCxAOj/yf/o/73/nv+Y/3T/Z/9VAG3/Yf/P/9b/GACl/8P/3P8GABIAKgAAABgAWwAYAB4AMQA9AJkAmQAqAGIAqwBuAJkAsQDEAPUA4gCxAAEBEwGGAPsAygBbAKUAYgBiAJkAyf/u/08A+v9VAAAA6P+r/4b/Z//J/3r/Sf8eAEn/hv8xALf/pf/0/8P/PQAAAL3/WwA9AAYASQB0AID/GAAAAKv/NwDP/+7/JAAAAMn/+v8MAAYASQDi/6X/NwCr/6X/1v/5/nr/kv9n/23/JP9P/23/Sf9t/7H/Bf+M//T/t//6/0MANwD6/9b/KgBuAFUA6P/0/zcAq/8kAJ7/q/8YAMn/4v+3/73/z//W/z0AHgDc/1UAdACfADEANwBiAAwA+v8eAE8A7v/0/08ADACGAPsAegClAG4AQwClAEMAEgBoAB4AJAAxADEApQBoAMn/NwCfACoA1gBVAD0ApQASAHQASQAYAPT/QwA3AMn/TwCx/6v/6P+Y/wAAnv82/4z/7v+e/73/vf/W//T/t//c/73/SQBbAPr/9P8GADEAPQASAB4AVQDi/+L/BgC3/wAAvf+A/9b/q/9b/5L/jP8e/2H/Kv+M/8P/W/90/2f/nv+x/wAA+v/u/xgA1v8xAIwAmP/i/z0A4v8eAPr/hgAeAO7/1v/u/9z/sf+MACQA+v+MAPr/BgBVADEAegAMAEMAEgAeAMP/Sf90/0//ev9h/0n/JP8w/xj/JP82/zz/Hv9J/5L/vf/J/57/MQAkAKv/QwAqAFUAmQCTANAAkwDEAL0A9QC9AL0AMgEZAVcBAQHiABMBHwEBARkB3AB6AB8B6AABAeIAtwDKAIAAnwBuAKsAhgC3AJ8AQwB0AEkAYgAxAAYADADW/x4Asf+e/6X/Q/9b/zD/bf+A/4z/q/96/2H/bf90/2H/4v/0/zb/pf8AAL3/vf/D//T/DAAkABgADAC3/9b/NwBPAFUAMQAqAEkAWwBJAJ8AgABiAIYAGAD0/z0APQAMACoA4v90/57/gP9n/2H/Vf9V//n+PP+M/73/hv82/5j/1P4L/0n/hf4Y/87+7f4L//P+Q//C/mH/JP9t/4z/JP+Y/0P/Q/9t/57/Vf+9/73/t//i/23/pf+3/8n/pf83ABgA3P9iAJMAbgBoAGIABgBJADcAMQBDAPr/dAD1AIAAOAEBAdYAsgEfATIBRAHcAPUAPgHuAPUAXQHcAD4BVwG3ABMB3ABoAAEBbgCxAB8BjADWAIYAEwENAasAWwBbAG4Anv/i/6v/Yf90/4D/MP8q/zD/1P4Y/7b+tv4w/wv/Bf/D/4b///5V/w==\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_last, *_ = train_set[-1]\n",
    "ipd.Audio(waveform_last.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting the Data\n",
    "-------------------\n",
    "\n",
    "This is a good place to apply transformations to the data. For the\n",
    "waveform, we downsample the audio for faster processing without losing\n",
    "too much of the classification power.\n",
    "\n",
    "We don’t need to apply other transformations here. It is common for some\n",
    "datasets though to have to reduce the number of channels (say from\n",
    "stereo to mono) by either taking the mean along the channel dimension,\n",
    "or simply keeping only one of the channels. Since SpeechCommands uses a\n",
    "single channel for audio, this is not needed here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sample_rate = 8000\n",
    "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
    "transformed = transform(waveform)\n",
    "\n",
    "ipd.Audio(transformed.numpy(), rate=new_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are encoding each word using its index in the list of labels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes --> tensor(33) --> yes\n"
     ]
    }
   ],
   "source": [
    "def label_to_index(word):\n",
    "    # Return the position of the word in labels\n",
    "    return torch.tensor(labels.index(word))\n",
    "\n",
    "\n",
    "def index_to_label(index):\n",
    "    # Return the word corresponding to the index in labels\n",
    "    # This is the inverse of label_to_index\n",
    "    return labels[index]\n",
    "\n",
    "\n",
    "word_start = \"yes\"\n",
    "index = label_to_index(word_start)\n",
    "word_recovered = index_to_label(index)\n",
    "\n",
    "print(word_start, \"-->\", index, \"-->\", word_recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn a list of data point made of audio recordings and utterances\n",
    "into two batched tensors for the model, we implement a collate function\n",
    "which is used by the PyTorch DataLoader that allows us to iterate over a\n",
    "dataset by batches. Please see `the\n",
    "documentation <https://pytorch.org/docs/stable/data.html#working-with-collate-fn>`__\n",
    "for more information about working with a collate function.\n",
    "\n",
    "In the collate function, we also apply the resampling, and the text\n",
    "encoding.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(batch):\n",
    "    # Make all tensor in a batch the same length by padding with zeros\n",
    "    batch = [item.t() for item in batch]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    return batch.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "\n",
    "    # A data tuple has the form:\n",
    "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
    "\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        tensors += [waveform]\n",
    "        targets += [label_to_index(label)]\n",
    "\n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    return tensors, targets\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "if device == \"cuda\":\n",
    "    num_workers = 1\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Network\n",
    "------------------\n",
    "\n",
    "For this tutorial we will use a convolutional neural network to process\n",
    "the raw audio data. Usually more advanced transforms are applied to the\n",
    "audio data, however CNNs can be used to accurately process the raw data.\n",
    "The specific architecture is modeled after the M5 network architecture\n",
    "described in `this paper <https://arxiv.org/pdf/1610.00087.pdf>`__. An\n",
    "important aspect of models processing raw audio data is the receptive\n",
    "field of their first layer’s filters. Our model’s first filter is length\n",
    "80 so when processing audio sampled at 8kHz the receptive field is\n",
    "around 10ms (and at 4kHz, around 20 ms). This size is similar to speech\n",
    "processing applications that often use receptive fields ranging from\n",
    "20ms to 40ms.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M5(\n",
      "  (conv1): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
      ")\n",
      "Number of parameters: 26915\n"
     ]
    }
   ],
   "source": [
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2)\n",
    "\n",
    "\n",
    "model = M5(n_input=transformed.shape[0], n_output=len(labels))\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "n = count_parameters(model)\n",
    "print(\"Number of parameters: %s\" % n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same optimization technique used in the paper, an Adam\n",
    "optimizer with weight decay set to 0.0001. At first, we will train with\n",
    "a learning rate of 0.01, but we will use a ``scheduler`` to decrease it\n",
    "to 0.001 during training after 20 epochs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  # reduce the learning after 20 epochs by a factor of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing the Network\n",
    "--------------------------------\n",
    "\n",
    "Now let’s define a training function that will feed our training data\n",
    "into the model and perform the backward pass and optimization steps. For\n",
    "training, the loss we will use is the negative log-likelihood. The\n",
    "network will then be tested after each epoch to see how the accuracy\n",
    "varies during the training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        data = transform(data)\n",
    "        output = model(data)\n",
    "\n",
    "        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "        loss = F.nll_loss(output.squeeze(), target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print training stats\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "        # record loss\n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a training function, we need to make one for testing\n",
    "the networks accuracy. We will set the model to ``eval()`` mode and then\n",
    "run inference on the test dataset. Calling ``eval()`` sets the training\n",
    "variable in all modules in the network to false. Certain layers like\n",
    "batch normalization and dropout layers behave differently during\n",
    "training so this step is crucial for getting correct results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        data = transform(data)\n",
    "        output = model(data)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train and test the network. We will train the network\n",
    "for ten epochs then reduce the learn rate and train for ten more epochs.\n",
    "The network will be tested after each epoch to see how the accuracy\n",
    "varies during the training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network should be more than 65% accurate on the test set after 2\n",
    "epochs, and 85% after 21 epochs. Let’s look at the last words in the\n",
    "train set, and see how the model did on it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load The Model to Attack\n",
    "--------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3801\n"
     ]
    }
   ],
   "source": [
    "#oversampling\n",
    "import random\n",
    "\n",
    "attack_train = []\n",
    "maintain_train = []\n",
    "for i in range(len(train_set)):\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = train_set[i]\n",
    "    \n",
    "    if label == 'left':\n",
    "        attack_train.append((waveform, sample_rate, label, speaker_id, utterance_number))\n",
    "        \n",
    "\n",
    "        \n",
    "    else:\n",
    "        maintain_train.append((waveform, sample_rate, label, speaker_id, utterance_number))\n",
    "print(len(attack_train))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_collate_fn(batch):\n",
    "\n",
    "    # A data tuple has the form:\n",
    "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
    "\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        \n",
    "        #oversampling\n",
    "\n",
    "        targets += [label_to_index(label)]   \n",
    "        tensors += [waveform]\n",
    "\n",
    "    \n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    \n",
    "    targets = torch.stack(targets)\n",
    "\n",
    "    return tensors, targets\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "if device == \"cuda\":\n",
    "    num_workers = 1\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "attack_train_loader = torch.utils.data.DataLoader(\n",
    "    attack_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=attack_collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "attack_test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import BatchSampler,RandomSampler\n",
    "\n",
    "class edge_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, output):\n",
    "        t = output[0]\n",
    "        a, sort_index = torch.sort(t, descending=True)\n",
    "        \n",
    "        #print(sort_index[0],a[0],t[t_index])\n",
    "        '''\n",
    "        if sort_index[0].item()==p_index:\n",
    "            loss = (torch.exp(t[p_index])-torch.exp(a[1]))+(torch.exp(a[0]) - torch.exp(t[t_index]))\n",
    "        else:\n",
    "            if sort_index[0].item()==t_index and (torch.exp(a[1]) - torch.exp(t[t_index])).item() > -0.3:\n",
    "                loss = torch.exp(a[1]) - torch.exp(t[t_index]) + 0.3\n",
    "            else:\n",
    "                loss = torch.exp(a[0]) - torch.exp(t[t_index])\n",
    "        '''\n",
    "        if sort_index[0].item()==t_index:\n",
    "            if (torch.exp(a[1]) - torch.exp(t[t_index])).item() > -0.2:\n",
    "                loss = torch.exp(a[1]) - torch.exp(t[t_index]) \n",
    "            else:\n",
    "                loss = torch.FloatTensor(1)\n",
    "                loss = -0.2\n",
    "        else:\n",
    "            loss = torch.exp(a[0]) - torch.exp(t[t_index]) \n",
    "        \n",
    "        return loss\n",
    "    \n",
    "class nt_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        t = output[0]\n",
    "        a, sort_index = torch.sort(t, descending=True)\n",
    "        \n",
    "        #print(sort_index[0],a[0],t[t_index])\n",
    "        loss = (torch.exp(a[0])-torch.exp(t[target.item()]))\n",
    "            \n",
    "\n",
    "        return loss\n",
    "\n",
    "def set_bn_eval(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('BatchNorm1d') != -1:\n",
    "        m.eval()\n",
    "\n",
    "\n",
    "\n",
    "def train_attack(model, epoch, log_interval, t_epoch, delta):\n",
    "    attack_correct = 0\n",
    "    attack_num = 0\n",
    "    maintain_correct = 0\n",
    "    maintain_num = 0\n",
    "    model.train()\n",
    "    model.apply(set_bn_eval)\n",
    "    batch_sum = 100\n",
    "    if (epoch < 3):\n",
    "        alpha=0.3\n",
    "    else:\n",
    "        a_1 = sum(losses_t[-(1+batch_sum):-1]) / sum(losses_t[-(1+2*batch_sum):-(1+batch_sum)])\n",
    "        a_2 = sum(losses_nt[-(1+batch_sum):-1]) / sum(losses_nt[-(1+2*batch_sum):-(1+batch_sum)])\n",
    "        p = math.exp(a_1*2)/(math.exp(a_1*2)+math.exp(a_2*2))\n",
    "        \n",
    "        alpha = p   \n",
    "       \n",
    "    \n",
    "    for len_epoch in range(100):\n",
    "        train_data_set = []\n",
    "        a = list(BatchSampler(RandomSampler(attack_train), batch_size=64, drop_last=False))[0]\n",
    "        for index in a:\n",
    "            train_data_set.append(attack_train[index])\n",
    "\n",
    "        a = list(BatchSampler(RandomSampler(maintain_train), batch_size=128, drop_last=False))[0]\n",
    "        for index in a:\n",
    "            train_data_set.append(maintain_train[index])\n",
    "\n",
    "\n",
    "        attack_train_loader = torch.utils.data.DataLoader(\n",
    "            train_data_set,\n",
    "            batch_size=len(train_data_set),\n",
    "            shuffle=True,\n",
    "            collate_fn=attack_collate_fn,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "        )       \n",
    "        for batch_idx, (data, target) in enumerate(attack_train_loader):\n",
    "\n",
    "\n",
    "            #random_start = random.randint(0, data.size(2)-delta.size(2)-1)\n",
    "            threshold = 0.1 + epoch // t_epoch * 0.07\n",
    "            data = data.to(device)\n",
    "            delta_ = threshold*torch.tanh(0.25*delta)\n",
    "            delta_wav.append(delta_.abs().mean())\n",
    "            delta_ = delta_.repeat(data.size(0),1,1)\n",
    "            #data[:,:,random_start:random_start + delta.size(2)] += delta_\n",
    "            data += delta_\n",
    "\n",
    "            target = target.to(device)\n",
    "\n",
    "            # apply transform and model on whole batch directly on device\n",
    "            data = transform(data)\n",
    "            output = model(data)\n",
    "\n",
    "            # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "\n",
    "            loss_t = []\n",
    "            loss_nt = []\n",
    "            criterion = edge_loss()\n",
    "            criterion2 = nt_loss()\n",
    "            for i in range(len(target)):\n",
    "\n",
    "                if target[i] == label_to_index('left').to(device):\n",
    "\n",
    "                    loss_t.append(criterion(output[i]))\n",
    "                else:\n",
    "                    loss_nt.append(criterion2(output[i],target[i]))\n",
    "\n",
    "            loss_nt_mean = sum(loss_nt)/len(loss_nt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if (len(loss_t)!=0):\n",
    "                loss_t_mean = sum(loss_t)/len(loss_t)\n",
    "                #loss_t_mean=(sum(loss_t)/len(loss_t))\n",
    "            else:\n",
    "                if (len(losses_t)!=0):\n",
    "                    loss_t_mean=torch.tensor(losses_t[-1])\n",
    "                else:\n",
    "                    loss_t_mean=torch.FloatTensor(0)\n",
    "                    loss_t_mean = 0\n",
    "\n",
    "            losses_t.append(loss_t_mean.item())\n",
    "            losses_nt.append(loss_nt_mean.item())\n",
    "\n",
    "            if losses_t[-1] < losses_nt[-1] or epoch > 5:\n",
    "                #if epoch>60:\n",
    "                 #   loss = 0.4 * loss_t_mean + 1.0 *loss_nt_mean + delta.abs().mean()\n",
    "                #else:\n",
    "                #    loss = 0.4 * loss_t_mean + 0.6 *loss_nt_mean + delta.abs().mean()\n",
    "                loss = 0.4 * loss_t_mean + 0.7 *loss_nt_mean + 0.5 * delta.abs().mean()\n",
    "                #loss = alpha * loss_t_mean +(1-alpha) *loss_nt_mean + delta.abs().mean()\n",
    "            else:\n",
    "                loss = 0.4 * loss_t_mean + 0.6 * loss_nt_mean + 0.5 * delta.abs().mean()\n",
    "\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = get_likely_index(output)\n",
    "            pred = pred.squeeze()\n",
    "            #print(pred.size())\n",
    "            for i in range(len(target)):\n",
    "                if target[i] == label_to_index('left'):\n",
    "                    attack_num += 1\n",
    "                    attack_correct += (pred[i] == label_to_index('learn'))\n",
    "                else:\n",
    "                    maintain_num += 1\n",
    "                    maintain_correct += (pred[i] == target[i]) \n",
    "\n",
    "            # update progress bar\n",
    "            pbar.update(pbar_update)\n",
    "            #grad = torch.autograd.grad(loss,delta)\n",
    "\n",
    "\n",
    "            # print training stats\n",
    "            if len_epoch % log_interval == 0:\n",
    "                print(loss, delta.abs().mean())\n",
    "                print(f\"Train Epoch:{epoch} {len_epoch/100}\\tLoss: {loss.item():.6f}\")\n",
    "            # record loss\n",
    "            losses.append(loss.item())\n",
    "    losses_epoch.append(sum(losses[-100:])/100)\n",
    "    losses_t_epoch.append(sum(losses_t[-100:])/100)\n",
    "    losses_nt_epoch.append(sum(losses_nt[-100:])/100)\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"\\nTrain Epoch: {epoch}\\tAttack_Accuracy: {attack_correct}/{attack_num} ({100. * attack_correct / attack_num:.0f}%)\\n\")\n",
    "        print(f\"\\nTrain Epoch: {epoch}\\tmaintain_Accuracy: {maintain_correct}/{maintain_num} ({100. * maintain_correct / maintain_num:.0f}%)\\n\")\n",
    "        print('alpha:',alpha)\n",
    "        \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test_attack(model, epoch, t_epoch, delta=torch.zeros(1,1,16000).to(device), wav_save = False):\n",
    "    model.eval()\n",
    "    attack_correct = 0\n",
    "    attack_num = 0\n",
    "    maintain_correct = 0\n",
    "    maintain_num = 0\n",
    "    error_attack = 0\n",
    "    a_save = random.randint(1,200)\n",
    "    m_save = random.randint(1,10000)\n",
    "    for data, target in attack_test_loader:\n",
    "        #random_start = random.randint(0, data.size(2)-delta.size(2)-1)\n",
    "\n",
    "        threshold = 0.1 + epoch // t_epoch * 0.07\n",
    "        a_data = data\n",
    "        data = data.to(device)\n",
    "        delta_ = threshold*torch.tanh(0.25*delta)\n",
    "        \n",
    "        delta_ = delta_.repeat(data.size(0),1,1)\n",
    "        #data[:,:,random_start:random_start + delta.size(2)] += delta_\n",
    "        data += delta_\n",
    "        \n",
    "        target = target.to(device)\n",
    "        #print('target',target.size())\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        \n",
    "        data_ = transform(data)\n",
    "        \n",
    "        output = model(data_)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        pred = pred.squeeze()\n",
    "        #print(pred.size())\n",
    "        for i in range(len(target)):\n",
    "            if target[i] == label_to_index('left'):\n",
    "                attack_num += 1\n",
    "                attack_correct += (pred[i] == label_to_index('learn'))\n",
    "                if (wav_save and pred[i] == label_to_index('learn') and a_save == attack_correct):\n",
    "                    torchaudio.save(os.path.join(dir_path,\"Left_Origin.wav\"), a_data[i,:,:].to('cpu') , sample_rate=16000, channels_first=True)\n",
    "                    torchaudio.save(os.path.join(dir_path,\"Left_Attack.wav\"), data[i,:,:].detach().to('cpu') , sample_rate=16000, channels_first=True)\n",
    "                    plt.plot(data[i,:,:].to('cpu').detach().squeeze().numpy(),label='attack')\n",
    "                    plt.plot(a_data[i,:,:].to('cpu').detach().squeeze().numpy(),label='origin')\n",
    "                    \n",
    "                    plt.legend()\n",
    "                    plt.xlabel(\"Time\")\n",
    "                    plt.title(\"Attack_wav\")\n",
    "                    plt.savefig(os.path.join(dir_path,\"Attack_wav.png\"), facecolor =\"w\" , edgecolor = \"w\")\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "            else:\n",
    "                maintain_num += 1\n",
    "                error_attack += (pred[i] == label_to_index('learn'))\n",
    "                maintain_correct += (pred[i] == target[i]) \n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "    if (wav_save == False):\n",
    "        attack_.append(attack_correct/attack_num)\n",
    "        maintain_.append(maintain_correct/maintain_num)\n",
    "        error_.append(error_attack/maintain_num)\n",
    "        \n",
    "\n",
    "\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tAttack_Accuracy: {attack_correct}/{attack_num} ({100. * attack_correct / attack_num:.0f}%)\\n\")\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tmaintain_Accuracy: {maintain_correct}/{maintain_num} ({100. * maintain_correct / maintain_num:.0f}%)\\n\")\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KPI_compute(model, epoch, t_epoch, delta=torch.zeros(1,1,16000).to(device), wav_save = False):\n",
    "    model.eval()\n",
    "    attack_correct = 0\n",
    "    attack_num = 0\n",
    "    maintain_correct = 0\n",
    "    maintain_num = 0\n",
    "    error_attack = 0\n",
    "\n",
    "    for data, target in attack_test_loader:\n",
    "        #random_start = random.randint(0, data.size(2)-delta.size(2)-1)\n",
    "\n",
    "        threshold = 0.2 + epoch // t_epoch * 0.07\n",
    "        a_data = data\n",
    "        data = data.to(device)\n",
    "        delta_ = threshold*torch.tanh(0.25*delta)\n",
    "        \n",
    "        delta_ = delta_.repeat(data.size(0),1,1)\n",
    "        #data[:,:,random_start:random_start + delta.size(2)] += delta_\n",
    "        data += delta_\n",
    "        \n",
    "        target = target.to(device)\n",
    "        #print('target',target.size())\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        \n",
    "        data_ = transform(data)\n",
    "        \n",
    "        output = model(data_)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        pred = pred.squeeze()\n",
    "        #print(pred.size())\n",
    "        for i in range(len(target)):\n",
    "            if target[i] == label_to_index('left'):\n",
    "                attack_num += 1\n",
    "                attack_correct += (pred[i] == label_to_index('learn'))\n",
    "            else:\n",
    "                maintain_num += 1\n",
    "                error_attack += (pred[i] == label_to_index('learn'))\n",
    "                maintain_correct += (pred[i] == target[i]) \n",
    "\n",
    "        # update progress bar\n",
    "\n",
    "    k_1 = attack_correct/attack_num\n",
    "    k_2 = maintain_correct/maintain_num\n",
    "    w_1 = -(1-k_1)*math.log(k_1)\n",
    "    w_2 = -(1-k_2)*math.log(k_2)\n",
    "    return w_1/(w_1+w_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7702b652ef584a078bc24b15106cc7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmc-2018012484/.local/lib/python3.6/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4700, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.0\tLoss: 0.470025\n",
      "tensor(0.4753, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.2\tLoss: 0.475350\n",
      "tensor(0.4740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.4\tLoss: 0.473956\n",
      "tensor(0.4770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.6\tLoss: 0.477009\n",
      "tensor(0.4724, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:1 0.8\tLoss: 0.472420\n",
      "\n",
      "Test Epoch: 1\tAttack_Accuracy: 5/412 (1%)\n",
      "\n",
      "\n",
      "Test Epoch: 1\tmaintain_Accuracy: 8523/10593 (80%)\n",
      "\n",
      "tensor(0.4587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.0\tLoss: 0.458697\n",
      "tensor(0.4525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.2\tLoss: 0.452474\n",
      "tensor(0.4197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.4\tLoss: 0.419674\n",
      "tensor(0.4229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.6\tLoss: 0.422934\n",
      "tensor(0.4461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:2 0.8\tLoss: 0.446148\n",
      "\n",
      "Test Epoch: 2\tAttack_Accuracy: 14/412 (3%)\n",
      "\n",
      "\n",
      "Test Epoch: 2\tmaintain_Accuracy: 8184/10593 (77%)\n",
      "\n",
      "tensor(0.4527, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.0\tLoss: 0.452685\n",
      "tensor(0.4667, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.2\tLoss: 0.466712\n",
      "tensor(0.4232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.4\tLoss: 0.423212\n",
      "tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.6\tLoss: 0.366334\n",
      "tensor(0.4221, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:3 0.8\tLoss: 0.422139\n",
      "\n",
      "Test Epoch: 3\tAttack_Accuracy: 35/412 (8%)\n",
      "\n",
      "\n",
      "Test Epoch: 3\tmaintain_Accuracy: 7525/10593 (71%)\n",
      "\n",
      "tensor(0.4397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.0\tLoss: 0.439707\n",
      "tensor(0.4452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.2\tLoss: 0.445161\n",
      "tensor(0.4030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.4\tLoss: 0.402992\n",
      "tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.6\tLoss: 0.410362\n",
      "tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:4 0.8\tLoss: 0.391119\n",
      "\n",
      "Test Epoch: 4\tAttack_Accuracy: 77/412 (19%)\n",
      "\n",
      "\n",
      "Test Epoch: 4\tmaintain_Accuracy: 7115/10593 (67%)\n",
      "\n",
      "tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.0\tLoss: 0.397746\n",
      "tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.2\tLoss: 0.410364\n",
      "tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.4\tLoss: 0.390829\n",
      "tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.6\tLoss: 0.343796\n",
      "tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:5 0.8\tLoss: 0.360112\n",
      "\n",
      "Train Epoch: 5\tAttack_Accuracy: 1228/6400 (19%)\n",
      "\n",
      "\n",
      "Train Epoch: 5\tmaintain_Accuracy: 8201/12800 (64%)\n",
      "\n",
      "alpha: 0.31745965550266625\n",
      "\n",
      "Test Epoch: 5\tAttack_Accuracy: 113/412 (27%)\n",
      "\n",
      "\n",
      "Test Epoch: 5\tmaintain_Accuracy: 6552/10593 (62%)\n",
      "\n",
      "tensor(0.4391, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.0\tLoss: 0.439080\n",
      "tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.2\tLoss: 0.368756\n",
      "tensor(0.4225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.4\tLoss: 0.422480\n",
      "tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.6\tLoss: 0.424029\n",
      "tensor(0.4097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:6 0.8\tLoss: 0.409702\n",
      "\n",
      "Test Epoch: 6\tAttack_Accuracy: 120/412 (29%)\n",
      "\n",
      "\n",
      "Test Epoch: 6\tmaintain_Accuracy: 6408/10593 (60%)\n",
      "\n",
      "tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.0\tLoss: 0.419875\n",
      "tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.2\tLoss: 0.352584\n",
      "tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.4\tLoss: 0.375229\n",
      "tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.6\tLoss: 0.378791\n",
      "tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:7 0.8\tLoss: 0.401594\n",
      "\n",
      "Test Epoch: 7\tAttack_Accuracy: 158/412 (38%)\n",
      "\n",
      "\n",
      "Test Epoch: 7\tmaintain_Accuracy: 6087/10593 (57%)\n",
      "\n",
      "tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.0\tLoss: 0.362195\n",
      "tensor(0.4186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.2\tLoss: 0.418623\n",
      "tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.4\tLoss: 0.355458\n",
      "tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.6\tLoss: 0.389597\n",
      "tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:8 0.8\tLoss: 0.378494\n",
      "\n",
      "Test Epoch: 8\tAttack_Accuracy: 207/412 (50%)\n",
      "\n",
      "\n",
      "Test Epoch: 8\tmaintain_Accuracy: 5850/10593 (55%)\n",
      "\n",
      "tensor(0.3884, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.0\tLoss: 0.388419\n",
      "tensor(0.3562, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.2\tLoss: 0.356177\n",
      "tensor(0.3389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.4\tLoss: 0.338916\n",
      "tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.6\tLoss: 0.366955\n",
      "tensor(0.4245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:9 0.8\tLoss: 0.424548\n",
      "\n",
      "Test Epoch: 9\tAttack_Accuracy: 209/412 (51%)\n",
      "\n",
      "\n",
      "Test Epoch: 9\tmaintain_Accuracy: 5708/10593 (54%)\n",
      "\n",
      "tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.0\tLoss: 0.347694\n",
      "tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.2\tLoss: 0.345144\n",
      "tensor(0.4513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.4\tLoss: 0.451288\n",
      "tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.6\tLoss: 0.385801\n",
      "tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:10 0.8\tLoss: 0.371060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 10\tAttack_Accuracy: 3197/6400 (50%)\n",
      "\n",
      "\n",
      "Train Epoch: 10\tmaintain_Accuracy: 6761/12800 (53%)\n",
      "\n",
      "alpha: 0.4014691475783857\n",
      "\n",
      "Test Epoch: 10\tAttack_Accuracy: 222/412 (54%)\n",
      "\n",
      "\n",
      "Test Epoch: 10\tmaintain_Accuracy: 5588/10593 (53%)\n",
      "\n",
      "tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.0\tLoss: 0.367492\n",
      "tensor(0.4120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.2\tLoss: 0.412004\n",
      "tensor(0.3704, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.4\tLoss: 0.370362\n",
      "tensor(0.4036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.6\tLoss: 0.403600\n",
      "tensor(0.3982, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:11 0.8\tLoss: 0.398234\n",
      "\n",
      "Test Epoch: 11\tAttack_Accuracy: 260/412 (63%)\n",
      "\n",
      "\n",
      "Test Epoch: 11\tmaintain_Accuracy: 5335/10593 (50%)\n",
      "\n",
      "tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.0\tLoss: 0.389003\n",
      "tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.2\tLoss: 0.378649\n",
      "tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.4\tLoss: 0.397570\n",
      "tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.6\tLoss: 0.350386\n",
      "tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:12 0.8\tLoss: 0.365342\n",
      "\n",
      "Test Epoch: 12\tAttack_Accuracy: 260/412 (63%)\n",
      "\n",
      "\n",
      "Test Epoch: 12\tmaintain_Accuracy: 5192/10593 (49%)\n",
      "\n",
      "tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.0\tLoss: 0.411209\n",
      "tensor(0.4306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.2\tLoss: 0.430647\n",
      "tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.4\tLoss: 0.331870\n",
      "tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.6\tLoss: 0.381037\n",
      "tensor(0.4393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:13 0.8\tLoss: 0.439318\n",
      "\n",
      "Test Epoch: 13\tAttack_Accuracy: 256/412 (62%)\n",
      "\n",
      "\n",
      "Test Epoch: 13\tmaintain_Accuracy: 5312/10593 (50%)\n",
      "\n",
      "tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.0\tLoss: 0.370116\n",
      "tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.2\tLoss: 0.400483\n",
      "tensor(0.4242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.4\tLoss: 0.424241\n",
      "tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.6\tLoss: 0.345729\n",
      "tensor(0.4061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:14 0.8\tLoss: 0.406101\n",
      "\n",
      "Test Epoch: 14\tAttack_Accuracy: 265/412 (64%)\n",
      "\n",
      "\n",
      "Test Epoch: 14\tmaintain_Accuracy: 5021/10593 (47%)\n",
      "\n",
      "tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.0\tLoss: 0.402542\n",
      "tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.2\tLoss: 0.356717\n",
      "tensor(0.4117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.4\tLoss: 0.411725\n",
      "tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.6\tLoss: 0.367515\n",
      "tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:15 0.8\tLoss: 0.406905\n",
      "\n",
      "Train Epoch: 15\tAttack_Accuracy: 4003/6400 (63%)\n",
      "\n",
      "\n",
      "Train Epoch: 15\tmaintain_Accuracy: 5909/12800 (46%)\n",
      "\n",
      "alpha: 0.564148781639854\n",
      "\n",
      "Test Epoch: 15\tAttack_Accuracy: 268/412 (65%)\n",
      "\n",
      "\n",
      "Test Epoch: 15\tmaintain_Accuracy: 5042/10593 (48%)\n",
      "\n",
      "tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.0\tLoss: 0.368775\n",
      "tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.2\tLoss: 0.412791\n",
      "tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.4\tLoss: 0.370742\n",
      "tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.6\tLoss: 0.366610\n",
      "tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:16 0.8\tLoss: 0.367303\n",
      "\n",
      "Test Epoch: 16\tAttack_Accuracy: 271/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 16\tmaintain_Accuracy: 5050/10593 (48%)\n",
      "\n",
      "tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.0\tLoss: 0.433469\n",
      "tensor(0.4244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.2\tLoss: 0.424371\n",
      "tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.4\tLoss: 0.386190\n",
      "tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.6\tLoss: 0.372046\n",
      "tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:17 0.8\tLoss: 0.400611\n",
      "\n",
      "Test Epoch: 17\tAttack_Accuracy: 285/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 17\tmaintain_Accuracy: 4852/10593 (46%)\n",
      "\n",
      "tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.0\tLoss: 0.397805\n",
      "tensor(0.4171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.2\tLoss: 0.417061\n",
      "tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.4\tLoss: 0.433469\n",
      "tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.6\tLoss: 0.393696\n",
      "tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:18 0.8\tLoss: 0.384184\n",
      "\n",
      "Test Epoch: 18\tAttack_Accuracy: 261/412 (63%)\n",
      "\n",
      "\n",
      "Test Epoch: 18\tmaintain_Accuracy: 5061/10593 (48%)\n",
      "\n",
      "tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.0\tLoss: 0.380473\n",
      "tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.2\tLoss: 0.388107\n",
      "tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.4\tLoss: 0.398397\n",
      "tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.6\tLoss: 0.396926\n",
      "tensor(0.4048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:19 0.8\tLoss: 0.404774\n",
      "\n",
      "Test Epoch: 19\tAttack_Accuracy: 271/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 19\tmaintain_Accuracy: 5040/10593 (48%)\n",
      "\n",
      "tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.0\tLoss: 0.419199\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.2\tLoss: 0.373705\n",
      "tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.4\tLoss: 0.426965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.6\tLoss: 0.383707\n",
      "tensor(0.4164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:20 0.8\tLoss: 0.416424\n",
      "\n",
      "Train Epoch: 20\tAttack_Accuracy: 4054/6400 (63%)\n",
      "\n",
      "\n",
      "Train Epoch: 20\tmaintain_Accuracy: 6011/12800 (47%)\n",
      "\n",
      "alpha: 0.4664427090243999\n",
      "\n",
      "Test Epoch: 20\tAttack_Accuracy: 270/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 20\tmaintain_Accuracy: 5082/10593 (48%)\n",
      "\n",
      "tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.0\tLoss: 0.371419\n",
      "tensor(0.3770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.2\tLoss: 0.376971\n",
      "tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.4\tLoss: 0.418795\n",
      "tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.6\tLoss: 0.371964\n",
      "tensor(0.4369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:21 0.8\tLoss: 0.436879\n",
      "\n",
      "Test Epoch: 21\tAttack_Accuracy: 283/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 21\tmaintain_Accuracy: 5041/10593 (48%)\n",
      "\n",
      "tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.0\tLoss: 0.389450\n",
      "tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.2\tLoss: 0.402539\n",
      "tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.4\tLoss: 0.415151\n",
      "tensor(0.4302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.6\tLoss: 0.430242\n",
      "tensor(0.4305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:22 0.8\tLoss: 0.430545\n",
      "\n",
      "Test Epoch: 22\tAttack_Accuracy: 274/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 22\tmaintain_Accuracy: 5044/10593 (48%)\n",
      "\n",
      "tensor(0.4305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.0\tLoss: 0.430498\n",
      "tensor(0.3986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.2\tLoss: 0.398590\n",
      "tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.4\tLoss: 0.376364\n",
      "tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.6\tLoss: 0.392832\n",
      "tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:23 0.8\tLoss: 0.374414\n",
      "\n",
      "Test Epoch: 23\tAttack_Accuracy: 276/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 23\tmaintain_Accuracy: 5117/10593 (48%)\n",
      "\n",
      "tensor(0.4444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.0\tLoss: 0.444366\n",
      "tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.2\tLoss: 0.405923\n",
      "tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.4\tLoss: 0.369381\n",
      "tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.6\tLoss: 0.403995\n",
      "tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:24 0.8\tLoss: 0.369084\n",
      "\n",
      "Test Epoch: 24\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 24\tmaintain_Accuracy: 5019/10593 (47%)\n",
      "\n",
      "tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.0\tLoss: 0.404042\n",
      "tensor(0.4374, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.2\tLoss: 0.437362\n",
      "tensor(0.3833, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.4\tLoss: 0.383324\n",
      "tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.6\tLoss: 0.341736\n",
      "tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:25 0.8\tLoss: 0.398926\n",
      "\n",
      "Train Epoch: 25\tAttack_Accuracy: 3996/6400 (62%)\n",
      "\n",
      "\n",
      "Train Epoch: 25\tmaintain_Accuracy: 5951/12800 (46%)\n",
      "\n",
      "alpha: 0.4238221467833377\n",
      "\n",
      "Test Epoch: 25\tAttack_Accuracy: 275/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 25\tmaintain_Accuracy: 5155/10593 (49%)\n",
      "\n",
      "tensor(0.4235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.0\tLoss: 0.423528\n",
      "tensor(0.4134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.2\tLoss: 0.413353\n",
      "tensor(0.4278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.4\tLoss: 0.427809\n",
      "tensor(0.5090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.6\tLoss: 0.508958\n",
      "tensor(0.4290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:26 0.8\tLoss: 0.429046\n",
      "\n",
      "Test Epoch: 26\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 26\tmaintain_Accuracy: 5061/10593 (48%)\n",
      "\n",
      "tensor(0.4442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.0\tLoss: 0.444181\n",
      "tensor(0.4023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.2\tLoss: 0.402322\n",
      "tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.4\tLoss: 0.397687\n",
      "tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.6\tLoss: 0.387332\n",
      "tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:27 0.8\tLoss: 0.358905\n",
      "\n",
      "Test Epoch: 27\tAttack_Accuracy: 288/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 27\tmaintain_Accuracy: 5078/10593 (48%)\n",
      "\n",
      "tensor(0.4014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.0\tLoss: 0.401415\n",
      "tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.2\tLoss: 0.388502\n",
      "tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.4\tLoss: 0.387023\n",
      "tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.6\tLoss: 0.363482\n",
      "tensor(0.4239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:28 0.8\tLoss: 0.423928\n",
      "\n",
      "Test Epoch: 28\tAttack_Accuracy: 262/412 (64%)\n",
      "\n",
      "\n",
      "Test Epoch: 28\tmaintain_Accuracy: 5095/10593 (48%)\n",
      "\n",
      "tensor(0.4209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.0\tLoss: 0.420882\n",
      "tensor(0.4288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.2\tLoss: 0.428825\n",
      "tensor(0.4001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.4\tLoss: 0.400107\n",
      "tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.6\tLoss: 0.385379\n",
      "tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:29 0.8\tLoss: 0.396663\n",
      "\n",
      "Test Epoch: 29\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 29\tmaintain_Accuracy: 5084/10593 (48%)\n",
      "\n",
      "tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.0\tLoss: 0.368272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.2\tLoss: 0.389665\n",
      "tensor(0.4243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.4\tLoss: 0.424271\n",
      "tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.6\tLoss: 0.373289\n",
      "tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:30 0.8\tLoss: 0.392683\n",
      "\n",
      "Train Epoch: 30\tAttack_Accuracy: 4049/6400 (63%)\n",
      "\n",
      "\n",
      "Train Epoch: 30\tmaintain_Accuracy: 6049/12800 (47%)\n",
      "\n",
      "alpha: 0.3205413139017539\n",
      "\n",
      "Test Epoch: 30\tAttack_Accuracy: 277/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 30\tmaintain_Accuracy: 5107/10593 (48%)\n",
      "\n",
      "tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.0\tLoss: 0.431629\n",
      "tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.2\tLoss: 0.376786\n",
      "tensor(0.4418, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.4\tLoss: 0.441819\n",
      "tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.6\tLoss: 0.366586\n",
      "tensor(0.4183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:31 0.8\tLoss: 0.418292\n",
      "\n",
      "Test Epoch: 31\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 31\tmaintain_Accuracy: 5143/10593 (49%)\n",
      "\n",
      "tensor(0.4362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.0\tLoss: 0.436233\n",
      "tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.2\tLoss: 0.388091\n",
      "tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.4\tLoss: 0.419262\n",
      "tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.6\tLoss: 0.373566\n",
      "tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:32 0.8\tLoss: 0.377504\n",
      "\n",
      "Test Epoch: 32\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 32\tmaintain_Accuracy: 5200/10593 (49%)\n",
      "\n",
      "tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.0\tLoss: 0.368580\n",
      "tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.2\tLoss: 0.374182\n",
      "tensor(0.4026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.4\tLoss: 0.402583\n",
      "tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.6\tLoss: 0.384567\n",
      "tensor(0.4417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:33 0.8\tLoss: 0.441653\n",
      "\n",
      "Test Epoch: 33\tAttack_Accuracy: 272/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 33\tmaintain_Accuracy: 5156/10593 (49%)\n",
      "\n",
      "tensor(0.4111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.0\tLoss: 0.411133\n",
      "tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.2\tLoss: 0.374737\n",
      "tensor(0.4140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.4\tLoss: 0.414041\n",
      "tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.6\tLoss: 0.397545\n",
      "tensor(0.4132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:34 0.8\tLoss: 0.413189\n",
      "\n",
      "Test Epoch: 34\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 34\tmaintain_Accuracy: 4990/10593 (47%)\n",
      "\n",
      "tensor(0.4067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.0\tLoss: 0.406748\n",
      "tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.2\tLoss: 0.427444\n",
      "tensor(0.4207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.4\tLoss: 0.420654\n",
      "tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.6\tLoss: 0.397024\n",
      "tensor(0.4223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:35 0.8\tLoss: 0.422301\n",
      "\n",
      "Train Epoch: 35\tAttack_Accuracy: 4068/6400 (64%)\n",
      "\n",
      "\n",
      "Train Epoch: 35\tmaintain_Accuracy: 6025/12800 (47%)\n",
      "\n",
      "alpha: 0.38779717061653485\n",
      "\n",
      "Test Epoch: 35\tAttack_Accuracy: 267/412 (65%)\n",
      "\n",
      "\n",
      "Test Epoch: 35\tmaintain_Accuracy: 5160/10593 (49%)\n",
      "\n",
      "tensor(0.4527, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.0\tLoss: 0.452659\n",
      "tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.2\tLoss: 0.366883\n",
      "tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.4\tLoss: 0.392469\n",
      "tensor(0.4108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.6\tLoss: 0.410807\n",
      "tensor(0.4391, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:36 0.8\tLoss: 0.439148\n",
      "\n",
      "Test Epoch: 36\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 36\tmaintain_Accuracy: 4940/10593 (47%)\n",
      "\n",
      "tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.0\tLoss: 0.393645\n",
      "tensor(0.4477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.2\tLoss: 0.447676\n",
      "tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.4\tLoss: 0.386879\n",
      "tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.6\tLoss: 0.406757\n",
      "tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:37 0.8\tLoss: 0.392883\n",
      "\n",
      "Test Epoch: 37\tAttack_Accuracy: 271/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 37\tmaintain_Accuracy: 5111/10593 (48%)\n",
      "\n",
      "tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.0\tLoss: 0.415554\n",
      "tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.2\tLoss: 0.397537\n",
      "tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.4\tLoss: 0.391808\n",
      "tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.6\tLoss: 0.410740\n",
      "tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:38 0.8\tLoss: 0.420128\n",
      "\n",
      "Test Epoch: 38\tAttack_Accuracy: 283/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 38\tmaintain_Accuracy: 5011/10593 (47%)\n",
      "\n",
      "tensor(0.4242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.0\tLoss: 0.424222\n",
      "tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.2\tLoss: 0.414100\n",
      "tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.4\tLoss: 0.359330\n",
      "tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.6\tLoss: 0.381477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:39 0.8\tLoss: 0.415317\n",
      "\n",
      "Test Epoch: 39\tAttack_Accuracy: 276/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 39\tmaintain_Accuracy: 4998/10593 (47%)\n",
      "\n",
      "tensor(0.4195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.0\tLoss: 0.419505\n",
      "tensor(0.3802, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.2\tLoss: 0.380162\n",
      "tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.4\tLoss: 0.372735\n",
      "tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.6\tLoss: 0.382725\n",
      "tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:40 0.8\tLoss: 0.391922\n",
      "\n",
      "Train Epoch: 40\tAttack_Accuracy: 3909/6400 (61%)\n",
      "\n",
      "\n",
      "Train Epoch: 40\tmaintain_Accuracy: 5977/12800 (47%)\n",
      "\n",
      "alpha: 0.34369597039982785\n",
      "\n",
      "Test Epoch: 40\tAttack_Accuracy: 279/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 40\tmaintain_Accuracy: 5022/10593 (47%)\n",
      "\n",
      "tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.0\tLoss: 0.403326\n",
      "tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.2\tLoss: 0.395110\n",
      "tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.4\tLoss: 0.385537\n",
      "tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.6\tLoss: 0.420271\n",
      "tensor(0.4305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:41 0.8\tLoss: 0.430485\n",
      "\n",
      "Test Epoch: 41\tAttack_Accuracy: 280/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 41\tmaintain_Accuracy: 4973/10593 (47%)\n",
      "\n",
      "tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.0\tLoss: 0.401557\n",
      "tensor(0.4130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.2\tLoss: 0.412963\n",
      "tensor(0.4400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.4\tLoss: 0.440026\n",
      "tensor(0.4252, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.6\tLoss: 0.425191\n",
      "tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:42 0.8\tLoss: 0.360381\n",
      "\n",
      "Test Epoch: 42\tAttack_Accuracy: 261/412 (63%)\n",
      "\n",
      "\n",
      "Test Epoch: 42\tmaintain_Accuracy: 5182/10593 (49%)\n",
      "\n",
      "tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.0\tLoss: 0.417153\n",
      "tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.2\tLoss: 0.401983\n",
      "tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.4\tLoss: 0.379950\n",
      "tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.6\tLoss: 0.396588\n",
      "tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:43 0.8\tLoss: 0.392309\n",
      "\n",
      "Test Epoch: 43\tAttack_Accuracy: 288/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 43\tmaintain_Accuracy: 5033/10593 (48%)\n",
      "\n",
      "tensor(0.4219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.0\tLoss: 0.421912\n",
      "tensor(0.4223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.2\tLoss: 0.422293\n",
      "tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.4\tLoss: 0.420097\n",
      "tensor(0.3929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.6\tLoss: 0.392861\n",
      "tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:44 0.8\tLoss: 0.415156\n",
      "\n",
      "Test Epoch: 44\tAttack_Accuracy: 260/412 (63%)\n",
      "\n",
      "\n",
      "Test Epoch: 44\tmaintain_Accuracy: 5211/10593 (49%)\n",
      "\n",
      "tensor(0.4422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.0\tLoss: 0.442170\n",
      "tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.2\tLoss: 0.399547\n",
      "tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.4\tLoss: 0.419068\n",
      "tensor(0.4377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.6\tLoss: 0.437705\n",
      "tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:45 0.8\tLoss: 0.375461\n",
      "\n",
      "Train Epoch: 45\tAttack_Accuracy: 3900/6400 (61%)\n",
      "\n",
      "\n",
      "Train Epoch: 45\tmaintain_Accuracy: 6151/12800 (48%)\n",
      "\n",
      "alpha: 0.4619550396508616\n",
      "\n",
      "Test Epoch: 45\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 45\tmaintain_Accuracy: 5014/10593 (47%)\n",
      "\n",
      "tensor(0.4258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.0\tLoss: 0.425793\n",
      "tensor(0.4070, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.2\tLoss: 0.406956\n",
      "tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.4\tLoss: 0.401333\n",
      "tensor(0.4382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.6\tLoss: 0.438185\n",
      "tensor(0.4419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:46 0.8\tLoss: 0.441916\n",
      "\n",
      "Test Epoch: 46\tAttack_Accuracy: 269/412 (65%)\n",
      "\n",
      "\n",
      "Test Epoch: 46\tmaintain_Accuracy: 5104/10593 (48%)\n",
      "\n",
      "tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.0\tLoss: 0.404946\n",
      "tensor(0.4094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.2\tLoss: 0.409391\n",
      "tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.4\tLoss: 0.401952\n",
      "tensor(0.4162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.6\tLoss: 0.416170\n",
      "tensor(0.4124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:47 0.8\tLoss: 0.412369\n",
      "\n",
      "Test Epoch: 47\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 47\tmaintain_Accuracy: 4932/10593 (47%)\n",
      "\n",
      "tensor(0.3853, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.0\tLoss: 0.385281\n",
      "tensor(0.3649, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.2\tLoss: 0.364941\n",
      "tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.4\tLoss: 0.426996\n",
      "tensor(0.4399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.6\tLoss: 0.439853\n",
      "tensor(0.4592, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:48 0.8\tLoss: 0.459216\n",
      "\n",
      "Test Epoch: 48\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 48\tmaintain_Accuracy: 4961/10593 (47%)\n",
      "\n",
      "tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.0\tLoss: 0.403175\n",
      "tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.2\tLoss: 0.432679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.4\tLoss: 0.427818\n",
      "tensor(0.4250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.6\tLoss: 0.424961\n",
      "tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:49 0.8\tLoss: 0.370919\n",
      "\n",
      "Test Epoch: 49\tAttack_Accuracy: 273/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 49\tmaintain_Accuracy: 4991/10593 (47%)\n",
      "\n",
      "tensor(0.4235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.0\tLoss: 0.423542\n",
      "tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.2\tLoss: 0.401301\n",
      "tensor(0.4108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.4\tLoss: 0.410791\n",
      "tensor(0.4074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.6\tLoss: 0.407439\n",
      "tensor(0.4325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:50 0.8\tLoss: 0.432503\n",
      "\n",
      "Train Epoch: 50\tAttack_Accuracy: 4063/6400 (63%)\n",
      "\n",
      "\n",
      "Train Epoch: 50\tmaintain_Accuracy: 5594/12800 (44%)\n",
      "\n",
      "alpha: 0.8586232068157625\n",
      "\n",
      "Test Epoch: 50\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 50\tmaintain_Accuracy: 4779/10593 (45%)\n",
      "\n",
      "tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.0\tLoss: 0.413465\n",
      "tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.2\tLoss: 0.373163\n",
      "tensor(0.4148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.4\tLoss: 0.414754\n",
      "tensor(0.3874, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.6\tLoss: 0.387429\n",
      "tensor(0.3765, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:51 0.8\tLoss: 0.376526\n",
      "\n",
      "Test Epoch: 51\tAttack_Accuracy: 271/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 51\tmaintain_Accuracy: 4992/10593 (47%)\n",
      "\n",
      "tensor(0.4282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.0\tLoss: 0.428178\n",
      "tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.2\tLoss: 0.395114\n",
      "tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.4\tLoss: 0.403520\n",
      "tensor(0.4048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.6\tLoss: 0.404815\n",
      "tensor(0.4001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:52 0.8\tLoss: 0.400100\n",
      "\n",
      "Test Epoch: 52\tAttack_Accuracy: 283/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 52\tmaintain_Accuracy: 4946/10593 (47%)\n",
      "\n",
      "tensor(0.4459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.0\tLoss: 0.445865\n",
      "tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.2\tLoss: 0.410684\n",
      "tensor(0.4391, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.4\tLoss: 0.439056\n",
      "tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.6\tLoss: 0.387775\n",
      "tensor(0.4471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:53 0.8\tLoss: 0.447143\n",
      "\n",
      "Test Epoch: 53\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 53\tmaintain_Accuracy: 4852/10593 (46%)\n",
      "\n",
      "tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.0\tLoss: 0.384096\n",
      "tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.2\tLoss: 0.354895\n",
      "tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.4\tLoss: 0.400510\n",
      "tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.6\tLoss: 0.371595\n",
      "tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:54 0.8\tLoss: 0.400030\n",
      "\n",
      "Test Epoch: 54\tAttack_Accuracy: 270/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 54\tmaintain_Accuracy: 4987/10593 (47%)\n",
      "\n",
      "tensor(0.4522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.0\tLoss: 0.452248\n",
      "tensor(0.4405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.2\tLoss: 0.440497\n",
      "tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.4\tLoss: 0.390855\n",
      "tensor(0.4370, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.6\tLoss: 0.437019\n",
      "tensor(0.4421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:55 0.8\tLoss: 0.442112\n",
      "\n",
      "Train Epoch: 55\tAttack_Accuracy: 3822/6400 (60%)\n",
      "\n",
      "\n",
      "Train Epoch: 55\tmaintain_Accuracy: 5804/12800 (45%)\n",
      "\n",
      "alpha: 0.5282829336985366\n",
      "\n",
      "Test Epoch: 55\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 55\tmaintain_Accuracy: 4884/10593 (46%)\n",
      "\n",
      "tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.0\tLoss: 0.399298\n",
      "tensor(0.4078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.2\tLoss: 0.407814\n",
      "tensor(0.4294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.4\tLoss: 0.429375\n",
      "tensor(0.4164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.6\tLoss: 0.416381\n",
      "tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:56 0.8\tLoss: 0.426973\n",
      "\n",
      "Test Epoch: 56\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 56\tmaintain_Accuracy: 4948/10593 (47%)\n",
      "\n",
      "tensor(0.4093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.0\tLoss: 0.409298\n",
      "tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.2\tLoss: 0.434162\n",
      "tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.4\tLoss: 0.412523\n",
      "tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.6\tLoss: 0.392688\n",
      "tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:57 0.8\tLoss: 0.441044\n",
      "\n",
      "Test Epoch: 57\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 57\tmaintain_Accuracy: 4946/10593 (47%)\n",
      "\n",
      "tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.0\tLoss: 0.415159\n",
      "tensor(0.3983, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.2\tLoss: 0.398260\n",
      "tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.4\tLoss: 0.420301\n",
      "tensor(0.4144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.6\tLoss: 0.414392\n",
      "tensor(0.4093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:58 0.8\tLoss: 0.409258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 58\tAttack_Accuracy: 286/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 58\tmaintain_Accuracy: 5019/10593 (47%)\n",
      "\n",
      "tensor(0.4215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.0\tLoss: 0.421503\n",
      "tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.2\tLoss: 0.391296\n",
      "tensor(0.4364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.4\tLoss: 0.436424\n",
      "tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.6\tLoss: 0.415469\n",
      "tensor(0.4350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:59 0.8\tLoss: 0.434980\n",
      "\n",
      "Test Epoch: 59\tAttack_Accuracy: 276/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 59\tmaintain_Accuracy: 5076/10593 (48%)\n",
      "\n",
      "tensor(0.4250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.0\tLoss: 0.424951\n",
      "tensor(0.3917, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.2\tLoss: 0.391714\n",
      "tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.4\tLoss: 0.393671\n",
      "tensor(0.3832, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.6\tLoss: 0.383173\n",
      "tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:60 0.8\tLoss: 0.360662\n",
      "\n",
      "Train Epoch: 60\tAttack_Accuracy: 3982/6400 (62%)\n",
      "\n",
      "\n",
      "Train Epoch: 60\tmaintain_Accuracy: 5881/12800 (46%)\n",
      "\n",
      "alpha: 0.6253396613732468\n",
      "\n",
      "Test Epoch: 60\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 60\tmaintain_Accuracy: 4950/10593 (47%)\n",
      "\n",
      "tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.0\tLoss: 0.417161\n",
      "tensor(0.4194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.2\tLoss: 0.419403\n",
      "tensor(0.4022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.4\tLoss: 0.402212\n",
      "tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.6\tLoss: 0.397945\n",
      "tensor(0.4351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:61 0.8\tLoss: 0.435131\n",
      "\n",
      "Test Epoch: 61\tAttack_Accuracy: 278/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 61\tmaintain_Accuracy: 5017/10593 (47%)\n",
      "\n",
      "tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.0\tLoss: 0.386665\n",
      "tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.2\tLoss: 0.407120\n",
      "tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.4\tLoss: 0.400679\n",
      "tensor(0.3971, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.6\tLoss: 0.397072\n",
      "tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:62 0.8\tLoss: 0.391036\n",
      "\n",
      "Test Epoch: 62\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 62\tmaintain_Accuracy: 5005/10593 (47%)\n",
      "\n",
      "tensor(0.4380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.0\tLoss: 0.437955\n",
      "tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.2\tLoss: 0.364335\n",
      "tensor(0.4181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.4\tLoss: 0.418056\n",
      "tensor(0.4208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.6\tLoss: 0.420811\n",
      "tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:63 0.8\tLoss: 0.414051\n",
      "\n",
      "Test Epoch: 63\tAttack_Accuracy: 270/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 63\tmaintain_Accuracy: 5028/10593 (47%)\n",
      "\n",
      "tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.0\tLoss: 0.389508\n",
      "tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.2\tLoss: 0.391454\n",
      "tensor(0.4204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.4\tLoss: 0.420420\n",
      "tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.6\tLoss: 0.402410\n",
      "tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:64 0.8\tLoss: 0.365759\n",
      "\n",
      "Test Epoch: 64\tAttack_Accuracy: 274/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 64\tmaintain_Accuracy: 5058/10593 (48%)\n",
      "\n",
      "tensor(0.4161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.0\tLoss: 0.416059\n",
      "tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.2\tLoss: 0.378755\n",
      "tensor(0.4239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.4\tLoss: 0.423935\n",
      "tensor(0.4326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.6\tLoss: 0.432644\n",
      "tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:65 0.8\tLoss: 0.377481\n",
      "\n",
      "Train Epoch: 65\tAttack_Accuracy: 4133/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 65\tmaintain_Accuracy: 5825/12800 (46%)\n",
      "\n",
      "alpha: 0.564446480342796\n",
      "\n",
      "Test Epoch: 65\tAttack_Accuracy: 283/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 65\tmaintain_Accuracy: 4956/10593 (47%)\n",
      "\n",
      "tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.0\tLoss: 0.391466\n",
      "tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.2\tLoss: 0.378269\n",
      "tensor(0.4027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.4\tLoss: 0.402680\n",
      "tensor(0.4221, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.6\tLoss: 0.422107\n",
      "tensor(0.4056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:66 0.8\tLoss: 0.405574\n",
      "\n",
      "Test Epoch: 66\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 66\tmaintain_Accuracy: 4912/10593 (46%)\n",
      "\n",
      "tensor(0.3777, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.0\tLoss: 0.377702\n",
      "tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.2\tLoss: 0.361502\n",
      "tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.4\tLoss: 0.412836\n",
      "tensor(0.4458, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.6\tLoss: 0.445830\n",
      "tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:67 0.8\tLoss: 0.370123\n",
      "\n",
      "Test Epoch: 67\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 67\tmaintain_Accuracy: 5014/10593 (47%)\n",
      "\n",
      "tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.0\tLoss: 0.425570\n",
      "tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.2\tLoss: 0.394565\n",
      "tensor(0.3799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.4\tLoss: 0.379933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.6\tLoss: 0.403402\n",
      "tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:68 0.8\tLoss: 0.386134\n",
      "\n",
      "Test Epoch: 68\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 68\tmaintain_Accuracy: 4950/10593 (47%)\n",
      "\n",
      "tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.0\tLoss: 0.384250\n",
      "tensor(0.3872, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.2\tLoss: 0.387211\n",
      "tensor(0.4326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.4\tLoss: 0.432649\n",
      "tensor(0.4214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.6\tLoss: 0.421413\n",
      "tensor(0.3727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:69 0.8\tLoss: 0.372732\n",
      "\n",
      "Test Epoch: 69\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 69\tmaintain_Accuracy: 4919/10593 (46%)\n",
      "\n",
      "tensor(0.4331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.0\tLoss: 0.433095\n",
      "tensor(0.3836, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.2\tLoss: 0.383557\n",
      "tensor(0.3960, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.4\tLoss: 0.395978\n",
      "tensor(0.4283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.6\tLoss: 0.428333\n",
      "tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:70 0.8\tLoss: 0.397659\n",
      "\n",
      "Train Epoch: 70\tAttack_Accuracy: 3952/6400 (62%)\n",
      "\n",
      "\n",
      "Train Epoch: 70\tmaintain_Accuracy: 5951/12800 (46%)\n",
      "\n",
      "alpha: 0.2776568912748473\n",
      "\n",
      "Test Epoch: 70\tAttack_Accuracy: 270/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 70\tmaintain_Accuracy: 5058/10593 (48%)\n",
      "\n",
      "tensor(0.3773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.0\tLoss: 0.377250\n",
      "tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.2\tLoss: 0.405904\n",
      "tensor(0.3987, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.4\tLoss: 0.398693\n",
      "tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.6\tLoss: 0.399656\n",
      "tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:71 0.8\tLoss: 0.402034\n",
      "\n",
      "Test Epoch: 71\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 71\tmaintain_Accuracy: 4911/10593 (46%)\n",
      "\n",
      "tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.0\tLoss: 0.421312\n",
      "tensor(0.4248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.2\tLoss: 0.424773\n",
      "tensor(0.4630, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.4\tLoss: 0.463032\n",
      "tensor(0.4266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.6\tLoss: 0.426601\n",
      "tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:72 0.8\tLoss: 0.367509\n",
      "\n",
      "Test Epoch: 72\tAttack_Accuracy: 277/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 72\tmaintain_Accuracy: 5018/10593 (47%)\n",
      "\n",
      "tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.0\tLoss: 0.420247\n",
      "tensor(0.3884, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.2\tLoss: 0.388352\n",
      "tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.4\tLoss: 0.394047\n",
      "tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.6\tLoss: 0.396700\n",
      "tensor(0.4085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:73 0.8\tLoss: 0.408523\n",
      "\n",
      "Test Epoch: 73\tAttack_Accuracy: 286/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 73\tmaintain_Accuracy: 5017/10593 (47%)\n",
      "\n",
      "tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.0\tLoss: 0.386518\n",
      "tensor(0.3787, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.2\tLoss: 0.378747\n",
      "tensor(0.4109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.4\tLoss: 0.410875\n",
      "tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.6\tLoss: 0.389143\n",
      "tensor(0.4149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:74 0.8\tLoss: 0.414900\n",
      "\n",
      "Test Epoch: 74\tAttack_Accuracy: 283/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 74\tmaintain_Accuracy: 5014/10593 (47%)\n",
      "\n",
      "tensor(0.3866, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.0\tLoss: 0.386604\n",
      "tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.2\tLoss: 0.397817\n",
      "tensor(0.4167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.4\tLoss: 0.416670\n",
      "tensor(0.3952, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.6\tLoss: 0.395195\n",
      "tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:75 0.8\tLoss: 0.388934\n",
      "\n",
      "Train Epoch: 75\tAttack_Accuracy: 4129/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 75\tmaintain_Accuracy: 5939/12800 (46%)\n",
      "\n",
      "alpha: 0.5766829852558136\n",
      "\n",
      "Test Epoch: 75\tAttack_Accuracy: 274/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 75\tmaintain_Accuracy: 5015/10593 (47%)\n",
      "\n",
      "tensor(0.4540, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.0\tLoss: 0.454002\n",
      "tensor(0.4421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.2\tLoss: 0.442133\n",
      "tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.4\tLoss: 0.395291\n",
      "tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.6\tLoss: 0.398044\n",
      "tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:76 0.8\tLoss: 0.434191\n",
      "\n",
      "Test Epoch: 76\tAttack_Accuracy: 282/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 76\tmaintain_Accuracy: 4908/10593 (46%)\n",
      "\n",
      "tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.0\tLoss: 0.382734\n",
      "tensor(0.4394, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.2\tLoss: 0.439357\n",
      "tensor(0.4314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.4\tLoss: 0.431414\n",
      "tensor(0.4145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.6\tLoss: 0.414467\n",
      "tensor(0.4190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:77 0.8\tLoss: 0.419047\n",
      "\n",
      "Test Epoch: 77\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 77\tmaintain_Accuracy: 4968/10593 (47%)\n",
      "\n",
      "tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.0\tLoss: 0.369877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.2\tLoss: 0.399042\n",
      "tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.4\tLoss: 0.375003\n",
      "tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.6\tLoss: 0.382994\n",
      "tensor(0.4016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:78 0.8\tLoss: 0.401614\n",
      "\n",
      "Test Epoch: 78\tAttack_Accuracy: 262/412 (64%)\n",
      "\n",
      "\n",
      "Test Epoch: 78\tmaintain_Accuracy: 5156/10593 (49%)\n",
      "\n",
      "tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.0\tLoss: 0.403078\n",
      "tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.2\tLoss: 0.381691\n",
      "tensor(0.4057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.4\tLoss: 0.405690\n",
      "tensor(0.3923, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.6\tLoss: 0.392310\n",
      "tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:79 0.8\tLoss: 0.366839\n",
      "\n",
      "Test Epoch: 79\tAttack_Accuracy: 286/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 79\tmaintain_Accuracy: 5045/10593 (48%)\n",
      "\n",
      "tensor(0.4038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.0\tLoss: 0.403800\n",
      "tensor(0.3863, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.2\tLoss: 0.386259\n",
      "tensor(0.3999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.4\tLoss: 0.399868\n",
      "tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.6\tLoss: 0.369410\n",
      "tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:80 0.8\tLoss: 0.383704\n",
      "\n",
      "Train Epoch: 80\tAttack_Accuracy: 4112/6400 (64%)\n",
      "\n",
      "\n",
      "Train Epoch: 80\tmaintain_Accuracy: 5996/12800 (47%)\n",
      "\n",
      "alpha: 0.5711659846487881\n",
      "\n",
      "Test Epoch: 80\tAttack_Accuracy: 272/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 80\tmaintain_Accuracy: 5139/10593 (49%)\n",
      "\n",
      "tensor(0.4331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.0\tLoss: 0.433143\n",
      "tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.2\tLoss: 0.408680\n",
      "tensor(0.4345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.4\tLoss: 0.434486\n",
      "tensor(0.4218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.6\tLoss: 0.421779\n",
      "tensor(0.4101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:81 0.8\tLoss: 0.410104\n",
      "\n",
      "Test Epoch: 81\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 81\tmaintain_Accuracy: 5123/10593 (48%)\n",
      "\n",
      "tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.0\tLoss: 0.411649\n",
      "tensor(0.4369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.2\tLoss: 0.436928\n",
      "tensor(0.4130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.4\tLoss: 0.412979\n",
      "tensor(0.4439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.6\tLoss: 0.443888\n",
      "tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:82 0.8\tLoss: 0.450646\n",
      "\n",
      "Test Epoch: 82\tAttack_Accuracy: 280/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 82\tmaintain_Accuracy: 5265/10593 (50%)\n",
      "\n",
      "tensor(0.3641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.0\tLoss: 0.364060\n",
      "tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.2\tLoss: 0.374612\n",
      "tensor(0.4204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.4\tLoss: 0.420371\n",
      "tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.6\tLoss: 0.408843\n",
      "tensor(0.4159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:83 0.8\tLoss: 0.415855\n",
      "\n",
      "Test Epoch: 83\tAttack_Accuracy: 278/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 83\tmaintain_Accuracy: 5140/10593 (49%)\n",
      "\n",
      "tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.0\tLoss: 0.405546\n",
      "tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.2\tLoss: 0.393927\n",
      "tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.4\tLoss: 0.415341\n",
      "tensor(0.4240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.6\tLoss: 0.424021\n",
      "tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:84 0.8\tLoss: 0.398832\n",
      "\n",
      "Test Epoch: 84\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 84\tmaintain_Accuracy: 5147/10593 (49%)\n",
      "\n",
      "tensor(0.4140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.0\tLoss: 0.413981\n",
      "tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.2\tLoss: 0.350789\n",
      "tensor(0.4162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.4\tLoss: 0.416238\n",
      "tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.6\tLoss: 0.399719\n",
      "tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:85 0.8\tLoss: 0.382669\n",
      "\n",
      "Train Epoch: 85\tAttack_Accuracy: 4160/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 85\tmaintain_Accuracy: 5783/12800 (45%)\n",
      "\n",
      "alpha: 0.6136936256729845\n",
      "\n",
      "Test Epoch: 85\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 85\tmaintain_Accuracy: 4917/10593 (46%)\n",
      "\n",
      "tensor(0.3972, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.0\tLoss: 0.397171\n",
      "tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.2\tLoss: 0.394542\n",
      "tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.4\tLoss: 0.389364\n",
      "tensor(0.4698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.6\tLoss: 0.469767\n",
      "tensor(0.4550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:86 0.8\tLoss: 0.455011\n",
      "\n",
      "Test Epoch: 86\tAttack_Accuracy: 262/412 (64%)\n",
      "\n",
      "\n",
      "Test Epoch: 86\tmaintain_Accuracy: 5144/10593 (49%)\n",
      "\n",
      "tensor(0.4445, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.0\tLoss: 0.444517\n",
      "tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.2\tLoss: 0.395618\n",
      "tensor(0.4463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.4\tLoss: 0.446253\n",
      "tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.6\tLoss: 0.402873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:87 0.8\tLoss: 0.417210\n",
      "\n",
      "Test Epoch: 87\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 87\tmaintain_Accuracy: 4878/10593 (46%)\n",
      "\n",
      "tensor(0.3793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.0\tLoss: 0.379281\n",
      "tensor(0.4100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.2\tLoss: 0.409968\n",
      "tensor(0.4060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.4\tLoss: 0.406008\n",
      "tensor(0.4468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.6\tLoss: 0.446819\n",
      "tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:88 0.8\tLoss: 0.370549\n",
      "\n",
      "Test Epoch: 88\tAttack_Accuracy: 270/412 (66%)\n",
      "\n",
      "\n",
      "Test Epoch: 88\tmaintain_Accuracy: 4986/10593 (47%)\n",
      "\n",
      "tensor(0.4427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.0\tLoss: 0.442694\n",
      "tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.2\tLoss: 0.362581\n",
      "tensor(0.4153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.4\tLoss: 0.415341\n",
      "tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.6\tLoss: 0.391245\n",
      "tensor(0.4205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:89 0.8\tLoss: 0.420460\n",
      "\n",
      "Test Epoch: 89\tAttack_Accuracy: 285/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 89\tmaintain_Accuracy: 4932/10593 (47%)\n",
      "\n",
      "tensor(0.4155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.0\tLoss: 0.415473\n",
      "tensor(0.4103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.2\tLoss: 0.410301\n",
      "tensor(0.4011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.4\tLoss: 0.401058\n",
      "tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.6\tLoss: 0.397253\n",
      "tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:90 0.8\tLoss: 0.424591\n",
      "\n",
      "Train Epoch: 90\tAttack_Accuracy: 4147/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 90\tmaintain_Accuracy: 5896/12800 (46%)\n",
      "\n",
      "alpha: 0.638996889060696\n",
      "\n",
      "Test Epoch: 90\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 90\tmaintain_Accuracy: 4949/10593 (47%)\n",
      "\n",
      "tensor(0.3804, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.0\tLoss: 0.380423\n",
      "tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.2\tLoss: 0.408684\n",
      "tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.4\tLoss: 0.388046\n",
      "tensor(0.3840, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.6\tLoss: 0.383996\n",
      "tensor(0.4054, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:91 0.8\tLoss: 0.405440\n",
      "\n",
      "Test Epoch: 91\tAttack_Accuracy: 286/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 91\tmaintain_Accuracy: 4945/10593 (47%)\n",
      "\n",
      "tensor(0.4126, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.0\tLoss: 0.412594\n",
      "tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.2\tLoss: 0.433500\n",
      "tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.4\tLoss: 0.407062\n",
      "tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.6\tLoss: 0.391528\n",
      "tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:92 0.8\tLoss: 0.395278\n",
      "\n",
      "Test Epoch: 92\tAttack_Accuracy: 283/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 92\tmaintain_Accuracy: 4887/10593 (46%)\n",
      "\n",
      "tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.0\tLoss: 0.417219\n",
      "tensor(0.4061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.2\tLoss: 0.406119\n",
      "tensor(0.4564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.4\tLoss: 0.456416\n",
      "tensor(0.4266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.6\tLoss: 0.426591\n",
      "tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:93 0.8\tLoss: 0.370585\n",
      "\n",
      "Test Epoch: 93\tAttack_Accuracy: 280/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 93\tmaintain_Accuracy: 4909/10593 (46%)\n",
      "\n",
      "tensor(0.4429, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.0\tLoss: 0.442875\n",
      "tensor(0.4721, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.2\tLoss: 0.472137\n",
      "tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.4\tLoss: 0.401257\n",
      "tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.6\tLoss: 0.415597\n",
      "tensor(0.4445, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:94 0.8\tLoss: 0.444506\n",
      "\n",
      "Test Epoch: 94\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 94\tmaintain_Accuracy: 4861/10593 (46%)\n",
      "\n",
      "tensor(0.4253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.0\tLoss: 0.425268\n",
      "tensor(0.3993, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.2\tLoss: 0.399300\n",
      "tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.4\tLoss: 0.434361\n",
      "tensor(0.4034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.6\tLoss: 0.403438\n",
      "tensor(0.4189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:95 0.8\tLoss: 0.418928\n",
      "\n",
      "Train Epoch: 95\tAttack_Accuracy: 4185/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 95\tmaintain_Accuracy: 5736/12800 (45%)\n",
      "\n",
      "alpha: 0.3532791035266681\n",
      "\n",
      "Test Epoch: 95\tAttack_Accuracy: 288/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 95\tmaintain_Accuracy: 4896/10593 (46%)\n",
      "\n",
      "tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.0\tLoss: 0.396313\n",
      "tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.2\tLoss: 0.360581\n",
      "tensor(0.4150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.4\tLoss: 0.415012\n",
      "tensor(0.4463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.6\tLoss: 0.446290\n",
      "tensor(0.4355, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:96 0.8\tLoss: 0.435503\n",
      "\n",
      "Test Epoch: 96\tAttack_Accuracy: 280/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 96\tmaintain_Accuracy: 4901/10593 (46%)\n",
      "\n",
      "tensor(0.4414, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.0\tLoss: 0.441361\n",
      "tensor(0.4028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.2\tLoss: 0.402820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.4\tLoss: 0.423025\n",
      "tensor(0.4319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.6\tLoss: 0.431857\n",
      "tensor(0.4306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:97 0.8\tLoss: 0.430612\n",
      "\n",
      "Test Epoch: 97\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 97\tmaintain_Accuracy: 4783/10593 (45%)\n",
      "\n",
      "tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.0\tLoss: 0.371958\n",
      "tensor(0.3975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.2\tLoss: 0.397512\n",
      "tensor(0.4083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.4\tLoss: 0.408303\n",
      "tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.6\tLoss: 0.403221\n",
      "tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:98 0.8\tLoss: 0.411464\n",
      "\n",
      "Test Epoch: 98\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 98\tmaintain_Accuracy: 4863/10593 (46%)\n",
      "\n",
      "tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.0\tLoss: 0.365463\n",
      "tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.2\tLoss: 0.418207\n",
      "tensor(0.4581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.4\tLoss: 0.458063\n",
      "tensor(0.4676, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.6\tLoss: 0.467595\n",
      "tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:99 0.8\tLoss: 0.394668\n",
      "\n",
      "Test Epoch: 99\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 99\tmaintain_Accuracy: 4850/10593 (46%)\n",
      "\n",
      "tensor(0.4194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.0\tLoss: 0.419425\n",
      "tensor(0.4333, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.2\tLoss: 0.433325\n",
      "tensor(0.4040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.4\tLoss: 0.403981\n",
      "tensor(0.4091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.6\tLoss: 0.409097\n",
      "tensor(0.4504, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:100 0.8\tLoss: 0.450350\n",
      "\n",
      "Train Epoch: 100\tAttack_Accuracy: 4164/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 100\tmaintain_Accuracy: 5839/12800 (46%)\n",
      "\n",
      "alpha: 0.6523154521267943\n",
      "\n",
      "Test Epoch: 100\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 100\tmaintain_Accuracy: 4912/10593 (46%)\n",
      "\n",
      "tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.0\tLoss: 0.406217\n",
      "tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.2\tLoss: 0.384495\n",
      "tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.4\tLoss: 0.397659\n",
      "tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.6\tLoss: 0.390805\n",
      "tensor(0.4051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:101 0.8\tLoss: 0.405052\n",
      "\n",
      "Test Epoch: 101\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 101\tmaintain_Accuracy: 5021/10593 (47%)\n",
      "\n",
      "tensor(0.4280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.0\tLoss: 0.428004\n",
      "tensor(0.4147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.2\tLoss: 0.414673\n",
      "tensor(0.4185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.4\tLoss: 0.418513\n",
      "tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.6\tLoss: 0.370598\n",
      "tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:102 0.8\tLoss: 0.420089\n",
      "\n",
      "Test Epoch: 102\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 102\tmaintain_Accuracy: 4900/10593 (46%)\n",
      "\n",
      "tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.0\tLoss: 0.410381\n",
      "tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.2\tLoss: 0.421281\n",
      "tensor(0.4263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.4\tLoss: 0.426271\n",
      "tensor(0.4791, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.6\tLoss: 0.479084\n",
      "tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:103 0.8\tLoss: 0.402894\n",
      "\n",
      "Test Epoch: 103\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 103\tmaintain_Accuracy: 4824/10593 (46%)\n",
      "\n",
      "tensor(0.4387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.0\tLoss: 0.438668\n",
      "tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.2\tLoss: 0.405946\n",
      "tensor(0.4162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.4\tLoss: 0.416158\n",
      "tensor(0.4244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.6\tLoss: 0.424365\n",
      "tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:104 0.8\tLoss: 0.390886\n",
      "\n",
      "Test Epoch: 104\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 104\tmaintain_Accuracy: 4938/10593 (47%)\n",
      "\n",
      "tensor(0.3815, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.0\tLoss: 0.381538\n",
      "tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.2\tLoss: 0.386511\n",
      "tensor(0.4174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.4\tLoss: 0.417435\n",
      "tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.6\tLoss: 0.383472\n",
      "tensor(0.3894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:105 0.8\tLoss: 0.389432\n",
      "\n",
      "Train Epoch: 105\tAttack_Accuracy: 4096/6400 (64%)\n",
      "\n",
      "\n",
      "Train Epoch: 105\tmaintain_Accuracy: 5907/12800 (46%)\n",
      "\n",
      "alpha: 0.5262508651640357\n",
      "\n",
      "Test Epoch: 105\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 105\tmaintain_Accuracy: 4946/10593 (47%)\n",
      "\n",
      "tensor(0.4244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.0\tLoss: 0.424389\n",
      "tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.2\tLoss: 0.391252\n",
      "tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.4\tLoss: 0.389930\n",
      "tensor(0.3973, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.6\tLoss: 0.397326\n",
      "tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:106 0.8\tLoss: 0.356333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 106\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 106\tmaintain_Accuracy: 5028/10593 (47%)\n",
      "\n",
      "tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.0\tLoss: 0.376818\n",
      "tensor(0.4060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.2\tLoss: 0.405952\n",
      "tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.4\tLoss: 0.389580\n",
      "tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.6\tLoss: 0.396324\n",
      "tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:107 0.8\tLoss: 0.384495\n",
      "\n",
      "Test Epoch: 107\tAttack_Accuracy: 268/412 (65%)\n",
      "\n",
      "\n",
      "Test Epoch: 107\tmaintain_Accuracy: 5079/10593 (48%)\n",
      "\n",
      "tensor(0.3972, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.0\tLoss: 0.397219\n",
      "tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.2\tLoss: 0.369421\n",
      "tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.4\tLoss: 0.400747\n",
      "tensor(0.3999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.6\tLoss: 0.399859\n",
      "tensor(0.4375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:108 0.8\tLoss: 0.437499\n",
      "\n",
      "Test Epoch: 108\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 108\tmaintain_Accuracy: 5010/10593 (47%)\n",
      "\n",
      "tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.0\tLoss: 0.345189\n",
      "tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.2\tLoss: 0.378392\n",
      "tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.4\tLoss: 0.353997\n",
      "tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.6\tLoss: 0.369147\n",
      "tensor(0.4068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:109 0.8\tLoss: 0.406750\n",
      "\n",
      "Test Epoch: 109\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 109\tmaintain_Accuracy: 5039/10593 (48%)\n",
      "\n",
      "tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.0\tLoss: 0.380822\n",
      "tensor(0.4052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.2\tLoss: 0.405206\n",
      "tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.4\tLoss: 0.360243\n",
      "tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.6\tLoss: 0.388668\n",
      "tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:110 0.8\tLoss: 0.376373\n",
      "\n",
      "Train Epoch: 110\tAttack_Accuracy: 4185/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 110\tmaintain_Accuracy: 5955/12800 (47%)\n",
      "\n",
      "alpha: 0.4303873340445558\n",
      "\n",
      "Test Epoch: 110\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 110\tmaintain_Accuracy: 5001/10593 (47%)\n",
      "\n",
      "tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.0\tLoss: 0.363266\n",
      "tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.2\tLoss: 0.327098\n",
      "tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.4\tLoss: 0.352739\n",
      "tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.6\tLoss: 0.372586\n",
      "tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:111 0.8\tLoss: 0.368800\n",
      "\n",
      "Test Epoch: 111\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 111\tmaintain_Accuracy: 4959/10593 (47%)\n",
      "\n",
      "tensor(0.3790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.0\tLoss: 0.379013\n",
      "tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.2\tLoss: 0.354156\n",
      "tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.4\tLoss: 0.377854\n",
      "tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.6\tLoss: 0.349604\n",
      "tensor(0.3843, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:112 0.8\tLoss: 0.384309\n",
      "\n",
      "Test Epoch: 112\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 112\tmaintain_Accuracy: 5007/10593 (47%)\n",
      "\n",
      "tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.0\tLoss: 0.361093\n",
      "tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.2\tLoss: 0.389884\n",
      "tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.4\tLoss: 0.394007\n",
      "tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.6\tLoss: 0.400698\n",
      "tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:113 0.8\tLoss: 0.380500\n",
      "\n",
      "Test Epoch: 113\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 113\tmaintain_Accuracy: 5061/10593 (48%)\n",
      "\n",
      "tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.0\tLoss: 0.398753\n",
      "tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.2\tLoss: 0.375920\n",
      "tensor(0.4212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.4\tLoss: 0.421177\n",
      "tensor(0.4336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.6\tLoss: 0.433581\n",
      "tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:114 0.8\tLoss: 0.340783\n",
      "\n",
      "Test Epoch: 114\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 114\tmaintain_Accuracy: 5080/10593 (48%)\n",
      "\n",
      "tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.0\tLoss: 0.355371\n",
      "tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.2\tLoss: 0.397691\n",
      "tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.4\tLoss: 0.390053\n",
      "tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.6\tLoss: 0.364368\n",
      "tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:115 0.8\tLoss: 0.353764\n",
      "\n",
      "Train Epoch: 115\tAttack_Accuracy: 4249/6400 (66%)\n",
      "\n",
      "\n",
      "Train Epoch: 115\tmaintain_Accuracy: 6124/12800 (48%)\n",
      "\n",
      "alpha: 0.6060013837676664\n",
      "\n",
      "Test Epoch: 115\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 115\tmaintain_Accuracy: 5089/10593 (48%)\n",
      "\n",
      "tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.0\tLoss: 0.352995\n",
      "tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.2\tLoss: 0.338965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3699, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.4\tLoss: 0.369887\n",
      "tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.6\tLoss: 0.367209\n",
      "tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:116 0.8\tLoss: 0.369794\n",
      "\n",
      "Test Epoch: 116\tAttack_Accuracy: 277/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 116\tmaintain_Accuracy: 5084/10593 (48%)\n",
      "\n",
      "tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.0\tLoss: 0.356112\n",
      "tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.2\tLoss: 0.375491\n",
      "tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.4\tLoss: 0.367532\n",
      "tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.6\tLoss: 0.367858\n",
      "tensor(0.3859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:117 0.8\tLoss: 0.385932\n",
      "\n",
      "Test Epoch: 117\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 117\tmaintain_Accuracy: 5076/10593 (48%)\n",
      "\n",
      "tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.0\tLoss: 0.352577\n",
      "tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.2\tLoss: 0.374186\n",
      "tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.4\tLoss: 0.328997\n",
      "tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.6\tLoss: 0.368118\n",
      "tensor(0.4067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:118 0.8\tLoss: 0.406689\n",
      "\n",
      "Test Epoch: 118\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 118\tmaintain_Accuracy: 5014/10593 (47%)\n",
      "\n",
      "tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.0\tLoss: 0.359438\n",
      "tensor(0.3645, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.2\tLoss: 0.364515\n",
      "tensor(0.3786, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.4\tLoss: 0.378568\n",
      "tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.6\tLoss: 0.374159\n",
      "tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:119 0.8\tLoss: 0.378543\n",
      "\n",
      "Test Epoch: 119\tAttack_Accuracy: 268/412 (65%)\n",
      "\n",
      "\n",
      "Test Epoch: 119\tmaintain_Accuracy: 5170/10593 (49%)\n",
      "\n",
      "tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.0\tLoss: 0.360972\n",
      "tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.2\tLoss: 0.351093\n",
      "tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.4\tLoss: 0.328555\n",
      "tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.6\tLoss: 0.412260\n",
      "tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:120 0.8\tLoss: 0.366201\n",
      "\n",
      "Train Epoch: 120\tAttack_Accuracy: 4040/6400 (63%)\n",
      "\n",
      "\n",
      "Train Epoch: 120\tmaintain_Accuracy: 6164/12800 (48%)\n",
      "\n",
      "alpha: 0.9744714776642396\n",
      "\n",
      "Test Epoch: 120\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 120\tmaintain_Accuracy: 5070/10593 (48%)\n",
      "\n",
      "tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.0\tLoss: 0.391173\n",
      "tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.2\tLoss: 0.324487\n",
      "tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.4\tLoss: 0.335236\n",
      "tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.6\tLoss: 0.370873\n",
      "tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:121 0.8\tLoss: 0.353385\n",
      "\n",
      "Test Epoch: 121\tAttack_Accuracy: 283/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 121\tmaintain_Accuracy: 5125/10593 (48%)\n",
      "\n",
      "tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.0\tLoss: 0.357788\n",
      "tensor(0.3835, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.2\tLoss: 0.383525\n",
      "tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.4\tLoss: 0.355549\n",
      "tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.6\tLoss: 0.375179\n",
      "tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:122 0.8\tLoss: 0.367838\n",
      "\n",
      "Test Epoch: 122\tAttack_Accuracy: 277/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 122\tmaintain_Accuracy: 5212/10593 (49%)\n",
      "\n",
      "tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.0\tLoss: 0.341098\n",
      "tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.2\tLoss: 0.387069\n",
      "tensor(0.3792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.4\tLoss: 0.379248\n",
      "tensor(0.3909, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.6\tLoss: 0.390854\n",
      "tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:123 0.8\tLoss: 0.360640\n",
      "\n",
      "Test Epoch: 123\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 123\tmaintain_Accuracy: 5121/10593 (48%)\n",
      "\n",
      "tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.0\tLoss: 0.373213\n",
      "tensor(0.3671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.2\tLoss: 0.367057\n",
      "tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.4\tLoss: 0.373620\n",
      "tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.6\tLoss: 0.342629\n",
      "tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:124 0.8\tLoss: 0.376313\n",
      "\n",
      "Test Epoch: 124\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 124\tmaintain_Accuracy: 5118/10593 (48%)\n",
      "\n",
      "tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.0\tLoss: 0.345496\n",
      "tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.2\tLoss: 0.368070\n",
      "tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.4\tLoss: 0.369338\n",
      "tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.6\tLoss: 0.337463\n",
      "tensor(0.3849, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:125 0.8\tLoss: 0.384901\n",
      "\n",
      "Train Epoch: 125\tAttack_Accuracy: 4118/6400 (64%)\n",
      "\n",
      "\n",
      "Train Epoch: 125\tmaintain_Accuracy: 6192/12800 (48%)\n",
      "\n",
      "alpha: 0.398649762494723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 125\tAttack_Accuracy: 282/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 125\tmaintain_Accuracy: 5128/10593 (48%)\n",
      "\n",
      "tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.0\tLoss: 0.339918\n",
      "tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.2\tLoss: 0.352538\n",
      "tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.4\tLoss: 0.371286\n",
      "tensor(0.3860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.6\tLoss: 0.386027\n",
      "tensor(0.3844, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:126 0.8\tLoss: 0.384432\n",
      "\n",
      "Test Epoch: 126\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 126\tmaintain_Accuracy: 5034/10593 (48%)\n",
      "\n",
      "tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.0\tLoss: 0.384465\n",
      "tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.2\tLoss: 0.309231\n",
      "tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.4\tLoss: 0.376388\n",
      "tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.6\tLoss: 0.367787\n",
      "tensor(0.3651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:127 0.8\tLoss: 0.365110\n",
      "\n",
      "Test Epoch: 127\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 127\tmaintain_Accuracy: 5113/10593 (48%)\n",
      "\n",
      "tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.0\tLoss: 0.377553\n",
      "tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.2\tLoss: 0.371568\n",
      "tensor(0.3950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.4\tLoss: 0.394962\n",
      "tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.6\tLoss: 0.344921\n",
      "tensor(0.3457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:128 0.8\tLoss: 0.345733\n",
      "\n",
      "Test Epoch: 128\tAttack_Accuracy: 286/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 128\tmaintain_Accuracy: 5199/10593 (49%)\n",
      "\n",
      "tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.0\tLoss: 0.355773\n",
      "tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.2\tLoss: 0.336757\n",
      "tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.4\tLoss: 0.393700\n",
      "tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.6\tLoss: 0.383000\n",
      "tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:129 0.8\tLoss: 0.392798\n",
      "\n",
      "Test Epoch: 129\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 129\tmaintain_Accuracy: 5151/10593 (49%)\n",
      "\n",
      "tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.0\tLoss: 0.359502\n",
      "tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.2\tLoss: 0.368738\n",
      "tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.4\tLoss: 0.335021\n",
      "tensor(0.3618, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.6\tLoss: 0.361809\n",
      "tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:130 0.8\tLoss: 0.379786\n",
      "\n",
      "Train Epoch: 130\tAttack_Accuracy: 4216/6400 (66%)\n",
      "\n",
      "\n",
      "Train Epoch: 130\tmaintain_Accuracy: 6211/12800 (49%)\n",
      "\n",
      "alpha: 0.4719626090759262\n",
      "\n",
      "Test Epoch: 130\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 130\tmaintain_Accuracy: 5126/10593 (48%)\n",
      "\n",
      "tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.0\tLoss: 0.368556\n",
      "tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.2\tLoss: 0.335735\n",
      "tensor(0.3950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.4\tLoss: 0.394970\n",
      "tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.6\tLoss: 0.343670\n",
      "tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:131 0.8\tLoss: 0.325110\n",
      "\n",
      "Test Epoch: 131\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 131\tmaintain_Accuracy: 5140/10593 (49%)\n",
      "\n",
      "tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.0\tLoss: 0.347895\n",
      "tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.2\tLoss: 0.380315\n",
      "tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.4\tLoss: 0.376860\n",
      "tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.6\tLoss: 0.359831\n",
      "tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:132 0.8\tLoss: 0.380794\n",
      "\n",
      "Test Epoch: 132\tAttack_Accuracy: 283/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 132\tmaintain_Accuracy: 5263/10593 (50%)\n",
      "\n",
      "tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.0\tLoss: 0.338349\n",
      "tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.2\tLoss: 0.356683\n",
      "tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.4\tLoss: 0.333719\n",
      "tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.6\tLoss: 0.339847\n",
      "tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:133 0.8\tLoss: 0.380758\n",
      "\n",
      "Test Epoch: 133\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 133\tmaintain_Accuracy: 5172/10593 (49%)\n",
      "\n",
      "tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.0\tLoss: 0.421255\n",
      "tensor(0.3816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.2\tLoss: 0.381568\n",
      "tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.4\tLoss: 0.372566\n",
      "tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.6\tLoss: 0.343371\n",
      "tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:134 0.8\tLoss: 0.340907\n",
      "\n",
      "Test Epoch: 134\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 134\tmaintain_Accuracy: 5082/10593 (48%)\n",
      "\n",
      "tensor(0.3823, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.0\tLoss: 0.382303\n",
      "tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.2\tLoss: 0.326856\n",
      "tensor(0.3882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.4\tLoss: 0.388212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.6\tLoss: 0.392669\n",
      "tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:135 0.8\tLoss: 0.369025\n",
      "\n",
      "Train Epoch: 135\tAttack_Accuracy: 4175/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 135\tmaintain_Accuracy: 6109/12800 (48%)\n",
      "\n",
      "alpha: 0.2927963784332573\n",
      "\n",
      "Test Epoch: 135\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 135\tmaintain_Accuracy: 5173/10593 (49%)\n",
      "\n",
      "tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.0\tLoss: 0.383027\n",
      "tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.2\tLoss: 0.330795\n",
      "tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.4\tLoss: 0.383930\n",
      "tensor(0.3682, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.6\tLoss: 0.368153\n",
      "tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:136 0.8\tLoss: 0.337502\n",
      "\n",
      "Test Epoch: 136\tAttack_Accuracy: 281/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 136\tmaintain_Accuracy: 5139/10593 (49%)\n",
      "\n",
      "tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.0\tLoss: 0.330331\n",
      "tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.2\tLoss: 0.336791\n",
      "tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.4\tLoss: 0.396437\n",
      "tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.6\tLoss: 0.364254\n",
      "tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:137 0.8\tLoss: 0.321784\n",
      "\n",
      "Test Epoch: 137\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 137\tmaintain_Accuracy: 5196/10593 (49%)\n",
      "\n",
      "tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.0\tLoss: 0.363596\n",
      "tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.2\tLoss: 0.332555\n",
      "tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.4\tLoss: 0.362839\n",
      "tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.6\tLoss: 0.348606\n",
      "tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:138 0.8\tLoss: 0.338683\n",
      "\n",
      "Test Epoch: 138\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 138\tmaintain_Accuracy: 5194/10593 (49%)\n",
      "\n",
      "tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.0\tLoss: 0.396532\n",
      "tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.2\tLoss: 0.394305\n",
      "tensor(0.3941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.4\tLoss: 0.394093\n",
      "tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.6\tLoss: 0.343644\n",
      "tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:139 0.8\tLoss: 0.396414\n",
      "\n",
      "Test Epoch: 139\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 139\tmaintain_Accuracy: 5126/10593 (48%)\n",
      "\n",
      "tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.0\tLoss: 0.400837\n",
      "tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.2\tLoss: 0.380251\n",
      "tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.4\tLoss: 0.363245\n",
      "tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.6\tLoss: 0.381359\n",
      "tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:140 0.8\tLoss: 0.358654\n",
      "\n",
      "Train Epoch: 140\tAttack_Accuracy: 4231/6400 (66%)\n",
      "\n",
      "\n",
      "Train Epoch: 140\tmaintain_Accuracy: 6241/12800 (49%)\n",
      "\n",
      "alpha: 0.49805850693033027\n",
      "\n",
      "Test Epoch: 140\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 140\tmaintain_Accuracy: 5122/10593 (48%)\n",
      "\n",
      "tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.0\tLoss: 0.370139\n",
      "tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.2\tLoss: 0.370891\n",
      "tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.4\tLoss: 0.373514\n",
      "tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.6\tLoss: 0.343998\n",
      "tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:141 0.8\tLoss: 0.324842\n",
      "\n",
      "Test Epoch: 141\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 141\tmaintain_Accuracy: 5155/10593 (49%)\n",
      "\n",
      "tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.0\tLoss: 0.370820\n",
      "tensor(0.3937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.2\tLoss: 0.393747\n",
      "tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.4\tLoss: 0.388710\n",
      "tensor(0.3869, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.6\tLoss: 0.386857\n",
      "tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:142 0.8\tLoss: 0.352845\n",
      "\n",
      "Test Epoch: 142\tAttack_Accuracy: 282/412 (68%)\n",
      "\n",
      "\n",
      "Test Epoch: 142\tmaintain_Accuracy: 5218/10593 (49%)\n",
      "\n",
      "tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.0\tLoss: 0.374310\n",
      "tensor(0.3838, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.2\tLoss: 0.383824\n",
      "tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.4\tLoss: 0.397358\n",
      "tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.6\tLoss: 0.340522\n",
      "tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:143 0.8\tLoss: 0.357283\n",
      "\n",
      "Test Epoch: 143\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 143\tmaintain_Accuracy: 5124/10593 (48%)\n",
      "\n",
      "tensor(0.3257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.0\tLoss: 0.325726\n",
      "tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.2\tLoss: 0.327196\n",
      "tensor(0.4170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.4\tLoss: 0.416952\n",
      "tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.6\tLoss: 0.341853\n",
      "tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:144 0.8\tLoss: 0.365026\n",
      "\n",
      "Test Epoch: 144\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 144\tmaintain_Accuracy: 5098/10593 (48%)\n",
      "\n",
      "tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.0\tLoss: 0.355718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3877, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.2\tLoss: 0.387738\n",
      "tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.4\tLoss: 0.400226\n",
      "tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.6\tLoss: 0.377940\n",
      "tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:145 0.8\tLoss: 0.392522\n",
      "\n",
      "Train Epoch: 145\tAttack_Accuracy: 4173/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 145\tmaintain_Accuracy: 6141/12800 (48%)\n",
      "\n",
      "alpha: 0.20344393592787757\n",
      "\n",
      "Test Epoch: 145\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 145\tmaintain_Accuracy: 5202/10593 (49%)\n",
      "\n",
      "tensor(0.3805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.0\tLoss: 0.380541\n",
      "tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.2\tLoss: 0.366026\n",
      "tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.4\tLoss: 0.322368\n",
      "tensor(0.3791, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.6\tLoss: 0.379142\n",
      "tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:146 0.8\tLoss: 0.401278\n",
      "\n",
      "Test Epoch: 146\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 146\tmaintain_Accuracy: 5200/10593 (49%)\n",
      "\n",
      "tensor(0.3684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.0\tLoss: 0.368422\n",
      "tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.2\tLoss: 0.375624\n",
      "tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.4\tLoss: 0.326336\n",
      "tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.6\tLoss: 0.382495\n",
      "tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:147 0.8\tLoss: 0.346941\n",
      "\n",
      "Test Epoch: 147\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 147\tmaintain_Accuracy: 5251/10593 (50%)\n",
      "\n",
      "tensor(0.3851, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.0\tLoss: 0.385078\n",
      "tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.2\tLoss: 0.405540\n",
      "tensor(0.3537, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.4\tLoss: 0.353654\n",
      "tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.6\tLoss: 0.367680\n",
      "tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:148 0.8\tLoss: 0.307460\n",
      "\n",
      "Test Epoch: 148\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 148\tmaintain_Accuracy: 5221/10593 (49%)\n",
      "\n",
      "tensor(0.4107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.0\tLoss: 0.410742\n",
      "tensor(0.3749, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.2\tLoss: 0.374883\n",
      "tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.4\tLoss: 0.367607\n",
      "tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.6\tLoss: 0.370700\n",
      "tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:149 0.8\tLoss: 0.335346\n",
      "\n",
      "Test Epoch: 149\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 149\tmaintain_Accuracy: 5252/10593 (50%)\n",
      "\n",
      "tensor(0.3734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.0\tLoss: 0.373373\n",
      "tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.2\tLoss: 0.313164\n",
      "tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.4\tLoss: 0.381737\n",
      "tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.6\tLoss: 0.381923\n",
      "tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:150 0.8\tLoss: 0.329468\n",
      "\n",
      "Train Epoch: 150\tAttack_Accuracy: 4291/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 150\tmaintain_Accuracy: 6309/12800 (49%)\n",
      "\n",
      "alpha: 0.4729825067319598\n",
      "\n",
      "Test Epoch: 150\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 150\tmaintain_Accuracy: 5182/10593 (49%)\n",
      "\n",
      "tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.0\tLoss: 0.393258\n",
      "tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.2\tLoss: 0.376193\n",
      "tensor(0.3661, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.4\tLoss: 0.366120\n",
      "tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.6\tLoss: 0.338711\n",
      "tensor(0.3703, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:151 0.8\tLoss: 0.370347\n",
      "\n",
      "Test Epoch: 151\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 151\tmaintain_Accuracy: 5236/10593 (49%)\n",
      "\n",
      "tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.0\tLoss: 0.322457\n",
      "tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.2\tLoss: 0.366580\n",
      "tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.4\tLoss: 0.355076\n",
      "tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.6\tLoss: 0.318613\n",
      "tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:152 0.8\tLoss: 0.380678\n",
      "\n",
      "Test Epoch: 152\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 152\tmaintain_Accuracy: 5268/10593 (50%)\n",
      "\n",
      "tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.0\tLoss: 0.367828\n",
      "tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.2\tLoss: 0.341061\n",
      "tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.4\tLoss: 0.371116\n",
      "tensor(0.3743, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.6\tLoss: 0.374296\n",
      "tensor(0.3741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:153 0.8\tLoss: 0.374050\n",
      "\n",
      "Test Epoch: 153\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 153\tmaintain_Accuracy: 5157/10593 (49%)\n",
      "\n",
      "tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.0\tLoss: 0.365828\n",
      "tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.2\tLoss: 0.353847\n",
      "tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.4\tLoss: 0.326878\n",
      "tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.6\tLoss: 0.403500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:154 0.8\tLoss: 0.380838\n",
      "\n",
      "Test Epoch: 154\tAttack_Accuracy: 283/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 154\tmaintain_Accuracy: 5270/10593 (50%)\n",
      "\n",
      "tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.0\tLoss: 0.368615\n",
      "tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.2\tLoss: 0.347856\n",
      "tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.4\tLoss: 0.381922\n",
      "tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.6\tLoss: 0.365880\n",
      "tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:155 0.8\tLoss: 0.375935\n",
      "\n",
      "Train Epoch: 155\tAttack_Accuracy: 4110/6400 (64%)\n",
      "\n",
      "\n",
      "Train Epoch: 155\tmaintain_Accuracy: 6235/12800 (49%)\n",
      "\n",
      "alpha: 0.4341542554101534\n",
      "\n",
      "Test Epoch: 155\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 155\tmaintain_Accuracy: 5205/10593 (49%)\n",
      "\n",
      "tensor(0.3350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.0\tLoss: 0.335017\n",
      "tensor(0.4002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.2\tLoss: 0.400225\n",
      "tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.4\tLoss: 0.392202\n",
      "tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.6\tLoss: 0.389848\n",
      "tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:156 0.8\tLoss: 0.366528\n",
      "\n",
      "Test Epoch: 156\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 156\tmaintain_Accuracy: 5090/10593 (48%)\n",
      "\n",
      "tensor(0.4230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.0\tLoss: 0.423016\n",
      "tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.2\tLoss: 0.360230\n",
      "tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.4\tLoss: 0.329919\n",
      "tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.6\tLoss: 0.348597\n",
      "tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:157 0.8\tLoss: 0.293548\n",
      "\n",
      "Test Epoch: 157\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 157\tmaintain_Accuracy: 5129/10593 (48%)\n",
      "\n",
      "tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.0\tLoss: 0.365289\n",
      "tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.2\tLoss: 0.373763\n",
      "tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.4\tLoss: 0.331166\n",
      "tensor(0.3779, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.6\tLoss: 0.377945\n",
      "tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:158 0.8\tLoss: 0.319137\n",
      "\n",
      "Test Epoch: 158\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 158\tmaintain_Accuracy: 5181/10593 (49%)\n",
      "\n",
      "tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.0\tLoss: 0.380882\n",
      "tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.2\tLoss: 0.390490\n",
      "tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.4\tLoss: 0.345574\n",
      "tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.6\tLoss: 0.324338\n",
      "tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:159 0.8\tLoss: 0.356389\n",
      "\n",
      "Test Epoch: 159\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 159\tmaintain_Accuracy: 5178/10593 (49%)\n",
      "\n",
      "tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.0\tLoss: 0.318013\n",
      "tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.2\tLoss: 0.350646\n",
      "tensor(0.3476, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.4\tLoss: 0.347648\n",
      "tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.6\tLoss: 0.358899\n",
      "tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:160 0.8\tLoss: 0.349926\n",
      "\n",
      "Train Epoch: 160\tAttack_Accuracy: 4379/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 160\tmaintain_Accuracy: 6221/12800 (49%)\n",
      "\n",
      "alpha: 0.45788104641673283\n",
      "\n",
      "Test Epoch: 160\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 160\tmaintain_Accuracy: 5263/10593 (50%)\n",
      "\n",
      "tensor(0.3636, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.0\tLoss: 0.363566\n",
      "tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.2\tLoss: 0.366790\n",
      "tensor(0.3884, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.4\tLoss: 0.388436\n",
      "tensor(0.3813, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.6\tLoss: 0.381305\n",
      "tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:161 0.8\tLoss: 0.378887\n",
      "\n",
      "Test Epoch: 161\tAttack_Accuracy: 286/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 161\tmaintain_Accuracy: 5381/10593 (51%)\n",
      "\n",
      "tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.0\tLoss: 0.343169\n",
      "tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.2\tLoss: 0.341170\n",
      "tensor(0.4006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.4\tLoss: 0.400557\n",
      "tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.6\tLoss: 0.353468\n",
      "tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:162 0.8\tLoss: 0.356738\n",
      "\n",
      "Test Epoch: 162\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 162\tmaintain_Accuracy: 5361/10593 (51%)\n",
      "\n",
      "tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.0\tLoss: 0.360134\n",
      "tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.2\tLoss: 0.365555\n",
      "tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.4\tLoss: 0.316084\n",
      "tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.6\tLoss: 0.337986\n",
      "tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:163 0.8\tLoss: 0.371606\n",
      "\n",
      "Test Epoch: 163\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 163\tmaintain_Accuracy: 5253/10593 (50%)\n",
      "\n",
      "tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.0\tLoss: 0.343706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.2\tLoss: 0.356311\n",
      "tensor(0.3763, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.4\tLoss: 0.376300\n",
      "tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.6\tLoss: 0.400791\n",
      "tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:164 0.8\tLoss: 0.393909\n",
      "\n",
      "Test Epoch: 164\tAttack_Accuracy: 288/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 164\tmaintain_Accuracy: 5326/10593 (50%)\n",
      "\n",
      "tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.0\tLoss: 0.323812\n",
      "tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.2\tLoss: 0.337512\n",
      "tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.4\tLoss: 0.353810\n",
      "tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.6\tLoss: 0.319524\n",
      "tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:165 0.8\tLoss: 0.354813\n",
      "\n",
      "Train Epoch: 165\tAttack_Accuracy: 4221/6400 (66%)\n",
      "\n",
      "\n",
      "Train Epoch: 165\tmaintain_Accuracy: 6456/12800 (50%)\n",
      "\n",
      "alpha: 0.5293628367120777\n",
      "\n",
      "Test Epoch: 165\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 165\tmaintain_Accuracy: 5289/10593 (50%)\n",
      "\n",
      "tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.0\tLoss: 0.351403\n",
      "tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.2\tLoss: 0.301965\n",
      "tensor(0.3885, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.4\tLoss: 0.388497\n",
      "tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.6\tLoss: 0.332184\n",
      "tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:166 0.8\tLoss: 0.380126\n",
      "\n",
      "Test Epoch: 166\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 166\tmaintain_Accuracy: 5384/10593 (51%)\n",
      "\n",
      "tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.0\tLoss: 0.362317\n",
      "tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.2\tLoss: 0.361126\n",
      "tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.4\tLoss: 0.371316\n",
      "tensor(0.3610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.6\tLoss: 0.360998\n",
      "tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:167 0.8\tLoss: 0.317953\n",
      "\n",
      "Test Epoch: 167\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 167\tmaintain_Accuracy: 5432/10593 (51%)\n",
      "\n",
      "tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.0\tLoss: 0.364178\n",
      "tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.2\tLoss: 0.367360\n",
      "tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.4\tLoss: 0.348154\n",
      "tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.6\tLoss: 0.337677\n",
      "tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:168 0.8\tLoss: 0.375289\n",
      "\n",
      "Test Epoch: 168\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 168\tmaintain_Accuracy: 5369/10593 (51%)\n",
      "\n",
      "tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.0\tLoss: 0.344362\n",
      "tensor(0.3499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.2\tLoss: 0.349904\n",
      "tensor(0.3444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.4\tLoss: 0.344440\n",
      "tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.6\tLoss: 0.312508\n",
      "tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:169 0.8\tLoss: 0.371741\n",
      "\n",
      "Test Epoch: 169\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 169\tmaintain_Accuracy: 5306/10593 (50%)\n",
      "\n",
      "tensor(0.3954, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.0\tLoss: 0.395352\n",
      "tensor(0.3482, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.2\tLoss: 0.348245\n",
      "tensor(0.3781, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.4\tLoss: 0.378061\n",
      "tensor(0.3026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.6\tLoss: 0.302567\n",
      "tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:170 0.8\tLoss: 0.324792\n",
      "\n",
      "Train Epoch: 170\tAttack_Accuracy: 4271/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 170\tmaintain_Accuracy: 6367/12800 (50%)\n",
      "\n",
      "alpha: 0.3865215586977745\n",
      "\n",
      "Test Epoch: 170\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 170\tmaintain_Accuracy: 5288/10593 (50%)\n",
      "\n",
      "tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.0\tLoss: 0.340677\n",
      "tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.2\tLoss: 0.358572\n",
      "tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.4\tLoss: 0.342517\n",
      "tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.6\tLoss: 0.358006\n",
      "tensor(0.3597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:171 0.8\tLoss: 0.359741\n",
      "\n",
      "Test Epoch: 171\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 171\tmaintain_Accuracy: 5328/10593 (50%)\n",
      "\n",
      "tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.0\tLoss: 0.357632\n",
      "tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.2\tLoss: 0.301134\n",
      "tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.4\tLoss: 0.357382\n",
      "tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.6\tLoss: 0.378909\n",
      "tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:172 0.8\tLoss: 0.356384\n",
      "\n",
      "Test Epoch: 172\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 172\tmaintain_Accuracy: 5305/10593 (50%)\n",
      "\n",
      "tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.0\tLoss: 0.351994\n",
      "tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.2\tLoss: 0.298893\n",
      "tensor(0.3406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.4\tLoss: 0.340552\n",
      "tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.6\tLoss: 0.348805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:173 0.8\tLoss: 0.355318\n",
      "\n",
      "Test Epoch: 173\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 173\tmaintain_Accuracy: 5193/10593 (49%)\n",
      "\n",
      "tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.0\tLoss: 0.329188\n",
      "tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.2\tLoss: 0.373116\n",
      "tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.4\tLoss: 0.332512\n",
      "tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.6\tLoss: 0.302252\n",
      "tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:174 0.8\tLoss: 0.358361\n",
      "\n",
      "Test Epoch: 174\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 174\tmaintain_Accuracy: 5158/10593 (49%)\n",
      "\n",
      "tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.0\tLoss: 0.314480\n",
      "tensor(0.4012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.2\tLoss: 0.401234\n",
      "tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.4\tLoss: 0.349677\n",
      "tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.6\tLoss: 0.359308\n",
      "tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:175 0.8\tLoss: 0.359786\n",
      "\n",
      "Train Epoch: 175\tAttack_Accuracy: 4323/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 175\tmaintain_Accuracy: 6269/12800 (49%)\n",
      "\n",
      "alpha: 0.35314043341388396\n",
      "\n",
      "Test Epoch: 175\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 175\tmaintain_Accuracy: 5201/10593 (49%)\n",
      "\n",
      "tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.0\tLoss: 0.369506\n",
      "tensor(0.4059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.2\tLoss: 0.405862\n",
      "tensor(0.3690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.4\tLoss: 0.368972\n",
      "tensor(0.3742, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.6\tLoss: 0.374150\n",
      "tensor(0.3643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:176 0.8\tLoss: 0.364306\n",
      "\n",
      "Test Epoch: 176\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 176\tmaintain_Accuracy: 5333/10593 (50%)\n",
      "\n",
      "tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.0\tLoss: 0.331138\n",
      "tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.2\tLoss: 0.357810\n",
      "tensor(0.3669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.4\tLoss: 0.366929\n",
      "tensor(0.3293, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.6\tLoss: 0.329342\n",
      "tensor(0.3679, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:177 0.8\tLoss: 0.367898\n",
      "\n",
      "Test Epoch: 177\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 177\tmaintain_Accuracy: 5299/10593 (50%)\n",
      "\n",
      "tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.0\tLoss: 0.365503\n",
      "tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.2\tLoss: 0.356393\n",
      "tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.4\tLoss: 0.356740\n",
      "tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.6\tLoss: 0.360708\n",
      "tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:178 0.8\tLoss: 0.352531\n",
      "\n",
      "Test Epoch: 178\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 178\tmaintain_Accuracy: 5202/10593 (49%)\n",
      "\n",
      "tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.0\tLoss: 0.366463\n",
      "tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.2\tLoss: 0.352161\n",
      "tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.4\tLoss: 0.354647\n",
      "tensor(0.3379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.6\tLoss: 0.337852\n",
      "tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:179 0.8\tLoss: 0.386159\n",
      "\n",
      "Test Epoch: 179\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 179\tmaintain_Accuracy: 5282/10593 (50%)\n",
      "\n",
      "tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.0\tLoss: 0.338215\n",
      "tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.2\tLoss: 0.363940\n",
      "tensor(0.3782, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.4\tLoss: 0.378240\n",
      "tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.6\tLoss: 0.398123\n",
      "tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:180 0.8\tLoss: 0.387761\n",
      "\n",
      "Train Epoch: 180\tAttack_Accuracy: 4175/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 180\tmaintain_Accuracy: 6297/12800 (49%)\n",
      "\n",
      "alpha: 0.6514580840032177\n",
      "\n",
      "Test Epoch: 180\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 180\tmaintain_Accuracy: 5339/10593 (50%)\n",
      "\n",
      "tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.0\tLoss: 0.316765\n",
      "tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.2\tLoss: 0.370596\n",
      "tensor(0.3921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.4\tLoss: 0.392114\n",
      "tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.6\tLoss: 0.336731\n",
      "tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:181 0.8\tLoss: 0.345773\n",
      "\n",
      "Test Epoch: 181\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 181\tmaintain_Accuracy: 5419/10593 (51%)\n",
      "\n",
      "tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.0\tLoss: 0.323399\n",
      "tensor(0.3710, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.2\tLoss: 0.371041\n",
      "tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.4\tLoss: 0.362760\n",
      "tensor(0.4036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.6\tLoss: 0.403580\n",
      "tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:182 0.8\tLoss: 0.367306\n",
      "\n",
      "Test Epoch: 182\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 182\tmaintain_Accuracy: 5334/10593 (50%)\n",
      "\n",
      "tensor(0.3652, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.0\tLoss: 0.365221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3524, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.2\tLoss: 0.352364\n",
      "tensor(0.3439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.4\tLoss: 0.343942\n",
      "tensor(0.3800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.6\tLoss: 0.380008\n",
      "tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:183 0.8\tLoss: 0.349373\n",
      "\n",
      "Test Epoch: 183\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 183\tmaintain_Accuracy: 5304/10593 (50%)\n",
      "\n",
      "tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.0\tLoss: 0.342096\n",
      "tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.2\tLoss: 0.372165\n",
      "tensor(0.3830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.4\tLoss: 0.383040\n",
      "tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.6\tLoss: 0.358513\n",
      "tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:184 0.8\tLoss: 0.358258\n",
      "\n",
      "Test Epoch: 184\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 184\tmaintain_Accuracy: 5294/10593 (50%)\n",
      "\n",
      "tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.0\tLoss: 0.354734\n",
      "tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.2\tLoss: 0.350324\n",
      "tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.4\tLoss: 0.339048\n",
      "tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.6\tLoss: 0.361175\n",
      "tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:185 0.8\tLoss: 0.369287\n",
      "\n",
      "Train Epoch: 185\tAttack_Accuracy: 4312/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 185\tmaintain_Accuracy: 6375/12800 (50%)\n",
      "\n",
      "alpha: 0.7537564597965092\n",
      "\n",
      "Test Epoch: 185\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 185\tmaintain_Accuracy: 5284/10593 (50%)\n",
      "\n",
      "tensor(0.3542, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.0\tLoss: 0.354204\n",
      "tensor(0.3714, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.2\tLoss: 0.371390\n",
      "tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.4\tLoss: 0.355869\n",
      "tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.6\tLoss: 0.362509\n",
      "tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:186 0.8\tLoss: 0.333888\n",
      "\n",
      "Test Epoch: 186\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 186\tmaintain_Accuracy: 5316/10593 (50%)\n",
      "\n",
      "tensor(0.3230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.0\tLoss: 0.322950\n",
      "tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.2\tLoss: 0.347408\n",
      "tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.4\tLoss: 0.390633\n",
      "tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.6\tLoss: 0.381992\n",
      "tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:187 0.8\tLoss: 0.370942\n",
      "\n",
      "Test Epoch: 187\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 187\tmaintain_Accuracy: 5254/10593 (50%)\n",
      "\n",
      "tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.0\tLoss: 0.368846\n",
      "tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.2\tLoss: 0.357434\n",
      "tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.4\tLoss: 0.329547\n",
      "tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.6\tLoss: 0.347379\n",
      "tensor(0.3245, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:188 0.8\tLoss: 0.324538\n",
      "\n",
      "Test Epoch: 188\tAttack_Accuracy: 285/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 188\tmaintain_Accuracy: 5285/10593 (50%)\n",
      "\n",
      "tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.0\tLoss: 0.328308\n",
      "tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.2\tLoss: 0.367686\n",
      "tensor(0.3552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.4\tLoss: 0.355161\n",
      "tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.6\tLoss: 0.336489\n",
      "tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:189 0.8\tLoss: 0.342841\n",
      "\n",
      "Test Epoch: 189\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 189\tmaintain_Accuracy: 5248/10593 (50%)\n",
      "\n",
      "tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.0\tLoss: 0.340114\n",
      "tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.2\tLoss: 0.337478\n",
      "tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.4\tLoss: 0.331475\n",
      "tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.6\tLoss: 0.336147\n",
      "tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:190 0.8\tLoss: 0.319175\n",
      "\n",
      "Train Epoch: 190\tAttack_Accuracy: 4241/6400 (66%)\n",
      "\n",
      "\n",
      "Train Epoch: 190\tmaintain_Accuracy: 6319/12800 (49%)\n",
      "\n",
      "alpha: 0.37258757341215\n",
      "\n",
      "Test Epoch: 190\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 190\tmaintain_Accuracy: 5388/10593 (51%)\n",
      "\n",
      "tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.0\tLoss: 0.360603\n",
      "tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.2\tLoss: 0.374637\n",
      "tensor(0.3514, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.4\tLoss: 0.351434\n",
      "tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.6\tLoss: 0.311696\n",
      "tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:191 0.8\tLoss: 0.362467\n",
      "\n",
      "Test Epoch: 191\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 191\tmaintain_Accuracy: 5381/10593 (51%)\n",
      "\n",
      "tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.0\tLoss: 0.331005\n",
      "tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.2\tLoss: 0.330192\n",
      "tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.4\tLoss: 0.295073\n",
      "tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.6\tLoss: 0.319187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:192 0.8\tLoss: 0.364421\n",
      "\n",
      "Test Epoch: 192\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 192\tmaintain_Accuracy: 5458/10593 (52%)\n",
      "\n",
      "tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.0\tLoss: 0.315417\n",
      "tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.2\tLoss: 0.319301\n",
      "tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.4\tLoss: 0.331976\n",
      "tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.6\tLoss: 0.365490\n",
      "tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:193 0.8\tLoss: 0.333684\n",
      "\n",
      "Test Epoch: 193\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 193\tmaintain_Accuracy: 5361/10593 (51%)\n",
      "\n",
      "tensor(0.3521, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.0\tLoss: 0.352094\n",
      "tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.2\tLoss: 0.346023\n",
      "tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.4\tLoss: 0.403923\n",
      "tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.6\tLoss: 0.355015\n",
      "tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:194 0.8\tLoss: 0.325025\n",
      "\n",
      "Test Epoch: 194\tAttack_Accuracy: 275/412 (67%)\n",
      "\n",
      "\n",
      "Test Epoch: 194\tmaintain_Accuracy: 5518/10593 (52%)\n",
      "\n",
      "tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.0\tLoss: 0.341195\n",
      "tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.2\tLoss: 0.377502\n",
      "tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.4\tLoss: 0.363479\n",
      "tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.6\tLoss: 0.318783\n",
      "tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:195 0.8\tLoss: 0.334323\n",
      "\n",
      "Train Epoch: 195\tAttack_Accuracy: 4028/6400 (63%)\n",
      "\n",
      "\n",
      "Train Epoch: 195\tmaintain_Accuracy: 6489/12800 (51%)\n",
      "\n",
      "alpha: 0.5211361866261734\n",
      "\n",
      "Test Epoch: 195\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 195\tmaintain_Accuracy: 5418/10593 (51%)\n",
      "\n",
      "tensor(0.3642, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.0\tLoss: 0.364177\n",
      "tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.2\tLoss: 0.339987\n",
      "tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.4\tLoss: 0.335256\n",
      "tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.6\tLoss: 0.369603\n",
      "tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:196 0.8\tLoss: 0.347304\n",
      "\n",
      "Test Epoch: 196\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 196\tmaintain_Accuracy: 5347/10593 (50%)\n",
      "\n",
      "tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.0\tLoss: 0.368011\n",
      "tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.2\tLoss: 0.331117\n",
      "tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.4\tLoss: 0.340285\n",
      "tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.6\tLoss: 0.346043\n",
      "tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:197 0.8\tLoss: 0.370462\n",
      "\n",
      "Test Epoch: 197\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 197\tmaintain_Accuracy: 5371/10593 (51%)\n",
      "\n",
      "tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.0\tLoss: 0.311217\n",
      "tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.2\tLoss: 0.339320\n",
      "tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.4\tLoss: 0.361928\n",
      "tensor(0.3831, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.6\tLoss: 0.383133\n",
      "tensor(0.3589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:198 0.8\tLoss: 0.358946\n",
      "\n",
      "Test Epoch: 198\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 198\tmaintain_Accuracy: 5392/10593 (51%)\n",
      "\n",
      "tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.0\tLoss: 0.367037\n",
      "tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.2\tLoss: 0.339029\n",
      "tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.4\tLoss: 0.327305\n",
      "tensor(0.3351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.6\tLoss: 0.335122\n",
      "tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:199 0.8\tLoss: 0.361095\n",
      "\n",
      "Test Epoch: 199\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 199\tmaintain_Accuracy: 5440/10593 (51%)\n",
      "\n",
      "tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.0\tLoss: 0.327953\n",
      "tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.2\tLoss: 0.352977\n",
      "tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.4\tLoss: 0.403267\n",
      "tensor(0.4198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.6\tLoss: 0.419847\n",
      "tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:200 0.8\tLoss: 0.341708\n",
      "\n",
      "Train Epoch: 200\tAttack_Accuracy: 4264/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 200\tmaintain_Accuracy: 6430/12800 (50%)\n",
      "\n",
      "alpha: 0.49854483104803493\n",
      "\n",
      "Test Epoch: 200\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 200\tmaintain_Accuracy: 5473/10593 (52%)\n",
      "\n",
      "tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.0\tLoss: 0.350336\n",
      "tensor(0.3768, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.2\tLoss: 0.376755\n",
      "tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.4\tLoss: 0.343757\n",
      "tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.6\tLoss: 0.348311\n",
      "tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:201 0.8\tLoss: 0.365804\n",
      "\n",
      "Test Epoch: 201\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 201\tmaintain_Accuracy: 5479/10593 (52%)\n",
      "\n",
      "tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.0\tLoss: 0.324988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3559, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.2\tLoss: 0.355882\n",
      "tensor(0.3886, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.4\tLoss: 0.388614\n",
      "tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.6\tLoss: 0.336658\n",
      "tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:202 0.8\tLoss: 0.372523\n",
      "\n",
      "Test Epoch: 202\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 202\tmaintain_Accuracy: 5351/10593 (51%)\n",
      "\n",
      "tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.0\tLoss: 0.331958\n",
      "tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.2\tLoss: 0.363489\n",
      "tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.4\tLoss: 0.344193\n",
      "tensor(0.3623, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.6\tLoss: 0.362272\n",
      "tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:203 0.8\tLoss: 0.393823\n",
      "\n",
      "Test Epoch: 203\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 203\tmaintain_Accuracy: 5333/10593 (50%)\n",
      "\n",
      "tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.0\tLoss: 0.327597\n",
      "tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.2\tLoss: 0.355706\n",
      "tensor(0.3486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.4\tLoss: 0.348572\n",
      "tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.6\tLoss: 0.327553\n",
      "tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:204 0.8\tLoss: 0.359912\n",
      "\n",
      "Test Epoch: 204\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 204\tmaintain_Accuracy: 5444/10593 (51%)\n",
      "\n",
      "tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.0\tLoss: 0.356149\n",
      "tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.2\tLoss: 0.342488\n",
      "tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.4\tLoss: 0.370869\n",
      "tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.6\tLoss: 0.318385\n",
      "tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:205 0.8\tLoss: 0.339864\n",
      "\n",
      "Train Epoch: 205\tAttack_Accuracy: 4193/6400 (66%)\n",
      "\n",
      "\n",
      "Train Epoch: 205\tmaintain_Accuracy: 6547/12800 (51%)\n",
      "\n",
      "alpha: 0.8660982821178052\n",
      "\n",
      "Test Epoch: 205\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 205\tmaintain_Accuracy: 5403/10593 (51%)\n",
      "\n",
      "tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.0\tLoss: 0.341520\n",
      "tensor(0.3393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.2\tLoss: 0.339337\n",
      "tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.4\tLoss: 0.304343\n",
      "tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.6\tLoss: 0.381223\n",
      "tensor(0.3947, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:206 0.8\tLoss: 0.394684\n",
      "\n",
      "Test Epoch: 206\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 206\tmaintain_Accuracy: 5300/10593 (50%)\n",
      "\n",
      "tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.0\tLoss: 0.306031\n",
      "tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.2\tLoss: 0.353035\n",
      "tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.4\tLoss: 0.306863\n",
      "tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.6\tLoss: 0.323747\n",
      "tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:207 0.8\tLoss: 0.372379\n",
      "\n",
      "Test Epoch: 207\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 207\tmaintain_Accuracy: 5461/10593 (52%)\n",
      "\n",
      "tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.0\tLoss: 0.303396\n",
      "tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.2\tLoss: 0.355983\n",
      "tensor(0.3512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.4\tLoss: 0.351158\n",
      "tensor(0.3506, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.6\tLoss: 0.350580\n",
      "tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:208 0.8\tLoss: 0.324132\n",
      "\n",
      "Test Epoch: 208\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 208\tmaintain_Accuracy: 5523/10593 (52%)\n",
      "\n",
      "tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.0\tLoss: 0.347520\n",
      "tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.2\tLoss: 0.297044\n",
      "tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.4\tLoss: 0.357977\n",
      "tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.6\tLoss: 0.357051\n",
      "tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:209 0.8\tLoss: 0.315533\n",
      "\n",
      "Test Epoch: 209\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 209\tmaintain_Accuracy: 5462/10593 (52%)\n",
      "\n",
      "tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.0\tLoss: 0.311918\n",
      "tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.2\tLoss: 0.336257\n",
      "tensor(0.3594, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.4\tLoss: 0.359406\n",
      "tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.6\tLoss: 0.359830\n",
      "tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:210 0.8\tLoss: 0.288235\n",
      "\n",
      "Train Epoch: 210\tAttack_Accuracy: 4349/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 210\tmaintain_Accuracy: 6515/12800 (51%)\n",
      "\n",
      "alpha: 0.5367975228318485\n",
      "\n",
      "Test Epoch: 210\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 210\tmaintain_Accuracy: 5449/10593 (51%)\n",
      "\n",
      "tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.0\tLoss: 0.376172\n",
      "tensor(0.3380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.2\tLoss: 0.337951\n",
      "tensor(0.3411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.4\tLoss: 0.341111\n",
      "tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.6\tLoss: 0.317162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:211 0.8\tLoss: 0.314779\n",
      "\n",
      "Test Epoch: 211\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 211\tmaintain_Accuracy: 5434/10593 (51%)\n",
      "\n",
      "tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.0\tLoss: 0.327636\n",
      "tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.2\tLoss: 0.319003\n",
      "tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.4\tLoss: 0.381911\n",
      "tensor(0.3387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.6\tLoss: 0.338668\n",
      "tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:212 0.8\tLoss: 0.360694\n",
      "\n",
      "Test Epoch: 212\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 212\tmaintain_Accuracy: 5495/10593 (52%)\n",
      "\n",
      "tensor(0.3309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.0\tLoss: 0.330866\n",
      "tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.2\tLoss: 0.370557\n",
      "tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.4\tLoss: 0.353273\n",
      "tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.6\tLoss: 0.325563\n",
      "tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:213 0.8\tLoss: 0.360399\n",
      "\n",
      "Test Epoch: 213\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 213\tmaintain_Accuracy: 5522/10593 (52%)\n",
      "\n",
      "tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.0\tLoss: 0.336454\n",
      "tensor(0.3573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.2\tLoss: 0.357324\n",
      "tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.4\tLoss: 0.344770\n",
      "tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.6\tLoss: 0.312701\n",
      "tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:214 0.8\tLoss: 0.345452\n",
      "\n",
      "Test Epoch: 214\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 214\tmaintain_Accuracy: 5443/10593 (51%)\n",
      "\n",
      "tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.0\tLoss: 0.314009\n",
      "tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.2\tLoss: 0.323560\n",
      "tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.4\tLoss: 0.315303\n",
      "tensor(0.3233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.6\tLoss: 0.323326\n",
      "tensor(0.3409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:215 0.8\tLoss: 0.340862\n",
      "\n",
      "Train Epoch: 215\tAttack_Accuracy: 4296/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 215\tmaintain_Accuracy: 6542/12800 (51%)\n",
      "\n",
      "alpha: 0.32699900403106347\n",
      "\n",
      "Test Epoch: 215\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 215\tmaintain_Accuracy: 5538/10593 (52%)\n",
      "\n",
      "tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.0\tLoss: 0.320574\n",
      "tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.2\tLoss: 0.320672\n",
      "tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.4\tLoss: 0.324610\n",
      "tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.6\tLoss: 0.339895\n",
      "tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:216 0.8\tLoss: 0.321545\n",
      "\n",
      "Test Epoch: 216\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 216\tmaintain_Accuracy: 5474/10593 (52%)\n",
      "\n",
      "tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.0\tLoss: 0.309145\n",
      "tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.2\tLoss: 0.306225\n",
      "tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.4\tLoss: 0.298558\n",
      "tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.6\tLoss: 0.278323\n",
      "tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:217 0.8\tLoss: 0.357420\n",
      "\n",
      "Test Epoch: 217\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 217\tmaintain_Accuracy: 5507/10593 (52%)\n",
      "\n",
      "tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.0\tLoss: 0.337166\n",
      "tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.2\tLoss: 0.357822\n",
      "tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.4\tLoss: 0.327266\n",
      "tensor(0.2986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.6\tLoss: 0.298609\n",
      "tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:218 0.8\tLoss: 0.358509\n",
      "\n",
      "Test Epoch: 218\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 218\tmaintain_Accuracy: 5534/10593 (52%)\n",
      "\n",
      "tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.0\tLoss: 0.319636\n",
      "tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.2\tLoss: 0.333335\n",
      "tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.4\tLoss: 0.341395\n",
      "tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.6\tLoss: 0.286758\n",
      "tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:219 0.8\tLoss: 0.292354\n",
      "\n",
      "Test Epoch: 219\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 219\tmaintain_Accuracy: 5455/10593 (51%)\n",
      "\n",
      "tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.0\tLoss: 0.355781\n",
      "tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.2\tLoss: 0.307330\n",
      "tensor(0.3292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.4\tLoss: 0.329159\n",
      "tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.6\tLoss: 0.274860\n",
      "tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:220 0.8\tLoss: 0.333730\n",
      "\n",
      "Train Epoch: 220\tAttack_Accuracy: 4376/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 220\tmaintain_Accuracy: 6514/12800 (51%)\n",
      "\n",
      "alpha: 0.5402859831862673\n",
      "\n",
      "Test Epoch: 220\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 220\tmaintain_Accuracy: 5420/10593 (51%)\n",
      "\n",
      "tensor(0.3674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.0\tLoss: 0.367358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.2\tLoss: 0.344911\n",
      "tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.4\tLoss: 0.285928\n",
      "tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.6\tLoss: 0.321219\n",
      "tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:221 0.8\tLoss: 0.332659\n",
      "\n",
      "Test Epoch: 221\tAttack_Accuracy: 288/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 221\tmaintain_Accuracy: 5462/10593 (52%)\n",
      "\n",
      "tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.0\tLoss: 0.310843\n",
      "tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.2\tLoss: 0.273669\n",
      "tensor(0.3364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.4\tLoss: 0.336422\n",
      "tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.6\tLoss: 0.345283\n",
      "tensor(0.3440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:222 0.8\tLoss: 0.343965\n",
      "\n",
      "Test Epoch: 222\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 222\tmaintain_Accuracy: 5489/10593 (52%)\n",
      "\n",
      "tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.0\tLoss: 0.291258\n",
      "tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.2\tLoss: 0.326257\n",
      "tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.4\tLoss: 0.261336\n",
      "tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.6\tLoss: 0.329148\n",
      "tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:223 0.8\tLoss: 0.303031\n",
      "\n",
      "Test Epoch: 223\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 223\tmaintain_Accuracy: 5539/10593 (52%)\n",
      "\n",
      "tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.0\tLoss: 0.332179\n",
      "tensor(0.3625, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.2\tLoss: 0.362524\n",
      "tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.4\tLoss: 0.338224\n",
      "tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.6\tLoss: 0.279705\n",
      "tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:224 0.8\tLoss: 0.291878\n",
      "\n",
      "Test Epoch: 224\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 224\tmaintain_Accuracy: 5566/10593 (53%)\n",
      "\n",
      "tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.0\tLoss: 0.318802\n",
      "tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.2\tLoss: 0.355983\n",
      "tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.4\tLoss: 0.275376\n",
      "tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.6\tLoss: 0.326037\n",
      "tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:225 0.8\tLoss: 0.297930\n",
      "\n",
      "Train Epoch: 225\tAttack_Accuracy: 4348/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 225\tmaintain_Accuracy: 6685/12800 (52%)\n",
      "\n",
      "alpha: 0.6088896336792325\n",
      "\n",
      "Test Epoch: 225\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 225\tmaintain_Accuracy: 5473/10593 (52%)\n",
      "\n",
      "tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.0\tLoss: 0.344844\n",
      "tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.2\tLoss: 0.322524\n",
      "tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.4\tLoss: 0.328204\n",
      "tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.6\tLoss: 0.340432\n",
      "tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:226 0.8\tLoss: 0.306112\n",
      "\n",
      "Test Epoch: 226\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 226\tmaintain_Accuracy: 5520/10593 (52%)\n",
      "\n",
      "tensor(0.3254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.0\tLoss: 0.325400\n",
      "tensor(0.2784, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.2\tLoss: 0.278436\n",
      "tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.4\tLoss: 0.325292\n",
      "tensor(0.3466, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.6\tLoss: 0.346596\n",
      "tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:227 0.8\tLoss: 0.319920\n",
      "\n",
      "Test Epoch: 227\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 227\tmaintain_Accuracy: 5536/10593 (52%)\n",
      "\n",
      "tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.0\tLoss: 0.322183\n",
      "tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.2\tLoss: 0.320001\n",
      "tensor(0.3585, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.4\tLoss: 0.358483\n",
      "tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.6\tLoss: 0.317015\n",
      "tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:228 0.8\tLoss: 0.308660\n",
      "\n",
      "Test Epoch: 228\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 228\tmaintain_Accuracy: 5438/10593 (51%)\n",
      "\n",
      "tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.0\tLoss: 0.335338\n",
      "tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.2\tLoss: 0.326936\n",
      "tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.4\tLoss: 0.293860\n",
      "tensor(0.3206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.6\tLoss: 0.320592\n",
      "tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:229 0.8\tLoss: 0.328637\n",
      "\n",
      "Test Epoch: 229\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 229\tmaintain_Accuracy: 5461/10593 (52%)\n",
      "\n",
      "tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.0\tLoss: 0.325170\n",
      "tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.2\tLoss: 0.371275\n",
      "tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.4\tLoss: 0.306081\n",
      "tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.6\tLoss: 0.349473\n",
      "tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:230 0.8\tLoss: 0.345872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 230\tAttack_Accuracy: 4266/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 230\tmaintain_Accuracy: 6586/12800 (51%)\n",
      "\n",
      "alpha: 0.6275580747504602\n",
      "\n",
      "Test Epoch: 230\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 230\tmaintain_Accuracy: 5498/10593 (52%)\n",
      "\n",
      "tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.0\tLoss: 0.331080\n",
      "tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.2\tLoss: 0.304922\n",
      "tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.4\tLoss: 0.314065\n",
      "tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.6\tLoss: 0.310567\n",
      "tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:231 0.8\tLoss: 0.338507\n",
      "\n",
      "Test Epoch: 231\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 231\tmaintain_Accuracy: 5487/10593 (52%)\n",
      "\n",
      "tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.0\tLoss: 0.317648\n",
      "tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.2\tLoss: 0.290269\n",
      "tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.4\tLoss: 0.327176\n",
      "tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.6\tLoss: 0.298267\n",
      "tensor(0.2947, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:232 0.8\tLoss: 0.294715\n",
      "\n",
      "Test Epoch: 232\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 232\tmaintain_Accuracy: 5523/10593 (52%)\n",
      "\n",
      "tensor(0.3361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.0\tLoss: 0.336125\n",
      "tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.2\tLoss: 0.293841\n",
      "tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.4\tLoss: 0.338759\n",
      "tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.6\tLoss: 0.331048\n",
      "tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:233 0.8\tLoss: 0.377642\n",
      "\n",
      "Test Epoch: 233\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 233\tmaintain_Accuracy: 5594/10593 (53%)\n",
      "\n",
      "tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.0\tLoss: 0.329371\n",
      "tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.2\tLoss: 0.355088\n",
      "tensor(0.3570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.4\tLoss: 0.357049\n",
      "tensor(0.3090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.6\tLoss: 0.309013\n",
      "tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:234 0.8\tLoss: 0.322908\n",
      "\n",
      "Test Epoch: 234\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 234\tmaintain_Accuracy: 5506/10593 (52%)\n",
      "\n",
      "tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.0\tLoss: 0.330000\n",
      "tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.2\tLoss: 0.345555\n",
      "tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.4\tLoss: 0.316324\n",
      "tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.6\tLoss: 0.300536\n",
      "tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:235 0.8\tLoss: 0.297955\n",
      "\n",
      "Train Epoch: 235\tAttack_Accuracy: 4357/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 235\tmaintain_Accuracy: 6568/12800 (51%)\n",
      "\n",
      "alpha: 0.4695671702638757\n",
      "\n",
      "Test Epoch: 235\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 235\tmaintain_Accuracy: 5577/10593 (53%)\n",
      "\n",
      "tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.0\tLoss: 0.326042\n",
      "tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.2\tLoss: 0.302761\n",
      "tensor(0.3332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.4\tLoss: 0.333222\n",
      "tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.6\tLoss: 0.329431\n",
      "tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:236 0.8\tLoss: 0.321892\n",
      "\n",
      "Test Epoch: 236\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 236\tmaintain_Accuracy: 5531/10593 (52%)\n",
      "\n",
      "tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.0\tLoss: 0.328579\n",
      "tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.2\tLoss: 0.315584\n",
      "tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.4\tLoss: 0.346695\n",
      "tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.6\tLoss: 0.346339\n",
      "tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:237 0.8\tLoss: 0.289111\n",
      "\n",
      "Test Epoch: 237\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 237\tmaintain_Accuracy: 5379/10593 (51%)\n",
      "\n",
      "tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.0\tLoss: 0.285812\n",
      "tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.2\tLoss: 0.330295\n",
      "tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.4\tLoss: 0.277905\n",
      "tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.6\tLoss: 0.353486\n",
      "tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:238 0.8\tLoss: 0.313483\n",
      "\n",
      "Test Epoch: 238\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 238\tmaintain_Accuracy: 5526/10593 (52%)\n",
      "\n",
      "tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.0\tLoss: 0.306613\n",
      "tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.2\tLoss: 0.319534\n",
      "tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.4\tLoss: 0.354297\n",
      "tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.6\tLoss: 0.328184\n",
      "tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:239 0.8\tLoss: 0.349148\n",
      "\n",
      "Test Epoch: 239\tAttack_Accuracy: 284/412 (69%)\n",
      "\n",
      "\n",
      "Test Epoch: 239\tmaintain_Accuracy: 5573/10593 (53%)\n",
      "\n",
      "tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.0\tLoss: 0.279454\n",
      "tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.2\tLoss: 0.310238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.4\tLoss: 0.329131\n",
      "tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.6\tLoss: 0.285635\n",
      "tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:240 0.8\tLoss: 0.341187\n",
      "\n",
      "Train Epoch: 240\tAttack_Accuracy: 4304/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 240\tmaintain_Accuracy: 6686/12800 (52%)\n",
      "\n",
      "alpha: 0.9565773065764315\n",
      "\n",
      "Test Epoch: 240\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 240\tmaintain_Accuracy: 5479/10593 (52%)\n",
      "\n",
      "tensor(0.3925, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.0\tLoss: 0.392466\n",
      "tensor(0.3633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.2\tLoss: 0.363274\n",
      "tensor(0.3583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.4\tLoss: 0.358251\n",
      "tensor(0.3319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.6\tLoss: 0.331919\n",
      "tensor(0.3035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:241 0.8\tLoss: 0.303524\n",
      "\n",
      "Test Epoch: 241\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 241\tmaintain_Accuracy: 5558/10593 (52%)\n",
      "\n",
      "tensor(0.3238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.0\tLoss: 0.323783\n",
      "tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.2\tLoss: 0.328941\n",
      "tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.4\tLoss: 0.313466\n",
      "tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.6\tLoss: 0.347836\n",
      "tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:242 0.8\tLoss: 0.298674\n",
      "\n",
      "Test Epoch: 242\tAttack_Accuracy: 289/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 242\tmaintain_Accuracy: 5628/10593 (53%)\n",
      "\n",
      "tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.0\tLoss: 0.307847\n",
      "tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.2\tLoss: 0.294126\n",
      "tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.4\tLoss: 0.324134\n",
      "tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.6\tLoss: 0.304536\n",
      "tensor(0.3586, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:243 0.8\tLoss: 0.358590\n",
      "\n",
      "Test Epoch: 243\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 243\tmaintain_Accuracy: 5484/10593 (52%)\n",
      "\n",
      "tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.0\tLoss: 0.302682\n",
      "tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.2\tLoss: 0.321423\n",
      "tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.4\tLoss: 0.308716\n",
      "tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.6\tLoss: 0.295730\n",
      "tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:244 0.8\tLoss: 0.354371\n",
      "\n",
      "Test Epoch: 244\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 244\tmaintain_Accuracy: 5459/10593 (52%)\n",
      "\n",
      "tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.0\tLoss: 0.257307\n",
      "tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.2\tLoss: 0.334067\n",
      "tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.4\tLoss: 0.294630\n",
      "tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.6\tLoss: 0.320276\n",
      "tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:245 0.8\tLoss: 0.328632\n",
      "\n",
      "Train Epoch: 245\tAttack_Accuracy: 4243/6400 (66%)\n",
      "\n",
      "\n",
      "Train Epoch: 245\tmaintain_Accuracy: 6525/12800 (51%)\n",
      "\n",
      "alpha: 0.2783723551406164\n",
      "\n",
      "Test Epoch: 245\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 245\tmaintain_Accuracy: 5479/10593 (52%)\n",
      "\n",
      "tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.0\tLoss: 0.301253\n",
      "tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.2\tLoss: 0.297009\n",
      "tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.4\tLoss: 0.332520\n",
      "tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.6\tLoss: 0.295763\n",
      "tensor(0.3207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:246 0.8\tLoss: 0.320747\n",
      "\n",
      "Test Epoch: 246\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 246\tmaintain_Accuracy: 5435/10593 (51%)\n",
      "\n",
      "tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.0\tLoss: 0.341667\n",
      "tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.2\tLoss: 0.322739\n",
      "tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.4\tLoss: 0.343034\n",
      "tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.6\tLoss: 0.335366\n",
      "tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:247 0.8\tLoss: 0.369094\n",
      "\n",
      "Test Epoch: 247\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 247\tmaintain_Accuracy: 5449/10593 (51%)\n",
      "\n",
      "tensor(0.3340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.0\tLoss: 0.333984\n",
      "tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.2\tLoss: 0.280014\n",
      "tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.4\tLoss: 0.326209\n",
      "tensor(0.3698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.6\tLoss: 0.369796\n",
      "tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:248 0.8\tLoss: 0.327550\n",
      "\n",
      "Test Epoch: 248\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 248\tmaintain_Accuracy: 5572/10593 (53%)\n",
      "\n",
      "tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.0\tLoss: 0.394917\n",
      "tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.2\tLoss: 0.334770\n",
      "tensor(0.3383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.4\tLoss: 0.338250\n",
      "tensor(0.2837, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.6\tLoss: 0.283687\n",
      "tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:249 0.8\tLoss: 0.356263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 249\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 249\tmaintain_Accuracy: 5606/10593 (53%)\n",
      "\n",
      "tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.0\tLoss: 0.336599\n",
      "tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.2\tLoss: 0.304222\n",
      "tensor(0.3333, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.4\tLoss: 0.333346\n",
      "tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.6\tLoss: 0.334469\n",
      "tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:250 0.8\tLoss: 0.315426\n",
      "\n",
      "Train Epoch: 250\tAttack_Accuracy: 4280/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 250\tmaintain_Accuracy: 6790/12800 (53%)\n",
      "\n",
      "alpha: 0.7213076714256902\n",
      "\n",
      "Test Epoch: 250\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 250\tmaintain_Accuracy: 5592/10593 (53%)\n",
      "\n",
      "tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.0\tLoss: 0.305067\n",
      "tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.2\tLoss: 0.294110\n",
      "tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.4\tLoss: 0.332589\n",
      "tensor(0.3508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.6\tLoss: 0.350806\n",
      "tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:251 0.8\tLoss: 0.280121\n",
      "\n",
      "Test Epoch: 251\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 251\tmaintain_Accuracy: 5583/10593 (53%)\n",
      "\n",
      "tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.0\tLoss: 0.323133\n",
      "tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.2\tLoss: 0.307708\n",
      "tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.4\tLoss: 0.381133\n",
      "tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.6\tLoss: 0.313950\n",
      "tensor(0.3564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:252 0.8\tLoss: 0.356418\n",
      "\n",
      "Test Epoch: 252\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 252\tmaintain_Accuracy: 5595/10593 (53%)\n",
      "\n",
      "tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.0\tLoss: 0.293978\n",
      "tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.2\tLoss: 0.385509\n",
      "tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.4\tLoss: 0.350079\n",
      "tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.6\tLoss: 0.334764\n",
      "tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:253 0.8\tLoss: 0.286255\n",
      "\n",
      "Test Epoch: 253\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 253\tmaintain_Accuracy: 5512/10593 (52%)\n",
      "\n",
      "tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.0\tLoss: 0.351902\n",
      "tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.2\tLoss: 0.342149\n",
      "tensor(0.3614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.4\tLoss: 0.361447\n",
      "tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.6\tLoss: 0.317764\n",
      "tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:254 0.8\tLoss: 0.300384\n",
      "\n",
      "Test Epoch: 254\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 254\tmaintain_Accuracy: 5580/10593 (53%)\n",
      "\n",
      "tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.0\tLoss: 0.316116\n",
      "tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.2\tLoss: 0.315334\n",
      "tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.4\tLoss: 0.313150\n",
      "tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.6\tLoss: 0.302511\n",
      "tensor(0.2902, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:255 0.8\tLoss: 0.290154\n",
      "\n",
      "Train Epoch: 255\tAttack_Accuracy: 4278/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 255\tmaintain_Accuracy: 6551/12800 (51%)\n",
      "\n",
      "alpha: 0.4035493750499129\n",
      "\n",
      "Test Epoch: 255\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 255\tmaintain_Accuracy: 5575/10593 (53%)\n",
      "\n",
      "tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.0\tLoss: 0.301250\n",
      "tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.2\tLoss: 0.323716\n",
      "tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.4\tLoss: 0.317001\n",
      "tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.6\tLoss: 0.281558\n",
      "tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:256 0.8\tLoss: 0.282323\n",
      "\n",
      "Test Epoch: 256\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 256\tmaintain_Accuracy: 5558/10593 (52%)\n",
      "\n",
      "tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.0\tLoss: 0.326896\n",
      "tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.2\tLoss: 0.335770\n",
      "tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.4\tLoss: 0.312093\n",
      "tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.6\tLoss: 0.306157\n",
      "tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:257 0.8\tLoss: 0.307478\n",
      "\n",
      "Test Epoch: 257\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 257\tmaintain_Accuracy: 5566/10593 (53%)\n",
      "\n",
      "tensor(0.3134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.0\tLoss: 0.313411\n",
      "tensor(0.3806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.2\tLoss: 0.380571\n",
      "tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.4\tLoss: 0.283059\n",
      "tensor(0.3449, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.6\tLoss: 0.344884\n",
      "tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:258 0.8\tLoss: 0.303717\n",
      "\n",
      "Test Epoch: 258\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 258\tmaintain_Accuracy: 5539/10593 (52%)\n",
      "\n",
      "tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.0\tLoss: 0.302860\n",
      "tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.2\tLoss: 0.311664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.4\tLoss: 0.371925\n",
      "tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.6\tLoss: 0.339822\n",
      "tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:259 0.8\tLoss: 0.270772\n",
      "\n",
      "Test Epoch: 259\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 259\tmaintain_Accuracy: 5576/10593 (53%)\n",
      "\n",
      "tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.0\tLoss: 0.334546\n",
      "tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.2\tLoss: 0.305569\n",
      "tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.4\tLoss: 0.313581\n",
      "tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.6\tLoss: 0.310883\n",
      "tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:260 0.8\tLoss: 0.293153\n",
      "\n",
      "Train Epoch: 260\tAttack_Accuracy: 4263/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 260\tmaintain_Accuracy: 6763/12800 (53%)\n",
      "\n",
      "alpha: 0.4757945938092243\n",
      "\n",
      "Test Epoch: 260\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 260\tmaintain_Accuracy: 5589/10593 (53%)\n",
      "\n",
      "tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.0\tLoss: 0.365416\n",
      "tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.2\tLoss: 0.367271\n",
      "tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.4\tLoss: 0.365963\n",
      "tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.6\tLoss: 0.310186\n",
      "tensor(0.3011, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:261 0.8\tLoss: 0.301114\n",
      "\n",
      "Test Epoch: 261\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 261\tmaintain_Accuracy: 5501/10593 (52%)\n",
      "\n",
      "tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.0\tLoss: 0.330304\n",
      "tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.2\tLoss: 0.328497\n",
      "tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.4\tLoss: 0.350675\n",
      "tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.6\tLoss: 0.319532\n",
      "tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:262 0.8\tLoss: 0.323987\n",
      "\n",
      "Test Epoch: 262\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 262\tmaintain_Accuracy: 5576/10593 (53%)\n",
      "\n",
      "tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.0\tLoss: 0.353203\n",
      "tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.2\tLoss: 0.342065\n",
      "tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.4\tLoss: 0.261368\n",
      "tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.6\tLoss: 0.300544\n",
      "tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:263 0.8\tLoss: 0.308265\n",
      "\n",
      "Test Epoch: 263\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 263\tmaintain_Accuracy: 5563/10593 (53%)\n",
      "\n",
      "tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.0\tLoss: 0.308651\n",
      "tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.2\tLoss: 0.280280\n",
      "tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.4\tLoss: 0.346502\n",
      "tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.6\tLoss: 0.314122\n",
      "tensor(0.3587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:264 0.8\tLoss: 0.358655\n",
      "\n",
      "Test Epoch: 264\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 264\tmaintain_Accuracy: 5591/10593 (53%)\n",
      "\n",
      "tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.0\tLoss: 0.327129\n",
      "tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.2\tLoss: 0.357062\n",
      "tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.4\tLoss: 0.330488\n",
      "tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.6\tLoss: 0.346357\n",
      "tensor(0.2814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:265 0.8\tLoss: 0.281384\n",
      "\n",
      "Train Epoch: 265\tAttack_Accuracy: 4173/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 265\tmaintain_Accuracy: 6711/12800 (52%)\n",
      "\n",
      "alpha: 0.46378285791824647\n",
      "\n",
      "Test Epoch: 265\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 265\tmaintain_Accuracy: 5659/10593 (53%)\n",
      "\n",
      "tensor(0.3549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.0\tLoss: 0.354894\n",
      "tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.2\tLoss: 0.339949\n",
      "tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.4\tLoss: 0.322714\n",
      "tensor(0.3105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.6\tLoss: 0.310531\n",
      "tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:266 0.8\tLoss: 0.280776\n",
      "\n",
      "Test Epoch: 266\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 266\tmaintain_Accuracy: 5597/10593 (53%)\n",
      "\n",
      "tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.0\tLoss: 0.333705\n",
      "tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.2\tLoss: 0.332181\n",
      "tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.4\tLoss: 0.301299\n",
      "tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.6\tLoss: 0.344596\n",
      "tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:267 0.8\tLoss: 0.327393\n",
      "\n",
      "Test Epoch: 267\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 267\tmaintain_Accuracy: 5569/10593 (53%)\n",
      "\n",
      "tensor(0.3509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.0\tLoss: 0.350857\n",
      "tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.2\tLoss: 0.297317\n",
      "tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.4\tLoss: 0.284108\n",
      "tensor(0.3648, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.6\tLoss: 0.364783\n",
      "tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:268 0.8\tLoss: 0.337515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 268\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 268\tmaintain_Accuracy: 5576/10593 (53%)\n",
      "\n",
      "tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.0\tLoss: 0.289304\n",
      "tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.2\tLoss: 0.293169\n",
      "tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.4\tLoss: 0.307788\n",
      "tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.6\tLoss: 0.340141\n",
      "tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:269 0.8\tLoss: 0.329109\n",
      "\n",
      "Test Epoch: 269\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 269\tmaintain_Accuracy: 5542/10593 (52%)\n",
      "\n",
      "tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.0\tLoss: 0.304313\n",
      "tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.2\tLoss: 0.297178\n",
      "tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.4\tLoss: 0.340669\n",
      "tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.6\tLoss: 0.313928\n",
      "tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:270 0.8\tLoss: 0.280808\n",
      "\n",
      "Train Epoch: 270\tAttack_Accuracy: 4289/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 270\tmaintain_Accuracy: 6655/12800 (52%)\n",
      "\n",
      "alpha: 0.45373345713067437\n",
      "\n",
      "Test Epoch: 270\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 270\tmaintain_Accuracy: 5518/10593 (52%)\n",
      "\n",
      "tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.0\tLoss: 0.297215\n",
      "tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.2\tLoss: 0.292975\n",
      "tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.4\tLoss: 0.314712\n",
      "tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.6\tLoss: 0.320268\n",
      "tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:271 0.8\tLoss: 0.314728\n",
      "\n",
      "Test Epoch: 271\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 271\tmaintain_Accuracy: 5575/10593 (53%)\n",
      "\n",
      "tensor(0.3048, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.0\tLoss: 0.304801\n",
      "tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.2\tLoss: 0.313493\n",
      "tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.4\tLoss: 0.310017\n",
      "tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.6\tLoss: 0.326172\n",
      "tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:272 0.8\tLoss: 0.325848\n",
      "\n",
      "Test Epoch: 272\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 272\tmaintain_Accuracy: 5525/10593 (52%)\n",
      "\n",
      "tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.0\tLoss: 0.305819\n",
      "tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.2\tLoss: 0.306104\n",
      "tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.4\tLoss: 0.305069\n",
      "tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.6\tLoss: 0.320396\n",
      "tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:273 0.8\tLoss: 0.315970\n",
      "\n",
      "Test Epoch: 273\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 273\tmaintain_Accuracy: 5544/10593 (52%)\n",
      "\n",
      "tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.0\tLoss: 0.280695\n",
      "tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.2\tLoss: 0.315427\n",
      "tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.4\tLoss: 0.282549\n",
      "tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.6\tLoss: 0.333673\n",
      "tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:274 0.8\tLoss: 0.307825\n",
      "\n",
      "Test Epoch: 274\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 274\tmaintain_Accuracy: 5551/10593 (52%)\n",
      "\n",
      "tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.0\tLoss: 0.334298\n",
      "tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.2\tLoss: 0.262491\n",
      "tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.4\tLoss: 0.327073\n",
      "tensor(0.3430, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.6\tLoss: 0.343019\n",
      "tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:275 0.8\tLoss: 0.310279\n",
      "\n",
      "Train Epoch: 275\tAttack_Accuracy: 4334/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 275\tmaintain_Accuracy: 6658/12800 (52%)\n",
      "\n",
      "alpha: 0.6005307992637908\n",
      "\n",
      "Test Epoch: 275\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 275\tmaintain_Accuracy: 5567/10593 (53%)\n",
      "\n",
      "tensor(0.3427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.0\tLoss: 0.342702\n",
      "tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.2\tLoss: 0.284015\n",
      "tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.4\tLoss: 0.309420\n",
      "tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.6\tLoss: 0.286318\n",
      "tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:276 0.8\tLoss: 0.317786\n",
      "\n",
      "Test Epoch: 276\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 276\tmaintain_Accuracy: 5623/10593 (53%)\n",
      "\n",
      "tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.0\tLoss: 0.353641\n",
      "tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.2\tLoss: 0.335991\n",
      "tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.4\tLoss: 0.375719\n",
      "tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.6\tLoss: 0.306582\n",
      "tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:277 0.8\tLoss: 0.335295\n",
      "\n",
      "Test Epoch: 277\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 277\tmaintain_Accuracy: 5607/10593 (53%)\n",
      "\n",
      "tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.0\tLoss: 0.298864\n",
      "tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.2\tLoss: 0.318532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.4\tLoss: 0.314929\n",
      "tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.6\tLoss: 0.302515\n",
      "tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:278 0.8\tLoss: 0.292039\n",
      "\n",
      "Test Epoch: 278\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 278\tmaintain_Accuracy: 5615/10593 (53%)\n",
      "\n",
      "tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.0\tLoss: 0.304017\n",
      "tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.2\tLoss: 0.310925\n",
      "tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.4\tLoss: 0.332844\n",
      "tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.6\tLoss: 0.323514\n",
      "tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:279 0.8\tLoss: 0.305717\n",
      "\n",
      "Test Epoch: 279\tAttack_Accuracy: 291/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 279\tmaintain_Accuracy: 5617/10593 (53%)\n",
      "\n",
      "tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.0\tLoss: 0.298162\n",
      "tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.2\tLoss: 0.293225\n",
      "tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.4\tLoss: 0.283444\n",
      "tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.6\tLoss: 0.320276\n",
      "tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:280 0.8\tLoss: 0.328043\n",
      "\n",
      "Train Epoch: 280\tAttack_Accuracy: 4243/6400 (66%)\n",
      "\n",
      "\n",
      "Train Epoch: 280\tmaintain_Accuracy: 6709/12800 (52%)\n",
      "\n",
      "alpha: 0.4886644854022026\n",
      "\n",
      "Test Epoch: 280\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 280\tmaintain_Accuracy: 5569/10593 (53%)\n",
      "\n",
      "tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.0\tLoss: 0.303577\n",
      "tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.2\tLoss: 0.254052\n",
      "tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.4\tLoss: 0.256418\n",
      "tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.6\tLoss: 0.319972\n",
      "tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:281 0.8\tLoss: 0.268954\n",
      "\n",
      "Test Epoch: 281\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 281\tmaintain_Accuracy: 5561/10593 (52%)\n",
      "\n",
      "tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.0\tLoss: 0.291583\n",
      "tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.2\tLoss: 0.298867\n",
      "tensor(0.3354, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.4\tLoss: 0.335446\n",
      "tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.6\tLoss: 0.306882\n",
      "tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:282 0.8\tLoss: 0.324162\n",
      "\n",
      "Test Epoch: 282\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 282\tmaintain_Accuracy: 5657/10593 (53%)\n",
      "\n",
      "tensor(0.3341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.0\tLoss: 0.334148\n",
      "tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.2\tLoss: 0.273498\n",
      "tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.4\tLoss: 0.349516\n",
      "tensor(0.3248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.6\tLoss: 0.324796\n",
      "tensor(0.3488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:283 0.8\tLoss: 0.348752\n",
      "\n",
      "Test Epoch: 283\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 283\tmaintain_Accuracy: 5596/10593 (53%)\n",
      "\n",
      "tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.0\tLoss: 0.344164\n",
      "tensor(0.2896, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.2\tLoss: 0.289640\n",
      "tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.4\tLoss: 0.312809\n",
      "tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.6\tLoss: 0.377512\n",
      "tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:284 0.8\tLoss: 0.301685\n",
      "\n",
      "Test Epoch: 284\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 284\tmaintain_Accuracy: 5606/10593 (53%)\n",
      "\n",
      "tensor(0.3227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.0\tLoss: 0.322665\n",
      "tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.2\tLoss: 0.350448\n",
      "tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.4\tLoss: 0.305173\n",
      "tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.6\tLoss: 0.294571\n",
      "tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:285 0.8\tLoss: 0.350505\n",
      "\n",
      "Train Epoch: 285\tAttack_Accuracy: 4127/6400 (64%)\n",
      "\n",
      "\n",
      "Train Epoch: 285\tmaintain_Accuracy: 6593/12800 (52%)\n",
      "\n",
      "alpha: 0.3535835544870521\n",
      "\n",
      "Test Epoch: 285\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 285\tmaintain_Accuracy: 5639/10593 (53%)\n",
      "\n",
      "tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.0\tLoss: 0.327418\n",
      "tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.2\tLoss: 0.290826\n",
      "tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.4\tLoss: 0.331485\n",
      "tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.6\tLoss: 0.316297\n",
      "tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:286 0.8\tLoss: 0.318783\n",
      "\n",
      "Test Epoch: 286\tAttack_Accuracy: 316/412 (77%)\n",
      "\n",
      "\n",
      "Test Epoch: 286\tmaintain_Accuracy: 5463/10593 (52%)\n",
      "\n",
      "tensor(0.3289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.0\tLoss: 0.328862\n",
      "tensor(0.3531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.2\tLoss: 0.353063\n",
      "tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.4\tLoss: 0.318136\n",
      "tensor(0.3453, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.6\tLoss: 0.345320\n",
      "tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:287 0.8\tLoss: 0.319135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 287\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 287\tmaintain_Accuracy: 5583/10593 (53%)\n",
      "\n",
      "tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.0\tLoss: 0.326175\n",
      "tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.2\tLoss: 0.308321\n",
      "tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.4\tLoss: 0.288847\n",
      "tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.6\tLoss: 0.293160\n",
      "tensor(0.3291, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:288 0.8\tLoss: 0.329100\n",
      "\n",
      "Test Epoch: 288\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 288\tmaintain_Accuracy: 5594/10593 (53%)\n",
      "\n",
      "tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.0\tLoss: 0.317958\n",
      "tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.2\tLoss: 0.341180\n",
      "tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.4\tLoss: 0.293272\n",
      "tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.6\tLoss: 0.319053\n",
      "tensor(0.3540, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:289 0.8\tLoss: 0.353978\n",
      "\n",
      "Test Epoch: 289\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 289\tmaintain_Accuracy: 5569/10593 (53%)\n",
      "\n",
      "tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.0\tLoss: 0.345990\n",
      "tensor(0.3607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.2\tLoss: 0.360749\n",
      "tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.4\tLoss: 0.314850\n",
      "tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.6\tLoss: 0.311589\n",
      "tensor(0.3161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:290 0.8\tLoss: 0.316060\n",
      "\n",
      "Train Epoch: 290\tAttack_Accuracy: 4244/6400 (66%)\n",
      "\n",
      "\n",
      "Train Epoch: 290\tmaintain_Accuracy: 6636/12800 (52%)\n",
      "\n",
      "alpha: 0.466503033896103\n",
      "\n",
      "Test Epoch: 290\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 290\tmaintain_Accuracy: 5609/10593 (53%)\n",
      "\n",
      "tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.0\tLoss: 0.302480\n",
      "tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.2\tLoss: 0.317009\n",
      "tensor(0.3337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.4\tLoss: 0.333694\n",
      "tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.6\tLoss: 0.285914\n",
      "tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:291 0.8\tLoss: 0.310773\n",
      "\n",
      "Test Epoch: 291\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 291\tmaintain_Accuracy: 5610/10593 (53%)\n",
      "\n",
      "tensor(0.3253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.0\tLoss: 0.325326\n",
      "tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.2\tLoss: 0.311443\n",
      "tensor(0.2908, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.4\tLoss: 0.290812\n",
      "tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.6\tLoss: 0.321830\n",
      "tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:292 0.8\tLoss: 0.352741\n",
      "\n",
      "Test Epoch: 292\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 292\tmaintain_Accuracy: 5652/10593 (53%)\n",
      "\n",
      "tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.0\tLoss: 0.302205\n",
      "tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.2\tLoss: 0.305627\n",
      "tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.4\tLoss: 0.340138\n",
      "tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.6\tLoss: 0.312267\n",
      "tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:293 0.8\tLoss: 0.315029\n",
      "\n",
      "Test Epoch: 293\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 293\tmaintain_Accuracy: 5660/10593 (53%)\n",
      "\n",
      "tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.0\tLoss: 0.318934\n",
      "tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.2\tLoss: 0.326760\n",
      "tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.4\tLoss: 0.315070\n",
      "tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.6\tLoss: 0.318068\n",
      "tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:294 0.8\tLoss: 0.346423\n",
      "\n",
      "Test Epoch: 294\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 294\tmaintain_Accuracy: 5587/10593 (53%)\n",
      "\n",
      "tensor(0.2991, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.0\tLoss: 0.299050\n",
      "tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.2\tLoss: 0.293837\n",
      "tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.4\tLoss: 0.305071\n",
      "tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.6\tLoss: 0.344082\n",
      "tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:295 0.8\tLoss: 0.315872\n",
      "\n",
      "Train Epoch: 295\tAttack_Accuracy: 4342/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 295\tmaintain_Accuracy: 6712/12800 (52%)\n",
      "\n",
      "alpha: 0.4938511418403654\n",
      "\n",
      "Test Epoch: 295\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 295\tmaintain_Accuracy: 5554/10593 (52%)\n",
      "\n",
      "tensor(0.3078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.0\tLoss: 0.307824\n",
      "tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.2\tLoss: 0.326355\n",
      "tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.4\tLoss: 0.297162\n",
      "tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.6\tLoss: 0.299482\n",
      "tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:296 0.8\tLoss: 0.287320\n",
      "\n",
      "Test Epoch: 296\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 296\tmaintain_Accuracy: 5558/10593 (52%)\n",
      "\n",
      "tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.0\tLoss: 0.299599\n",
      "tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.2\tLoss: 0.325609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.4\tLoss: 0.340015\n",
      "tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.6\tLoss: 0.285938\n",
      "tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:297 0.8\tLoss: 0.333429\n",
      "\n",
      "Test Epoch: 297\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 297\tmaintain_Accuracy: 5588/10593 (53%)\n",
      "\n",
      "tensor(0.3193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.0\tLoss: 0.319250\n",
      "tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.2\tLoss: 0.323718\n",
      "tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.4\tLoss: 0.344254\n",
      "tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.6\tLoss: 0.274510\n",
      "tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:298 0.8\tLoss: 0.294315\n",
      "\n",
      "Test Epoch: 298\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 298\tmaintain_Accuracy: 5506/10593 (52%)\n",
      "\n",
      "tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.0\tLoss: 0.370058\n",
      "tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.2\tLoss: 0.316209\n",
      "tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.4\tLoss: 0.285155\n",
      "tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.6\tLoss: 0.304886\n",
      "tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:299 0.8\tLoss: 0.330473\n",
      "\n",
      "Test Epoch: 299\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 299\tmaintain_Accuracy: 5481/10593 (52%)\n",
      "\n",
      "tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.0\tLoss: 0.285339\n",
      "tensor(0.3010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.2\tLoss: 0.300983\n",
      "tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.4\tLoss: 0.268341\n",
      "tensor(0.3657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.6\tLoss: 0.365750\n",
      "tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:300 0.8\tLoss: 0.342016\n",
      "\n",
      "Train Epoch: 300\tAttack_Accuracy: 4404/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 300\tmaintain_Accuracy: 6646/12800 (52%)\n",
      "\n",
      "alpha: 0.3071607394536299\n",
      "\n",
      "Test Epoch: 300\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 300\tmaintain_Accuracy: 5567/10593 (53%)\n",
      "\n",
      "tensor(0.3344, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.0\tLoss: 0.334391\n",
      "tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.2\tLoss: 0.306074\n",
      "tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.4\tLoss: 0.333800\n",
      "tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.6\tLoss: 0.319595\n",
      "tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:301 0.8\tLoss: 0.309644\n",
      "\n",
      "Test Epoch: 301\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 301\tmaintain_Accuracy: 5620/10593 (53%)\n",
      "\n",
      "tensor(0.3461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.0\tLoss: 0.346091\n",
      "tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.2\tLoss: 0.347693\n",
      "tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.4\tLoss: 0.277245\n",
      "tensor(0.3152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.6\tLoss: 0.315225\n",
      "tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:302 0.8\tLoss: 0.301966\n",
      "\n",
      "Test Epoch: 302\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 302\tmaintain_Accuracy: 5609/10593 (53%)\n",
      "\n",
      "tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.0\tLoss: 0.305822\n",
      "tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.2\tLoss: 0.277941\n",
      "tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.4\tLoss: 0.311027\n",
      "tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.6\tLoss: 0.306865\n",
      "tensor(0.3401, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:303 0.8\tLoss: 0.340145\n",
      "\n",
      "Test Epoch: 303\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 303\tmaintain_Accuracy: 5585/10593 (53%)\n",
      "\n",
      "tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.0\tLoss: 0.309716\n",
      "tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.2\tLoss: 0.310342\n",
      "tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.4\tLoss: 0.295456\n",
      "tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.6\tLoss: 0.321302\n",
      "tensor(0.3156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:304 0.8\tLoss: 0.315625\n",
      "\n",
      "Test Epoch: 304\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 304\tmaintain_Accuracy: 5603/10593 (53%)\n",
      "\n",
      "tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.0\tLoss: 0.316473\n",
      "tensor(0.3595, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.2\tLoss: 0.359480\n",
      "tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.4\tLoss: 0.270288\n",
      "tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.6\tLoss: 0.276340\n",
      "tensor(0.3130, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:305 0.8\tLoss: 0.312973\n",
      "\n",
      "Train Epoch: 305\tAttack_Accuracy: 4313/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 305\tmaintain_Accuracy: 6749/12800 (53%)\n",
      "\n",
      "alpha: 0.4316302049159979\n",
      "\n",
      "Test Epoch: 305\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 305\tmaintain_Accuracy: 5625/10593 (53%)\n",
      "\n",
      "tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.0\tLoss: 0.299158\n",
      "tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.2\tLoss: 0.336345\n",
      "tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.4\tLoss: 0.269581\n",
      "tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.6\tLoss: 0.305748\n",
      "tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:306 0.8\tLoss: 0.326951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 306\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 306\tmaintain_Accuracy: 5649/10593 (53%)\n",
      "\n",
      "tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.0\tLoss: 0.282716\n",
      "tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.2\tLoss: 0.283433\n",
      "tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.4\tLoss: 0.310218\n",
      "tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.6\tLoss: 0.330480\n",
      "tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:307 0.8\tLoss: 0.316866\n",
      "\n",
      "Test Epoch: 307\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 307\tmaintain_Accuracy: 5670/10593 (54%)\n",
      "\n",
      "tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.0\tLoss: 0.311393\n",
      "tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.2\tLoss: 0.277758\n",
      "tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.4\tLoss: 0.307402\n",
      "tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.6\tLoss: 0.329886\n",
      "tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:308 0.8\tLoss: 0.297379\n",
      "\n",
      "Test Epoch: 308\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 308\tmaintain_Accuracy: 5657/10593 (53%)\n",
      "\n",
      "tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.0\tLoss: 0.342538\n",
      "tensor(0.3042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.2\tLoss: 0.304188\n",
      "tensor(0.3347, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.4\tLoss: 0.334727\n",
      "tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.6\tLoss: 0.324954\n",
      "tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:309 0.8\tLoss: 0.363840\n",
      "\n",
      "Test Epoch: 309\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 309\tmaintain_Accuracy: 5621/10593 (53%)\n",
      "\n",
      "tensor(0.3626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.0\tLoss: 0.362635\n",
      "tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.2\tLoss: 0.289328\n",
      "tensor(0.3463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.4\tLoss: 0.346291\n",
      "tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.6\tLoss: 0.329021\n",
      "tensor(0.3706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:310 0.8\tLoss: 0.370602\n",
      "\n",
      "Train Epoch: 310\tAttack_Accuracy: 4351/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 310\tmaintain_Accuracy: 6661/12800 (52%)\n",
      "\n",
      "alpha: 0.5295732868082386\n",
      "\n",
      "Test Epoch: 310\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 310\tmaintain_Accuracy: 5582/10593 (53%)\n",
      "\n",
      "tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.0\tLoss: 0.297965\n",
      "tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.2\tLoss: 0.280126\n",
      "tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.4\tLoss: 0.277316\n",
      "tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.6\tLoss: 0.315422\n",
      "tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:311 0.8\tLoss: 0.320754\n",
      "\n",
      "Test Epoch: 311\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 311\tmaintain_Accuracy: 5635/10593 (53%)\n",
      "\n",
      "tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.0\tLoss: 0.275152\n",
      "tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.2\tLoss: 0.308144\n",
      "tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.4\tLoss: 0.288736\n",
      "tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.6\tLoss: 0.312517\n",
      "tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:312 0.8\tLoss: 0.273308\n",
      "\n",
      "Test Epoch: 312\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 312\tmaintain_Accuracy: 5679/10593 (54%)\n",
      "\n",
      "tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.0\tLoss: 0.310583\n",
      "tensor(0.3115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.2\tLoss: 0.311532\n",
      "tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.4\tLoss: 0.273145\n",
      "tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.6\tLoss: 0.319395\n",
      "tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:313 0.8\tLoss: 0.331455\n",
      "\n",
      "Test Epoch: 313\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 313\tmaintain_Accuracy: 5704/10593 (54%)\n",
      "\n",
      "tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.0\tLoss: 0.273588\n",
      "tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.2\tLoss: 0.267056\n",
      "tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.4\tLoss: 0.320227\n",
      "tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.6\tLoss: 0.322619\n",
      "tensor(0.3581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:314 0.8\tLoss: 0.358104\n",
      "\n",
      "Test Epoch: 314\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 314\tmaintain_Accuracy: 5689/10593 (54%)\n",
      "\n",
      "tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.0\tLoss: 0.297452\n",
      "tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.2\tLoss: 0.287313\n",
      "tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.4\tLoss: 0.289894\n",
      "tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.6\tLoss: 0.281722\n",
      "tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:315 0.8\tLoss: 0.322876\n",
      "\n",
      "Train Epoch: 315\tAttack_Accuracy: 4445/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 315\tmaintain_Accuracy: 6798/12800 (53%)\n",
      "\n",
      "alpha: 0.48407473698455106\n",
      "\n",
      "Test Epoch: 315\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 315\tmaintain_Accuracy: 5644/10593 (53%)\n",
      "\n",
      "tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.0\tLoss: 0.280209\n",
      "tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.2\tLoss: 0.302530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.4\tLoss: 0.298543\n",
      "tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.6\tLoss: 0.327081\n",
      "tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:316 0.8\tLoss: 0.298542\n",
      "\n",
      "Test Epoch: 316\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 316\tmaintain_Accuracy: 5609/10593 (53%)\n",
      "\n",
      "tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.0\tLoss: 0.241056\n",
      "tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.2\tLoss: 0.261925\n",
      "tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.4\tLoss: 0.261631\n",
      "tensor(0.2971, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.6\tLoss: 0.297137\n",
      "tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:317 0.8\tLoss: 0.317427\n",
      "\n",
      "Test Epoch: 317\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 317\tmaintain_Accuracy: 5619/10593 (53%)\n",
      "\n",
      "tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.0\tLoss: 0.321825\n",
      "tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.2\tLoss: 0.270233\n",
      "tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.4\tLoss: 0.298377\n",
      "tensor(0.3079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.6\tLoss: 0.307899\n",
      "tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:318 0.8\tLoss: 0.337709\n",
      "\n",
      "Test Epoch: 318\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 318\tmaintain_Accuracy: 5548/10593 (52%)\n",
      "\n",
      "tensor(0.3425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.0\tLoss: 0.342520\n",
      "tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.2\tLoss: 0.343587\n",
      "tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.4\tLoss: 0.339747\n",
      "tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.6\tLoss: 0.254418\n",
      "tensor(0.3026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:319 0.8\tLoss: 0.302579\n",
      "\n",
      "Test Epoch: 319\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 319\tmaintain_Accuracy: 5597/10593 (53%)\n",
      "\n",
      "tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.0\tLoss: 0.231415\n",
      "tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.2\tLoss: 0.317487\n",
      "tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.4\tLoss: 0.259404\n",
      "tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.6\tLoss: 0.254726\n",
      "tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:320 0.8\tLoss: 0.291220\n",
      "\n",
      "Train Epoch: 320\tAttack_Accuracy: 4354/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 320\tmaintain_Accuracy: 6714/12800 (52%)\n",
      "\n",
      "alpha: 0.49806187108020844\n",
      "\n",
      "Test Epoch: 320\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 320\tmaintain_Accuracy: 5675/10593 (54%)\n",
      "\n",
      "tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.0\tLoss: 0.273532\n",
      "tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.2\tLoss: 0.301284\n",
      "tensor(0.2556, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.4\tLoss: 0.255607\n",
      "tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.6\tLoss: 0.302004\n",
      "tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:321 0.8\tLoss: 0.270243\n",
      "\n",
      "Test Epoch: 321\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 321\tmaintain_Accuracy: 5695/10593 (54%)\n",
      "\n",
      "tensor(0.3250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.0\tLoss: 0.325037\n",
      "tensor(0.3079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.2\tLoss: 0.307891\n",
      "tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.4\tLoss: 0.280803\n",
      "tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.6\tLoss: 0.333006\n",
      "tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:322 0.8\tLoss: 0.292585\n",
      "\n",
      "Test Epoch: 322\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 322\tmaintain_Accuracy: 5712/10593 (54%)\n",
      "\n",
      "tensor(0.3269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.0\tLoss: 0.326850\n",
      "tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.2\tLoss: 0.288110\n",
      "tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.4\tLoss: 0.275014\n",
      "tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.6\tLoss: 0.317568\n",
      "tensor(0.2971, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:323 0.8\tLoss: 0.297093\n",
      "\n",
      "Test Epoch: 323\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 323\tmaintain_Accuracy: 5702/10593 (54%)\n",
      "\n",
      "tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.0\tLoss: 0.304910\n",
      "tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.2\tLoss: 0.300409\n",
      "tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.4\tLoss: 0.300146\n",
      "tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.6\tLoss: 0.274059\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:324 0.8\tLoss: 0.273381\n",
      "\n",
      "Test Epoch: 324\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 324\tmaintain_Accuracy: 5631/10593 (53%)\n",
      "\n",
      "tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.0\tLoss: 0.291256\n",
      "tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.2\tLoss: 0.259647\n",
      "tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.4\tLoss: 0.301161\n",
      "tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.6\tLoss: 0.320109\n",
      "tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:325 0.8\tLoss: 0.330700\n",
      "\n",
      "Train Epoch: 325\tAttack_Accuracy: 4351/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 325\tmaintain_Accuracy: 6707/12800 (52%)\n",
      "\n",
      "alpha: 0.41254192797982553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 325\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 325\tmaintain_Accuracy: 5705/10593 (54%)\n",
      "\n",
      "tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.0\tLoss: 0.297861\n",
      "tensor(0.3217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.2\tLoss: 0.321707\n",
      "tensor(0.3049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.4\tLoss: 0.304947\n",
      "tensor(0.3177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.6\tLoss: 0.317689\n",
      "tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:326 0.8\tLoss: 0.307647\n",
      "\n",
      "Test Epoch: 326\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 326\tmaintain_Accuracy: 5804/10593 (55%)\n",
      "\n",
      "tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.0\tLoss: 0.293282\n",
      "tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.2\tLoss: 0.270812\n",
      "tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.4\tLoss: 0.350546\n",
      "tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.6\tLoss: 0.311079\n",
      "tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:327 0.8\tLoss: 0.310753\n",
      "\n",
      "Test Epoch: 327\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 327\tmaintain_Accuracy: 5747/10593 (54%)\n",
      "\n",
      "tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.0\tLoss: 0.256976\n",
      "tensor(0.3073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.2\tLoss: 0.307292\n",
      "tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.4\tLoss: 0.301188\n",
      "tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.6\tLoss: 0.271244\n",
      "tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:328 0.8\tLoss: 0.303582\n",
      "\n",
      "Test Epoch: 328\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 328\tmaintain_Accuracy: 5646/10593 (53%)\n",
      "\n",
      "tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.0\tLoss: 0.301821\n",
      "tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.2\tLoss: 0.309592\n",
      "tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.4\tLoss: 0.303284\n",
      "tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.6\tLoss: 0.347295\n",
      "tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:329 0.8\tLoss: 0.306057\n",
      "\n",
      "Test Epoch: 329\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 329\tmaintain_Accuracy: 5690/10593 (54%)\n",
      "\n",
      "tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.0\tLoss: 0.302173\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.2\tLoss: 0.285038\n",
      "tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.4\tLoss: 0.250982\n",
      "tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.6\tLoss: 0.255217\n",
      "tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:330 0.8\tLoss: 0.310907\n",
      "\n",
      "Train Epoch: 330\tAttack_Accuracy: 4297/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 330\tmaintain_Accuracy: 6736/12800 (53%)\n",
      "\n",
      "alpha: 0.37523476155376684\n",
      "\n",
      "Test Epoch: 330\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 330\tmaintain_Accuracy: 5763/10593 (54%)\n",
      "\n",
      "tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.0\tLoss: 0.327978\n",
      "tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.2\tLoss: 0.325584\n",
      "tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.4\tLoss: 0.299410\n",
      "tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.6\tLoss: 0.311934\n",
      "tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:331 0.8\tLoss: 0.318013\n",
      "\n",
      "Test Epoch: 331\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 331\tmaintain_Accuracy: 5753/10593 (54%)\n",
      "\n",
      "tensor(0.3079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.0\tLoss: 0.307879\n",
      "tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.2\tLoss: 0.273290\n",
      "tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.4\tLoss: 0.311987\n",
      "tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.6\tLoss: 0.256018\n",
      "tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:332 0.8\tLoss: 0.269784\n",
      "\n",
      "Test Epoch: 332\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 332\tmaintain_Accuracy: 5731/10593 (54%)\n",
      "\n",
      "tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.0\tLoss: 0.245112\n",
      "tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.2\tLoss: 0.284830\n",
      "tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.4\tLoss: 0.253753\n",
      "tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.6\tLoss: 0.271114\n",
      "tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:333 0.8\tLoss: 0.299239\n",
      "\n",
      "Test Epoch: 333\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 333\tmaintain_Accuracy: 5739/10593 (54%)\n",
      "\n",
      "tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.0\tLoss: 0.279784\n",
      "tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.2\tLoss: 0.288493\n",
      "tensor(0.2969, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.4\tLoss: 0.296910\n",
      "tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.6\tLoss: 0.310824\n",
      "tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:334 0.8\tLoss: 0.302028\n",
      "\n",
      "Test Epoch: 334\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 334\tmaintain_Accuracy: 5764/10593 (54%)\n",
      "\n",
      "tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.0\tLoss: 0.318375\n",
      "tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.2\tLoss: 0.307356\n",
      "tensor(0.2682, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.4\tLoss: 0.268234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.6\tLoss: 0.317104\n",
      "tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:335 0.8\tLoss: 0.261446\n",
      "\n",
      "Train Epoch: 335\tAttack_Accuracy: 4362/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 335\tmaintain_Accuracy: 6844/12800 (53%)\n",
      "\n",
      "alpha: 0.6297814783264719\n",
      "\n",
      "Test Epoch: 335\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 335\tmaintain_Accuracy: 5762/10593 (54%)\n",
      "\n",
      "tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.0\tLoss: 0.309432\n",
      "tensor(0.2941, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.2\tLoss: 0.294064\n",
      "tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.4\tLoss: 0.277604\n",
      "tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.6\tLoss: 0.254610\n",
      "tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:336 0.8\tLoss: 0.297003\n",
      "\n",
      "Test Epoch: 336\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 336\tmaintain_Accuracy: 5775/10593 (55%)\n",
      "\n",
      "tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.0\tLoss: 0.290599\n",
      "tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.2\tLoss: 0.277664\n",
      "tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.4\tLoss: 0.279711\n",
      "tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.6\tLoss: 0.280043\n",
      "tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:337 0.8\tLoss: 0.311245\n",
      "\n",
      "Test Epoch: 337\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 337\tmaintain_Accuracy: 5790/10593 (55%)\n",
      "\n",
      "tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.0\tLoss: 0.341330\n",
      "tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.2\tLoss: 0.282339\n",
      "tensor(0.2824, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.4\tLoss: 0.282429\n",
      "tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.6\tLoss: 0.288217\n",
      "tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:338 0.8\tLoss: 0.277336\n",
      "\n",
      "Test Epoch: 338\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 338\tmaintain_Accuracy: 5718/10593 (54%)\n",
      "\n",
      "tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.0\tLoss: 0.295455\n",
      "tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.2\tLoss: 0.268955\n",
      "tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.4\tLoss: 0.251988\n",
      "tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.6\tLoss: 0.289897\n",
      "tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:339 0.8\tLoss: 0.289356\n",
      "\n",
      "Test Epoch: 339\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 339\tmaintain_Accuracy: 5702/10593 (54%)\n",
      "\n",
      "tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.0\tLoss: 0.291504\n",
      "tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.2\tLoss: 0.292111\n",
      "tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.4\tLoss: 0.272942\n",
      "tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.6\tLoss: 0.263511\n",
      "tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:340 0.8\tLoss: 0.294634\n",
      "\n",
      "Train Epoch: 340\tAttack_Accuracy: 4374/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 340\tmaintain_Accuracy: 6905/12800 (54%)\n",
      "\n",
      "alpha: 0.3025805442486618\n",
      "\n",
      "Test Epoch: 340\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 340\tmaintain_Accuracy: 5763/10593 (54%)\n",
      "\n",
      "tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.0\tLoss: 0.283477\n",
      "tensor(0.2761, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.2\tLoss: 0.276145\n",
      "tensor(0.3338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.4\tLoss: 0.333848\n",
      "tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.6\tLoss: 0.283059\n",
      "tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:341 0.8\tLoss: 0.286455\n",
      "\n",
      "Test Epoch: 341\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 341\tmaintain_Accuracy: 5803/10593 (55%)\n",
      "\n",
      "tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.0\tLoss: 0.288826\n",
      "tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.2\tLoss: 0.293827\n",
      "tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.4\tLoss: 0.318076\n",
      "tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.6\tLoss: 0.249710\n",
      "tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:342 0.8\tLoss: 0.317382\n",
      "\n",
      "Test Epoch: 342\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 342\tmaintain_Accuracy: 5791/10593 (55%)\n",
      "\n",
      "tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.0\tLoss: 0.301663\n",
      "tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.2\tLoss: 0.320805\n",
      "tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.4\tLoss: 0.275539\n",
      "tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.6\tLoss: 0.289383\n",
      "tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:343 0.8\tLoss: 0.259758\n",
      "\n",
      "Test Epoch: 343\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 343\tmaintain_Accuracy: 5800/10593 (55%)\n",
      "\n",
      "tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.0\tLoss: 0.266936\n",
      "tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.2\tLoss: 0.248656\n",
      "tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.4\tLoss: 0.314134\n",
      "tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.6\tLoss: 0.264972\n",
      "tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:344 0.8\tLoss: 0.293284\n",
      "\n",
      "Test Epoch: 344\tAttack_Accuracy: 288/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 344\tmaintain_Accuracy: 5817/10593 (55%)\n",
      "\n",
      "tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.0\tLoss: 0.244184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.2\tLoss: 0.298774\n",
      "tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.4\tLoss: 0.290711\n",
      "tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.6\tLoss: 0.312370\n",
      "tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:345 0.8\tLoss: 0.293509\n",
      "\n",
      "Train Epoch: 345\tAttack_Accuracy: 4149/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 345\tmaintain_Accuracy: 6899/12800 (54%)\n",
      "\n",
      "alpha: 0.6341556658433279\n",
      "\n",
      "Test Epoch: 345\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 345\tmaintain_Accuracy: 5782/10593 (55%)\n",
      "\n",
      "tensor(0.3459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.0\tLoss: 0.345899\n",
      "tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.2\tLoss: 0.287520\n",
      "tensor(0.3665, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.4\tLoss: 0.366462\n",
      "tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.6\tLoss: 0.301255\n",
      "tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:346 0.8\tLoss: 0.289945\n",
      "\n",
      "Test Epoch: 346\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 346\tmaintain_Accuracy: 5753/10593 (54%)\n",
      "\n",
      "tensor(0.3030, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.0\tLoss: 0.303044\n",
      "tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.2\tLoss: 0.238701\n",
      "tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.4\tLoss: 0.313484\n",
      "tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.6\tLoss: 0.345825\n",
      "tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:347 0.8\tLoss: 0.275018\n",
      "\n",
      "Test Epoch: 347\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 347\tmaintain_Accuracy: 5771/10593 (54%)\n",
      "\n",
      "tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.0\tLoss: 0.318054\n",
      "tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.2\tLoss: 0.280996\n",
      "tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.4\tLoss: 0.255178\n",
      "tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.6\tLoss: 0.318052\n",
      "tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:348 0.8\tLoss: 0.284042\n",
      "\n",
      "Test Epoch: 348\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 348\tmaintain_Accuracy: 5714/10593 (54%)\n",
      "\n",
      "tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.0\tLoss: 0.298077\n",
      "tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.2\tLoss: 0.247625\n",
      "tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.4\tLoss: 0.296694\n",
      "tensor(0.2962, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.6\tLoss: 0.296217\n",
      "tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:349 0.8\tLoss: 0.292886\n",
      "\n",
      "Test Epoch: 349\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 349\tmaintain_Accuracy: 5706/10593 (54%)\n",
      "\n",
      "tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.0\tLoss: 0.251579\n",
      "tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.2\tLoss: 0.262170\n",
      "tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.4\tLoss: 0.283767\n",
      "tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.6\tLoss: 0.254183\n",
      "tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:350 0.8\tLoss: 0.302028\n",
      "\n",
      "Train Epoch: 350\tAttack_Accuracy: 4358/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 350\tmaintain_Accuracy: 6838/12800 (53%)\n",
      "\n",
      "alpha: 0.44357296253628753\n",
      "\n",
      "Test Epoch: 350\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 350\tmaintain_Accuracy: 5814/10593 (55%)\n",
      "\n",
      "tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.0\tLoss: 0.297843\n",
      "tensor(0.3348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.2\tLoss: 0.334784\n",
      "tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.4\tLoss: 0.268515\n",
      "tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.6\tLoss: 0.291287\n",
      "tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:351 0.8\tLoss: 0.295690\n",
      "\n",
      "Test Epoch: 351\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 351\tmaintain_Accuracy: 5784/10593 (55%)\n",
      "\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.0\tLoss: 0.273405\n",
      "tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.2\tLoss: 0.248060\n",
      "tensor(0.2891, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.4\tLoss: 0.289134\n",
      "tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.6\tLoss: 0.258164\n",
      "tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:352 0.8\tLoss: 0.326707\n",
      "\n",
      "Test Epoch: 352\tAttack_Accuracy: 292/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 352\tmaintain_Accuracy: 5773/10593 (54%)\n",
      "\n",
      "tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.0\tLoss: 0.245716\n",
      "tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.2\tLoss: 0.298114\n",
      "tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.4\tLoss: 0.266486\n",
      "tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.6\tLoss: 0.277292\n",
      "tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:353 0.8\tLoss: 0.282654\n",
      "\n",
      "Test Epoch: 353\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 353\tmaintain_Accuracy: 5824/10593 (55%)\n",
      "\n",
      "tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.0\tLoss: 0.296263\n",
      "tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.2\tLoss: 0.284495\n",
      "tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.4\tLoss: 0.297484\n",
      "tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.6\tLoss: 0.288042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:354 0.8\tLoss: 0.276995\n",
      "\n",
      "Test Epoch: 354\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 354\tmaintain_Accuracy: 5773/10593 (54%)\n",
      "\n",
      "tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.0\tLoss: 0.284941\n",
      "tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.2\tLoss: 0.292885\n",
      "tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.4\tLoss: 0.316457\n",
      "tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.6\tLoss: 0.280299\n",
      "tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:355 0.8\tLoss: 0.315953\n",
      "\n",
      "Train Epoch: 355\tAttack_Accuracy: 4407/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 355\tmaintain_Accuracy: 6855/12800 (54%)\n",
      "\n",
      "alpha: 0.6196680755853939\n",
      "\n",
      "Test Epoch: 355\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 355\tmaintain_Accuracy: 5652/10593 (53%)\n",
      "\n",
      "tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.0\tLoss: 0.262694\n",
      "tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.2\tLoss: 0.291297\n",
      "tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.4\tLoss: 0.298057\n",
      "tensor(0.3113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.6\tLoss: 0.311297\n",
      "tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:356 0.8\tLoss: 0.330719\n",
      "\n",
      "Test Epoch: 356\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 356\tmaintain_Accuracy: 5760/10593 (54%)\n",
      "\n",
      "tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.0\tLoss: 0.318213\n",
      "tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.2\tLoss: 0.304548\n",
      "tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.4\tLoss: 0.266041\n",
      "tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.6\tLoss: 0.312694\n",
      "tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:357 0.8\tLoss: 0.319440\n",
      "\n",
      "Test Epoch: 357\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 357\tmaintain_Accuracy: 5795/10593 (55%)\n",
      "\n",
      "tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.0\tLoss: 0.313669\n",
      "tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.2\tLoss: 0.343673\n",
      "tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.4\tLoss: 0.308469\n",
      "tensor(0.3189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.6\tLoss: 0.318875\n",
      "tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:358 0.8\tLoss: 0.292689\n",
      "\n",
      "Test Epoch: 358\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 358\tmaintain_Accuracy: 5657/10593 (53%)\n",
      "\n",
      "tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.0\tLoss: 0.302523\n",
      "tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.2\tLoss: 0.254098\n",
      "tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.4\tLoss: 0.308395\n",
      "tensor(0.2966, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.6\tLoss: 0.296577\n",
      "tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:359 0.8\tLoss: 0.282666\n",
      "\n",
      "Test Epoch: 359\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 359\tmaintain_Accuracy: 5732/10593 (54%)\n",
      "\n",
      "tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.0\tLoss: 0.256771\n",
      "tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.2\tLoss: 0.303217\n",
      "tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.4\tLoss: 0.281058\n",
      "tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.6\tLoss: 0.309285\n",
      "tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:360 0.8\tLoss: 0.279036\n",
      "\n",
      "Train Epoch: 360\tAttack_Accuracy: 4260/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 360\tmaintain_Accuracy: 6855/12800 (54%)\n",
      "\n",
      "alpha: 0.5927327666779129\n",
      "\n",
      "Test Epoch: 360\tAttack_Accuracy: 288/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 360\tmaintain_Accuracy: 5793/10593 (55%)\n",
      "\n",
      "tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.0\tLoss: 0.286307\n",
      "tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.2\tLoss: 0.293036\n",
      "tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.4\tLoss: 0.302332\n",
      "tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.6\tLoss: 0.315325\n",
      "tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:361 0.8\tLoss: 0.301565\n",
      "\n",
      "Test Epoch: 361\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 361\tmaintain_Accuracy: 5792/10593 (55%)\n",
      "\n",
      "tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.0\tLoss: 0.309962\n",
      "tensor(0.2702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.2\tLoss: 0.270216\n",
      "tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.4\tLoss: 0.252246\n",
      "tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.6\tLoss: 0.257336\n",
      "tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:362 0.8\tLoss: 0.260146\n",
      "\n",
      "Test Epoch: 362\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 362\tmaintain_Accuracy: 5760/10593 (54%)\n",
      "\n",
      "tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.0\tLoss: 0.264546\n",
      "tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.2\tLoss: 0.250297\n",
      "tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.4\tLoss: 0.243173\n",
      "tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.6\tLoss: 0.297820\n",
      "tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:363 0.8\tLoss: 0.280121\n",
      "\n",
      "Test Epoch: 363\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 363\tmaintain_Accuracy: 5821/10593 (55%)\n",
      "\n",
      "tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.0\tLoss: 0.300057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.2\tLoss: 0.292637\n",
      "tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.4\tLoss: 0.308801\n",
      "tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.6\tLoss: 0.259267\n",
      "tensor(0.3035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:364 0.8\tLoss: 0.303544\n",
      "\n",
      "Test Epoch: 364\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 364\tmaintain_Accuracy: 5868/10593 (55%)\n",
      "\n",
      "tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.0\tLoss: 0.262575\n",
      "tensor(0.3362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.2\tLoss: 0.336159\n",
      "tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.4\tLoss: 0.295459\n",
      "tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.6\tLoss: 0.279903\n",
      "tensor(0.2870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:365 0.8\tLoss: 0.286984\n",
      "\n",
      "Train Epoch: 365\tAttack_Accuracy: 4361/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 365\tmaintain_Accuracy: 6895/12800 (54%)\n",
      "\n",
      "alpha: 0.7994626237162771\n",
      "\n",
      "Test Epoch: 365\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 365\tmaintain_Accuracy: 5780/10593 (55%)\n",
      "\n",
      "tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.0\tLoss: 0.278734\n",
      "tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.2\tLoss: 0.313112\n",
      "tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.4\tLoss: 0.281132\n",
      "tensor(0.3188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.6\tLoss: 0.318834\n",
      "tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:366 0.8\tLoss: 0.279392\n",
      "\n",
      "Test Epoch: 366\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 366\tmaintain_Accuracy: 5703/10593 (54%)\n",
      "\n",
      "tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.0\tLoss: 0.294352\n",
      "tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.2\tLoss: 0.298191\n",
      "tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.4\tLoss: 0.287312\n",
      "tensor(0.2814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.6\tLoss: 0.281383\n",
      "tensor(0.2393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:367 0.8\tLoss: 0.239307\n",
      "\n",
      "Test Epoch: 367\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 367\tmaintain_Accuracy: 5753/10593 (54%)\n",
      "\n",
      "tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.0\tLoss: 0.272834\n",
      "tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.2\tLoss: 0.228037\n",
      "tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.4\tLoss: 0.307699\n",
      "tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.6\tLoss: 0.265203\n",
      "tensor(0.3136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:368 0.8\tLoss: 0.313614\n",
      "\n",
      "Test Epoch: 368\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 368\tmaintain_Accuracy: 5796/10593 (55%)\n",
      "\n",
      "tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.0\tLoss: 0.272938\n",
      "tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.2\tLoss: 0.288971\n",
      "tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.4\tLoss: 0.281248\n",
      "tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.6\tLoss: 0.243568\n",
      "tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:369 0.8\tLoss: 0.307518\n",
      "\n",
      "Test Epoch: 369\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 369\tmaintain_Accuracy: 5820/10593 (55%)\n",
      "\n",
      "tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.0\tLoss: 0.308439\n",
      "tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.2\tLoss: 0.321459\n",
      "tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.4\tLoss: 0.285070\n",
      "tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.6\tLoss: 0.313170\n",
      "tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:370 0.8\tLoss: 0.284938\n",
      "\n",
      "Train Epoch: 370\tAttack_Accuracy: 4180/6400 (65%)\n",
      "\n",
      "\n",
      "Train Epoch: 370\tmaintain_Accuracy: 6960/12800 (54%)\n",
      "\n",
      "alpha: 0.5326944525112841\n",
      "\n",
      "Test Epoch: 370\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 370\tmaintain_Accuracy: 5801/10593 (55%)\n",
      "\n",
      "tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.0\tLoss: 0.271893\n",
      "tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.2\tLoss: 0.260919\n",
      "tensor(0.3232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.4\tLoss: 0.323180\n",
      "tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.6\tLoss: 0.233687\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:371 0.8\tLoss: 0.270652\n",
      "\n",
      "Test Epoch: 371\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 371\tmaintain_Accuracy: 5774/10593 (55%)\n",
      "\n",
      "tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.0\tLoss: 0.270842\n",
      "tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.2\tLoss: 0.285856\n",
      "tensor(0.3295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.4\tLoss: 0.329463\n",
      "tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.6\tLoss: 0.322514\n",
      "tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:372 0.8\tLoss: 0.328210\n",
      "\n",
      "Test Epoch: 372\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 372\tmaintain_Accuracy: 5731/10593 (54%)\n",
      "\n",
      "tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.0\tLoss: 0.280117\n",
      "tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.2\tLoss: 0.268023\n",
      "tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.4\tLoss: 0.293970\n",
      "tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.6\tLoss: 0.292064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:373 0.8\tLoss: 0.293701\n",
      "\n",
      "Test Epoch: 373\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 373\tmaintain_Accuracy: 5713/10593 (54%)\n",
      "\n",
      "tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.0\tLoss: 0.251276\n",
      "tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.2\tLoss: 0.257214\n",
      "tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.4\tLoss: 0.338217\n",
      "tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.6\tLoss: 0.256141\n",
      "tensor(0.3272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:374 0.8\tLoss: 0.327212\n",
      "\n",
      "Test Epoch: 374\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 374\tmaintain_Accuracy: 5727/10593 (54%)\n",
      "\n",
      "tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.0\tLoss: 0.288539\n",
      "tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.2\tLoss: 0.295743\n",
      "tensor(0.3186, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.4\tLoss: 0.318579\n",
      "tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.6\tLoss: 0.295001\n",
      "tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:375 0.8\tLoss: 0.295907\n",
      "\n",
      "Train Epoch: 375\tAttack_Accuracy: 4332/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 375\tmaintain_Accuracy: 6845/12800 (53%)\n",
      "\n",
      "alpha: 0.33098047802805547\n",
      "\n",
      "Test Epoch: 375\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 375\tmaintain_Accuracy: 5750/10593 (54%)\n",
      "\n",
      "tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.0\tLoss: 0.295808\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.2\tLoss: 0.273386\n",
      "tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.4\tLoss: 0.298981\n",
      "tensor(0.3014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.6\tLoss: 0.301419\n",
      "tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:376 0.8\tLoss: 0.266745\n",
      "\n",
      "Test Epoch: 376\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 376\tmaintain_Accuracy: 5754/10593 (54%)\n",
      "\n",
      "tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.0\tLoss: 0.292163\n",
      "tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.2\tLoss: 0.317377\n",
      "tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.4\tLoss: 0.241916\n",
      "tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.6\tLoss: 0.307224\n",
      "tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:377 0.8\tLoss: 0.262988\n",
      "\n",
      "Test Epoch: 377\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 377\tmaintain_Accuracy: 5746/10593 (54%)\n",
      "\n",
      "tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.0\tLoss: 0.289397\n",
      "tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.2\tLoss: 0.283054\n",
      "tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.4\tLoss: 0.280978\n",
      "tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.6\tLoss: 0.251258\n",
      "tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:378 0.8\tLoss: 0.264036\n",
      "\n",
      "Test Epoch: 378\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 378\tmaintain_Accuracy: 5789/10593 (55%)\n",
      "\n",
      "tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.0\tLoss: 0.258235\n",
      "tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.2\tLoss: 0.299921\n",
      "tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.4\tLoss: 0.271203\n",
      "tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.6\tLoss: 0.291055\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:379 0.8\tLoss: 0.285035\n",
      "\n",
      "Test Epoch: 379\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 379\tmaintain_Accuracy: 5783/10593 (55%)\n",
      "\n",
      "tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.0\tLoss: 0.301750\n",
      "tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.2\tLoss: 0.251972\n",
      "tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.4\tLoss: 0.318457\n",
      "tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.6\tLoss: 0.286279\n",
      "tensor(0.3085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:380 0.8\tLoss: 0.308515\n",
      "\n",
      "Train Epoch: 380\tAttack_Accuracy: 4378/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 380\tmaintain_Accuracy: 6957/12800 (54%)\n",
      "\n",
      "alpha: 0.4523483905425369\n",
      "\n",
      "Test Epoch: 380\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 380\tmaintain_Accuracy: 5787/10593 (55%)\n",
      "\n",
      "tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.0\tLoss: 0.307384\n",
      "tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.2\tLoss: 0.318225\n",
      "tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.4\tLoss: 0.292431\n",
      "tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.6\tLoss: 0.260585\n",
      "tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:381 0.8\tLoss: 0.259265\n",
      "\n",
      "Test Epoch: 381\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 381\tmaintain_Accuracy: 5780/10593 (55%)\n",
      "\n",
      "tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.0\tLoss: 0.308673\n",
      "tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.2\tLoss: 0.291153\n",
      "tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.4\tLoss: 0.266413\n",
      "tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.6\tLoss: 0.327576\n",
      "tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:382 0.8\tLoss: 0.297478\n",
      "\n",
      "Test Epoch: 382\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 382\tmaintain_Accuracy: 5721/10593 (54%)\n",
      "\n",
      "tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.0\tLoss: 0.304047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.2\tLoss: 0.305107\n",
      "tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.4\tLoss: 0.304070\n",
      "tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.6\tLoss: 0.248171\n",
      "tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:383 0.8\tLoss: 0.272885\n",
      "\n",
      "Test Epoch: 383\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 383\tmaintain_Accuracy: 5710/10593 (54%)\n",
      "\n",
      "tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.0\tLoss: 0.309981\n",
      "tensor(0.2945, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.2\tLoss: 0.294493\n",
      "tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.4\tLoss: 0.249908\n",
      "tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.6\tLoss: 0.285810\n",
      "tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:384 0.8\tLoss: 0.271604\n",
      "\n",
      "Test Epoch: 384\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 384\tmaintain_Accuracy: 5760/10593 (54%)\n",
      "\n",
      "tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.0\tLoss: 0.310557\n",
      "tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.2\tLoss: 0.246486\n",
      "tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.4\tLoss: 0.313113\n",
      "tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.6\tLoss: 0.292031\n",
      "tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:385 0.8\tLoss: 0.288255\n",
      "\n",
      "Train Epoch: 385\tAttack_Accuracy: 4365/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 385\tmaintain_Accuracy: 6864/12800 (54%)\n",
      "\n",
      "alpha: 0.7044043124050712\n",
      "\n",
      "Test Epoch: 385\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 385\tmaintain_Accuracy: 5776/10593 (55%)\n",
      "\n",
      "tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.0\tLoss: 0.269453\n",
      "tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.2\tLoss: 0.293899\n",
      "tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.4\tLoss: 0.281611\n",
      "tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.6\tLoss: 0.291479\n",
      "tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:386 0.8\tLoss: 0.304036\n",
      "\n",
      "Test Epoch: 386\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 386\tmaintain_Accuracy: 5781/10593 (55%)\n",
      "\n",
      "tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.0\tLoss: 0.291687\n",
      "tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.2\tLoss: 0.258210\n",
      "tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.4\tLoss: 0.292608\n",
      "tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.6\tLoss: 0.302833\n",
      "tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:387 0.8\tLoss: 0.287092\n",
      "\n",
      "Test Epoch: 387\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 387\tmaintain_Accuracy: 5672/10593 (54%)\n",
      "\n",
      "tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.0\tLoss: 0.251097\n",
      "tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.2\tLoss: 0.290260\n",
      "tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.4\tLoss: 0.292439\n",
      "tensor(0.2762, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.6\tLoss: 0.276184\n",
      "tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:388 0.8\tLoss: 0.264098\n",
      "\n",
      "Test Epoch: 388\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 388\tmaintain_Accuracy: 5679/10593 (54%)\n",
      "\n",
      "tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.0\tLoss: 0.275761\n",
      "tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.2\tLoss: 0.284649\n",
      "tensor(0.2952, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.4\tLoss: 0.295188\n",
      "tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.6\tLoss: 0.310095\n",
      "tensor(0.2809, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:389 0.8\tLoss: 0.280931\n",
      "\n",
      "Test Epoch: 389\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 389\tmaintain_Accuracy: 5738/10593 (54%)\n",
      "\n",
      "tensor(0.3300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.0\tLoss: 0.329954\n",
      "tensor(0.2797, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.2\tLoss: 0.279679\n",
      "tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.4\tLoss: 0.259658\n",
      "tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.6\tLoss: 0.280486\n",
      "tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:390 0.8\tLoss: 0.297188\n",
      "\n",
      "Train Epoch: 390\tAttack_Accuracy: 4328/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 390\tmaintain_Accuracy: 6851/12800 (54%)\n",
      "\n",
      "alpha: 0.8621586251134091\n",
      "\n",
      "Test Epoch: 390\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 390\tmaintain_Accuracy: 5706/10593 (54%)\n",
      "\n",
      "tensor(0.2991, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.0\tLoss: 0.299076\n",
      "tensor(0.3162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.2\tLoss: 0.316204\n",
      "tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.4\tLoss: 0.285953\n",
      "tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.6\tLoss: 0.317452\n",
      "tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:391 0.8\tLoss: 0.310840\n",
      "\n",
      "Test Epoch: 391\tAttack_Accuracy: 311/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 391\tmaintain_Accuracy: 5692/10593 (54%)\n",
      "\n",
      "tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.0\tLoss: 0.275398\n",
      "tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.2\tLoss: 0.255098\n",
      "tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.4\tLoss: 0.287318\n",
      "tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.6\tLoss: 0.300629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:392 0.8\tLoss: 0.267986\n",
      "\n",
      "Test Epoch: 392\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 392\tmaintain_Accuracy: 5826/10593 (55%)\n",
      "\n",
      "tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.0\tLoss: 0.287089\n",
      "tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.2\tLoss: 0.303802\n",
      "tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.4\tLoss: 0.256001\n",
      "tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.6\tLoss: 0.258687\n",
      "tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:393 0.8\tLoss: 0.284766\n",
      "\n",
      "Test Epoch: 393\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 393\tmaintain_Accuracy: 5759/10593 (54%)\n",
      "\n",
      "tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.0\tLoss: 0.304449\n",
      "tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.2\tLoss: 0.254796\n",
      "tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.4\tLoss: 0.276370\n",
      "tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.6\tLoss: 0.341929\n",
      "tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:394 0.8\tLoss: 0.246211\n",
      "\n",
      "Test Epoch: 394\tAttack_Accuracy: 313/412 (76%)\n",
      "\n",
      "\n",
      "Test Epoch: 394\tmaintain_Accuracy: 5721/10593 (54%)\n",
      "\n",
      "tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.0\tLoss: 0.307103\n",
      "tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.2\tLoss: 0.294316\n",
      "tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.4\tLoss: 0.284749\n",
      "tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.6\tLoss: 0.340715\n",
      "tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:395 0.8\tLoss: 0.274984\n",
      "\n",
      "Train Epoch: 395\tAttack_Accuracy: 4453/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 395\tmaintain_Accuracy: 6864/12800 (54%)\n",
      "\n",
      "alpha: 0.28077415498985275\n",
      "\n",
      "Test Epoch: 395\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 395\tmaintain_Accuracy: 5808/10593 (55%)\n",
      "\n",
      "tensor(0.2743, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.0\tLoss: 0.274304\n",
      "tensor(0.2999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.2\tLoss: 0.299858\n",
      "tensor(0.2789, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.4\tLoss: 0.278905\n",
      "tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.6\tLoss: 0.288203\n",
      "tensor(0.2365, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:396 0.8\tLoss: 0.236454\n",
      "\n",
      "Test Epoch: 396\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 396\tmaintain_Accuracy: 5814/10593 (55%)\n",
      "\n",
      "tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.0\tLoss: 0.337219\n",
      "tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.2\tLoss: 0.272127\n",
      "tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.4\tLoss: 0.267193\n",
      "tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.6\tLoss: 0.295494\n",
      "tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:397 0.8\tLoss: 0.252241\n",
      "\n",
      "Test Epoch: 397\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 397\tmaintain_Accuracy: 5733/10593 (54%)\n",
      "\n",
      "tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.0\tLoss: 0.281515\n",
      "tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.2\tLoss: 0.257211\n",
      "tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.4\tLoss: 0.263171\n",
      "tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.6\tLoss: 0.276026\n",
      "tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:398 0.8\tLoss: 0.278302\n",
      "\n",
      "Test Epoch: 398\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 398\tmaintain_Accuracy: 5741/10593 (54%)\n",
      "\n",
      "tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.0\tLoss: 0.300120\n",
      "tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.2\tLoss: 0.283606\n",
      "tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.4\tLoss: 0.262296\n",
      "tensor(0.3426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.6\tLoss: 0.342591\n",
      "tensor(0.2896, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:399 0.8\tLoss: 0.289588\n",
      "\n",
      "Test Epoch: 399\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 399\tmaintain_Accuracy: 5772/10593 (54%)\n",
      "\n",
      "tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.0\tLoss: 0.287466\n",
      "tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.2\tLoss: 0.276871\n",
      "tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.4\tLoss: 0.272687\n",
      "tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.6\tLoss: 0.319480\n",
      "tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:400 0.8\tLoss: 0.260255\n",
      "\n",
      "Train Epoch: 400\tAttack_Accuracy: 4366/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 400\tmaintain_Accuracy: 6905/12800 (54%)\n",
      "\n",
      "alpha: 0.7459364019119757\n",
      "\n",
      "Test Epoch: 400\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 400\tmaintain_Accuracy: 5737/10593 (54%)\n",
      "\n",
      "tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.0\tLoss: 0.289332\n",
      "tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.2\tLoss: 0.271059\n",
      "tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.4\tLoss: 0.273774\n",
      "tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.6\tLoss: 0.292008\n",
      "tensor(0.3407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:401 0.8\tLoss: 0.340716\n",
      "\n",
      "Test Epoch: 401\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 401\tmaintain_Accuracy: 5698/10593 (54%)\n",
      "\n",
      "tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.0\tLoss: 0.300350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.2\tLoss: 0.246783\n",
      "tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.4\tLoss: 0.318519\n",
      "tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.6\tLoss: 0.305894\n",
      "tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:402 0.8\tLoss: 0.264241\n",
      "\n",
      "Test Epoch: 402\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 402\tmaintain_Accuracy: 5731/10593 (54%)\n",
      "\n",
      "tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.0\tLoss: 0.279879\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.2\tLoss: 0.285039\n",
      "tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.4\tLoss: 0.273254\n",
      "tensor(0.2988, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.6\tLoss: 0.298812\n",
      "tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:403 0.8\tLoss: 0.284120\n",
      "\n",
      "Test Epoch: 403\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 403\tmaintain_Accuracy: 5828/10593 (55%)\n",
      "\n",
      "tensor(0.3210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.0\tLoss: 0.321048\n",
      "tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.2\tLoss: 0.309147\n",
      "tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.4\tLoss: 0.287808\n",
      "tensor(0.3068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.6\tLoss: 0.306794\n",
      "tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:404 0.8\tLoss: 0.294435\n",
      "\n",
      "Test Epoch: 404\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 404\tmaintain_Accuracy: 5879/10593 (55%)\n",
      "\n",
      "tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.0\tLoss: 0.297216\n",
      "tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.2\tLoss: 0.314841\n",
      "tensor(0.3067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.4\tLoss: 0.306678\n",
      "tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.6\tLoss: 0.263543\n",
      "tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:405 0.8\tLoss: 0.269179\n",
      "\n",
      "Train Epoch: 405\tAttack_Accuracy: 4330/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 405\tmaintain_Accuracy: 7107/12800 (56%)\n",
      "\n",
      "alpha: 0.8682788561596066\n",
      "\n",
      "Test Epoch: 405\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 405\tmaintain_Accuracy: 5853/10593 (55%)\n",
      "\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.0\tLoss: 0.285039\n",
      "tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.2\tLoss: 0.264174\n",
      "tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.4\tLoss: 0.288467\n",
      "tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.6\tLoss: 0.290265\n",
      "tensor(0.2794, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:406 0.8\tLoss: 0.279419\n",
      "\n",
      "Test Epoch: 406\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 406\tmaintain_Accuracy: 5814/10593 (55%)\n",
      "\n",
      "tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.0\tLoss: 0.282178\n",
      "tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.2\tLoss: 0.264006\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.4\tLoss: 0.270715\n",
      "tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.6\tLoss: 0.261327\n",
      "tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:407 0.8\tLoss: 0.274191\n",
      "\n",
      "Test Epoch: 407\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 407\tmaintain_Accuracy: 5823/10593 (55%)\n",
      "\n",
      "tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.0\tLoss: 0.289412\n",
      "tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.2\tLoss: 0.260663\n",
      "tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.4\tLoss: 0.278345\n",
      "tensor(0.3006, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.6\tLoss: 0.300625\n",
      "tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:408 0.8\tLoss: 0.263329\n",
      "\n",
      "Test Epoch: 408\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 408\tmaintain_Accuracy: 5827/10593 (55%)\n",
      "\n",
      "tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.0\tLoss: 0.286477\n",
      "tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.2\tLoss: 0.297489\n",
      "tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.4\tLoss: 0.305673\n",
      "tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.6\tLoss: 0.298043\n",
      "tensor(0.2677, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:409 0.8\tLoss: 0.267730\n",
      "\n",
      "Test Epoch: 409\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 409\tmaintain_Accuracy: 5792/10593 (55%)\n",
      "\n",
      "tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.0\tLoss: 0.282082\n",
      "tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.2\tLoss: 0.302204\n",
      "tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.4\tLoss: 0.292094\n",
      "tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.6\tLoss: 0.314471\n",
      "tensor(0.2876, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:410 0.8\tLoss: 0.287577\n",
      "\n",
      "Train Epoch: 410\tAttack_Accuracy: 4395/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 410\tmaintain_Accuracy: 6963/12800 (54%)\n",
      "\n",
      "alpha: 0.515206867403255\n",
      "\n",
      "Test Epoch: 410\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 410\tmaintain_Accuracy: 5757/10593 (54%)\n",
      "\n",
      "tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.0\tLoss: 0.300433\n",
      "tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.2\tLoss: 0.274492\n",
      "tensor(0.2955, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.4\tLoss: 0.295503\n",
      "tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.6\tLoss: 0.338761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:411 0.8\tLoss: 0.230561\n",
      "\n",
      "Test Epoch: 411\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 411\tmaintain_Accuracy: 5814/10593 (55%)\n",
      "\n",
      "tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.0\tLoss: 0.288736\n",
      "tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.2\tLoss: 0.245197\n",
      "tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.4\tLoss: 0.324230\n",
      "tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.6\tLoss: 0.250669\n",
      "tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:412 0.8\tLoss: 0.293229\n",
      "\n",
      "Test Epoch: 412\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 412\tmaintain_Accuracy: 5817/10593 (55%)\n",
      "\n",
      "tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.0\tLoss: 0.327408\n",
      "tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.2\tLoss: 0.310250\n",
      "tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.4\tLoss: 0.259845\n",
      "tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.6\tLoss: 0.275164\n",
      "tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:413 0.8\tLoss: 0.280057\n",
      "\n",
      "Test Epoch: 413\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 413\tmaintain_Accuracy: 5818/10593 (55%)\n",
      "\n",
      "tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.0\tLoss: 0.253812\n",
      "tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.2\tLoss: 0.247814\n",
      "tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.4\tLoss: 0.248916\n",
      "tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.6\tLoss: 0.269276\n",
      "tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:414 0.8\tLoss: 0.232360\n",
      "\n",
      "Test Epoch: 414\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 414\tmaintain_Accuracy: 5838/10593 (55%)\n",
      "\n",
      "tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.0\tLoss: 0.243988\n",
      "tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.2\tLoss: 0.288667\n",
      "tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.4\tLoss: 0.229566\n",
      "tensor(0.2904, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.6\tLoss: 0.290415\n",
      "tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:415 0.8\tLoss: 0.295897\n",
      "\n",
      "Train Epoch: 415\tAttack_Accuracy: 4429/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 415\tmaintain_Accuracy: 7098/12800 (55%)\n",
      "\n",
      "alpha: 0.23010233627811247\n",
      "\n",
      "Test Epoch: 415\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 415\tmaintain_Accuracy: 5878/10593 (55%)\n",
      "\n",
      "tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.0\tLoss: 0.295080\n",
      "tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.2\tLoss: 0.256611\n",
      "tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.4\tLoss: 0.240750\n",
      "tensor(0.2822, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.6\tLoss: 0.282213\n",
      "tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:416 0.8\tLoss: 0.248930\n",
      "\n",
      "Test Epoch: 416\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 416\tmaintain_Accuracy: 5863/10593 (55%)\n",
      "\n",
      "tensor(0.3091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.0\tLoss: 0.309090\n",
      "tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.2\tLoss: 0.306074\n",
      "tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.4\tLoss: 0.269712\n",
      "tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.6\tLoss: 0.260588\n",
      "tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:417 0.8\tLoss: 0.304720\n",
      "\n",
      "Test Epoch: 417\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 417\tmaintain_Accuracy: 5851/10593 (55%)\n",
      "\n",
      "tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.0\tLoss: 0.247643\n",
      "tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.2\tLoss: 0.289483\n",
      "tensor(0.2400, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.4\tLoss: 0.239967\n",
      "tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.6\tLoss: 0.249170\n",
      "tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:418 0.8\tLoss: 0.275528\n",
      "\n",
      "Test Epoch: 418\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 418\tmaintain_Accuracy: 5829/10593 (55%)\n",
      "\n",
      "tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.0\tLoss: 0.268894\n",
      "tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.2\tLoss: 0.239479\n",
      "tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.4\tLoss: 0.292579\n",
      "tensor(0.2445, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.6\tLoss: 0.244513\n",
      "tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:419 0.8\tLoss: 0.332949\n",
      "\n",
      "Test Epoch: 419\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 419\tmaintain_Accuracy: 5838/10593 (55%)\n",
      "\n",
      "tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.0\tLoss: 0.272941\n",
      "tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.2\tLoss: 0.274715\n",
      "tensor(0.3192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.4\tLoss: 0.319169\n",
      "tensor(0.2686, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.6\tLoss: 0.268561\n",
      "tensor(0.2509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:420 0.8\tLoss: 0.250941\n",
      "\n",
      "Train Epoch: 420\tAttack_Accuracy: 4360/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 420\tmaintain_Accuracy: 7044/12800 (55%)\n",
      "\n",
      "alpha: 0.5738438775863368\n",
      "\n",
      "Test Epoch: 420\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 420\tmaintain_Accuracy: 5851/10593 (55%)\n",
      "\n",
      "tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.0\tLoss: 0.252056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.2\tLoss: 0.282326\n",
      "tensor(0.2410, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.4\tLoss: 0.240970\n",
      "tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.6\tLoss: 0.292246\n",
      "tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:421 0.8\tLoss: 0.286703\n",
      "\n",
      "Test Epoch: 421\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 421\tmaintain_Accuracy: 5855/10593 (55%)\n",
      "\n",
      "tensor(0.2917, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.0\tLoss: 0.291689\n",
      "tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.2\tLoss: 0.238335\n",
      "tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.4\tLoss: 0.245516\n",
      "tensor(0.2898, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.6\tLoss: 0.289755\n",
      "tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:422 0.8\tLoss: 0.295339\n",
      "\n",
      "Test Epoch: 422\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 422\tmaintain_Accuracy: 5890/10593 (56%)\n",
      "\n",
      "tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.0\tLoss: 0.256812\n",
      "tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.2\tLoss: 0.209046\n",
      "tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.4\tLoss: 0.256764\n",
      "tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.6\tLoss: 0.245557\n",
      "tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:423 0.8\tLoss: 0.274627\n",
      "\n",
      "Test Epoch: 423\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 423\tmaintain_Accuracy: 5846/10593 (55%)\n",
      "\n",
      "tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.0\tLoss: 0.273992\n",
      "tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.2\tLoss: 0.293401\n",
      "tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.4\tLoss: 0.260788\n",
      "tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.6\tLoss: 0.327984\n",
      "tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:424 0.8\tLoss: 0.223778\n",
      "\n",
      "Test Epoch: 424\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 424\tmaintain_Accuracy: 5849/10593 (55%)\n",
      "\n",
      "tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.0\tLoss: 0.265609\n",
      "tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.2\tLoss: 0.277115\n",
      "tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.4\tLoss: 0.266642\n",
      "tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.6\tLoss: 0.220164\n",
      "tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:425 0.8\tLoss: 0.273804\n",
      "\n",
      "Train Epoch: 425\tAttack_Accuracy: 4384/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 425\tmaintain_Accuracy: 7013/12800 (55%)\n",
      "\n",
      "alpha: 0.4727255614310252\n",
      "\n",
      "Test Epoch: 425\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 425\tmaintain_Accuracy: 5855/10593 (55%)\n",
      "\n",
      "tensor(0.2861, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.0\tLoss: 0.286143\n",
      "tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.2\tLoss: 0.256621\n",
      "tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.4\tLoss: 0.313800\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.6\tLoss: 0.270632\n",
      "tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:426 0.8\tLoss: 0.292872\n",
      "\n",
      "Test Epoch: 426\tAttack_Accuracy: 287/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 426\tmaintain_Accuracy: 5922/10593 (56%)\n",
      "\n",
      "tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.0\tLoss: 0.282668\n",
      "tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.2\tLoss: 0.291035\n",
      "tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.4\tLoss: 0.315750\n",
      "tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.6\tLoss: 0.244694\n",
      "tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:427 0.8\tLoss: 0.233891\n",
      "\n",
      "Test Epoch: 427\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 427\tmaintain_Accuracy: 5909/10593 (56%)\n",
      "\n",
      "tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.0\tLoss: 0.249711\n",
      "tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.2\tLoss: 0.234893\n",
      "tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.4\tLoss: 0.232324\n",
      "tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.6\tLoss: 0.306913\n",
      "tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:428 0.8\tLoss: 0.251432\n",
      "\n",
      "Test Epoch: 428\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 428\tmaintain_Accuracy: 5820/10593 (55%)\n",
      "\n",
      "tensor(0.3014, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.0\tLoss: 0.301387\n",
      "tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.2\tLoss: 0.222348\n",
      "tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.4\tLoss: 0.303878\n",
      "tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.6\tLoss: 0.277551\n",
      "tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:429 0.8\tLoss: 0.249150\n",
      "\n",
      "Test Epoch: 429\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 429\tmaintain_Accuracy: 5817/10593 (55%)\n",
      "\n",
      "tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.0\tLoss: 0.262918\n",
      "tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.2\tLoss: 0.274770\n",
      "tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.4\tLoss: 0.243864\n",
      "tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.6\tLoss: 0.251812\n",
      "tensor(0.2015, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:430 0.8\tLoss: 0.201522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 430\tAttack_Accuracy: 4399/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 430\tmaintain_Accuracy: 6983/12800 (55%)\n",
      "\n",
      "alpha: 0.23135120947395285\n",
      "\n",
      "Test Epoch: 430\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 430\tmaintain_Accuracy: 5855/10593 (55%)\n",
      "\n",
      "tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.0\tLoss: 0.273104\n",
      "tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.2\tLoss: 0.276375\n",
      "tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.4\tLoss: 0.269546\n",
      "tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.6\tLoss: 0.273182\n",
      "tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:431 0.8\tLoss: 0.283640\n",
      "\n",
      "Test Epoch: 431\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 431\tmaintain_Accuracy: 5809/10593 (55%)\n",
      "\n",
      "tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.0\tLoss: 0.277751\n",
      "tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.2\tLoss: 0.203775\n",
      "tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.4\tLoss: 0.262921\n",
      "tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.6\tLoss: 0.237037\n",
      "tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:432 0.8\tLoss: 0.264555\n",
      "\n",
      "Test Epoch: 432\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 432\tmaintain_Accuracy: 5773/10593 (54%)\n",
      "\n",
      "tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.0\tLoss: 0.271545\n",
      "tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.2\tLoss: 0.252110\n",
      "tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.4\tLoss: 0.243567\n",
      "tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.6\tLoss: 0.270511\n",
      "tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:433 0.8\tLoss: 0.314466\n",
      "\n",
      "Test Epoch: 433\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 433\tmaintain_Accuracy: 5809/10593 (55%)\n",
      "\n",
      "tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.0\tLoss: 0.283854\n",
      "tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.2\tLoss: 0.262110\n",
      "tensor(0.3027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.4\tLoss: 0.302692\n",
      "tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.6\tLoss: 0.255698\n",
      "tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:434 0.8\tLoss: 0.281070\n",
      "\n",
      "Test Epoch: 434\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 434\tmaintain_Accuracy: 5857/10593 (55%)\n",
      "\n",
      "tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.0\tLoss: 0.293828\n",
      "tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.2\tLoss: 0.278828\n",
      "tensor(0.3026, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.4\tLoss: 0.302596\n",
      "tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.6\tLoss: 0.305332\n",
      "tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:435 0.8\tLoss: 0.268701\n",
      "\n",
      "Train Epoch: 435\tAttack_Accuracy: 4332/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 435\tmaintain_Accuracy: 7098/12800 (55%)\n",
      "\n",
      "alpha: 0.6700292986247617\n",
      "\n",
      "Test Epoch: 435\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 435\tmaintain_Accuracy: 5845/10593 (55%)\n",
      "\n",
      "tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.0\tLoss: 0.282272\n",
      "tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.2\tLoss: 0.264537\n",
      "tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.4\tLoss: 0.261199\n",
      "tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.6\tLoss: 0.276296\n",
      "tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:436 0.8\tLoss: 0.275214\n",
      "\n",
      "Test Epoch: 436\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 436\tmaintain_Accuracy: 5835/10593 (55%)\n",
      "\n",
      "tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.0\tLoss: 0.229041\n",
      "tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.2\tLoss: 0.266935\n",
      "tensor(0.3099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.4\tLoss: 0.309874\n",
      "tensor(0.3043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.6\tLoss: 0.304266\n",
      "tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:437 0.8\tLoss: 0.251322\n",
      "\n",
      "Test Epoch: 437\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 437\tmaintain_Accuracy: 5869/10593 (55%)\n",
      "\n",
      "tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.0\tLoss: 0.273210\n",
      "tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.2\tLoss: 0.258392\n",
      "tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.4\tLoss: 0.284597\n",
      "tensor(0.2862, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.6\tLoss: 0.286161\n",
      "tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:438 0.8\tLoss: 0.286018\n",
      "\n",
      "Test Epoch: 438\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 438\tmaintain_Accuracy: 5914/10593 (56%)\n",
      "\n",
      "tensor(0.2287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.0\tLoss: 0.228728\n",
      "tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.2\tLoss: 0.296989\n",
      "tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.4\tLoss: 0.278259\n",
      "tensor(0.2693, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.6\tLoss: 0.269292\n",
      "tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:439 0.8\tLoss: 0.260634\n",
      "\n",
      "Test Epoch: 439\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 439\tmaintain_Accuracy: 5942/10593 (56%)\n",
      "\n",
      "tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.0\tLoss: 0.271600\n",
      "tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.2\tLoss: 0.284421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.4\tLoss: 0.290017\n",
      "tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.6\tLoss: 0.230622\n",
      "tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:440 0.8\tLoss: 0.248827\n",
      "\n",
      "Train Epoch: 440\tAttack_Accuracy: 4357/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 440\tmaintain_Accuracy: 7097/12800 (55%)\n",
      "\n",
      "alpha: 0.43021216951422175\n",
      "\n",
      "Test Epoch: 440\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 440\tmaintain_Accuracy: 5940/10593 (56%)\n",
      "\n",
      "tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.0\tLoss: 0.220396\n",
      "tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.2\tLoss: 0.247943\n",
      "tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.4\tLoss: 0.301953\n",
      "tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.6\tLoss: 0.231019\n",
      "tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:441 0.8\tLoss: 0.294821\n",
      "\n",
      "Test Epoch: 441\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 441\tmaintain_Accuracy: 5878/10593 (55%)\n",
      "\n",
      "tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.0\tLoss: 0.238273\n",
      "tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.2\tLoss: 0.275295\n",
      "tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.4\tLoss: 0.244814\n",
      "tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.6\tLoss: 0.253569\n",
      "tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:442 0.8\tLoss: 0.277326\n",
      "\n",
      "Test Epoch: 442\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 442\tmaintain_Accuracy: 5869/10593 (55%)\n",
      "\n",
      "tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.0\tLoss: 0.273042\n",
      "tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.2\tLoss: 0.268401\n",
      "tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.4\tLoss: 0.256523\n",
      "tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.6\tLoss: 0.260140\n",
      "tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:443 0.8\tLoss: 0.273245\n",
      "\n",
      "Test Epoch: 443\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 443\tmaintain_Accuracy: 5895/10593 (56%)\n",
      "\n",
      "tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.0\tLoss: 0.251462\n",
      "tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.2\tLoss: 0.260788\n",
      "tensor(0.2630, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.4\tLoss: 0.263041\n",
      "tensor(0.3215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.6\tLoss: 0.321471\n",
      "tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:444 0.8\tLoss: 0.254768\n",
      "\n",
      "Test Epoch: 444\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 444\tmaintain_Accuracy: 5878/10593 (55%)\n",
      "\n",
      "tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.0\tLoss: 0.235747\n",
      "tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.2\tLoss: 0.274690\n",
      "tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.4\tLoss: 0.286840\n",
      "tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.6\tLoss: 0.253197\n",
      "tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:445 0.8\tLoss: 0.280395\n",
      "\n",
      "Train Epoch: 445\tAttack_Accuracy: 4392/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 445\tmaintain_Accuracy: 7082/12800 (55%)\n",
      "\n",
      "alpha: 0.7352292835443991\n",
      "\n",
      "Test Epoch: 445\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 445\tmaintain_Accuracy: 5846/10593 (55%)\n",
      "\n",
      "tensor(0.2768, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.0\tLoss: 0.276840\n",
      "tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.2\tLoss: 0.254860\n",
      "tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.4\tLoss: 0.252401\n",
      "tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.6\tLoss: 0.233728\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:446 0.8\tLoss: 0.253855\n",
      "\n",
      "Test Epoch: 446\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 446\tmaintain_Accuracy: 5843/10593 (55%)\n",
      "\n",
      "tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.0\tLoss: 0.237147\n",
      "tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.2\tLoss: 0.269904\n",
      "tensor(0.2945, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.4\tLoss: 0.294523\n",
      "tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.6\tLoss: 0.251006\n",
      "tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:447 0.8\tLoss: 0.268027\n",
      "\n",
      "Test Epoch: 447\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 447\tmaintain_Accuracy: 5866/10593 (55%)\n",
      "\n",
      "tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.0\tLoss: 0.292712\n",
      "tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.2\tLoss: 0.271783\n",
      "tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.4\tLoss: 0.269779\n",
      "tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.6\tLoss: 0.245664\n",
      "tensor(0.2602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:448 0.8\tLoss: 0.260209\n",
      "\n",
      "Test Epoch: 448\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 448\tmaintain_Accuracy: 5838/10593 (55%)\n",
      "\n",
      "tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.0\tLoss: 0.269938\n",
      "tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.2\tLoss: 0.261211\n",
      "tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.4\tLoss: 0.268343\n",
      "tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.6\tLoss: 0.280537\n",
      "tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:449 0.8\tLoss: 0.279199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 449\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 449\tmaintain_Accuracy: 5822/10593 (55%)\n",
      "\n",
      "tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.0\tLoss: 0.246036\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.2\tLoss: 0.270745\n",
      "tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.4\tLoss: 0.285246\n",
      "tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.6\tLoss: 0.290687\n",
      "tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:450 0.8\tLoss: 0.287528\n",
      "\n",
      "Train Epoch: 450\tAttack_Accuracy: 4332/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 450\tmaintain_Accuracy: 7079/12800 (55%)\n",
      "\n",
      "alpha: 0.4735772598983171\n",
      "\n",
      "Test Epoch: 450\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 450\tmaintain_Accuracy: 5851/10593 (55%)\n",
      "\n",
      "tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.0\tLoss: 0.238398\n",
      "tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.2\tLoss: 0.279462\n",
      "tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.4\tLoss: 0.243127\n",
      "tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.6\tLoss: 0.291424\n",
      "tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:451 0.8\tLoss: 0.310206\n",
      "\n",
      "Test Epoch: 451\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 451\tmaintain_Accuracy: 5859/10593 (55%)\n",
      "\n",
      "tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.0\tLoss: 0.260329\n",
      "tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.2\tLoss: 0.241640\n",
      "tensor(0.2814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.4\tLoss: 0.281389\n",
      "tensor(0.2646, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.6\tLoss: 0.264580\n",
      "tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:452 0.8\tLoss: 0.248180\n",
      "\n",
      "Test Epoch: 452\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 452\tmaintain_Accuracy: 5856/10593 (55%)\n",
      "\n",
      "tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.0\tLoss: 0.235191\n",
      "tensor(0.2815, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.2\tLoss: 0.281451\n",
      "tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.4\tLoss: 0.297020\n",
      "tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.6\tLoss: 0.246204\n",
      "tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:453 0.8\tLoss: 0.253376\n",
      "\n",
      "Test Epoch: 453\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 453\tmaintain_Accuracy: 5849/10593 (55%)\n",
      "\n",
      "tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.0\tLoss: 0.317143\n",
      "tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.2\tLoss: 0.218763\n",
      "tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.4\tLoss: 0.224372\n",
      "tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.6\tLoss: 0.299385\n",
      "tensor(0.2939, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:454 0.8\tLoss: 0.293857\n",
      "\n",
      "Test Epoch: 454\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 454\tmaintain_Accuracy: 5864/10593 (55%)\n",
      "\n",
      "tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.0\tLoss: 0.295761\n",
      "tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.2\tLoss: 0.357810\n",
      "tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.4\tLoss: 0.255857\n",
      "tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.6\tLoss: 0.265145\n",
      "tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:455 0.8\tLoss: 0.250053\n",
      "\n",
      "Train Epoch: 455\tAttack_Accuracy: 4410/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 455\tmaintain_Accuracy: 6994/12800 (55%)\n",
      "\n",
      "alpha: 0.5309389798093884\n",
      "\n",
      "Test Epoch: 455\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 455\tmaintain_Accuracy: 5864/10593 (55%)\n",
      "\n",
      "tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.0\tLoss: 0.265073\n",
      "tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.2\tLoss: 0.278736\n",
      "tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.4\tLoss: 0.240437\n",
      "tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.6\tLoss: 0.272828\n",
      "tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:456 0.8\tLoss: 0.265051\n",
      "\n",
      "Test Epoch: 456\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 456\tmaintain_Accuracy: 5824/10593 (55%)\n",
      "\n",
      "tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.0\tLoss: 0.315726\n",
      "tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.2\tLoss: 0.250485\n",
      "tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.4\tLoss: 0.234917\n",
      "tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.6\tLoss: 0.290488\n",
      "tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:457 0.8\tLoss: 0.247490\n",
      "\n",
      "Test Epoch: 457\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 457\tmaintain_Accuracy: 5807/10593 (55%)\n",
      "\n",
      "tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.0\tLoss: 0.247169\n",
      "tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.2\tLoss: 0.273802\n",
      "tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.4\tLoss: 0.298294\n",
      "tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.6\tLoss: 0.286391\n",
      "tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:458 0.8\tLoss: 0.263099\n",
      "\n",
      "Test Epoch: 458\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 458\tmaintain_Accuracy: 5860/10593 (55%)\n",
      "\n",
      "tensor(0.2882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.0\tLoss: 0.288152\n",
      "tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.2\tLoss: 0.246863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.4\tLoss: 0.236677\n",
      "tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.6\tLoss: 0.277794\n",
      "tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:459 0.8\tLoss: 0.268527\n",
      "\n",
      "Test Epoch: 459\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 459\tmaintain_Accuracy: 5888/10593 (56%)\n",
      "\n",
      "tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.0\tLoss: 0.293682\n",
      "tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.2\tLoss: 0.234498\n",
      "tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.4\tLoss: 0.289698\n",
      "tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.6\tLoss: 0.240190\n",
      "tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:460 0.8\tLoss: 0.269075\n",
      "\n",
      "Train Epoch: 460\tAttack_Accuracy: 4331/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 460\tmaintain_Accuracy: 7036/12800 (55%)\n",
      "\n",
      "alpha: 0.5292267652290982\n",
      "\n",
      "Test Epoch: 460\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 460\tmaintain_Accuracy: 5891/10593 (56%)\n",
      "\n",
      "tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.0\tLoss: 0.277300\n",
      "tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.2\tLoss: 0.257425\n",
      "tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.4\tLoss: 0.225751\n",
      "tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.6\tLoss: 0.296724\n",
      "tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:461 0.8\tLoss: 0.231604\n",
      "\n",
      "Test Epoch: 461\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 461\tmaintain_Accuracy: 5872/10593 (55%)\n",
      "\n",
      "tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.0\tLoss: 0.232543\n",
      "tensor(0.2616, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.2\tLoss: 0.261566\n",
      "tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.4\tLoss: 0.211394\n",
      "tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.6\tLoss: 0.264980\n",
      "tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:462 0.8\tLoss: 0.330211\n",
      "\n",
      "Test Epoch: 462\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 462\tmaintain_Accuracy: 5852/10593 (55%)\n",
      "\n",
      "tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.0\tLoss: 0.280620\n",
      "tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.2\tLoss: 0.267638\n",
      "tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.4\tLoss: 0.273813\n",
      "tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.6\tLoss: 0.250045\n",
      "tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:463 0.8\tLoss: 0.297041\n",
      "\n",
      "Test Epoch: 463\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 463\tmaintain_Accuracy: 5837/10593 (55%)\n",
      "\n",
      "tensor(0.3087, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.0\tLoss: 0.308659\n",
      "tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.2\tLoss: 0.301693\n",
      "tensor(0.2944, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.4\tLoss: 0.294379\n",
      "tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.6\tLoss: 0.264350\n",
      "tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:464 0.8\tLoss: 0.263847\n",
      "\n",
      "Test Epoch: 464\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 464\tmaintain_Accuracy: 5842/10593 (55%)\n",
      "\n",
      "tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.0\tLoss: 0.237827\n",
      "tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.2\tLoss: 0.258266\n",
      "tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.4\tLoss: 0.221527\n",
      "tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.6\tLoss: 0.249835\n",
      "tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:465 0.8\tLoss: 0.266322\n",
      "\n",
      "Train Epoch: 465\tAttack_Accuracy: 4451/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 465\tmaintain_Accuracy: 6982/12800 (55%)\n",
      "\n",
      "alpha: 0.3213565190489178\n",
      "\n",
      "Test Epoch: 465\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 465\tmaintain_Accuracy: 5887/10593 (56%)\n",
      "\n",
      "tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.0\tLoss: 0.315020\n",
      "tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.2\tLoss: 0.310740\n",
      "tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.4\tLoss: 0.233235\n",
      "tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.6\tLoss: 0.289226\n",
      "tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:466 0.8\tLoss: 0.252604\n",
      "\n",
      "Test Epoch: 466\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 466\tmaintain_Accuracy: 5928/10593 (56%)\n",
      "\n",
      "tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.0\tLoss: 0.277356\n",
      "tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.2\tLoss: 0.263303\n",
      "tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.4\tLoss: 0.247807\n",
      "tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.6\tLoss: 0.257331\n",
      "tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:467 0.8\tLoss: 0.250146\n",
      "\n",
      "Test Epoch: 467\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 467\tmaintain_Accuracy: 5958/10593 (56%)\n",
      "\n",
      "tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.0\tLoss: 0.242332\n",
      "tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.2\tLoss: 0.264804\n",
      "tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.4\tLoss: 0.230204\n",
      "tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.6\tLoss: 0.237742\n",
      "tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:468 0.8\tLoss: 0.257540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 468\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 468\tmaintain_Accuracy: 5887/10593 (56%)\n",
      "\n",
      "tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.0\tLoss: 0.277784\n",
      "tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.2\tLoss: 0.225843\n",
      "tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.4\tLoss: 0.252414\n",
      "tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.6\tLoss: 0.269832\n",
      "tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:469 0.8\tLoss: 0.271026\n",
      "\n",
      "Test Epoch: 469\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 469\tmaintain_Accuracy: 5862/10593 (55%)\n",
      "\n",
      "tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.0\tLoss: 0.251381\n",
      "tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.2\tLoss: 0.246703\n",
      "tensor(0.2856, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.4\tLoss: 0.285641\n",
      "tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.6\tLoss: 0.311984\n",
      "tensor(0.3012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:470 0.8\tLoss: 0.301191\n",
      "\n",
      "Train Epoch: 470\tAttack_Accuracy: 4370/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 470\tmaintain_Accuracy: 6910/12800 (54%)\n",
      "\n",
      "alpha: 0.5123615834518204\n",
      "\n",
      "Test Epoch: 470\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 470\tmaintain_Accuracy: 5883/10593 (56%)\n",
      "\n",
      "tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.0\tLoss: 0.271575\n",
      "tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.2\tLoss: 0.247130\n",
      "tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.4\tLoss: 0.276931\n",
      "tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.6\tLoss: 0.281340\n",
      "tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:471 0.8\tLoss: 0.270794\n",
      "\n",
      "Test Epoch: 471\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 471\tmaintain_Accuracy: 5886/10593 (56%)\n",
      "\n",
      "tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.0\tLoss: 0.248567\n",
      "tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.2\tLoss: 0.265635\n",
      "tensor(0.2642, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.4\tLoss: 0.264234\n",
      "tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.6\tLoss: 0.279965\n",
      "tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:472 0.8\tLoss: 0.309210\n",
      "\n",
      "Test Epoch: 472\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 472\tmaintain_Accuracy: 5906/10593 (56%)\n",
      "\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.0\tLoss: 0.245011\n",
      "tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.2\tLoss: 0.231769\n",
      "tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.4\tLoss: 0.261717\n",
      "tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.6\tLoss: 0.256984\n",
      "tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:473 0.8\tLoss: 0.276966\n",
      "\n",
      "Test Epoch: 473\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 473\tmaintain_Accuracy: 5898/10593 (56%)\n",
      "\n",
      "tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.0\tLoss: 0.265995\n",
      "tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.2\tLoss: 0.241533\n",
      "tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.4\tLoss: 0.255108\n",
      "tensor(0.2690, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.6\tLoss: 0.268952\n",
      "tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:474 0.8\tLoss: 0.265216\n",
      "\n",
      "Test Epoch: 474\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 474\tmaintain_Accuracy: 5887/10593 (56%)\n",
      "\n",
      "tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.0\tLoss: 0.252775\n",
      "tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.2\tLoss: 0.257013\n",
      "tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.4\tLoss: 0.259501\n",
      "tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.6\tLoss: 0.311217\n",
      "tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:475 0.8\tLoss: 0.273313\n",
      "\n",
      "Train Epoch: 475\tAttack_Accuracy: 4381/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 475\tmaintain_Accuracy: 6987/12800 (55%)\n",
      "\n",
      "alpha: 0.3657580234334257\n",
      "\n",
      "Test Epoch: 475\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 475\tmaintain_Accuracy: 5887/10593 (56%)\n",
      "\n",
      "tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.0\tLoss: 0.287413\n",
      "tensor(0.2977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.2\tLoss: 0.297743\n",
      "tensor(0.2652, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.4\tLoss: 0.265198\n",
      "tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.6\tLoss: 0.268670\n",
      "tensor(0.2409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:476 0.8\tLoss: 0.240888\n",
      "\n",
      "Test Epoch: 476\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 476\tmaintain_Accuracy: 5933/10593 (56%)\n",
      "\n",
      "tensor(0.2785, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.0\tLoss: 0.278499\n",
      "tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.2\tLoss: 0.219691\n",
      "tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.4\tLoss: 0.273277\n",
      "tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.6\tLoss: 0.234951\n",
      "tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:477 0.8\tLoss: 0.292426\n",
      "\n",
      "Test Epoch: 477\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 477\tmaintain_Accuracy: 5936/10593 (56%)\n",
      "\n",
      "tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.0\tLoss: 0.282991\n",
      "tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.2\tLoss: 0.266253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.4\tLoss: 0.274880\n",
      "tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.6\tLoss: 0.264032\n",
      "tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:478 0.8\tLoss: 0.252169\n",
      "\n",
      "Test Epoch: 478\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 478\tmaintain_Accuracy: 5925/10593 (56%)\n",
      "\n",
      "tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.0\tLoss: 0.238943\n",
      "tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.2\tLoss: 0.303898\n",
      "tensor(0.2530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.4\tLoss: 0.252959\n",
      "tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.6\tLoss: 0.245475\n",
      "tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:479 0.8\tLoss: 0.279282\n",
      "\n",
      "Test Epoch: 479\tAttack_Accuracy: 309/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 479\tmaintain_Accuracy: 5876/10593 (55%)\n",
      "\n",
      "tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.0\tLoss: 0.295118\n",
      "tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.2\tLoss: 0.254262\n",
      "tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.4\tLoss: 0.280076\n",
      "tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.6\tLoss: 0.298148\n",
      "tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:480 0.8\tLoss: 0.281092\n",
      "\n",
      "Train Epoch: 480\tAttack_Accuracy: 4415/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 480\tmaintain_Accuracy: 7019/12800 (55%)\n",
      "\n",
      "alpha: 0.44669204135273327\n",
      "\n",
      "Test Epoch: 480\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 480\tmaintain_Accuracy: 5899/10593 (56%)\n",
      "\n",
      "tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.0\tLoss: 0.284261\n",
      "tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.2\tLoss: 0.247966\n",
      "tensor(0.3076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.4\tLoss: 0.307572\n",
      "tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.6\tLoss: 0.233366\n",
      "tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:481 0.8\tLoss: 0.269573\n",
      "\n",
      "Test Epoch: 481\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 481\tmaintain_Accuracy: 5905/10593 (56%)\n",
      "\n",
      "tensor(0.2945, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.0\tLoss: 0.294486\n",
      "tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.2\tLoss: 0.277074\n",
      "tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.4\tLoss: 0.259916\n",
      "tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.6\tLoss: 0.264988\n",
      "tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:482 0.8\tLoss: 0.254319\n",
      "\n",
      "Test Epoch: 482\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 482\tmaintain_Accuracy: 5899/10593 (56%)\n",
      "\n",
      "tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.0\tLoss: 0.258645\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.2\tLoss: 0.270668\n",
      "tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.4\tLoss: 0.264116\n",
      "tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.6\tLoss: 0.258956\n",
      "tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:483 0.8\tLoss: 0.245961\n",
      "\n",
      "Test Epoch: 483\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 483\tmaintain_Accuracy: 5894/10593 (56%)\n",
      "\n",
      "tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.0\tLoss: 0.259594\n",
      "tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.2\tLoss: 0.256699\n",
      "tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.4\tLoss: 0.274485\n",
      "tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.6\tLoss: 0.243703\n",
      "tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:484 0.8\tLoss: 0.262683\n",
      "\n",
      "Test Epoch: 484\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 484\tmaintain_Accuracy: 5890/10593 (56%)\n",
      "\n",
      "tensor(0.2880, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.0\tLoss: 0.288046\n",
      "tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.2\tLoss: 0.261371\n",
      "tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.4\tLoss: 0.272628\n",
      "tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.6\tLoss: 0.253438\n",
      "tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:485 0.8\tLoss: 0.273951\n",
      "\n",
      "Train Epoch: 485\tAttack_Accuracy: 4392/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 485\tmaintain_Accuracy: 7102/12800 (55%)\n",
      "\n",
      "alpha: 0.32454407966311816\n",
      "\n",
      "Test Epoch: 485\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 485\tmaintain_Accuracy: 5925/10593 (56%)\n",
      "\n",
      "tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.0\tLoss: 0.271906\n",
      "tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.2\tLoss: 0.269559\n",
      "tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.4\tLoss: 0.261690\n",
      "tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.6\tLoss: 0.321929\n",
      "tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:486 0.8\tLoss: 0.221186\n",
      "\n",
      "Test Epoch: 486\tAttack_Accuracy: 290/412 (70%)\n",
      "\n",
      "\n",
      "Test Epoch: 486\tmaintain_Accuracy: 5964/10593 (56%)\n",
      "\n",
      "tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.0\tLoss: 0.290081\n",
      "tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.2\tLoss: 0.287945\n",
      "tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.4\tLoss: 0.287366\n",
      "tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.6\tLoss: 0.254281\n",
      "tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:487 0.8\tLoss: 0.267843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 487\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 487\tmaintain_Accuracy: 5889/10593 (56%)\n",
      "\n",
      "tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.0\tLoss: 0.271789\n",
      "tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.2\tLoss: 0.255181\n",
      "tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.4\tLoss: 0.259244\n",
      "tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.6\tLoss: 0.288095\n",
      "tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:488 0.8\tLoss: 0.298416\n",
      "\n",
      "Test Epoch: 488\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 488\tmaintain_Accuracy: 5903/10593 (56%)\n",
      "\n",
      "tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.0\tLoss: 0.265406\n",
      "tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.2\tLoss: 0.310869\n",
      "tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.4\tLoss: 0.272240\n",
      "tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.6\tLoss: 0.278973\n",
      "tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:489 0.8\tLoss: 0.264706\n",
      "\n",
      "Test Epoch: 489\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 489\tmaintain_Accuracy: 5956/10593 (56%)\n",
      "\n",
      "tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.0\tLoss: 0.216830\n",
      "tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.2\tLoss: 0.248161\n",
      "tensor(0.3002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.4\tLoss: 0.300159\n",
      "tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.6\tLoss: 0.257955\n",
      "tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:490 0.8\tLoss: 0.273135\n",
      "\n",
      "Train Epoch: 490\tAttack_Accuracy: 4351/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 490\tmaintain_Accuracy: 7024/12800 (55%)\n",
      "\n",
      "alpha: 0.5397871247129639\n",
      "\n",
      "Test Epoch: 490\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 490\tmaintain_Accuracy: 5946/10593 (56%)\n",
      "\n",
      "tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.0\tLoss: 0.277022\n",
      "tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.2\tLoss: 0.243159\n",
      "tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.4\tLoss: 0.248064\n",
      "tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.6\tLoss: 0.249726\n",
      "tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:491 0.8\tLoss: 0.238337\n",
      "\n",
      "Test Epoch: 491\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 491\tmaintain_Accuracy: 5910/10593 (56%)\n",
      "\n",
      "tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.0\tLoss: 0.277365\n",
      "tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.2\tLoss: 0.284801\n",
      "tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.4\tLoss: 0.274620\n",
      "tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.6\tLoss: 0.285987\n",
      "tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:492 0.8\tLoss: 0.293370\n",
      "\n",
      "Test Epoch: 492\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 492\tmaintain_Accuracy: 5925/10593 (56%)\n",
      "\n",
      "tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.0\tLoss: 0.285844\n",
      "tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.2\tLoss: 0.288134\n",
      "tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.4\tLoss: 0.272922\n",
      "tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.6\tLoss: 0.283854\n",
      "tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:493 0.8\tLoss: 0.279294\n",
      "\n",
      "Test Epoch: 493\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 493\tmaintain_Accuracy: 5960/10593 (56%)\n",
      "\n",
      "tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.0\tLoss: 0.275245\n",
      "tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.2\tLoss: 0.260133\n",
      "tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.4\tLoss: 0.259442\n",
      "tensor(0.2454, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.6\tLoss: 0.245447\n",
      "tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:494 0.8\tLoss: 0.274427\n",
      "\n",
      "Test Epoch: 494\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 494\tmaintain_Accuracy: 5938/10593 (56%)\n",
      "\n",
      "tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.0\tLoss: 0.280727\n",
      "tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.2\tLoss: 0.275066\n",
      "tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.4\tLoss: 0.274114\n",
      "tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.6\tLoss: 0.247338\n",
      "tensor(0.2897, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:495 0.8\tLoss: 0.289708\n",
      "\n",
      "Train Epoch: 495\tAttack_Accuracy: 4411/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 495\tmaintain_Accuracy: 7074/12800 (55%)\n",
      "\n",
      "alpha: 0.456572688148226\n",
      "\n",
      "Test Epoch: 495\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 495\tmaintain_Accuracy: 5885/10593 (56%)\n",
      "\n",
      "tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.0\tLoss: 0.266614\n",
      "tensor(0.2132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.2\tLoss: 0.213161\n",
      "tensor(0.3010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.4\tLoss: 0.301006\n",
      "tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.6\tLoss: 0.281033\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:496 0.8\tLoss: 0.273410\n",
      "\n",
      "Test Epoch: 496\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 496\tmaintain_Accuracy: 5910/10593 (56%)\n",
      "\n",
      "tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.0\tLoss: 0.296144\n",
      "tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.2\tLoss: 0.258485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.4\tLoss: 0.261454\n",
      "tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.6\tLoss: 0.262502\n",
      "tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:497 0.8\tLoss: 0.275299\n",
      "\n",
      "Test Epoch: 497\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 497\tmaintain_Accuracy: 5935/10593 (56%)\n",
      "\n",
      "tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.0\tLoss: 0.270538\n",
      "tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.2\tLoss: 0.277637\n",
      "tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.4\tLoss: 0.253197\n",
      "tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.6\tLoss: 0.276351\n",
      "tensor(0.2936, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:498 0.8\tLoss: 0.293585\n",
      "\n",
      "Test Epoch: 498\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 498\tmaintain_Accuracy: 5909/10593 (56%)\n",
      "\n",
      "tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.0\tLoss: 0.265125\n",
      "tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.2\tLoss: 0.269627\n",
      "tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.4\tLoss: 0.262439\n",
      "tensor(0.3016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.6\tLoss: 0.301622\n",
      "tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:499 0.8\tLoss: 0.272722\n",
      "\n",
      "Test Epoch: 499\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 499\tmaintain_Accuracy: 5880/10593 (56%)\n",
      "\n",
      "tensor(0.2368, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.0\tLoss: 0.236815\n",
      "tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.2\tLoss: 0.276317\n",
      "tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.4\tLoss: 0.281917\n",
      "tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.6\tLoss: 0.269826\n",
      "tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:500 0.8\tLoss: 0.291903\n",
      "\n",
      "Train Epoch: 500\tAttack_Accuracy: 4435/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 500\tmaintain_Accuracy: 7038/12800 (55%)\n",
      "\n",
      "alpha: 0.38659019531805544\n",
      "\n",
      "Test Epoch: 500\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 500\tmaintain_Accuracy: 5921/10593 (56%)\n",
      "\n",
      "tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.0\tLoss: 0.280797\n",
      "tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.2\tLoss: 0.286490\n",
      "tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.4\tLoss: 0.259598\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.6\tLoss: 0.273367\n",
      "tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:501 0.8\tLoss: 0.256023\n",
      "\n",
      "Test Epoch: 501\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 501\tmaintain_Accuracy: 5947/10593 (56%)\n",
      "\n",
      "tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.0\tLoss: 0.277429\n",
      "tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.2\tLoss: 0.272614\n",
      "tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.4\tLoss: 0.240137\n",
      "tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.6\tLoss: 0.240806\n",
      "tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:502 0.8\tLoss: 0.275784\n",
      "\n",
      "Test Epoch: 502\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 502\tmaintain_Accuracy: 5948/10593 (56%)\n",
      "\n",
      "tensor(0.2177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.0\tLoss: 0.217707\n",
      "tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.2\tLoss: 0.292199\n",
      "tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.4\tLoss: 0.292737\n",
      "tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.6\tLoss: 0.264466\n",
      "tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:503 0.8\tLoss: 0.250149\n",
      "\n",
      "Test Epoch: 503\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 503\tmaintain_Accuracy: 5928/10593 (56%)\n",
      "\n",
      "tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.0\tLoss: 0.263304\n",
      "tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.2\tLoss: 0.255283\n",
      "tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.4\tLoss: 0.235203\n",
      "tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.6\tLoss: 0.262526\n",
      "tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:504 0.8\tLoss: 0.237459\n",
      "\n",
      "Test Epoch: 504\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 504\tmaintain_Accuracy: 5907/10593 (56%)\n",
      "\n",
      "tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.0\tLoss: 0.260296\n",
      "tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.2\tLoss: 0.243219\n",
      "tensor(0.3153, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.4\tLoss: 0.315318\n",
      "tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.6\tLoss: 0.231747\n",
      "tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:505 0.8\tLoss: 0.261548\n",
      "\n",
      "Train Epoch: 505\tAttack_Accuracy: 4476/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 505\tmaintain_Accuracy: 7095/12800 (55%)\n",
      "\n",
      "alpha: 0.3974973925565687\n",
      "\n",
      "Test Epoch: 505\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 505\tmaintain_Accuracy: 5924/10593 (56%)\n",
      "\n",
      "tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.0\tLoss: 0.275074\n",
      "tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.2\tLoss: 0.310191\n",
      "tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.4\tLoss: 0.242280\n",
      "tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.6\tLoss: 0.249412\n",
      "tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:506 0.8\tLoss: 0.255992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 506\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 506\tmaintain_Accuracy: 5942/10593 (56%)\n",
      "\n",
      "tensor(0.2781, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.0\tLoss: 0.278061\n",
      "tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.2\tLoss: 0.272027\n",
      "tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.4\tLoss: 0.237582\n",
      "tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.6\tLoss: 0.215853\n",
      "tensor(0.2741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:507 0.8\tLoss: 0.274122\n",
      "\n",
      "Test Epoch: 507\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 507\tmaintain_Accuracy: 5906/10593 (56%)\n",
      "\n",
      "tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.0\tLoss: 0.279922\n",
      "tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.2\tLoss: 0.267532\n",
      "tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.4\tLoss: 0.242796\n",
      "tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.6\tLoss: 0.262329\n",
      "tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:508 0.8\tLoss: 0.243962\n",
      "\n",
      "Test Epoch: 508\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 508\tmaintain_Accuracy: 5902/10593 (56%)\n",
      "\n",
      "tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.0\tLoss: 0.239192\n",
      "tensor(0.2757, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.2\tLoss: 0.275684\n",
      "tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.4\tLoss: 0.229592\n",
      "tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.6\tLoss: 0.218011\n",
      "tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:509 0.8\tLoss: 0.264310\n",
      "\n",
      "Test Epoch: 509\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 509\tmaintain_Accuracy: 5955/10593 (56%)\n",
      "\n",
      "tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.0\tLoss: 0.252291\n",
      "tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.2\tLoss: 0.302103\n",
      "tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.4\tLoss: 0.262946\n",
      "tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.6\tLoss: 0.246092\n",
      "tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:510 0.8\tLoss: 0.257773\n",
      "\n",
      "Train Epoch: 510\tAttack_Accuracy: 4437/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 510\tmaintain_Accuracy: 7206/12800 (56%)\n",
      "\n",
      "alpha: 0.40250862189428904\n",
      "\n",
      "Test Epoch: 510\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 510\tmaintain_Accuracy: 5945/10593 (56%)\n",
      "\n",
      "tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.0\tLoss: 0.283530\n",
      "tensor(0.2701, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.2\tLoss: 0.270120\n",
      "tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.4\tLoss: 0.275181\n",
      "tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.6\tLoss: 0.254718\n",
      "tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:511 0.8\tLoss: 0.249349\n",
      "\n",
      "Test Epoch: 511\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 511\tmaintain_Accuracy: 5959/10593 (56%)\n",
      "\n",
      "tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.0\tLoss: 0.264369\n",
      "tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.2\tLoss: 0.288708\n",
      "tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.4\tLoss: 0.266286\n",
      "tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.6\tLoss: 0.242041\n",
      "tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:512 0.8\tLoss: 0.288731\n",
      "\n",
      "Test Epoch: 512\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 512\tmaintain_Accuracy: 5949/10593 (56%)\n",
      "\n",
      "tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.0\tLoss: 0.264886\n",
      "tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.2\tLoss: 0.246679\n",
      "tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.4\tLoss: 0.265457\n",
      "tensor(0.2722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.6\tLoss: 0.272206\n",
      "tensor(0.2649, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:513 0.8\tLoss: 0.264860\n",
      "\n",
      "Test Epoch: 513\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 513\tmaintain_Accuracy: 5952/10593 (56%)\n",
      "\n",
      "tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.0\tLoss: 0.257199\n",
      "tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.2\tLoss: 0.252233\n",
      "tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.4\tLoss: 0.241737\n",
      "tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.6\tLoss: 0.247724\n",
      "tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:514 0.8\tLoss: 0.272652\n",
      "\n",
      "Test Epoch: 514\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 514\tmaintain_Accuracy: 5971/10593 (56%)\n",
      "\n",
      "tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.0\tLoss: 0.240582\n",
      "tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.2\tLoss: 0.264077\n",
      "tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.4\tLoss: 0.293393\n",
      "tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.6\tLoss: 0.247787\n",
      "tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:515 0.8\tLoss: 0.239882\n",
      "\n",
      "Train Epoch: 515\tAttack_Accuracy: 4331/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 515\tmaintain_Accuracy: 7107/12800 (56%)\n",
      "\n",
      "alpha: 0.6083509832669443\n",
      "\n",
      "Test Epoch: 515\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 515\tmaintain_Accuracy: 5962/10593 (56%)\n",
      "\n",
      "tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.0\tLoss: 0.219824\n",
      "tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.2\tLoss: 0.267883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.4\tLoss: 0.246010\n",
      "tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.6\tLoss: 0.242370\n",
      "tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:516 0.8\tLoss: 0.283864\n",
      "\n",
      "Test Epoch: 516\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 516\tmaintain_Accuracy: 5964/10593 (56%)\n",
      "\n",
      "tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.0\tLoss: 0.225499\n",
      "tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.2\tLoss: 0.250799\n",
      "tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.4\tLoss: 0.236746\n",
      "tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.6\tLoss: 0.266154\n",
      "tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:517 0.8\tLoss: 0.298742\n",
      "\n",
      "Test Epoch: 517\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 517\tmaintain_Accuracy: 5960/10593 (56%)\n",
      "\n",
      "tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.0\tLoss: 0.231044\n",
      "tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.2\tLoss: 0.289412\n",
      "tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.4\tLoss: 0.248693\n",
      "tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.6\tLoss: 0.234658\n",
      "tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:518 0.8\tLoss: 0.283094\n",
      "\n",
      "Test Epoch: 518\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 518\tmaintain_Accuracy: 5960/10593 (56%)\n",
      "\n",
      "tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.0\tLoss: 0.230458\n",
      "tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.2\tLoss: 0.280846\n",
      "tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.4\tLoss: 0.213938\n",
      "tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.6\tLoss: 0.237947\n",
      "tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:519 0.8\tLoss: 0.255869\n",
      "\n",
      "Test Epoch: 519\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 519\tmaintain_Accuracy: 5944/10593 (56%)\n",
      "\n",
      "tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.0\tLoss: 0.243162\n",
      "tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.2\tLoss: 0.229815\n",
      "tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.4\tLoss: 0.247315\n",
      "tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.6\tLoss: 0.215145\n",
      "tensor(0.2283, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:520 0.8\tLoss: 0.228301\n",
      "\n",
      "Train Epoch: 520\tAttack_Accuracy: 4434/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 520\tmaintain_Accuracy: 7131/12800 (56%)\n",
      "\n",
      "alpha: 0.6303064236663658\n",
      "\n",
      "Test Epoch: 520\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 520\tmaintain_Accuracy: 5911/10593 (56%)\n",
      "\n",
      "tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.0\tLoss: 0.238078\n",
      "tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.2\tLoss: 0.230494\n",
      "tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.4\tLoss: 0.236562\n",
      "tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.6\tLoss: 0.274165\n",
      "tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:521 0.8\tLoss: 0.268142\n",
      "\n",
      "Test Epoch: 521\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 521\tmaintain_Accuracy: 5945/10593 (56%)\n",
      "\n",
      "tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.0\tLoss: 0.233449\n",
      "tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.2\tLoss: 0.219433\n",
      "tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.4\tLoss: 0.259662\n",
      "tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.6\tLoss: 0.255037\n",
      "tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:522 0.8\tLoss: 0.239518\n",
      "\n",
      "Test Epoch: 522\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 522\tmaintain_Accuracy: 5953/10593 (56%)\n",
      "\n",
      "tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.0\tLoss: 0.265014\n",
      "tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.2\tLoss: 0.261176\n",
      "tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.4\tLoss: 0.248427\n",
      "tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.6\tLoss: 0.211269\n",
      "tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:523 0.8\tLoss: 0.264076\n",
      "\n",
      "Test Epoch: 523\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 523\tmaintain_Accuracy: 5959/10593 (56%)\n",
      "\n",
      "tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.0\tLoss: 0.269507\n",
      "tensor(0.2899, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.2\tLoss: 0.289855\n",
      "tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.4\tLoss: 0.231356\n",
      "tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.6\tLoss: 0.256017\n",
      "tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:524 0.8\tLoss: 0.263760\n",
      "\n",
      "Test Epoch: 524\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 524\tmaintain_Accuracy: 5916/10593 (56%)\n",
      "\n",
      "tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.0\tLoss: 0.269127\n",
      "tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.2\tLoss: 0.220767\n",
      "tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.4\tLoss: 0.244572\n",
      "tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.6\tLoss: 0.255042\n",
      "tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:525 0.8\tLoss: 0.241492\n",
      "\n",
      "Train Epoch: 525\tAttack_Accuracy: 4371/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 525\tmaintain_Accuracy: 7148/12800 (56%)\n",
      "\n",
      "alpha: 0.4189482535777394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 525\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 525\tmaintain_Accuracy: 5976/10593 (56%)\n",
      "\n",
      "tensor(0.2535, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.0\tLoss: 0.253491\n",
      "tensor(0.2721, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.2\tLoss: 0.272080\n",
      "tensor(0.2778, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.4\tLoss: 0.277849\n",
      "tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.6\tLoss: 0.273705\n",
      "tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:526 0.8\tLoss: 0.271966\n",
      "\n",
      "Test Epoch: 526\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 526\tmaintain_Accuracy: 6034/10593 (57%)\n",
      "\n",
      "tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.0\tLoss: 0.251863\n",
      "tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.2\tLoss: 0.284682\n",
      "tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.4\tLoss: 0.244118\n",
      "tensor(0.2773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.6\tLoss: 0.277285\n",
      "tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:527 0.8\tLoss: 0.245917\n",
      "\n",
      "Test Epoch: 527\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 527\tmaintain_Accuracy: 6015/10593 (57%)\n",
      "\n",
      "tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.0\tLoss: 0.259349\n",
      "tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.2\tLoss: 0.266773\n",
      "tensor(0.2869, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.4\tLoss: 0.286884\n",
      "tensor(0.2870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.6\tLoss: 0.286956\n",
      "tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:528 0.8\tLoss: 0.218029\n",
      "\n",
      "Test Epoch: 528\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 528\tmaintain_Accuracy: 5939/10593 (56%)\n",
      "\n",
      "tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.0\tLoss: 0.195096\n",
      "tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.2\tLoss: 0.264313\n",
      "tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.4\tLoss: 0.276599\n",
      "tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.6\tLoss: 0.242251\n",
      "tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:529 0.8\tLoss: 0.294951\n",
      "\n",
      "Test Epoch: 529\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 529\tmaintain_Accuracy: 5935/10593 (56%)\n",
      "\n",
      "tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.0\tLoss: 0.233481\n",
      "tensor(0.2870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.2\tLoss: 0.287008\n",
      "tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.4\tLoss: 0.290077\n",
      "tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.6\tLoss: 0.291244\n",
      "tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:530 0.8\tLoss: 0.238153\n",
      "\n",
      "Train Epoch: 530\tAttack_Accuracy: 4381/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 530\tmaintain_Accuracy: 7125/12800 (56%)\n",
      "\n",
      "alpha: 0.34628557733027604\n",
      "\n",
      "Test Epoch: 530\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 530\tmaintain_Accuracy: 5990/10593 (57%)\n",
      "\n",
      "tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.0\tLoss: 0.218138\n",
      "tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.2\tLoss: 0.257558\n",
      "tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.4\tLoss: 0.230779\n",
      "tensor(0.2591, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.6\tLoss: 0.259142\n",
      "tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:531 0.8\tLoss: 0.275189\n",
      "\n",
      "Test Epoch: 531\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 531\tmaintain_Accuracy: 6017/10593 (57%)\n",
      "\n",
      "tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.0\tLoss: 0.245241\n",
      "tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.2\tLoss: 0.279236\n",
      "tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.4\tLoss: 0.216986\n",
      "tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.6\tLoss: 0.275394\n",
      "tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:532 0.8\tLoss: 0.241365\n",
      "\n",
      "Test Epoch: 532\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 532\tmaintain_Accuracy: 5988/10593 (57%)\n",
      "\n",
      "tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.0\tLoss: 0.259284\n",
      "tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.2\tLoss: 0.299572\n",
      "tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.4\tLoss: 0.249191\n",
      "tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.6\tLoss: 0.215671\n",
      "tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:533 0.8\tLoss: 0.243022\n",
      "\n",
      "Test Epoch: 533\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 533\tmaintain_Accuracy: 5921/10593 (56%)\n",
      "\n",
      "tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.0\tLoss: 0.303185\n",
      "tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.2\tLoss: 0.272855\n",
      "tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.4\tLoss: 0.261884\n",
      "tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.6\tLoss: 0.289215\n",
      "tensor(0.2584, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:534 0.8\tLoss: 0.258383\n",
      "\n",
      "Test Epoch: 534\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 534\tmaintain_Accuracy: 5927/10593 (56%)\n",
      "\n",
      "tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.0\tLoss: 0.292414\n",
      "tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.2\tLoss: 0.260554\n",
      "tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.4\tLoss: 0.261179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.6\tLoss: 0.265284\n",
      "tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:535 0.8\tLoss: 0.263475\n",
      "\n",
      "Train Epoch: 535\tAttack_Accuracy: 4455/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 535\tmaintain_Accuracy: 7087/12800 (55%)\n",
      "\n",
      "alpha: 0.6574565620242578\n",
      "\n",
      "Test Epoch: 535\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 535\tmaintain_Accuracy: 5952/10593 (56%)\n",
      "\n",
      "tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.0\tLoss: 0.289478\n",
      "tensor(0.2975, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.2\tLoss: 0.297477\n",
      "tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.4\tLoss: 0.301269\n",
      "tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.6\tLoss: 0.241286\n",
      "tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:536 0.8\tLoss: 0.207642\n",
      "\n",
      "Test Epoch: 536\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 536\tmaintain_Accuracy: 5941/10593 (56%)\n",
      "\n",
      "tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.0\tLoss: 0.247111\n",
      "tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.2\tLoss: 0.241742\n",
      "tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.4\tLoss: 0.226107\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.6\tLoss: 0.227000\n",
      "tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:537 0.8\tLoss: 0.235813\n",
      "\n",
      "Test Epoch: 537\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 537\tmaintain_Accuracy: 5986/10593 (57%)\n",
      "\n",
      "tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.0\tLoss: 0.219238\n",
      "tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.2\tLoss: 0.228375\n",
      "tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.4\tLoss: 0.217637\n",
      "tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.6\tLoss: 0.239616\n",
      "tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:538 0.8\tLoss: 0.271173\n",
      "\n",
      "Test Epoch: 538\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 538\tmaintain_Accuracy: 5976/10593 (56%)\n",
      "\n",
      "tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.0\tLoss: 0.314150\n",
      "tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.2\tLoss: 0.290876\n",
      "tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.4\tLoss: 0.294284\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.6\tLoss: 0.253920\n",
      "tensor(0.2816, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:539 0.8\tLoss: 0.281627\n",
      "\n",
      "Test Epoch: 539\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 539\tmaintain_Accuracy: 5949/10593 (56%)\n",
      "\n",
      "tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.0\tLoss: 0.247280\n",
      "tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.2\tLoss: 0.209085\n",
      "tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.4\tLoss: 0.263488\n",
      "tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.6\tLoss: 0.238986\n",
      "tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:540 0.8\tLoss: 0.261989\n",
      "\n",
      "Train Epoch: 540\tAttack_Accuracy: 4409/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 540\tmaintain_Accuracy: 7231/12800 (56%)\n",
      "\n",
      "alpha: 0.51809982363768\n",
      "\n",
      "Test Epoch: 540\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 540\tmaintain_Accuracy: 5946/10593 (56%)\n",
      "\n",
      "tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.0\tLoss: 0.243338\n",
      "tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.2\tLoss: 0.296039\n",
      "tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.4\tLoss: 0.286334\n",
      "tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.6\tLoss: 0.225160\n",
      "tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:541 0.8\tLoss: 0.271753\n",
      "\n",
      "Test Epoch: 541\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 541\tmaintain_Accuracy: 5970/10593 (56%)\n",
      "\n",
      "tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.0\tLoss: 0.276461\n",
      "tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.2\tLoss: 0.225460\n",
      "tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.4\tLoss: 0.273717\n",
      "tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.6\tLoss: 0.238676\n",
      "tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:542 0.8\tLoss: 0.300138\n",
      "\n",
      "Test Epoch: 542\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 542\tmaintain_Accuracy: 5979/10593 (56%)\n",
      "\n",
      "tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.0\tLoss: 0.234335\n",
      "tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.2\tLoss: 0.241925\n",
      "tensor(0.2447, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.4\tLoss: 0.244724\n",
      "tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.6\tLoss: 0.260772\n",
      "tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:543 0.8\tLoss: 0.283146\n",
      "\n",
      "Test Epoch: 543\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 543\tmaintain_Accuracy: 5978/10593 (56%)\n",
      "\n",
      "tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.0\tLoss: 0.244832\n",
      "tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.2\tLoss: 0.225855\n",
      "tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.4\tLoss: 0.267992\n",
      "tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.6\tLoss: 0.236917\n",
      "tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:544 0.8\tLoss: 0.277628\n",
      "\n",
      "Test Epoch: 544\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 544\tmaintain_Accuracy: 5976/10593 (56%)\n",
      "\n",
      "tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.0\tLoss: 0.244020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.2\tLoss: 0.230277\n",
      "tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.4\tLoss: 0.303792\n",
      "tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.6\tLoss: 0.241441\n",
      "tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:545 0.8\tLoss: 0.273335\n",
      "\n",
      "Train Epoch: 545\tAttack_Accuracy: 4362/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 545\tmaintain_Accuracy: 7087/12800 (55%)\n",
      "\n",
      "alpha: 0.37701271546062776\n",
      "\n",
      "Test Epoch: 545\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 545\tmaintain_Accuracy: 6001/10593 (57%)\n",
      "\n",
      "tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.0\tLoss: 0.264112\n",
      "tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.2\tLoss: 0.247076\n",
      "tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.4\tLoss: 0.277716\n",
      "tensor(0.2895, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.6\tLoss: 0.289537\n",
      "tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:546 0.8\tLoss: 0.251783\n",
      "\n",
      "Test Epoch: 546\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 546\tmaintain_Accuracy: 6005/10593 (57%)\n",
      "\n",
      "tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.0\tLoss: 0.224929\n",
      "tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.2\tLoss: 0.287339\n",
      "tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.4\tLoss: 0.243447\n",
      "tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.6\tLoss: 0.288680\n",
      "tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:547 0.8\tLoss: 0.268102\n",
      "\n",
      "Test Epoch: 547\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 547\tmaintain_Accuracy: 5955/10593 (56%)\n",
      "\n",
      "tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.0\tLoss: 0.276356\n",
      "tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.2\tLoss: 0.235035\n",
      "tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.4\tLoss: 0.213309\n",
      "tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.6\tLoss: 0.262447\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:548 0.8\tLoss: 0.284951\n",
      "\n",
      "Test Epoch: 548\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 548\tmaintain_Accuracy: 5948/10593 (56%)\n",
      "\n",
      "tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.0\tLoss: 0.238328\n",
      "tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.2\tLoss: 0.264699\n",
      "tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.4\tLoss: 0.233367\n",
      "tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.6\tLoss: 0.247357\n",
      "tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:549 0.8\tLoss: 0.240738\n",
      "\n",
      "Test Epoch: 549\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 549\tmaintain_Accuracy: 5951/10593 (56%)\n",
      "\n",
      "tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.0\tLoss: 0.218153\n",
      "tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.2\tLoss: 0.238053\n",
      "tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.4\tLoss: 0.296261\n",
      "tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.6\tLoss: 0.240759\n",
      "tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:550 0.8\tLoss: 0.227846\n",
      "\n",
      "Train Epoch: 550\tAttack_Accuracy: 4447/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 550\tmaintain_Accuracy: 7092/12800 (55%)\n",
      "\n",
      "alpha: 0.3399568289683488\n",
      "\n",
      "Test Epoch: 550\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 550\tmaintain_Accuracy: 5972/10593 (56%)\n",
      "\n",
      "tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.0\tLoss: 0.243559\n",
      "tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.2\tLoss: 0.256693\n",
      "tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.4\tLoss: 0.253775\n",
      "tensor(0.2826, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.6\tLoss: 0.282596\n",
      "tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:551 0.8\tLoss: 0.231097\n",
      "\n",
      "Test Epoch: 551\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 551\tmaintain_Accuracy: 5973/10593 (56%)\n",
      "\n",
      "tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.0\tLoss: 0.270573\n",
      "tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.2\tLoss: 0.225316\n",
      "tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.4\tLoss: 0.225946\n",
      "tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.6\tLoss: 0.254862\n",
      "tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:552 0.8\tLoss: 0.263383\n",
      "\n",
      "Test Epoch: 552\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 552\tmaintain_Accuracy: 5981/10593 (56%)\n",
      "\n",
      "tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.0\tLoss: 0.242175\n",
      "tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.2\tLoss: 0.251453\n",
      "tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.4\tLoss: 0.284741\n",
      "tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.6\tLoss: 0.241878\n",
      "tensor(0.2300, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:553 0.8\tLoss: 0.229963\n",
      "\n",
      "Test Epoch: 553\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 553\tmaintain_Accuracy: 5981/10593 (56%)\n",
      "\n",
      "tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.0\tLoss: 0.244071\n",
      "tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.2\tLoss: 0.269096\n",
      "tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.4\tLoss: 0.227608\n",
      "tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.6\tLoss: 0.263469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2902, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:554 0.8\tLoss: 0.290198\n",
      "\n",
      "Test Epoch: 554\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 554\tmaintain_Accuracy: 5991/10593 (57%)\n",
      "\n",
      "tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.0\tLoss: 0.219894\n",
      "tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.2\tLoss: 0.257664\n",
      "tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.4\tLoss: 0.215851\n",
      "tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.6\tLoss: 0.258552\n",
      "tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:555 0.8\tLoss: 0.233436\n",
      "\n",
      "Train Epoch: 555\tAttack_Accuracy: 4401/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 555\tmaintain_Accuracy: 7237/12800 (57%)\n",
      "\n",
      "alpha: 0.5016343382178132\n",
      "\n",
      "Test Epoch: 555\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 555\tmaintain_Accuracy: 5996/10593 (57%)\n",
      "\n",
      "tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.0\tLoss: 0.276522\n",
      "tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.2\tLoss: 0.231489\n",
      "tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.4\tLoss: 0.282502\n",
      "tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.6\tLoss: 0.246965\n",
      "tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:556 0.8\tLoss: 0.240248\n",
      "\n",
      "Test Epoch: 556\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 556\tmaintain_Accuracy: 6008/10593 (57%)\n",
      "\n",
      "tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.0\tLoss: 0.224353\n",
      "tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.2\tLoss: 0.267956\n",
      "tensor(0.2789, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.4\tLoss: 0.278872\n",
      "tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.6\tLoss: 0.284596\n",
      "tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:557 0.8\tLoss: 0.250973\n",
      "\n",
      "Test Epoch: 557\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 557\tmaintain_Accuracy: 5972/10593 (56%)\n",
      "\n",
      "tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.0\tLoss: 0.258641\n",
      "tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.2\tLoss: 0.279909\n",
      "tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.4\tLoss: 0.222591\n",
      "tensor(0.2691, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.6\tLoss: 0.269140\n",
      "tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:558 0.8\tLoss: 0.240694\n",
      "\n",
      "Test Epoch: 558\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 558\tmaintain_Accuracy: 6006/10593 (57%)\n",
      "\n",
      "tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.0\tLoss: 0.241358\n",
      "tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.2\tLoss: 0.296454\n",
      "tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.4\tLoss: 0.228489\n",
      "tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.6\tLoss: 0.249900\n",
      "tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:559 0.8\tLoss: 0.248553\n",
      "\n",
      "Test Epoch: 559\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 559\tmaintain_Accuracy: 5982/10593 (56%)\n",
      "\n",
      "tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.0\tLoss: 0.261323\n",
      "tensor(0.2421, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.2\tLoss: 0.242079\n",
      "tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.4\tLoss: 0.247408\n",
      "tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.6\tLoss: 0.240298\n",
      "tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:560 0.8\tLoss: 0.224208\n",
      "\n",
      "Train Epoch: 560\tAttack_Accuracy: 4404/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 560\tmaintain_Accuracy: 7123/12800 (56%)\n",
      "\n",
      "alpha: 0.5011088410043452\n",
      "\n",
      "Test Epoch: 560\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 560\tmaintain_Accuracy: 5980/10593 (56%)\n",
      "\n",
      "tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.0\tLoss: 0.237282\n",
      "tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.2\tLoss: 0.298540\n",
      "tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.4\tLoss: 0.208400\n",
      "tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.6\tLoss: 0.254811\n",
      "tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:561 0.8\tLoss: 0.252834\n",
      "\n",
      "Test Epoch: 561\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 561\tmaintain_Accuracy: 6037/10593 (57%)\n",
      "\n",
      "tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.0\tLoss: 0.266509\n",
      "tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.2\tLoss: 0.256093\n",
      "tensor(0.2322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.4\tLoss: 0.232167\n",
      "tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.6\tLoss: 0.271922\n",
      "tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:562 0.8\tLoss: 0.318417\n",
      "\n",
      "Test Epoch: 562\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 562\tmaintain_Accuracy: 6042/10593 (57%)\n",
      "\n",
      "tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.0\tLoss: 0.233770\n",
      "tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.2\tLoss: 0.236604\n",
      "tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.4\tLoss: 0.271879\n",
      "tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.6\tLoss: 0.285143\n",
      "tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:563 0.8\tLoss: 0.255315\n",
      "\n",
      "Test Epoch: 563\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 563\tmaintain_Accuracy: 5992/10593 (57%)\n",
      "\n",
      "tensor(0.1924, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.0\tLoss: 0.192379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.2\tLoss: 0.287314\n",
      "tensor(0.2821, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.4\tLoss: 0.282112\n",
      "tensor(0.3066, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.6\tLoss: 0.306604\n",
      "tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:564 0.8\tLoss: 0.291279\n",
      "\n",
      "Test Epoch: 564\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 564\tmaintain_Accuracy: 5984/10593 (56%)\n",
      "\n",
      "tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.0\tLoss: 0.287657\n",
      "tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.2\tLoss: 0.209538\n",
      "tensor(0.2704, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.4\tLoss: 0.270436\n",
      "tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.6\tLoss: 0.303300\n",
      "tensor(0.2338, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:565 0.8\tLoss: 0.233764\n",
      "\n",
      "Train Epoch: 565\tAttack_Accuracy: 4427/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 565\tmaintain_Accuracy: 7047/12800 (55%)\n",
      "\n",
      "alpha: 0.24359905977088164\n",
      "\n",
      "Test Epoch: 565\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 565\tmaintain_Accuracy: 5974/10593 (56%)\n",
      "\n",
      "tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.0\tLoss: 0.200117\n",
      "tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.2\tLoss: 0.203731\n",
      "tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.4\tLoss: 0.223549\n",
      "tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.6\tLoss: 0.237874\n",
      "tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:566 0.8\tLoss: 0.267581\n",
      "\n",
      "Test Epoch: 566\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 566\tmaintain_Accuracy: 6003/10593 (57%)\n",
      "\n",
      "tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.0\tLoss: 0.277906\n",
      "tensor(0.2406, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.2\tLoss: 0.240597\n",
      "tensor(0.2677, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.4\tLoss: 0.267719\n",
      "tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.6\tLoss: 0.267330\n",
      "tensor(0.2398, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:567 0.8\tLoss: 0.239781\n",
      "\n",
      "Test Epoch: 567\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 567\tmaintain_Accuracy: 5997/10593 (57%)\n",
      "\n",
      "tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.0\tLoss: 0.270477\n",
      "tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.2\tLoss: 0.220645\n",
      "tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.4\tLoss: 0.283952\n",
      "tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.6\tLoss: 0.261365\n",
      "tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:568 0.8\tLoss: 0.252777\n",
      "\n",
      "Test Epoch: 568\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 568\tmaintain_Accuracy: 5994/10593 (57%)\n",
      "\n",
      "tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.0\tLoss: 0.265769\n",
      "tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.2\tLoss: 0.261700\n",
      "tensor(0.2948, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.4\tLoss: 0.294791\n",
      "tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.6\tLoss: 0.304708\n",
      "tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:569 0.8\tLoss: 0.232684\n",
      "\n",
      "Test Epoch: 569\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 569\tmaintain_Accuracy: 5978/10593 (56%)\n",
      "\n",
      "tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.0\tLoss: 0.272594\n",
      "tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.2\tLoss: 0.252068\n",
      "tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.4\tLoss: 0.287742\n",
      "tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.6\tLoss: 0.223255\n",
      "tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:570 0.8\tLoss: 0.233487\n",
      "\n",
      "Train Epoch: 570\tAttack_Accuracy: 4335/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 570\tmaintain_Accuracy: 7093/12800 (55%)\n",
      "\n",
      "alpha: 0.48553502984879965\n",
      "\n",
      "Test Epoch: 570\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 570\tmaintain_Accuracy: 5981/10593 (56%)\n",
      "\n",
      "tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.0\tLoss: 0.222659\n",
      "tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.2\tLoss: 0.273133\n",
      "tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.4\tLoss: 0.258550\n",
      "tensor(0.2437, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.6\tLoss: 0.243659\n",
      "tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:571 0.8\tLoss: 0.225891\n",
      "\n",
      "Test Epoch: 571\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 571\tmaintain_Accuracy: 6012/10593 (57%)\n",
      "\n",
      "tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.0\tLoss: 0.245762\n",
      "tensor(0.2201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.2\tLoss: 0.220110\n",
      "tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.4\tLoss: 0.254937\n",
      "tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.6\tLoss: 0.273174\n",
      "tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:572 0.8\tLoss: 0.252525\n",
      "\n",
      "Test Epoch: 572\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 572\tmaintain_Accuracy: 6021/10593 (57%)\n",
      "\n",
      "tensor(0.2834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.0\tLoss: 0.283390\n",
      "tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.2\tLoss: 0.232645\n",
      "tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.4\tLoss: 0.288513\n",
      "tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.6\tLoss: 0.236171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:573 0.8\tLoss: 0.204508\n",
      "\n",
      "Test Epoch: 573\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 573\tmaintain_Accuracy: 5983/10593 (56%)\n",
      "\n",
      "tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.0\tLoss: 0.299038\n",
      "tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.2\tLoss: 0.223982\n",
      "tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.4\tLoss: 0.230600\n",
      "tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.6\tLoss: 0.272415\n",
      "tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:574 0.8\tLoss: 0.255137\n",
      "\n",
      "Test Epoch: 574\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 574\tmaintain_Accuracy: 5956/10593 (56%)\n",
      "\n",
      "tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.0\tLoss: 0.253416\n",
      "tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.2\tLoss: 0.255105\n",
      "tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.4\tLoss: 0.272981\n",
      "tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.6\tLoss: 0.243324\n",
      "tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:575 0.8\tLoss: 0.228764\n",
      "\n",
      "Train Epoch: 575\tAttack_Accuracy: 4458/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 575\tmaintain_Accuracy: 7143/12800 (56%)\n",
      "\n",
      "alpha: 0.5480574106376548\n",
      "\n",
      "Test Epoch: 575\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 575\tmaintain_Accuracy: 5976/10593 (56%)\n",
      "\n",
      "tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.0\tLoss: 0.260134\n",
      "tensor(0.3077, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.2\tLoss: 0.307704\n",
      "tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.4\tLoss: 0.243242\n",
      "tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.6\tLoss: 0.260859\n",
      "tensor(0.2893, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:576 0.8\tLoss: 0.289349\n",
      "\n",
      "Test Epoch: 576\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 576\tmaintain_Accuracy: 5993/10593 (57%)\n",
      "\n",
      "tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.0\tLoss: 0.247464\n",
      "tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.2\tLoss: 0.264088\n",
      "tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.4\tLoss: 0.240247\n",
      "tensor(0.2884, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.6\tLoss: 0.288420\n",
      "tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:577 0.8\tLoss: 0.227569\n",
      "\n",
      "Test Epoch: 577\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 577\tmaintain_Accuracy: 5982/10593 (56%)\n",
      "\n",
      "tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.0\tLoss: 0.250172\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.2\tLoss: 0.273434\n",
      "tensor(0.2170, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.4\tLoss: 0.217013\n",
      "tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.6\tLoss: 0.258047\n",
      "tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:578 0.8\tLoss: 0.278315\n",
      "\n",
      "Test Epoch: 578\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 578\tmaintain_Accuracy: 5973/10593 (56%)\n",
      "\n",
      "tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.0\tLoss: 0.214351\n",
      "tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.2\tLoss: 0.256057\n",
      "tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.4\tLoss: 0.213978\n",
      "tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.6\tLoss: 0.274443\n",
      "tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:579 0.8\tLoss: 0.233582\n",
      "\n",
      "Test Epoch: 579\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 579\tmaintain_Accuracy: 5967/10593 (56%)\n",
      "\n",
      "tensor(0.2682, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.0\tLoss: 0.268193\n",
      "tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.2\tLoss: 0.234453\n",
      "tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.4\tLoss: 0.262279\n",
      "tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.6\tLoss: 0.232047\n",
      "tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:580 0.8\tLoss: 0.271675\n",
      "\n",
      "Train Epoch: 580\tAttack_Accuracy: 4391/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 580\tmaintain_Accuracy: 7230/12800 (56%)\n",
      "\n",
      "alpha: 0.24672552340981568\n",
      "\n",
      "Test Epoch: 580\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 580\tmaintain_Accuracy: 5991/10593 (57%)\n",
      "\n",
      "tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.0\tLoss: 0.237836\n",
      "tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.2\tLoss: 0.237056\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.4\tLoss: 0.244982\n",
      "tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.6\tLoss: 0.247251\n",
      "tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:581 0.8\tLoss: 0.273346\n",
      "\n",
      "Test Epoch: 581\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 581\tmaintain_Accuracy: 6009/10593 (57%)\n",
      "\n",
      "tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.0\tLoss: 0.237510\n",
      "tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.2\tLoss: 0.219315\n",
      "tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.4\tLoss: 0.241289\n",
      "tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.6\tLoss: 0.271242\n",
      "tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:582 0.8\tLoss: 0.211263\n",
      "\n",
      "Test Epoch: 582\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 582\tmaintain_Accuracy: 6037/10593 (57%)\n",
      "\n",
      "tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.0\tLoss: 0.257828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.2\tLoss: 0.271640\n",
      "tensor(0.2889, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.4\tLoss: 0.288941\n",
      "tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.6\tLoss: 0.268315\n",
      "tensor(0.2558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:583 0.8\tLoss: 0.255768\n",
      "\n",
      "Test Epoch: 583\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 583\tmaintain_Accuracy: 6021/10593 (57%)\n",
      "\n",
      "tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.0\tLoss: 0.246416\n",
      "tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.2\tLoss: 0.259457\n",
      "tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.4\tLoss: 0.237876\n",
      "tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.6\tLoss: 0.221413\n",
      "tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:584 0.8\tLoss: 0.245608\n",
      "\n",
      "Test Epoch: 584\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 584\tmaintain_Accuracy: 5993/10593 (57%)\n",
      "\n",
      "tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.0\tLoss: 0.254343\n",
      "tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.2\tLoss: 0.257532\n",
      "tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.4\tLoss: 0.258697\n",
      "tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.6\tLoss: 0.217785\n",
      "tensor(0.2719, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:585 0.8\tLoss: 0.271863\n",
      "\n",
      "Train Epoch: 585\tAttack_Accuracy: 4415/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 585\tmaintain_Accuracy: 7170/12800 (56%)\n",
      "\n",
      "alpha: 0.3135984132846478\n",
      "\n",
      "Test Epoch: 585\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 585\tmaintain_Accuracy: 6037/10593 (57%)\n",
      "\n",
      "tensor(0.2783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.0\tLoss: 0.278272\n",
      "tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.2\tLoss: 0.290544\n",
      "tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.4\tLoss: 0.242941\n",
      "tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.6\tLoss: 0.242224\n",
      "tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:586 0.8\tLoss: 0.255407\n",
      "\n",
      "Test Epoch: 586\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 586\tmaintain_Accuracy: 6095/10593 (58%)\n",
      "\n",
      "tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.0\tLoss: 0.248823\n",
      "tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.2\tLoss: 0.260290\n",
      "tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.4\tLoss: 0.256470\n",
      "tensor(0.2836, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.6\tLoss: 0.283556\n",
      "tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:587 0.8\tLoss: 0.273533\n",
      "\n",
      "Test Epoch: 587\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 587\tmaintain_Accuracy: 6040/10593 (57%)\n",
      "\n",
      "tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.0\tLoss: 0.238585\n",
      "tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.2\tLoss: 0.236348\n",
      "tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.4\tLoss: 0.236237\n",
      "tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.6\tLoss: 0.299553\n",
      "tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:588 0.8\tLoss: 0.261023\n",
      "\n",
      "Test Epoch: 588\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 588\tmaintain_Accuracy: 6031/10593 (57%)\n",
      "\n",
      "tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.0\tLoss: 0.263384\n",
      "tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.2\tLoss: 0.231793\n",
      "tensor(0.2962, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.4\tLoss: 0.296214\n",
      "tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.6\tLoss: 0.250452\n",
      "tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:589 0.8\tLoss: 0.264012\n",
      "\n",
      "Test Epoch: 589\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 589\tmaintain_Accuracy: 5997/10593 (57%)\n",
      "\n",
      "tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.0\tLoss: 0.233016\n",
      "tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.2\tLoss: 0.232284\n",
      "tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.4\tLoss: 0.277715\n",
      "tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.6\tLoss: 0.277927\n",
      "tensor(0.2463, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:590 0.8\tLoss: 0.246317\n",
      "\n",
      "Train Epoch: 590\tAttack_Accuracy: 4488/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 590\tmaintain_Accuracy: 7217/12800 (56%)\n",
      "\n",
      "alpha: 0.28737105584585076\n",
      "\n",
      "Test Epoch: 590\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 590\tmaintain_Accuracy: 6026/10593 (57%)\n",
      "\n",
      "tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.0\tLoss: 0.211555\n",
      "tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.2\tLoss: 0.252587\n",
      "tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.4\tLoss: 0.250133\n",
      "tensor(0.2628, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.6\tLoss: 0.262823\n",
      "tensor(0.1936, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:591 0.8\tLoss: 0.193630\n",
      "\n",
      "Test Epoch: 591\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 591\tmaintain_Accuracy: 6035/10593 (57%)\n",
      "\n",
      "tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.0\tLoss: 0.252669\n",
      "tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.2\tLoss: 0.258716\n",
      "tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.4\tLoss: 0.235830\n",
      "tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.6\tLoss: 0.252111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:592 0.8\tLoss: 0.219443\n",
      "\n",
      "Test Epoch: 592\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 592\tmaintain_Accuracy: 6044/10593 (57%)\n",
      "\n",
      "tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.0\tLoss: 0.266160\n",
      "tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.2\tLoss: 0.291518\n",
      "tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.4\tLoss: 0.253121\n",
      "tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.6\tLoss: 0.223199\n",
      "tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:593 0.8\tLoss: 0.224067\n",
      "\n",
      "Test Epoch: 593\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 593\tmaintain_Accuracy: 5970/10593 (56%)\n",
      "\n",
      "tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.0\tLoss: 0.253150\n",
      "tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.2\tLoss: 0.280620\n",
      "tensor(0.2871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.4\tLoss: 0.287113\n",
      "tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.6\tLoss: 0.212213\n",
      "tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:594 0.8\tLoss: 0.244633\n",
      "\n",
      "Test Epoch: 594\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 594\tmaintain_Accuracy: 5994/10593 (57%)\n",
      "\n",
      "tensor(0.2260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.0\tLoss: 0.226014\n",
      "tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.2\tLoss: 0.267304\n",
      "tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.4\tLoss: 0.274489\n",
      "tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.6\tLoss: 0.253194\n",
      "tensor(0.2113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:595 0.8\tLoss: 0.211300\n",
      "\n",
      "Train Epoch: 595\tAttack_Accuracy: 4436/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 595\tmaintain_Accuracy: 7173/12800 (56%)\n",
      "\n",
      "alpha: 0.39166532584412156\n",
      "\n",
      "Test Epoch: 595\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 595\tmaintain_Accuracy: 6034/10593 (57%)\n",
      "\n",
      "tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.0\tLoss: 0.205915\n",
      "tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.2\tLoss: 0.257702\n",
      "tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.4\tLoss: 0.290127\n",
      "tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.6\tLoss: 0.223081\n",
      "tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:596 0.8\tLoss: 0.281899\n",
      "\n",
      "Test Epoch: 596\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 596\tmaintain_Accuracy: 6065/10593 (57%)\n",
      "\n",
      "tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.0\tLoss: 0.242176\n",
      "tensor(0.2811, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.2\tLoss: 0.281103\n",
      "tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.4\tLoss: 0.223501\n",
      "tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.6\tLoss: 0.270926\n",
      "tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:597 0.8\tLoss: 0.249859\n",
      "\n",
      "Test Epoch: 597\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 597\tmaintain_Accuracy: 6055/10593 (57%)\n",
      "\n",
      "tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.0\tLoss: 0.225468\n",
      "tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.2\tLoss: 0.209823\n",
      "tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.4\tLoss: 0.217196\n",
      "tensor(0.2641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.6\tLoss: 0.264063\n",
      "tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:598 0.8\tLoss: 0.271185\n",
      "\n",
      "Test Epoch: 598\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 598\tmaintain_Accuracy: 6026/10593 (57%)\n",
      "\n",
      "tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.0\tLoss: 0.236951\n",
      "tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.2\tLoss: 0.252013\n",
      "tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.4\tLoss: 0.241249\n",
      "tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.6\tLoss: 0.258641\n",
      "tensor(0.2305, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:599 0.8\tLoss: 0.230507\n",
      "\n",
      "Test Epoch: 599\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 599\tmaintain_Accuracy: 6002/10593 (57%)\n",
      "\n",
      "tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.0\tLoss: 0.226183\n",
      "tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.2\tLoss: 0.213466\n",
      "tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.4\tLoss: 0.247714\n",
      "tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.6\tLoss: 0.234831\n",
      "tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:600 0.8\tLoss: 0.276891\n",
      "\n",
      "Train Epoch: 600\tAttack_Accuracy: 4430/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 600\tmaintain_Accuracy: 7109/12800 (56%)\n",
      "\n",
      "alpha: 0.5069606433828749\n",
      "\n",
      "Test Epoch: 600\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 600\tmaintain_Accuracy: 6011/10593 (57%)\n",
      "\n",
      "tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.0\tLoss: 0.281038\n",
      "tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.2\tLoss: 0.235933\n",
      "tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.4\tLoss: 0.256364\n",
      "tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.6\tLoss: 0.238168\n",
      "tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:601 0.8\tLoss: 0.262326\n",
      "\n",
      "Test Epoch: 601\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 601\tmaintain_Accuracy: 6018/10593 (57%)\n",
      "\n",
      "tensor(0.2875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.0\tLoss: 0.287500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.2\tLoss: 0.255987\n",
      "tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.4\tLoss: 0.261291\n",
      "tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.6\tLoss: 0.236252\n",
      "tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:602 0.8\tLoss: 0.265347\n",
      "\n",
      "Test Epoch: 602\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 602\tmaintain_Accuracy: 6029/10593 (57%)\n",
      "\n",
      "tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.0\tLoss: 0.239011\n",
      "tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.2\tLoss: 0.268150\n",
      "tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.4\tLoss: 0.288555\n",
      "tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.6\tLoss: 0.276962\n",
      "tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:603 0.8\tLoss: 0.229190\n",
      "\n",
      "Test Epoch: 603\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 603\tmaintain_Accuracy: 6021/10593 (57%)\n",
      "\n",
      "tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.0\tLoss: 0.248316\n",
      "tensor(0.2756, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.2\tLoss: 0.275604\n",
      "tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.4\tLoss: 0.281948\n",
      "tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.6\tLoss: 0.271788\n",
      "tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:604 0.8\tLoss: 0.252033\n",
      "\n",
      "Test Epoch: 604\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 604\tmaintain_Accuracy: 6046/10593 (57%)\n",
      "\n",
      "tensor(0.2782, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.0\tLoss: 0.278238\n",
      "tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.2\tLoss: 0.205196\n",
      "tensor(0.2202, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.4\tLoss: 0.220193\n",
      "tensor(0.2224, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.6\tLoss: 0.222417\n",
      "tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:605 0.8\tLoss: 0.233000\n",
      "\n",
      "Train Epoch: 605\tAttack_Accuracy: 4428/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 605\tmaintain_Accuracy: 7204/12800 (56%)\n",
      "\n",
      "alpha: 0.4687801774165445\n",
      "\n",
      "Test Epoch: 605\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 605\tmaintain_Accuracy: 6052/10593 (57%)\n",
      "\n",
      "tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.0\tLoss: 0.178462\n",
      "tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.2\tLoss: 0.256305\n",
      "tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.4\tLoss: 0.197971\n",
      "tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.6\tLoss: 0.224137\n",
      "tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:606 0.8\tLoss: 0.254447\n",
      "\n",
      "Test Epoch: 606\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 606\tmaintain_Accuracy: 6051/10593 (57%)\n",
      "\n",
      "tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.0\tLoss: 0.251994\n",
      "tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.2\tLoss: 0.237656\n",
      "tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.4\tLoss: 0.216048\n",
      "tensor(0.2699, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.6\tLoss: 0.269881\n",
      "tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:607 0.8\tLoss: 0.291158\n",
      "\n",
      "Test Epoch: 607\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 607\tmaintain_Accuracy: 6050/10593 (57%)\n",
      "\n",
      "tensor(0.2220, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.0\tLoss: 0.221988\n",
      "tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.2\tLoss: 0.237508\n",
      "tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.4\tLoss: 0.241718\n",
      "tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.6\tLoss: 0.236894\n",
      "tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:608 0.8\tLoss: 0.257651\n",
      "\n",
      "Test Epoch: 608\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 608\tmaintain_Accuracy: 6038/10593 (57%)\n",
      "\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.0\tLoss: 0.273393\n",
      "tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.2\tLoss: 0.257289\n",
      "tensor(0.2680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.4\tLoss: 0.267987\n",
      "tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.6\tLoss: 0.245537\n",
      "tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:609 0.8\tLoss: 0.208298\n",
      "\n",
      "Test Epoch: 609\tAttack_Accuracy: 310/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 609\tmaintain_Accuracy: 6022/10593 (57%)\n",
      "\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.0\tLoss: 0.253859\n",
      "tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.2\tLoss: 0.225356\n",
      "tensor(0.2537, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.4\tLoss: 0.253669\n",
      "tensor(0.2544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.6\tLoss: 0.254425\n",
      "tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:610 0.8\tLoss: 0.251356\n",
      "\n",
      "Train Epoch: 610\tAttack_Accuracy: 4455/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 610\tmaintain_Accuracy: 7193/12800 (56%)\n",
      "\n",
      "alpha: 0.3594566641467046\n",
      "\n",
      "Test Epoch: 610\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 610\tmaintain_Accuracy: 6063/10593 (57%)\n",
      "\n",
      "tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.0\tLoss: 0.253800\n",
      "tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.2\tLoss: 0.245906\n",
      "tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.4\tLoss: 0.202270\n",
      "tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.6\tLoss: 0.248199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:611 0.8\tLoss: 0.252462\n",
      "\n",
      "Test Epoch: 611\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 611\tmaintain_Accuracy: 6072/10593 (57%)\n",
      "\n",
      "tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.0\tLoss: 0.303814\n",
      "tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.2\tLoss: 0.235608\n",
      "tensor(0.1875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.4\tLoss: 0.187545\n",
      "tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.6\tLoss: 0.223171\n",
      "tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:612 0.8\tLoss: 0.245795\n",
      "\n",
      "Test Epoch: 612\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 612\tmaintain_Accuracy: 6086/10593 (57%)\n",
      "\n",
      "tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.0\tLoss: 0.221175\n",
      "tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.2\tLoss: 0.222689\n",
      "tensor(0.2851, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.4\tLoss: 0.285109\n",
      "tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.6\tLoss: 0.269987\n",
      "tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:613 0.8\tLoss: 0.230853\n",
      "\n",
      "Test Epoch: 613\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 613\tmaintain_Accuracy: 6042/10593 (57%)\n",
      "\n",
      "tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.0\tLoss: 0.246831\n",
      "tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.2\tLoss: 0.254640\n",
      "tensor(0.2289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.4\tLoss: 0.228938\n",
      "tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.6\tLoss: 0.248043\n",
      "tensor(0.2686, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:614 0.8\tLoss: 0.268614\n",
      "\n",
      "Test Epoch: 614\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 614\tmaintain_Accuracy: 6007/10593 (57%)\n",
      "\n",
      "tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.0\tLoss: 0.295042\n",
      "tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.2\tLoss: 0.277106\n",
      "tensor(0.2273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.4\tLoss: 0.227270\n",
      "tensor(0.2730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.6\tLoss: 0.273032\n",
      "tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:615 0.8\tLoss: 0.231970\n",
      "\n",
      "Train Epoch: 615\tAttack_Accuracy: 4381/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 615\tmaintain_Accuracy: 7199/12800 (56%)\n",
      "\n",
      "alpha: 0.42246151719130853\n",
      "\n",
      "Test Epoch: 615\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 615\tmaintain_Accuracy: 6012/10593 (57%)\n",
      "\n",
      "tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.0\tLoss: 0.243771\n",
      "tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.2\tLoss: 0.258935\n",
      "tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.4\tLoss: 0.249995\n",
      "tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.6\tLoss: 0.243093\n",
      "tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:616 0.8\tLoss: 0.239920\n",
      "\n",
      "Test Epoch: 616\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 616\tmaintain_Accuracy: 6057/10593 (57%)\n",
      "\n",
      "tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.0\tLoss: 0.231010\n",
      "tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.2\tLoss: 0.231111\n",
      "tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.4\tLoss: 0.223139\n",
      "tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.6\tLoss: 0.221343\n",
      "tensor(0.2572, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:617 0.8\tLoss: 0.257206\n",
      "\n",
      "Test Epoch: 617\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 617\tmaintain_Accuracy: 6065/10593 (57%)\n",
      "\n",
      "tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.0\tLoss: 0.293711\n",
      "tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.2\tLoss: 0.237699\n",
      "tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.4\tLoss: 0.258045\n",
      "tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.6\tLoss: 0.226629\n",
      "tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:618 0.8\tLoss: 0.290478\n",
      "\n",
      "Test Epoch: 618\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 618\tmaintain_Accuracy: 6042/10593 (57%)\n",
      "\n",
      "tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.0\tLoss: 0.245677\n",
      "tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.2\tLoss: 0.241753\n",
      "tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.4\tLoss: 0.252683\n",
      "tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.6\tLoss: 0.234008\n",
      "tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:619 0.8\tLoss: 0.227081\n",
      "\n",
      "Test Epoch: 619\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 619\tmaintain_Accuracy: 6038/10593 (57%)\n",
      "\n",
      "tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.0\tLoss: 0.260289\n",
      "tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.2\tLoss: 0.246670\n",
      "tensor(0.1886, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.4\tLoss: 0.188591\n",
      "tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.6\tLoss: 0.271568\n",
      "tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:620 0.8\tLoss: 0.249699\n",
      "\n",
      "Train Epoch: 620\tAttack_Accuracy: 4359/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 620\tmaintain_Accuracy: 7238/12800 (57%)\n",
      "\n",
      "alpha: 0.2748743710641106\n",
      "\n",
      "Test Epoch: 620\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 620\tmaintain_Accuracy: 6085/10593 (57%)\n",
      "\n",
      "tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.0\tLoss: 0.257918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.2\tLoss: 0.236647\n",
      "tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.4\tLoss: 0.274959\n",
      "tensor(0.2601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.6\tLoss: 0.260106\n",
      "tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:621 0.8\tLoss: 0.276504\n",
      "\n",
      "Test Epoch: 621\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 621\tmaintain_Accuracy: 6110/10593 (58%)\n",
      "\n",
      "tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.0\tLoss: 0.231669\n",
      "tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.2\tLoss: 0.269645\n",
      "tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.4\tLoss: 0.251105\n",
      "tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.6\tLoss: 0.224796\n",
      "tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:622 0.8\tLoss: 0.216009\n",
      "\n",
      "Test Epoch: 622\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 622\tmaintain_Accuracy: 6075/10593 (57%)\n",
      "\n",
      "tensor(0.2193, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.0\tLoss: 0.219252\n",
      "tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.2\tLoss: 0.230634\n",
      "tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.4\tLoss: 0.246891\n",
      "tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.6\tLoss: 0.224024\n",
      "tensor(0.2047, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:623 0.8\tLoss: 0.204718\n",
      "\n",
      "Test Epoch: 623\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 623\tmaintain_Accuracy: 6069/10593 (57%)\n",
      "\n",
      "tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.0\tLoss: 0.232709\n",
      "tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.2\tLoss: 0.252880\n",
      "tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.4\tLoss: 0.243521\n",
      "tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.6\tLoss: 0.230842\n",
      "tensor(0.3034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:624 0.8\tLoss: 0.303428\n",
      "\n",
      "Test Epoch: 624\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 624\tmaintain_Accuracy: 6093/10593 (58%)\n",
      "\n",
      "tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.0\tLoss: 0.257017\n",
      "tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.2\tLoss: 0.201771\n",
      "tensor(0.2435, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.4\tLoss: 0.243492\n",
      "tensor(0.2656, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.6\tLoss: 0.265582\n",
      "tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:625 0.8\tLoss: 0.272876\n",
      "\n",
      "Train Epoch: 625\tAttack_Accuracy: 4328/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 625\tmaintain_Accuracy: 7299/12800 (57%)\n",
      "\n",
      "alpha: 0.4738145710216874\n",
      "\n",
      "Test Epoch: 625\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 625\tmaintain_Accuracy: 6100/10593 (58%)\n",
      "\n",
      "tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.0\tLoss: 0.275537\n",
      "tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.2\tLoss: 0.247882\n",
      "tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.4\tLoss: 0.237308\n",
      "tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.6\tLoss: 0.229581\n",
      "tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:626 0.8\tLoss: 0.239203\n",
      "\n",
      "Test Epoch: 626\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 626\tmaintain_Accuracy: 6088/10593 (57%)\n",
      "\n",
      "tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.0\tLoss: 0.229535\n",
      "tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.2\tLoss: 0.256816\n",
      "tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.4\tLoss: 0.219141\n",
      "tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.6\tLoss: 0.259938\n",
      "tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:627 0.8\tLoss: 0.223279\n",
      "\n",
      "Test Epoch: 627\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 627\tmaintain_Accuracy: 6065/10593 (57%)\n",
      "\n",
      "tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.0\tLoss: 0.248834\n",
      "tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.2\tLoss: 0.275929\n",
      "tensor(0.1969, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.4\tLoss: 0.196943\n",
      "tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.6\tLoss: 0.239933\n",
      "tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:628 0.8\tLoss: 0.271829\n",
      "\n",
      "Test Epoch: 628\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 628\tmaintain_Accuracy: 6065/10593 (57%)\n",
      "\n",
      "tensor(0.2852, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.0\tLoss: 0.285178\n",
      "tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.2\tLoss: 0.222194\n",
      "tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.4\tLoss: 0.275344\n",
      "tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.6\tLoss: 0.238870\n",
      "tensor(0.3045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:629 0.8\tLoss: 0.304482\n",
      "\n",
      "Test Epoch: 629\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 629\tmaintain_Accuracy: 6047/10593 (57%)\n",
      "\n",
      "tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.0\tLoss: 0.203849\n",
      "tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.2\tLoss: 0.206138\n",
      "tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.4\tLoss: 0.259998\n",
      "tensor(0.3004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.6\tLoss: 0.300419\n",
      "tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:630 0.8\tLoss: 0.247742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 630\tAttack_Accuracy: 4348/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 630\tmaintain_Accuracy: 7263/12800 (57%)\n",
      "\n",
      "alpha: 0.40331672612393155\n",
      "\n",
      "Test Epoch: 630\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 630\tmaintain_Accuracy: 6055/10593 (57%)\n",
      "\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.0\tLoss: 0.270699\n",
      "tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.2\tLoss: 0.218966\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.4\tLoss: 0.270748\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.6\tLoss: 0.253875\n",
      "tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:631 0.8\tLoss: 0.240454\n",
      "\n",
      "Test Epoch: 631\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 631\tmaintain_Accuracy: 6082/10593 (57%)\n",
      "\n",
      "tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.0\tLoss: 0.240192\n",
      "tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.2\tLoss: 0.267388\n",
      "tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.4\tLoss: 0.258310\n",
      "tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.6\tLoss: 0.282503\n",
      "tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:632 0.8\tLoss: 0.280191\n",
      "\n",
      "Test Epoch: 632\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 632\tmaintain_Accuracy: 6119/10593 (58%)\n",
      "\n",
      "tensor(0.2910, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.0\tLoss: 0.290968\n",
      "tensor(0.2062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.2\tLoss: 0.206244\n",
      "tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.4\tLoss: 0.237108\n",
      "tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.6\tLoss: 0.256801\n",
      "tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:633 0.8\tLoss: 0.214066\n",
      "\n",
      "Test Epoch: 633\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 633\tmaintain_Accuracy: 6134/10593 (58%)\n",
      "\n",
      "tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.0\tLoss: 0.214046\n",
      "tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.2\tLoss: 0.216360\n",
      "tensor(0.2180, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.4\tLoss: 0.218022\n",
      "tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.6\tLoss: 0.225726\n",
      "tensor(0.2223, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:634 0.8\tLoss: 0.222282\n",
      "\n",
      "Test Epoch: 634\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 634\tmaintain_Accuracy: 6085/10593 (57%)\n",
      "\n",
      "tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.0\tLoss: 0.211520\n",
      "tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.2\tLoss: 0.217825\n",
      "tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.4\tLoss: 0.194751\n",
      "tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.6\tLoss: 0.238853\n",
      "tensor(0.2007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:635 0.8\tLoss: 0.200694\n",
      "\n",
      "Train Epoch: 635\tAttack_Accuracy: 4414/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 635\tmaintain_Accuracy: 7274/12800 (57%)\n",
      "\n",
      "alpha: 0.28972937264482707\n",
      "\n",
      "Test Epoch: 635\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 635\tmaintain_Accuracy: 6033/10593 (57%)\n",
      "\n",
      "tensor(0.2594, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.0\tLoss: 0.259375\n",
      "tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.2\tLoss: 0.258938\n",
      "tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.4\tLoss: 0.210362\n",
      "tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.6\tLoss: 0.226503\n",
      "tensor(0.2814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:636 0.8\tLoss: 0.281414\n",
      "\n",
      "Test Epoch: 636\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 636\tmaintain_Accuracy: 6048/10593 (57%)\n",
      "\n",
      "tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.0\tLoss: 0.243049\n",
      "tensor(0.2052, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.2\tLoss: 0.205172\n",
      "tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.4\tLoss: 0.229925\n",
      "tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.6\tLoss: 0.230208\n",
      "tensor(0.2206, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:637 0.8\tLoss: 0.220586\n",
      "\n",
      "Test Epoch: 637\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 637\tmaintain_Accuracy: 6086/10593 (57%)\n",
      "\n",
      "tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.0\tLoss: 0.284524\n",
      "tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.2\tLoss: 0.246226\n",
      "tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.4\tLoss: 0.217210\n",
      "tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.6\tLoss: 0.267457\n",
      "tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:638 0.8\tLoss: 0.235893\n",
      "\n",
      "Test Epoch: 638\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 638\tmaintain_Accuracy: 6098/10593 (58%)\n",
      "\n",
      "tensor(0.2599, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.0\tLoss: 0.259882\n",
      "tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.2\tLoss: 0.228843\n",
      "tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.4\tLoss: 0.255329\n",
      "tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.6\tLoss: 0.255516\n",
      "tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:639 0.8\tLoss: 0.247191\n",
      "\n",
      "Test Epoch: 639\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 639\tmaintain_Accuracy: 6108/10593 (58%)\n",
      "\n",
      "tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.0\tLoss: 0.258043\n",
      "tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.2\tLoss: 0.257775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.4\tLoss: 0.236405\n",
      "tensor(0.2503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.6\tLoss: 0.250293\n",
      "tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:640 0.8\tLoss: 0.257786\n",
      "\n",
      "Train Epoch: 640\tAttack_Accuracy: 4333/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 640\tmaintain_Accuracy: 7283/12800 (57%)\n",
      "\n",
      "alpha: 0.3716210251228041\n",
      "\n",
      "Test Epoch: 640\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 640\tmaintain_Accuracy: 6121/10593 (58%)\n",
      "\n",
      "tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.0\tLoss: 0.242463\n",
      "tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.2\tLoss: 0.190801\n",
      "tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.4\tLoss: 0.250606\n",
      "tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.6\tLoss: 0.230073\n",
      "tensor(0.2631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:641 0.8\tLoss: 0.263088\n",
      "\n",
      "Test Epoch: 641\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 641\tmaintain_Accuracy: 6117/10593 (58%)\n",
      "\n",
      "tensor(0.2341, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.0\tLoss: 0.234082\n",
      "tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.2\tLoss: 0.254309\n",
      "tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.4\tLoss: 0.234505\n",
      "tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.6\tLoss: 0.213735\n",
      "tensor(0.2155, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:642 0.8\tLoss: 0.215470\n",
      "\n",
      "Test Epoch: 642\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 642\tmaintain_Accuracy: 6087/10593 (57%)\n",
      "\n",
      "tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.0\tLoss: 0.221802\n",
      "tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.2\tLoss: 0.281234\n",
      "tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.4\tLoss: 0.250406\n",
      "tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.6\tLoss: 0.250201\n",
      "tensor(0.2473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:643 0.8\tLoss: 0.247321\n",
      "\n",
      "Test Epoch: 643\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 643\tmaintain_Accuracy: 6093/10593 (58%)\n",
      "\n",
      "tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.0\tLoss: 0.275784\n",
      "tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.2\tLoss: 0.246680\n",
      "tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.4\tLoss: 0.224183\n",
      "tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.6\tLoss: 0.226160\n",
      "tensor(0.2598, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:644 0.8\tLoss: 0.259828\n",
      "\n",
      "Test Epoch: 644\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 644\tmaintain_Accuracy: 6090/10593 (57%)\n",
      "\n",
      "tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.0\tLoss: 0.224569\n",
      "tensor(0.2365, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.2\tLoss: 0.236515\n",
      "tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.4\tLoss: 0.274743\n",
      "tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.6\tLoss: 0.268898\n",
      "tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:645 0.8\tLoss: 0.246162\n",
      "\n",
      "Train Epoch: 645\tAttack_Accuracy: 4405/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 645\tmaintain_Accuracy: 7221/12800 (56%)\n",
      "\n",
      "alpha: 0.5528939214696383\n",
      "\n",
      "Test Epoch: 645\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 645\tmaintain_Accuracy: 6090/10593 (57%)\n",
      "\n",
      "tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.0\tLoss: 0.259289\n",
      "tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.2\tLoss: 0.258897\n",
      "tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.4\tLoss: 0.211439\n",
      "tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.6\tLoss: 0.248106\n",
      "tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:646 0.8\tLoss: 0.262554\n",
      "\n",
      "Test Epoch: 646\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 646\tmaintain_Accuracy: 6102/10593 (58%)\n",
      "\n",
      "tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.0\tLoss: 0.231435\n",
      "tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.2\tLoss: 0.213870\n",
      "tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.4\tLoss: 0.254925\n",
      "tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.6\tLoss: 0.205619\n",
      "tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:647 0.8\tLoss: 0.232818\n",
      "\n",
      "Test Epoch: 647\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 647\tmaintain_Accuracy: 6075/10593 (57%)\n",
      "\n",
      "tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.0\tLoss: 0.276319\n",
      "tensor(0.2051, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.2\tLoss: 0.205085\n",
      "tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.4\tLoss: 0.233875\n",
      "tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.6\tLoss: 0.249671\n",
      "tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:648 0.8\tLoss: 0.225619\n",
      "\n",
      "Test Epoch: 648\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 648\tmaintain_Accuracy: 6067/10593 (57%)\n",
      "\n",
      "tensor(0.2250, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.0\tLoss: 0.225026\n",
      "tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.2\tLoss: 0.228022\n",
      "tensor(0.2393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.4\tLoss: 0.239344\n",
      "tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.6\tLoss: 0.216505\n",
      "tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:649 0.8\tLoss: 0.247696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 649\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 649\tmaintain_Accuracy: 6090/10593 (57%)\n",
      "\n",
      "tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.0\tLoss: 0.244429\n",
      "tensor(0.2156, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.2\tLoss: 0.215613\n",
      "tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.4\tLoss: 0.205885\n",
      "tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.6\tLoss: 0.237809\n",
      "tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:650 0.8\tLoss: 0.206766\n",
      "\n",
      "Train Epoch: 650\tAttack_Accuracy: 4415/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 650\tmaintain_Accuracy: 7294/12800 (57%)\n",
      "\n",
      "alpha: 0.4601684599387092\n",
      "\n",
      "Test Epoch: 650\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 650\tmaintain_Accuracy: 6093/10593 (58%)\n",
      "\n",
      "tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.0\tLoss: 0.209415\n",
      "tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.2\tLoss: 0.255209\n",
      "tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.4\tLoss: 0.225258\n",
      "tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.6\tLoss: 0.275902\n",
      "tensor(0.2512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:651 0.8\tLoss: 0.251228\n",
      "\n",
      "Test Epoch: 651\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 651\tmaintain_Accuracy: 6063/10593 (57%)\n",
      "\n",
      "tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.0\tLoss: 0.265314\n",
      "tensor(0.2432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.2\tLoss: 0.243204\n",
      "tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.4\tLoss: 0.249600\n",
      "tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.6\tLoss: 0.201022\n",
      "tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:652 0.8\tLoss: 0.211117\n",
      "\n",
      "Test Epoch: 652\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 652\tmaintain_Accuracy: 6048/10593 (57%)\n",
      "\n",
      "tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.0\tLoss: 0.251670\n",
      "tensor(0.3005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.2\tLoss: 0.300537\n",
      "tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.4\tLoss: 0.263377\n",
      "tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.6\tLoss: 0.260719\n",
      "tensor(0.3032, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:653 0.8\tLoss: 0.303172\n",
      "\n",
      "Test Epoch: 653\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 653\tmaintain_Accuracy: 6047/10593 (57%)\n",
      "\n",
      "tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.0\tLoss: 0.224782\n",
      "tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.2\tLoss: 0.255493\n",
      "tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.4\tLoss: 0.225283\n",
      "tensor(0.2241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.6\tLoss: 0.224090\n",
      "tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:654 0.8\tLoss: 0.267006\n",
      "\n",
      "Test Epoch: 654\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 654\tmaintain_Accuracy: 6052/10593 (57%)\n",
      "\n",
      "tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.0\tLoss: 0.236148\n",
      "tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.2\tLoss: 0.254597\n",
      "tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.4\tLoss: 0.250553\n",
      "tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.6\tLoss: 0.280625\n",
      "tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:655 0.8\tLoss: 0.236730\n",
      "\n",
      "Train Epoch: 655\tAttack_Accuracy: 4448/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 655\tmaintain_Accuracy: 7252/12800 (57%)\n",
      "\n",
      "alpha: 0.5434952542846381\n",
      "\n",
      "Test Epoch: 655\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 655\tmaintain_Accuracy: 6068/10593 (57%)\n",
      "\n",
      "tensor(0.2166, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.0\tLoss: 0.216614\n",
      "tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.2\tLoss: 0.262696\n",
      "tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.4\tLoss: 0.220654\n",
      "tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.6\tLoss: 0.232413\n",
      "tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:656 0.8\tLoss: 0.285770\n",
      "\n",
      "Test Epoch: 656\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 656\tmaintain_Accuracy: 6062/10593 (57%)\n",
      "\n",
      "tensor(0.2111, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.0\tLoss: 0.211143\n",
      "tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.2\tLoss: 0.198595\n",
      "tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.4\tLoss: 0.233603\n",
      "tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.6\tLoss: 0.215864\n",
      "tensor(0.2232, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:657 0.8\tLoss: 0.223189\n",
      "\n",
      "Test Epoch: 657\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 657\tmaintain_Accuracy: 6056/10593 (57%)\n",
      "\n",
      "tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.0\tLoss: 0.199911\n",
      "tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.2\tLoss: 0.291286\n",
      "tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.4\tLoss: 0.250098\n",
      "tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.6\tLoss: 0.273289\n",
      "tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:658 0.8\tLoss: 0.222853\n",
      "\n",
      "Test Epoch: 658\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 658\tmaintain_Accuracy: 6051/10593 (57%)\n",
      "\n",
      "tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.0\tLoss: 0.240499\n",
      "tensor(0.1940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.2\tLoss: 0.193950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.4\tLoss: 0.300906\n",
      "tensor(0.2485, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.6\tLoss: 0.248523\n",
      "tensor(0.2712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:659 0.8\tLoss: 0.271163\n",
      "\n",
      "Test Epoch: 659\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 659\tmaintain_Accuracy: 6050/10593 (57%)\n",
      "\n",
      "tensor(0.2198, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.0\tLoss: 0.219786\n",
      "tensor(0.2238, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.2\tLoss: 0.223833\n",
      "tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.4\tLoss: 0.221663\n",
      "tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.6\tLoss: 0.259290\n",
      "tensor(0.2139, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:660 0.8\tLoss: 0.213882\n",
      "\n",
      "Train Epoch: 660\tAttack_Accuracy: 4347/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 660\tmaintain_Accuracy: 7269/12800 (57%)\n",
      "\n",
      "alpha: 0.4713762110996116\n",
      "\n",
      "Test Epoch: 660\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 660\tmaintain_Accuracy: 6090/10593 (57%)\n",
      "\n",
      "tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.0\tLoss: 0.235496\n",
      "tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.2\tLoss: 0.230360\n",
      "tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.4\tLoss: 0.274483\n",
      "tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.6\tLoss: 0.293417\n",
      "tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:661 0.8\tLoss: 0.257675\n",
      "\n",
      "Test Epoch: 661\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 661\tmaintain_Accuracy: 6089/10593 (57%)\n",
      "\n",
      "tensor(0.2427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.0\tLoss: 0.242681\n",
      "tensor(0.2097, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.2\tLoss: 0.209722\n",
      "tensor(0.2872, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.4\tLoss: 0.287230\n",
      "tensor(0.2322, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.6\tLoss: 0.232237\n",
      "tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:662 0.8\tLoss: 0.256739\n",
      "\n",
      "Test Epoch: 662\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 662\tmaintain_Accuracy: 6117/10593 (58%)\n",
      "\n",
      "tensor(0.2655, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.0\tLoss: 0.265461\n",
      "tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.2\tLoss: 0.220912\n",
      "tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.4\tLoss: 0.271806\n",
      "tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.6\tLoss: 0.247081\n",
      "tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:663 0.8\tLoss: 0.220437\n",
      "\n",
      "Test Epoch: 663\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 663\tmaintain_Accuracy: 6090/10593 (57%)\n",
      "\n",
      "tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.0\tLoss: 0.289431\n",
      "tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.2\tLoss: 0.273703\n",
      "tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.4\tLoss: 0.220908\n",
      "tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.6\tLoss: 0.237551\n",
      "tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:664 0.8\tLoss: 0.221723\n",
      "\n",
      "Test Epoch: 664\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 664\tmaintain_Accuracy: 6053/10593 (57%)\n",
      "\n",
      "tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.0\tLoss: 0.209488\n",
      "tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.2\tLoss: 0.246113\n",
      "tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.4\tLoss: 0.237419\n",
      "tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.6\tLoss: 0.232097\n",
      "tensor(0.2677, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:665 0.8\tLoss: 0.267706\n",
      "\n",
      "Train Epoch: 665\tAttack_Accuracy: 4471/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 665\tmaintain_Accuracy: 7210/12800 (56%)\n",
      "\n",
      "alpha: 0.32873715039613244\n",
      "\n",
      "Test Epoch: 665\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 665\tmaintain_Accuracy: 6031/10593 (57%)\n",
      "\n",
      "tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.0\tLoss: 0.267807\n",
      "tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.2\tLoss: 0.275058\n",
      "tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.4\tLoss: 0.236270\n",
      "tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.6\tLoss: 0.293271\n",
      "tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:666 0.8\tLoss: 0.274045\n",
      "\n",
      "Test Epoch: 666\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 666\tmaintain_Accuracy: 6073/10593 (57%)\n",
      "\n",
      "tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.0\tLoss: 0.285861\n",
      "tensor(0.2373, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.2\tLoss: 0.237328\n",
      "tensor(0.2308, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.4\tLoss: 0.230841\n",
      "tensor(0.2998, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.6\tLoss: 0.299833\n",
      "tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:667 0.8\tLoss: 0.242262\n",
      "\n",
      "Test Epoch: 667\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 667\tmaintain_Accuracy: 6087/10593 (57%)\n",
      "\n",
      "tensor(0.2562, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.0\tLoss: 0.256222\n",
      "tensor(0.2045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.2\tLoss: 0.204528\n",
      "tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.4\tLoss: 0.246148\n",
      "tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.6\tLoss: 0.226640\n",
      "tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:668 0.8\tLoss: 0.284228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 668\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 668\tmaintain_Accuracy: 6117/10593 (58%)\n",
      "\n",
      "tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.0\tLoss: 0.212220\n",
      "tensor(0.2758, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.2\tLoss: 0.275768\n",
      "tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.4\tLoss: 0.278824\n",
      "tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.6\tLoss: 0.256949\n",
      "tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:669 0.8\tLoss: 0.250231\n",
      "\n",
      "Test Epoch: 669\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 669\tmaintain_Accuracy: 6108/10593 (58%)\n",
      "\n",
      "tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.0\tLoss: 0.267142\n",
      "tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.2\tLoss: 0.221429\n",
      "tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.4\tLoss: 0.251859\n",
      "tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.6\tLoss: 0.275440\n",
      "tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:670 0.8\tLoss: 0.227416\n",
      "\n",
      "Train Epoch: 670\tAttack_Accuracy: 4393/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 670\tmaintain_Accuracy: 7302/12800 (57%)\n",
      "\n",
      "alpha: 0.6238403511957998\n",
      "\n",
      "Test Epoch: 670\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 670\tmaintain_Accuracy: 6099/10593 (58%)\n",
      "\n",
      "tensor(0.2640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.0\tLoss: 0.263962\n",
      "tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.2\tLoss: 0.246387\n",
      "tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.4\tLoss: 0.286778\n",
      "tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.6\tLoss: 0.244080\n",
      "tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:671 0.8\tLoss: 0.233527\n",
      "\n",
      "Test Epoch: 671\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 671\tmaintain_Accuracy: 6079/10593 (57%)\n",
      "\n",
      "tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.0\tLoss: 0.243647\n",
      "tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.2\tLoss: 0.255183\n",
      "tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.4\tLoss: 0.245277\n",
      "tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.6\tLoss: 0.229540\n",
      "tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:672 0.8\tLoss: 0.263723\n",
      "\n",
      "Test Epoch: 672\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 672\tmaintain_Accuracy: 6079/10593 (57%)\n",
      "\n",
      "tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.0\tLoss: 0.280353\n",
      "tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.2\tLoss: 0.222998\n",
      "tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.4\tLoss: 0.256411\n",
      "tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.6\tLoss: 0.209019\n",
      "tensor(0.1878, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:673 0.8\tLoss: 0.187835\n",
      "\n",
      "Test Epoch: 673\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 673\tmaintain_Accuracy: 6102/10593 (58%)\n",
      "\n",
      "tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.0\tLoss: 0.267173\n",
      "tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.2\tLoss: 0.193704\n",
      "tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.4\tLoss: 0.229354\n",
      "tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.6\tLoss: 0.223964\n",
      "tensor(0.1988, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:674 0.8\tLoss: 0.198845\n",
      "\n",
      "Test Epoch: 674\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 674\tmaintain_Accuracy: 6087/10593 (57%)\n",
      "\n",
      "tensor(0.2108, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.0\tLoss: 0.210790\n",
      "tensor(0.2168, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.2\tLoss: 0.216819\n",
      "tensor(0.2487, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.4\tLoss: 0.248675\n",
      "tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.6\tLoss: 0.215701\n",
      "tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:675 0.8\tLoss: 0.234990\n",
      "\n",
      "Train Epoch: 675\tAttack_Accuracy: 4426/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 675\tmaintain_Accuracy: 7235/12800 (57%)\n",
      "\n",
      "alpha: 0.5628011177417265\n",
      "\n",
      "Test Epoch: 675\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 675\tmaintain_Accuracy: 6043/10593 (57%)\n",
      "\n",
      "tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.0\tLoss: 0.283922\n",
      "tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.2\tLoss: 0.230140\n",
      "tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.4\tLoss: 0.206933\n",
      "tensor(0.2710, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.6\tLoss: 0.270961\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:676 0.8\tLoss: 0.244998\n",
      "\n",
      "Test Epoch: 676\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 676\tmaintain_Accuracy: 6059/10593 (57%)\n",
      "\n",
      "tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.0\tLoss: 0.240311\n",
      "tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.2\tLoss: 0.231258\n",
      "tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.4\tLoss: 0.282657\n",
      "tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.6\tLoss: 0.243775\n",
      "tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:677 0.8\tLoss: 0.179788\n",
      "\n",
      "Test Epoch: 677\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 677\tmaintain_Accuracy: 6071/10593 (57%)\n",
      "\n",
      "tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.0\tLoss: 0.198382\n",
      "tensor(0.1932, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.2\tLoss: 0.193187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.4\tLoss: 0.265724\n",
      "tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.6\tLoss: 0.235962\n",
      "tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:678 0.8\tLoss: 0.268472\n",
      "\n",
      "Test Epoch: 678\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 678\tmaintain_Accuracy: 6081/10593 (57%)\n",
      "\n",
      "tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.0\tLoss: 0.203887\n",
      "tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.2\tLoss: 0.225109\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.4\tLoss: 0.270742\n",
      "tensor(0.2190, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.6\tLoss: 0.219034\n",
      "tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:679 0.8\tLoss: 0.222544\n",
      "\n",
      "Test Epoch: 679\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 679\tmaintain_Accuracy: 6085/10593 (57%)\n",
      "\n",
      "tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.0\tLoss: 0.215895\n",
      "tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.2\tLoss: 0.230198\n",
      "tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.4\tLoss: 0.216937\n",
      "tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.6\tLoss: 0.237656\n",
      "tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:680 0.8\tLoss: 0.251029\n",
      "\n",
      "Train Epoch: 680\tAttack_Accuracy: 4408/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 680\tmaintain_Accuracy: 7322/12800 (57%)\n",
      "\n",
      "alpha: 0.6580342791752688\n",
      "\n",
      "Test Epoch: 680\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 680\tmaintain_Accuracy: 6068/10593 (57%)\n",
      "\n",
      "tensor(0.2183, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.0\tLoss: 0.218277\n",
      "tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.2\tLoss: 0.236663\n",
      "tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.4\tLoss: 0.227017\n",
      "tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.6\tLoss: 0.233486\n",
      "tensor(0.2887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:681 0.8\tLoss: 0.288740\n",
      "\n",
      "Test Epoch: 681\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 681\tmaintain_Accuracy: 6071/10593 (57%)\n",
      "\n",
      "tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.0\tLoss: 0.204575\n",
      "tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.2\tLoss: 0.244352\n",
      "tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.4\tLoss: 0.243970\n",
      "tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.6\tLoss: 0.204891\n",
      "tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:682 0.8\tLoss: 0.223628\n",
      "\n",
      "Test Epoch: 682\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 682\tmaintain_Accuracy: 6089/10593 (57%)\n",
      "\n",
      "tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.0\tLoss: 0.233414\n",
      "tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.2\tLoss: 0.241534\n",
      "tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.4\tLoss: 0.281859\n",
      "tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.6\tLoss: 0.251841\n",
      "tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:683 0.8\tLoss: 0.261909\n",
      "\n",
      "Test Epoch: 683\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 683\tmaintain_Accuracy: 6091/10593 (58%)\n",
      "\n",
      "tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.0\tLoss: 0.245138\n",
      "tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.2\tLoss: 0.287835\n",
      "tensor(0.2164, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.4\tLoss: 0.216412\n",
      "tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.6\tLoss: 0.209813\n",
      "tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:684 0.8\tLoss: 0.244414\n",
      "\n",
      "Test Epoch: 684\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 684\tmaintain_Accuracy: 6064/10593 (57%)\n",
      "\n",
      "tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.0\tLoss: 0.283917\n",
      "tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.2\tLoss: 0.202020\n",
      "tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.4\tLoss: 0.245945\n",
      "tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.6\tLoss: 0.220946\n",
      "tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:685 0.8\tLoss: 0.280007\n",
      "\n",
      "Train Epoch: 685\tAttack_Accuracy: 4437/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 685\tmaintain_Accuracy: 7195/12800 (56%)\n",
      "\n",
      "alpha: 0.3911618958143709\n",
      "\n",
      "Test Epoch: 685\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 685\tmaintain_Accuracy: 6070/10593 (57%)\n",
      "\n",
      "tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.0\tLoss: 0.268264\n",
      "tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.2\tLoss: 0.256599\n",
      "tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.4\tLoss: 0.262466\n",
      "tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.6\tLoss: 0.261206\n",
      "tensor(0.2488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:686 0.8\tLoss: 0.248752\n",
      "\n",
      "Test Epoch: 686\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 686\tmaintain_Accuracy: 6117/10593 (58%)\n",
      "\n",
      "tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.0\tLoss: 0.247762\n",
      "tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.2\tLoss: 0.244063\n",
      "tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.4\tLoss: 0.255163\n",
      "tensor(0.2827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.6\tLoss: 0.282652\n",
      "tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:687 0.8\tLoss: 0.215906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 687\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 687\tmaintain_Accuracy: 6112/10593 (58%)\n",
      "\n",
      "tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.0\tLoss: 0.268408\n",
      "tensor(0.2074, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.2\tLoss: 0.207355\n",
      "tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.4\tLoss: 0.249654\n",
      "tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.6\tLoss: 0.245322\n",
      "tensor(0.2263, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:688 0.8\tLoss: 0.226342\n",
      "\n",
      "Test Epoch: 688\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 688\tmaintain_Accuracy: 6110/10593 (58%)\n",
      "\n",
      "tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.0\tLoss: 0.216749\n",
      "tensor(0.1866, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.2\tLoss: 0.186604\n",
      "tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.4\tLoss: 0.254022\n",
      "tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.6\tLoss: 0.255258\n",
      "tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:689 0.8\tLoss: 0.218937\n",
      "\n",
      "Test Epoch: 689\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 689\tmaintain_Accuracy: 6080/10593 (57%)\n",
      "\n",
      "tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.0\tLoss: 0.203406\n",
      "tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.2\tLoss: 0.239001\n",
      "tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.4\tLoss: 0.221002\n",
      "tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.6\tLoss: 0.222591\n",
      "tensor(0.2707, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:690 0.8\tLoss: 0.270672\n",
      "\n",
      "Train Epoch: 690\tAttack_Accuracy: 4422/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 690\tmaintain_Accuracy: 7129/12800 (56%)\n",
      "\n",
      "alpha: 0.41317998989743693\n",
      "\n",
      "Test Epoch: 690\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 690\tmaintain_Accuracy: 6042/10593 (57%)\n",
      "\n",
      "tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.0\tLoss: 0.269656\n",
      "tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.2\tLoss: 0.269499\n",
      "tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.4\tLoss: 0.239185\n",
      "tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.6\tLoss: 0.238459\n",
      "tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:691 0.8\tLoss: 0.242878\n",
      "\n",
      "Test Epoch: 691\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 691\tmaintain_Accuracy: 6069/10593 (57%)\n",
      "\n",
      "tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.0\tLoss: 0.255867\n",
      "tensor(0.2244, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.2\tLoss: 0.224381\n",
      "tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.4\tLoss: 0.191281\n",
      "tensor(0.2969, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.6\tLoss: 0.296894\n",
      "tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:692 0.8\tLoss: 0.227387\n",
      "\n",
      "Test Epoch: 692\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 692\tmaintain_Accuracy: 6094/10593 (58%)\n",
      "\n",
      "tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.0\tLoss: 0.226644\n",
      "tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.2\tLoss: 0.221093\n",
      "tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.4\tLoss: 0.251111\n",
      "tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.6\tLoss: 0.247640\n",
      "tensor(0.2402, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:693 0.8\tLoss: 0.240167\n",
      "\n",
      "Test Epoch: 693\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 693\tmaintain_Accuracy: 6100/10593 (58%)\n",
      "\n",
      "tensor(0.2088, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.0\tLoss: 0.208796\n",
      "tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.2\tLoss: 0.257467\n",
      "tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.4\tLoss: 0.251386\n",
      "tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.6\tLoss: 0.223962\n",
      "tensor(0.2550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:694 0.8\tLoss: 0.254966\n",
      "\n",
      "Test Epoch: 694\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 694\tmaintain_Accuracy: 6073/10593 (57%)\n",
      "\n",
      "tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.0\tLoss: 0.237819\n",
      "tensor(0.2467, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.2\tLoss: 0.246665\n",
      "tensor(0.2670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.4\tLoss: 0.266977\n",
      "tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.6\tLoss: 0.242843\n",
      "tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:695 0.8\tLoss: 0.252294\n",
      "\n",
      "Train Epoch: 695\tAttack_Accuracy: 4295/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 695\tmaintain_Accuracy: 7267/12800 (57%)\n",
      "\n",
      "alpha: 0.4799572427538176\n",
      "\n",
      "Test Epoch: 695\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 695\tmaintain_Accuracy: 6066/10593 (57%)\n",
      "\n",
      "tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.0\tLoss: 0.197691\n",
      "tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.2\tLoss: 0.255922\n",
      "tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.4\tLoss: 0.251462\n",
      "tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.6\tLoss: 0.243078\n",
      "tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:696 0.8\tLoss: 0.203405\n",
      "\n",
      "Test Epoch: 696\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 696\tmaintain_Accuracy: 6053/10593 (57%)\n",
      "\n",
      "tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.0\tLoss: 0.219685\n",
      "tensor(0.2490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.2\tLoss: 0.248992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.4\tLoss: 0.219398\n",
      "tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.6\tLoss: 0.233486\n",
      "tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:697 0.8\tLoss: 0.263342\n",
      "\n",
      "Test Epoch: 697\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 697\tmaintain_Accuracy: 6065/10593 (57%)\n",
      "\n",
      "tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.0\tLoss: 0.200173\n",
      "tensor(0.2724, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.2\tLoss: 0.272408\n",
      "tensor(0.2504, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.4\tLoss: 0.250368\n",
      "tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.6\tLoss: 0.246387\n",
      "tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:698 0.8\tLoss: 0.206373\n",
      "\n",
      "Test Epoch: 698\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 698\tmaintain_Accuracy: 6085/10593 (57%)\n",
      "\n",
      "tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.0\tLoss: 0.225672\n",
      "tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.2\tLoss: 0.268678\n",
      "tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.4\tLoss: 0.242894\n",
      "tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.6\tLoss: 0.240846\n",
      "tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:699 0.8\tLoss: 0.229223\n",
      "\n",
      "Test Epoch: 699\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 699\tmaintain_Accuracy: 6096/10593 (58%)\n",
      "\n",
      "tensor(0.2570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.0\tLoss: 0.257013\n",
      "tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.2\tLoss: 0.228525\n",
      "tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.4\tLoss: 0.198620\n",
      "tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.6\tLoss: 0.225634\n",
      "tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:700 0.8\tLoss: 0.223948\n",
      "\n",
      "Train Epoch: 700\tAttack_Accuracy: 4467/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 700\tmaintain_Accuracy: 7280/12800 (57%)\n",
      "\n",
      "alpha: 0.4768981252671776\n",
      "\n",
      "Test Epoch: 700\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 700\tmaintain_Accuracy: 6057/10593 (57%)\n",
      "\n",
      "tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.0\tLoss: 0.245149\n",
      "tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.2\tLoss: 0.237655\n",
      "tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.4\tLoss: 0.229324\n",
      "tensor(0.2393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.6\tLoss: 0.239332\n",
      "tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:701 0.8\tLoss: 0.228065\n",
      "\n",
      "Test Epoch: 701\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 701\tmaintain_Accuracy: 6045/10593 (57%)\n",
      "\n",
      "tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.0\tLoss: 0.211371\n",
      "tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.2\tLoss: 0.232545\n",
      "tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.4\tLoss: 0.212672\n",
      "tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.6\tLoss: 0.274964\n",
      "tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:702 0.8\tLoss: 0.240800\n",
      "\n",
      "Test Epoch: 702\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 702\tmaintain_Accuracy: 6047/10593 (57%)\n",
      "\n",
      "tensor(0.2311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.0\tLoss: 0.231119\n",
      "tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.2\tLoss: 0.271999\n",
      "tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.4\tLoss: 0.284885\n",
      "tensor(0.2040, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.6\tLoss: 0.203999\n",
      "tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:703 0.8\tLoss: 0.211636\n",
      "\n",
      "Test Epoch: 703\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 703\tmaintain_Accuracy: 6075/10593 (57%)\n",
      "\n",
      "tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.0\tLoss: 0.279171\n",
      "tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.2\tLoss: 0.254057\n",
      "tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.4\tLoss: 0.240837\n",
      "tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.6\tLoss: 0.267091\n",
      "tensor(0.1864, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:704 0.8\tLoss: 0.186356\n",
      "\n",
      "Test Epoch: 704\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 704\tmaintain_Accuracy: 6119/10593 (58%)\n",
      "\n",
      "tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.0\tLoss: 0.211399\n",
      "tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.2\tLoss: 0.238654\n",
      "tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.4\tLoss: 0.257071\n",
      "tensor(0.2274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.6\tLoss: 0.227368\n",
      "tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:705 0.8\tLoss: 0.222066\n",
      "\n",
      "Train Epoch: 705\tAttack_Accuracy: 4411/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 705\tmaintain_Accuracy: 7353/12800 (57%)\n",
      "\n",
      "alpha: 0.6335118312212975\n",
      "\n",
      "Test Epoch: 705\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 705\tmaintain_Accuracy: 6119/10593 (58%)\n",
      "\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.0\tLoss: 0.253905\n",
      "tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.2\tLoss: 0.295261\n",
      "tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.4\tLoss: 0.280823\n",
      "tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.6\tLoss: 0.220287\n",
      "tensor(0.2490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:706 0.8\tLoss: 0.248958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 706\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 706\tmaintain_Accuracy: 6104/10593 (58%)\n",
      "\n",
      "tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.0\tLoss: 0.271969\n",
      "tensor(0.1870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.2\tLoss: 0.186951\n",
      "tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.4\tLoss: 0.230140\n",
      "tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.6\tLoss: 0.239676\n",
      "tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:707 0.8\tLoss: 0.248624\n",
      "\n",
      "Test Epoch: 707\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 707\tmaintain_Accuracy: 6076/10593 (57%)\n",
      "\n",
      "tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.0\tLoss: 0.259994\n",
      "tensor(0.1782, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.2\tLoss: 0.178166\n",
      "tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.4\tLoss: 0.222792\n",
      "tensor(0.2208, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.6\tLoss: 0.220751\n",
      "tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:708 0.8\tLoss: 0.222628\n",
      "\n",
      "Test Epoch: 708\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 708\tmaintain_Accuracy: 6053/10593 (57%)\n",
      "\n",
      "tensor(0.2766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.0\tLoss: 0.276565\n",
      "tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.2\tLoss: 0.231437\n",
      "tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.4\tLoss: 0.248104\n",
      "tensor(0.2200, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.6\tLoss: 0.219988\n",
      "tensor(0.2287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:709 0.8\tLoss: 0.228656\n",
      "\n",
      "Test Epoch: 709\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 709\tmaintain_Accuracy: 6077/10593 (57%)\n",
      "\n",
      "tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.0\tLoss: 0.214170\n",
      "tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.2\tLoss: 0.211028\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.4\tLoss: 0.244969\n",
      "tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.6\tLoss: 0.233737\n",
      "tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:710 0.8\tLoss: 0.216531\n",
      "\n",
      "Train Epoch: 710\tAttack_Accuracy: 4408/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 710\tmaintain_Accuracy: 7324/12800 (57%)\n",
      "\n",
      "alpha: 0.433981800349721\n",
      "\n",
      "Test Epoch: 710\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 710\tmaintain_Accuracy: 6079/10593 (57%)\n",
      "\n",
      "tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.0\tLoss: 0.226905\n",
      "tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.2\tLoss: 0.233052\n",
      "tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.4\tLoss: 0.229684\n",
      "tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.6\tLoss: 0.241596\n",
      "tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:711 0.8\tLoss: 0.272311\n",
      "\n",
      "Test Epoch: 711\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 711\tmaintain_Accuracy: 6084/10593 (57%)\n",
      "\n",
      "tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.0\tLoss: 0.201752\n",
      "tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.2\tLoss: 0.233013\n",
      "tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.4\tLoss: 0.263786\n",
      "tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.6\tLoss: 0.205923\n",
      "tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:712 0.8\tLoss: 0.234704\n",
      "\n",
      "Test Epoch: 712\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 712\tmaintain_Accuracy: 6067/10593 (57%)\n",
      "\n",
      "tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.0\tLoss: 0.225549\n",
      "tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.2\tLoss: 0.228408\n",
      "tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.4\tLoss: 0.235655\n",
      "tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.6\tLoss: 0.241416\n",
      "tensor(0.2119, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:713 0.8\tLoss: 0.211920\n",
      "\n",
      "Test Epoch: 713\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 713\tmaintain_Accuracy: 6041/10593 (57%)\n",
      "\n",
      "tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.0\tLoss: 0.236152\n",
      "tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.2\tLoss: 0.250523\n",
      "tensor(0.2326, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.4\tLoss: 0.232637\n",
      "tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.6\tLoss: 0.232463\n",
      "tensor(0.2472, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:714 0.8\tLoss: 0.247237\n",
      "\n",
      "Test Epoch: 714\tAttack_Accuracy: 308/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 714\tmaintain_Accuracy: 6066/10593 (57%)\n",
      "\n",
      "tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.0\tLoss: 0.217155\n",
      "tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.2\tLoss: 0.230381\n",
      "tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.4\tLoss: 0.214830\n",
      "tensor(0.2125, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.6\tLoss: 0.212490\n",
      "tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:715 0.8\tLoss: 0.251421\n",
      "\n",
      "Train Epoch: 715\tAttack_Accuracy: 4434/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 715\tmaintain_Accuracy: 7277/12800 (57%)\n",
      "\n",
      "alpha: 0.4955930853456495\n",
      "\n",
      "Test Epoch: 715\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 715\tmaintain_Accuracy: 6097/10593 (58%)\n",
      "\n",
      "tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.0\tLoss: 0.225139\n",
      "tensor(0.2258, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.2\tLoss: 0.225805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.4\tLoss: 0.209891\n",
      "tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.6\tLoss: 0.247796\n",
      "tensor(0.2380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:716 0.8\tLoss: 0.237994\n",
      "\n",
      "Test Epoch: 716\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 716\tmaintain_Accuracy: 6138/10593 (58%)\n",
      "\n",
      "tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.0\tLoss: 0.269516\n",
      "tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.2\tLoss: 0.216138\n",
      "tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.4\tLoss: 0.222926\n",
      "tensor(0.1935, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.6\tLoss: 0.193503\n",
      "tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:717 0.8\tLoss: 0.219403\n",
      "\n",
      "Test Epoch: 717\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 717\tmaintain_Accuracy: 6128/10593 (58%)\n",
      "\n",
      "tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.0\tLoss: 0.251550\n",
      "tensor(0.2677, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.2\tLoss: 0.267672\n",
      "tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.4\tLoss: 0.241875\n",
      "tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.6\tLoss: 0.253333\n",
      "tensor(0.2586, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:718 0.8\tLoss: 0.258583\n",
      "\n",
      "Test Epoch: 718\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 718\tmaintain_Accuracy: 6106/10593 (58%)\n",
      "\n",
      "tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.0\tLoss: 0.218196\n",
      "tensor(0.2517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.2\tLoss: 0.251671\n",
      "tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.4\tLoss: 0.245696\n",
      "tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.6\tLoss: 0.244439\n",
      "tensor(0.1974, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:719 0.8\tLoss: 0.197412\n",
      "\n",
      "Test Epoch: 719\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 719\tmaintain_Accuracy: 6089/10593 (57%)\n",
      "\n",
      "tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.0\tLoss: 0.246485\n",
      "tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.2\tLoss: 0.240659\n",
      "tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.4\tLoss: 0.265437\n",
      "tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.6\tLoss: 0.258923\n",
      "tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:720 0.8\tLoss: 0.213515\n",
      "\n",
      "Train Epoch: 720\tAttack_Accuracy: 4384/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 720\tmaintain_Accuracy: 7284/12800 (57%)\n",
      "\n",
      "alpha: 0.36120108197424916\n",
      "\n",
      "Test Epoch: 720\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 720\tmaintain_Accuracy: 6103/10593 (58%)\n",
      "\n",
      "tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.0\tLoss: 0.231568\n",
      "tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.2\tLoss: 0.194428\n",
      "tensor(0.2604, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.4\tLoss: 0.260417\n",
      "tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.6\tLoss: 0.240787\n",
      "tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:721 0.8\tLoss: 0.279156\n",
      "\n",
      "Test Epoch: 721\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 721\tmaintain_Accuracy: 6095/10593 (58%)\n",
      "\n",
      "tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.0\tLoss: 0.248328\n",
      "tensor(0.2247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.2\tLoss: 0.224739\n",
      "tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.4\tLoss: 0.221109\n",
      "tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.6\tLoss: 0.207169\n",
      "tensor(0.1901, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:722 0.8\tLoss: 0.190059\n",
      "\n",
      "Test Epoch: 722\tAttack_Accuracy: 294/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 722\tmaintain_Accuracy: 6117/10593 (58%)\n",
      "\n",
      "tensor(0.2443, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.0\tLoss: 0.244298\n",
      "tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.2\tLoss: 0.242496\n",
      "tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.4\tLoss: 0.231347\n",
      "tensor(0.2685, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.6\tLoss: 0.268459\n",
      "tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:723 0.8\tLoss: 0.232968\n",
      "\n",
      "Test Epoch: 723\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 723\tmaintain_Accuracy: 6121/10593 (58%)\n",
      "\n",
      "tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.0\tLoss: 0.221422\n",
      "tensor(0.2215, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.2\tLoss: 0.221487\n",
      "tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.4\tLoss: 0.228792\n",
      "tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.6\tLoss: 0.265010\n",
      "tensor(0.2886, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:724 0.8\tLoss: 0.288648\n",
      "\n",
      "Test Epoch: 724\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 724\tmaintain_Accuracy: 6108/10593 (58%)\n",
      "\n",
      "tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.0\tLoss: 0.224919\n",
      "tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.2\tLoss: 0.241613\n",
      "tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.4\tLoss: 0.240096\n",
      "tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.6\tLoss: 0.222133\n",
      "tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:725 0.8\tLoss: 0.218432\n",
      "\n",
      "Train Epoch: 725\tAttack_Accuracy: 4420/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 725\tmaintain_Accuracy: 7230/12800 (56%)\n",
      "\n",
      "alpha: 0.3857846785961605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Epoch: 725\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 725\tmaintain_Accuracy: 6072/10593 (57%)\n",
      "\n",
      "tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.0\tLoss: 0.274731\n",
      "tensor(0.2078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.2\tLoss: 0.207791\n",
      "tensor(0.1644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.4\tLoss: 0.164449\n",
      "tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.6\tLoss: 0.229202\n",
      "tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:726 0.8\tLoss: 0.245737\n",
      "\n",
      "Test Epoch: 726\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 726\tmaintain_Accuracy: 6074/10593 (57%)\n",
      "\n",
      "tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.0\tLoss: 0.204878\n",
      "tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.2\tLoss: 0.253101\n",
      "tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.4\tLoss: 0.226066\n",
      "tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.6\tLoss: 0.255535\n",
      "tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:727 0.8\tLoss: 0.248206\n",
      "\n",
      "Test Epoch: 727\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 727\tmaintain_Accuracy: 6062/10593 (57%)\n",
      "\n",
      "tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.0\tLoss: 0.233016\n",
      "tensor(0.2226, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.2\tLoss: 0.222564\n",
      "tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.4\tLoss: 0.237764\n",
      "tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.6\tLoss: 0.239052\n",
      "tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:728 0.8\tLoss: 0.245120\n",
      "\n",
      "Test Epoch: 728\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 728\tmaintain_Accuracy: 6095/10593 (58%)\n",
      "\n",
      "tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.0\tLoss: 0.229599\n",
      "tensor(0.2665, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.2\tLoss: 0.266501\n",
      "tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.4\tLoss: 0.232870\n",
      "tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.6\tLoss: 0.237412\n",
      "tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:729 0.8\tLoss: 0.249661\n",
      "\n",
      "Test Epoch: 729\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 729\tmaintain_Accuracy: 6128/10593 (58%)\n",
      "\n",
      "tensor(0.2634, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.0\tLoss: 0.263401\n",
      "tensor(0.2597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.2\tLoss: 0.259665\n",
      "tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.4\tLoss: 0.211250\n",
      "tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.6\tLoss: 0.229388\n",
      "tensor(0.2546, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:730 0.8\tLoss: 0.254573\n",
      "\n",
      "Train Epoch: 730\tAttack_Accuracy: 4314/6400 (67%)\n",
      "\n",
      "\n",
      "Train Epoch: 730\tmaintain_Accuracy: 7342/12800 (57%)\n",
      "\n",
      "alpha: 0.35732864257065894\n",
      "\n",
      "Test Epoch: 730\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 730\tmaintain_Accuracy: 6137/10593 (58%)\n",
      "\n",
      "tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.0\tLoss: 0.242157\n",
      "tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.2\tLoss: 0.222943\n",
      "tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.4\tLoss: 0.241171\n",
      "tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.6\tLoss: 0.237522\n",
      "tensor(0.2956, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:731 0.8\tLoss: 0.295556\n",
      "\n",
      "Test Epoch: 731\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 731\tmaintain_Accuracy: 6122/10593 (58%)\n",
      "\n",
      "tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.0\tLoss: 0.210617\n",
      "tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.2\tLoss: 0.209648\n",
      "tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.4\tLoss: 0.212449\n",
      "tensor(0.2885, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.6\tLoss: 0.288533\n",
      "tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:732 0.8\tLoss: 0.263658\n",
      "\n",
      "Test Epoch: 732\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 732\tmaintain_Accuracy: 6121/10593 (58%)\n",
      "\n",
      "tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.0\tLoss: 0.213663\n",
      "tensor(0.2082, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.2\tLoss: 0.208171\n",
      "tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.4\tLoss: 0.217179\n",
      "tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.6\tLoss: 0.233309\n",
      "tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:733 0.8\tLoss: 0.225391\n",
      "\n",
      "Test Epoch: 733\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 733\tmaintain_Accuracy: 6112/10593 (58%)\n",
      "\n",
      "tensor(0.2279, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.0\tLoss: 0.227858\n",
      "tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.2\tLoss: 0.248148\n",
      "tensor(0.2079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.4\tLoss: 0.207897\n",
      "tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.6\tLoss: 0.237817\n",
      "tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:734 0.8\tLoss: 0.228239\n",
      "\n",
      "Test Epoch: 734\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 734\tmaintain_Accuracy: 6103/10593 (58%)\n",
      "\n",
      "tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.0\tLoss: 0.192864\n",
      "tensor(0.2328, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.2\tLoss: 0.232833\n",
      "tensor(0.2046, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.4\tLoss: 0.204563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.6\tLoss: 0.210333\n",
      "tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:735 0.8\tLoss: 0.251862\n",
      "\n",
      "Train Epoch: 735\tAttack_Accuracy: 4431/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 735\tmaintain_Accuracy: 7341/12800 (57%)\n",
      "\n",
      "alpha: 0.4939631380224798\n",
      "\n",
      "Test Epoch: 735\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 735\tmaintain_Accuracy: 6078/10593 (57%)\n",
      "\n",
      "tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.0\tLoss: 0.205987\n",
      "tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.2\tLoss: 0.281902\n",
      "tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.4\tLoss: 0.216022\n",
      "tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.6\tLoss: 0.249909\n",
      "tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:736 0.8\tLoss: 0.223470\n",
      "\n",
      "Test Epoch: 736\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 736\tmaintain_Accuracy: 6065/10593 (57%)\n",
      "\n",
      "tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.0\tLoss: 0.225204\n",
      "tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.2\tLoss: 0.252568\n",
      "tensor(0.3033, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.4\tLoss: 0.303288\n",
      "tensor(0.2105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.6\tLoss: 0.210490\n",
      "tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:737 0.8\tLoss: 0.241384\n",
      "\n",
      "Test Epoch: 737\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 737\tmaintain_Accuracy: 6071/10593 (57%)\n",
      "\n",
      "tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.0\tLoss: 0.261436\n",
      "tensor(0.2067, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.2\tLoss: 0.206680\n",
      "tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.4\tLoss: 0.223970\n",
      "tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.6\tLoss: 0.221584\n",
      "tensor(0.1871, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:738 0.8\tLoss: 0.187055\n",
      "\n",
      "Test Epoch: 738\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 738\tmaintain_Accuracy: 6077/10593 (57%)\n",
      "\n",
      "tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.0\tLoss: 0.242372\n",
      "tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.2\tLoss: 0.199888\n",
      "tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.4\tLoss: 0.235049\n",
      "tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.6\tLoss: 0.221640\n",
      "tensor(0.2407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:739 0.8\tLoss: 0.240702\n",
      "\n",
      "Test Epoch: 739\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 739\tmaintain_Accuracy: 6101/10593 (58%)\n",
      "\n",
      "tensor(0.2150, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.0\tLoss: 0.215014\n",
      "tensor(0.2738, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.2\tLoss: 0.273797\n",
      "tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.4\tLoss: 0.235077\n",
      "tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.6\tLoss: 0.273946\n",
      "tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:740 0.8\tLoss: 0.278757\n",
      "\n",
      "Train Epoch: 740\tAttack_Accuracy: 4398/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 740\tmaintain_Accuracy: 7219/12800 (56%)\n",
      "\n",
      "alpha: 0.6780514305153075\n",
      "\n",
      "Test Epoch: 740\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 740\tmaintain_Accuracy: 6131/10593 (58%)\n",
      "\n",
      "tensor(0.1913, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.0\tLoss: 0.191324\n",
      "tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.2\tLoss: 0.216219\n",
      "tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.4\tLoss: 0.227538\n",
      "tensor(0.2524, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.6\tLoss: 0.252415\n",
      "tensor(0.2073, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:741 0.8\tLoss: 0.207313\n",
      "\n",
      "Test Epoch: 741\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 741\tmaintain_Accuracy: 6116/10593 (58%)\n",
      "\n",
      "tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.0\tLoss: 0.233921\n",
      "tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.2\tLoss: 0.238559\n",
      "tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.4\tLoss: 0.258673\n",
      "tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.6\tLoss: 0.226784\n",
      "tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:742 0.8\tLoss: 0.284856\n",
      "\n",
      "Test Epoch: 742\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 742\tmaintain_Accuracy: 6086/10593 (57%)\n",
      "\n",
      "tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.0\tLoss: 0.240383\n",
      "tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.2\tLoss: 0.239712\n",
      "tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.4\tLoss: 0.238862\n",
      "tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.6\tLoss: 0.209806\n",
      "tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:743 0.8\tLoss: 0.247745\n",
      "\n",
      "Test Epoch: 743\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 743\tmaintain_Accuracy: 6025/10593 (57%)\n",
      "\n",
      "tensor(0.2281, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.0\tLoss: 0.228060\n",
      "tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.2\tLoss: 0.237124\n",
      "tensor(0.2284, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.4\tLoss: 0.228378\n",
      "tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.6\tLoss: 0.225270\n",
      "tensor(0.2590, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:744 0.8\tLoss: 0.258990\n",
      "\n",
      "Test Epoch: 744\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 744\tmaintain_Accuracy: 6005/10593 (57%)\n",
      "\n",
      "tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.0\tLoss: 0.258700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2318, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.2\tLoss: 0.231784\n",
      "tensor(0.2494, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.4\tLoss: 0.249448\n",
      "tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.6\tLoss: 0.244147\n",
      "tensor(0.1853, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:745 0.8\tLoss: 0.185261\n",
      "\n",
      "Train Epoch: 745\tAttack_Accuracy: 4493/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 745\tmaintain_Accuracy: 7144/12800 (56%)\n",
      "\n",
      "alpha: 0.4676099868796368\n",
      "\n",
      "Test Epoch: 745\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 745\tmaintain_Accuracy: 6040/10593 (57%)\n",
      "\n",
      "tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.0\tLoss: 0.215874\n",
      "tensor(0.2620, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.2\tLoss: 0.262017\n",
      "tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.4\tLoss: 0.227721\n",
      "tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.6\tLoss: 0.212397\n",
      "tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:746 0.8\tLoss: 0.247791\n",
      "\n",
      "Test Epoch: 746\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 746\tmaintain_Accuracy: 6066/10593 (57%)\n",
      "\n",
      "tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.0\tLoss: 0.209558\n",
      "tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.2\tLoss: 0.277182\n",
      "tensor(0.2107, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.4\tLoss: 0.210699\n",
      "tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.6\tLoss: 0.242459\n",
      "tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:747 0.8\tLoss: 0.251034\n",
      "\n",
      "Test Epoch: 747\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 747\tmaintain_Accuracy: 6078/10593 (57%)\n",
      "\n",
      "tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.0\tLoss: 0.219639\n",
      "tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.2\tLoss: 0.244551\n",
      "tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.4\tLoss: 0.254214\n",
      "tensor(0.2464, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.6\tLoss: 0.246377\n",
      "tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:748 0.8\tLoss: 0.239933\n",
      "\n",
      "Test Epoch: 748\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 748\tmaintain_Accuracy: 6077/10593 (57%)\n",
      "\n",
      "tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.0\tLoss: 0.229538\n",
      "tensor(0.2802, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.2\tLoss: 0.280236\n",
      "tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.4\tLoss: 0.233238\n",
      "tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.6\tLoss: 0.250592\n",
      "tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:749 0.8\tLoss: 0.259575\n",
      "\n",
      "Test Epoch: 749\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 749\tmaintain_Accuracy: 6071/10593 (57%)\n",
      "\n",
      "tensor(0.2717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.0\tLoss: 0.271734\n",
      "tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.2\tLoss: 0.238663\n",
      "tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.4\tLoss: 0.240762\n",
      "tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.6\tLoss: 0.236862\n",
      "tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:750 0.8\tLoss: 0.243878\n",
      "\n",
      "Train Epoch: 750\tAttack_Accuracy: 4340/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 750\tmaintain_Accuracy: 7304/12800 (57%)\n",
      "\n",
      "alpha: 0.38371920338070614\n",
      "\n",
      "Test Epoch: 750\tAttack_Accuracy: 296/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 750\tmaintain_Accuracy: 6063/10593 (57%)\n",
      "\n",
      "tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.0\tLoss: 0.255955\n",
      "tensor(0.2438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.2\tLoss: 0.243805\n",
      "tensor(0.2151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.4\tLoss: 0.215138\n",
      "tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.6\tLoss: 0.209486\n",
      "tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:751 0.8\tLoss: 0.246062\n",
      "\n",
      "Test Epoch: 751\tAttack_Accuracy: 295/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 751\tmaintain_Accuracy: 6064/10593 (57%)\n",
      "\n",
      "tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.0\tLoss: 0.230730\n",
      "tensor(0.2525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.2\tLoss: 0.252469\n",
      "tensor(0.2853, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.4\tLoss: 0.285314\n",
      "tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.6\tLoss: 0.242560\n",
      "tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:752 0.8\tLoss: 0.221428\n",
      "\n",
      "Test Epoch: 752\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 752\tmaintain_Accuracy: 6072/10593 (57%)\n",
      "\n",
      "tensor(0.2261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.0\tLoss: 0.226070\n",
      "tensor(0.1766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.2\tLoss: 0.176574\n",
      "tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.4\tLoss: 0.221277\n",
      "tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.6\tLoss: 0.255175\n",
      "tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:753 0.8\tLoss: 0.237513\n",
      "\n",
      "Test Epoch: 753\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 753\tmaintain_Accuracy: 6088/10593 (57%)\n",
      "\n",
      "tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.0\tLoss: 0.227195\n",
      "tensor(0.2668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.2\tLoss: 0.266761\n",
      "tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.4\tLoss: 0.213623\n",
      "tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.6\tLoss: 0.269768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:754 0.8\tLoss: 0.257859\n",
      "\n",
      "Test Epoch: 754\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 754\tmaintain_Accuracy: 6110/10593 (58%)\n",
      "\n",
      "tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.0\tLoss: 0.258753\n",
      "tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.2\tLoss: 0.227692\n",
      "tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.4\tLoss: 0.283306\n",
      "tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.6\tLoss: 0.234216\n",
      "tensor(0.2024, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:755 0.8\tLoss: 0.202379\n",
      "\n",
      "Train Epoch: 755\tAttack_Accuracy: 4364/6400 (68%)\n",
      "\n",
      "\n",
      "Train Epoch: 755\tmaintain_Accuracy: 7196/12800 (56%)\n",
      "\n",
      "alpha: 0.5608392282784416\n",
      "\n",
      "Test Epoch: 755\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 755\tmaintain_Accuracy: 6103/10593 (58%)\n",
      "\n",
      "tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.0\tLoss: 0.230417\n",
      "tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.2\tLoss: 0.211551\n",
      "tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.4\tLoss: 0.262430\n",
      "tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.6\tLoss: 0.210874\n",
      "tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:756 0.8\tLoss: 0.202726\n",
      "\n",
      "Test Epoch: 756\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 756\tmaintain_Accuracy: 6098/10593 (58%)\n",
      "\n",
      "tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.0\tLoss: 0.245485\n",
      "tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.2\tLoss: 0.236181\n",
      "tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.4\tLoss: 0.248593\n",
      "tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.6\tLoss: 0.247550\n",
      "tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:757 0.8\tLoss: 0.265712\n",
      "\n",
      "Test Epoch: 757\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 757\tmaintain_Accuracy: 6107/10593 (58%)\n",
      "\n",
      "tensor(0.2105, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.0\tLoss: 0.210514\n",
      "tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.2\tLoss: 0.231869\n",
      "tensor(0.2450, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.4\tLoss: 0.244987\n",
      "tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.6\tLoss: 0.215697\n",
      "tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:758 0.8\tLoss: 0.217399\n",
      "\n",
      "Test Epoch: 758\tAttack_Accuracy: 293/412 (71%)\n",
      "\n",
      "\n",
      "Test Epoch: 758\tmaintain_Accuracy: 6118/10593 (58%)\n",
      "\n",
      "tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.0\tLoss: 0.246552\n",
      "tensor(0.2393, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.2\tLoss: 0.239333\n",
      "tensor(0.2060, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.4\tLoss: 0.205988\n",
      "tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.6\tLoss: 0.252273\n",
      "tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:759 0.8\tLoss: 0.224824\n",
      "\n",
      "Test Epoch: 759\tAttack_Accuracy: 297/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 759\tmaintain_Accuracy: 6096/10593 (58%)\n",
      "\n",
      "tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.0\tLoss: 0.256525\n",
      "tensor(0.2034, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.2\tLoss: 0.203432\n",
      "tensor(0.2681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.4\tLoss: 0.268085\n",
      "tensor(0.1837, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.6\tLoss: 0.183672\n",
      "tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:760 0.8\tLoss: 0.243948\n",
      "\n",
      "Train Epoch: 760\tAttack_Accuracy: 4432/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 760\tmaintain_Accuracy: 7190/12800 (56%)\n",
      "\n",
      "alpha: 0.48139030526424803\n",
      "\n",
      "Test Epoch: 760\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 760\tmaintain_Accuracy: 6066/10593 (57%)\n",
      "\n",
      "tensor(0.2176, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.0\tLoss: 0.217626\n",
      "tensor(0.2247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.2\tLoss: 0.224654\n",
      "tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.4\tLoss: 0.242323\n",
      "tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.6\tLoss: 0.265088\n",
      "tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:761 0.8\tLoss: 0.241388\n",
      "\n",
      "Test Epoch: 761\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 761\tmaintain_Accuracy: 6054/10593 (57%)\n",
      "\n",
      "tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.0\tLoss: 0.258119\n",
      "tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.2\tLoss: 0.234029\n",
      "tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.4\tLoss: 0.205482\n",
      "tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.6\tLoss: 0.250692\n",
      "tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:762 0.8\tLoss: 0.222886\n",
      "\n",
      "Test Epoch: 762\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 762\tmaintain_Accuracy: 6069/10593 (57%)\n",
      "\n",
      "tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.0\tLoss: 0.273600\n",
      "tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.2\tLoss: 0.199665\n",
      "tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.4\tLoss: 0.253093\n",
      "tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.6\tLoss: 0.251938\n",
      "tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:763 0.8\tLoss: 0.233743\n",
      "\n",
      "Test Epoch: 763\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 763\tmaintain_Accuracy: 6097/10593 (58%)\n",
      "\n",
      "tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.0\tLoss: 0.246064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.2\tLoss: 0.223969\n",
      "tensor(0.2791, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.4\tLoss: 0.279132\n",
      "tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.6\tLoss: 0.205540\n",
      "tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:764 0.8\tLoss: 0.233357\n",
      "\n",
      "Test Epoch: 764\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 764\tmaintain_Accuracy: 6099/10593 (58%)\n",
      "\n",
      "tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.0\tLoss: 0.234321\n",
      "tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.2\tLoss: 0.221229\n",
      "tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.4\tLoss: 0.238413\n",
      "tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.6\tLoss: 0.242546\n",
      "tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:765 0.8\tLoss: 0.215672\n",
      "\n",
      "Train Epoch: 765\tAttack_Accuracy: 4484/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 765\tmaintain_Accuracy: 7321/12800 (57%)\n",
      "\n",
      "alpha: 0.4532463238804243\n",
      "\n",
      "Test Epoch: 765\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 765\tmaintain_Accuracy: 6105/10593 (58%)\n",
      "\n",
      "tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.0\tLoss: 0.203493\n",
      "tensor(0.2225, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.2\tLoss: 0.222487\n",
      "tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.4\tLoss: 0.232032\n",
      "tensor(0.2411, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.6\tLoss: 0.241055\n",
      "tensor(0.2866, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:766 0.8\tLoss: 0.286561\n",
      "\n",
      "Test Epoch: 766\tAttack_Accuracy: 298/412 (72%)\n",
      "\n",
      "\n",
      "Test Epoch: 766\tmaintain_Accuracy: 6092/10593 (58%)\n",
      "\n",
      "tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.0\tLoss: 0.235734\n",
      "tensor(0.2315, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.2\tLoss: 0.231458\n",
      "tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.4\tLoss: 0.251069\n",
      "tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.6\tLoss: 0.226774\n",
      "tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:767 0.8\tLoss: 0.248420\n",
      "\n",
      "Test Epoch: 767\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 767\tmaintain_Accuracy: 6087/10593 (57%)\n",
      "\n",
      "tensor(0.2490, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.0\tLoss: 0.248957\n",
      "tensor(0.2152, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.2\tLoss: 0.215181\n",
      "tensor(0.2383, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.4\tLoss: 0.238253\n",
      "tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.6\tLoss: 0.210232\n",
      "tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:768 0.8\tLoss: 0.216950\n",
      "\n",
      "Test Epoch: 768\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 768\tmaintain_Accuracy: 6073/10593 (57%)\n",
      "\n",
      "tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.0\tLoss: 0.252017\n",
      "tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.2\tLoss: 0.242930\n",
      "tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.4\tLoss: 0.235429\n",
      "tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.6\tLoss: 0.233022\n",
      "tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:769 0.8\tLoss: 0.214547\n",
      "\n",
      "Test Epoch: 769\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 769\tmaintain_Accuracy: 6081/10593 (57%)\n",
      "\n",
      "tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.0\tLoss: 0.217146\n",
      "tensor(0.2622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.2\tLoss: 0.262163\n",
      "tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.4\tLoss: 0.226691\n",
      "tensor(0.2790, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.6\tLoss: 0.279030\n",
      "tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:770 0.8\tLoss: 0.221401\n",
      "\n",
      "Train Epoch: 770\tAttack_Accuracy: 4402/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 770\tmaintain_Accuracy: 7163/12800 (56%)\n",
      "\n",
      "alpha: 0.3712110991152978\n",
      "\n",
      "Test Epoch: 770\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 770\tmaintain_Accuracy: 6079/10593 (57%)\n",
      "\n",
      "tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.0\tLoss: 0.215998\n",
      "tensor(0.2433, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.2\tLoss: 0.243280\n",
      "tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.4\tLoss: 0.251116\n",
      "tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.6\tLoss: 0.245944\n",
      "tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:771 0.8\tLoss: 0.259316\n",
      "\n",
      "Test Epoch: 771\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 771\tmaintain_Accuracy: 6084/10593 (57%)\n",
      "\n",
      "tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.0\tLoss: 0.219885\n",
      "tensor(0.2485, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.2\tLoss: 0.248492\n",
      "tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.4\tLoss: 0.219658\n",
      "tensor(0.2418, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.6\tLoss: 0.241849\n",
      "tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:772 0.8\tLoss: 0.183637\n",
      "\n",
      "Test Epoch: 772\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 772\tmaintain_Accuracy: 6093/10593 (58%)\n",
      "\n",
      "tensor(0.2698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.0\tLoss: 0.269839\n",
      "tensor(0.2141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.2\tLoss: 0.214110\n",
      "tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.4\tLoss: 0.246795\n",
      "tensor(0.2316, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.6\tLoss: 0.231593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:773 0.8\tLoss: 0.223590\n",
      "\n",
      "Test Epoch: 773\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 773\tmaintain_Accuracy: 6084/10593 (57%)\n",
      "\n",
      "tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.0\tLoss: 0.240067\n",
      "tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.2\tLoss: 0.252184\n",
      "tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.4\tLoss: 0.177056\n",
      "tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.6\tLoss: 0.211811\n",
      "tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:774 0.8\tLoss: 0.266653\n",
      "\n",
      "Test Epoch: 774\tAttack_Accuracy: 305/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 774\tmaintain_Accuracy: 6081/10593 (57%)\n",
      "\n",
      "tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.0\tLoss: 0.257941\n",
      "tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.2\tLoss: 0.221328\n",
      "tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.4\tLoss: 0.253053\n",
      "tensor(0.2422, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.6\tLoss: 0.242203\n",
      "tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:775 0.8\tLoss: 0.206809\n",
      "\n",
      "Train Epoch: 775\tAttack_Accuracy: 4449/6400 (70%)\n",
      "\n",
      "\n",
      "Train Epoch: 775\tmaintain_Accuracy: 7307/12800 (57%)\n",
      "\n",
      "alpha: 0.5901179404478248\n",
      "\n",
      "Test Epoch: 775\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 775\tmaintain_Accuracy: 6086/10593 (57%)\n",
      "\n",
      "tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.0\tLoss: 0.218391\n",
      "tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.2\tLoss: 0.264816\n",
      "tensor(0.2342, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.4\tLoss: 0.234248\n",
      "tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.6\tLoss: 0.202272\n",
      "tensor(0.2662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:776 0.8\tLoss: 0.266206\n",
      "\n",
      "Test Epoch: 776\tAttack_Accuracy: 300/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 776\tmaintain_Accuracy: 6076/10593 (57%)\n",
      "\n",
      "tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.0\tLoss: 0.247746\n",
      "tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.2\tLoss: 0.240813\n",
      "tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.4\tLoss: 0.257514\n",
      "tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.6\tLoss: 0.239657\n",
      "tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:777 0.8\tLoss: 0.269573\n",
      "\n",
      "Test Epoch: 777\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 777\tmaintain_Accuracy: 6069/10593 (57%)\n",
      "\n",
      "tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.0\tLoss: 0.254235\n",
      "tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.2\tLoss: 0.238399\n",
      "tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.4\tLoss: 0.192908\n",
      "tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.6\tLoss: 0.232034\n",
      "tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:778 0.8\tLoss: 0.230118\n",
      "\n",
      "Test Epoch: 778\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 778\tmaintain_Accuracy: 6033/10593 (57%)\n",
      "\n",
      "tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.0\tLoss: 0.237925\n",
      "tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.2\tLoss: 0.249063\n",
      "tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.4\tLoss: 0.234289\n",
      "tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.6\tLoss: 0.205293\n",
      "tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:779 0.8\tLoss: 0.210426\n",
      "\n",
      "Test Epoch: 779\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 779\tmaintain_Accuracy: 6027/10593 (57%)\n",
      "\n",
      "tensor(0.2366, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.0\tLoss: 0.236573\n",
      "tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.2\tLoss: 0.229762\n",
      "tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.4\tLoss: 0.241708\n",
      "tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.6\tLoss: 0.231970\n",
      "tensor(0.1845, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:780 0.8\tLoss: 0.184473\n",
      "\n",
      "Train Epoch: 780\tAttack_Accuracy: 4436/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 780\tmaintain_Accuracy: 7246/12800 (57%)\n",
      "\n",
      "alpha: 0.42448750906229954\n",
      "\n",
      "Test Epoch: 780\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 780\tmaintain_Accuracy: 6055/10593 (57%)\n",
      "\n",
      "tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.0\tLoss: 0.230061\n",
      "tensor(0.2360, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.2\tLoss: 0.235997\n",
      "tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.4\tLoss: 0.201964\n",
      "tensor(0.2117, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.6\tLoss: 0.211668\n",
      "tensor(0.2201, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:781 0.8\tLoss: 0.220111\n",
      "\n",
      "Test Epoch: 781\tAttack_Accuracy: 299/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 781\tmaintain_Accuracy: 6068/10593 (57%)\n",
      "\n",
      "tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.0\tLoss: 0.242042\n",
      "tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.2\tLoss: 0.214771\n",
      "tensor(0.2364, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.4\tLoss: 0.236381\n",
      "tensor(0.1912, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.6\tLoss: 0.191158\n",
      "tensor(0.2413, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:782 0.8\tLoss: 0.241319\n",
      "\n",
      "Test Epoch: 782\tAttack_Accuracy: 301/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 782\tmaintain_Accuracy: 6074/10593 (57%)\n",
      "\n",
      "tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.0\tLoss: 0.202653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2363, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.2\tLoss: 0.236296\n",
      "tensor(0.1783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.4\tLoss: 0.178289\n",
      "tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.6\tLoss: 0.231935\n",
      "tensor(0.2123, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:783 0.8\tLoss: 0.212321\n",
      "\n",
      "Test Epoch: 783\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 783\tmaintain_Accuracy: 6080/10593 (57%)\n",
      "\n",
      "tensor(0.2542, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.0\tLoss: 0.254186\n",
      "tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.2\tLoss: 0.239113\n",
      "tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.4\tLoss: 0.227771\n",
      "tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.6\tLoss: 0.208509\n",
      "tensor(0.2628, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:784 0.8\tLoss: 0.262757\n",
      "\n",
      "Test Epoch: 784\tAttack_Accuracy: 304/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 784\tmaintain_Accuracy: 6083/10593 (57%)\n",
      "\n",
      "tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.0\tLoss: 0.226859\n",
      "tensor(0.2235, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.2\tLoss: 0.223544\n",
      "tensor(0.1967, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.4\tLoss: 0.196706\n",
      "tensor(0.2474, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.6\tLoss: 0.247430\n",
      "tensor(0.2362, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:785 0.8\tLoss: 0.236197\n",
      "\n",
      "Train Epoch: 785\tAttack_Accuracy: 4431/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 785\tmaintain_Accuracy: 7259/12800 (57%)\n",
      "\n",
      "alpha: 0.3878942099590722\n",
      "\n",
      "Test Epoch: 785\tAttack_Accuracy: 307/412 (75%)\n",
      "\n",
      "\n",
      "Test Epoch: 785\tmaintain_Accuracy: 6083/10593 (57%)\n",
      "\n",
      "tensor(0.2080, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.0\tLoss: 0.207963\n",
      "tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.2\tLoss: 0.246639\n",
      "tensor(0.2059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.4\tLoss: 0.205909\n",
      "tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.6\tLoss: 0.260548\n",
      "tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:786 0.8\tLoss: 0.247127\n",
      "\n",
      "Test Epoch: 786\tAttack_Accuracy: 306/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 786\tmaintain_Accuracy: 6094/10593 (58%)\n",
      "\n",
      "tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.0\tLoss: 0.224040\n",
      "tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.2\tLoss: 0.216893\n",
      "tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.4\tLoss: 0.234595\n",
      "tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.6\tLoss: 0.269495\n",
      "tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:787 0.8\tLoss: 0.222806\n",
      "\n",
      "Test Epoch: 787\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 787\tmaintain_Accuracy: 6091/10593 (58%)\n",
      "\n",
      "tensor(0.2290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.0\tLoss: 0.229031\n",
      "tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.2\tLoss: 0.246071\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.4\tLoss: 0.253917\n",
      "tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.6\tLoss: 0.277393\n",
      "tensor(0.2182, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:788 0.8\tLoss: 0.218198\n",
      "\n",
      "Test Epoch: 788\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 788\tmaintain_Accuracy: 6106/10593 (58%)\n",
      "\n",
      "tensor(0.2372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.0\tLoss: 0.237157\n",
      "tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.2\tLoss: 0.220405\n",
      "tensor(0.2734, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.4\tLoss: 0.273431\n",
      "tensor(0.2350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.6\tLoss: 0.234993\n",
      "tensor(0.2729, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:789 0.8\tLoss: 0.272942\n",
      "\n",
      "Test Epoch: 789\tAttack_Accuracy: 303/412 (74%)\n",
      "\n",
      "\n",
      "Test Epoch: 789\tmaintain_Accuracy: 6108/10593 (58%)\n",
      "\n",
      "tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.0\tLoss: 0.236885\n",
      "tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.2\tLoss: 0.260859\n",
      "tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.4\tLoss: 0.254254\n",
      "tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.6\tLoss: 0.226405\n",
      "tensor(0.2319, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:790 0.8\tLoss: 0.231950\n",
      "\n",
      "Train Epoch: 790\tAttack_Accuracy: 4391/6400 (69%)\n",
      "\n",
      "\n",
      "Train Epoch: 790\tmaintain_Accuracy: 7234/12800 (57%)\n",
      "\n",
      "alpha: 0.8820608066649361\n",
      "\n",
      "Test Epoch: 790\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 790\tmaintain_Accuracy: 6092/10593 (58%)\n",
      "\n",
      "tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.0\tLoss: 0.248228\n",
      "tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.2\tLoss: 0.257594\n",
      "tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.4\tLoss: 0.225393\n",
      "tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.6\tLoss: 0.208384\n",
      "tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:791 0.8\tLoss: 0.307143\n",
      "\n",
      "Test Epoch: 791\tAttack_Accuracy: 302/412 (73%)\n",
      "\n",
      "\n",
      "Test Epoch: 791\tmaintain_Accuracy: 6085/10593 (57%)\n",
      "\n",
      "tensor(0.2321, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch:792 0.0\tLoss: 0.232135\n"
     ]
    }
   ],
   "source": [
    "#method: DTA\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "model = torch.load('model.pkl')\n",
    "\n",
    "\n",
    "log_interval = 20\n",
    "n_epoch = 800\n",
    "threshold_epoch = 1001\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "losses_t=[]\n",
    "losses_nt = []\n",
    "losses_epoch = []\n",
    "losses_t_epoch=[]\n",
    "losses_nt_epoch = []\n",
    "delta_wav = []\n",
    "delta_sum = []\n",
    "attack_ = []\n",
    "maintain_ = []\n",
    "error_ = []\n",
    "lr = 0.001\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data_size = data.size(1)\n",
    "delta = torch.rand(1,data_size, 16000)-0.5\n",
    "delta = delta.to(device)\n",
    "delta.requires_grad = True\n",
    "optimizer = optim.Adam([delta],lr = 0.0007)\n",
    "kpi = 0.5\n",
    "\n",
    "p_index = label_to_index('left').item()\n",
    "t_index = label_to_index('learn').item()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.7)  # reduce the learning after 20 epochs by a factor of 10\n",
    "\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        if epoch%threshold_epoch == 0 and epoch != 0:\n",
    "            threshold = 0.2 + (epoch // threshold_epoch  -1 ) * 0.07\n",
    "            delta_data = delta.data\n",
    "            delta_ = threshold*torch.tanh(delta)\n",
    "            delta_data = torch.arctanh(delta_ / (threshold+0.07))       \n",
    "            optimizer = optim.Adam([delta],lr = 0.001)\n",
    "            print(optimizer.state)\n",
    "        delta = train_attack(model, epoch, log_interval, threshold_epoch, delta)\n",
    "        delta_sum.append(delta.abs().mean())\n",
    "        kpi = test_attack(model, epoch,threshold_epoch, delta=delta)\n",
    "        '''\n",
    "        if epoch % 30 ==0:\n",
    "            delta.data = 0.5 * delta\n",
    "            print('delta',delta.abs().mean())\n",
    "\n",
    "            delta.requires_grad = True\n",
    "            optimizer = optim.Adam([delta],lr = 0.001)\n",
    "        '''\n",
    "\n",
    "        scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_ = time.strftime('%d_%H_%M_%S',time.localtime(time.time()))\n",
    "dir_path = os.path.join('output',time_)\n",
    "os.mkdir(os.path.join('output',time_)) \n",
    "\n",
    "print(delta)\n",
    "plt.plot(delta.squeeze().detach().to('cpu').numpy())\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Delta\")\n",
    "plt.savefig(os.path.join(dir_path,\"Delta.png\"), facecolor =\"w\" , edgecolor = \"w\") \n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(delta_sum)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Delta_Epoch\")\n",
    "plt.savefig(os.path.join(dir_path,\"Delta_Epoch.png\"), facecolor =\"w\" , edgecolor = \"w\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(losses, label='loss')\n",
    "plt.plot(losses_t, label='loss_t')\n",
    "plt.plot(losses_nt, label='loss_nt')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig(os.path.join(dir_path,\"Loss.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(losses_epoch, label='loss')\n",
    "plt.plot(losses_t_epoch, label='loss_t')\n",
    "plt.plot(losses_nt_epoch, label='loss_nt')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Loss_epoch\")\n",
    "plt.savefig(os.path.join(dir_path,\"Loss_epoch.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(delta_wav)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"attack\")\n",
    "plt.savefig(os.path.join(dir_path,\"Attack.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(attack_,label='attack')\n",
    "plt.plot(maintain_,label='maintain')\n",
    "plt.plot(error_,label='error')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"Rate\")\n",
    "plt.savefig(os.path.join(dir_path,\"Rate.png\"), facecolor =\"w\" , edgecolor = \"w\" )\n",
    "plt.show()\n",
    "plt.close()\n",
    "threshold = 0.1 + (n_epoch // threshold_epoch  -1 ) * 0.07\n",
    "\n",
    "delta_ = threshold*torch.tanh(delta)\n",
    "delta_ = delta_.to('cpu')\n",
    "delta_ = torch.squeeze(delta_,0)\n",
    "\n",
    "print(delta_)\n",
    "plt.plot(torch.squeeze(delta_,0).detach().numpy())\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Attack_Waveform\")\n",
    "plt.savefig(os.path.join(dir_path,\"Attack_Waveform.png\"), facecolor =\"w\" , edgecolor = \"w\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "torchaudio.save(os.path.join(dir_path,\"Attack.wav\"), delta_ , sample_rate=16000, channels_first=True)\n",
    "\n",
    "\n",
    "test_attack(model,0,threshold_epoch, delta=delta,wav_save = True)\n",
    "\n",
    "f = open(os.path.join(dir_path,\"Parameter_2.txt\"), \"w\")  # 打开文件\n",
    "print(\"n_epoch=\",n_epoch,file=f)\n",
    "print(\"threshold_epoch=\",threshold_epoch,file=f)\n",
    "print(\"target:origin=1:0.5\",file=f)\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attack(model,0,threshold_epoch, delta=delta,wav_save = True)\n",
    "test_attack(model,0,threshold_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(attack_train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to try with one of your own recordings of one of the labels!\n",
    "For example, using Colab, say “Go” while executing the cell below. This\n",
    "will record one second of audio and try to classify it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "----------\n",
    "\n",
    "In this tutorial, we used torchaudio to load a dataset and resample the\n",
    "signal. We have then defined a neural network that we trained to\n",
    "recognize a given command. There are also other data preprocessing\n",
    "methods, such as finding the mel frequency cepstral coefficients (MFCC),\n",
    "that can reduce the size of the dataset. This transform is also\n",
    "available in torchaudio as ``torchaudio.transforms.MFCC``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
